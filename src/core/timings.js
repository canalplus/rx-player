/**
 * Copyright 2015 CANAL+ Group
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

var { Observable } = require("canal-js-utils/rx");
var { BufferedRanges } = require("./ranges");

// time changes interval in milliseconds
var TIMINGS_SAMPLING_INTERVAL = 1000;

// time in seconds protecting live buffer to prevent ahead of time
// buffering
var LIVE_PROTECTION = 10;

// stall gap in seconds
var STALL_GAP = 0.5;
var RESUME_GAP = 5;

// seek gap in seconds
var SEEK_GAP = 2;

// waiting time differs between a "seeking" stall and
// a buffering stall
function resumeGap(stalled) {
  return (stalled.name == "seeking")
    ? STALL_GAP
    : RESUME_GAP;
}

function isEnding(gap, range, duration) {
  if (range) {
    return (duration - (gap + range.end)) <= STALL_GAP;
  } else {
    return false;
  }
}

function getEmptyTimings() {
  return {
    name: "timeupdate",
    ts: 0,
    range: null,
    gap: Infinity,
    duration: 0,
    playback: 1,
    readyState: 0,
    stalled: false,
    buffered: new BufferedRanges(),
  };
}

function getTimings(video, name) {
  var playback = video.playbackRate;
  var duration = video.duration;
  var ts = video.currentTime;
  var readyState = video.readyState;
  var buffered = new BufferedRanges(video.buffered);
  var range = buffered.getRange(ts);
  var gap = buffered.getGap(ts);
  var stalled = null;
  return {
    name,
    ts,
    range,
    gap,
    duration,
    playback,
    readyState,
    stalled,
    buffered,
  };
}

/**
 * Timings observable.
 *
 * This streams samples snapshots of player's current state:
 *   * time position
 *   * playback rate
 *   * current buffered range
 *   * gap with current buffered range ending
 *   * video duration
 *
 * In addition to sampling, this stream also reacts to "seeking" and "play"
 * events.
 *
 * Observable is shared for performance reason: reduces the number of event
 * listeners and intervals/timeouts but also limit access to <video>
 * properties and gap calculations.
 *
 * The sampling is manual instead of based on "timeupdate" to reduce the
 * number of events.
 */
function timingsSampler(video) {

  function scanTimingsSamples(prevTimings, timingEventType) {
    var currentTimings = getTimings(video, timingEventType);

    var wasStalled = prevTimings.stalled;
    var currentGap = currentTimings.gap;

    var hasStalled = (
      timingEventType != "loadedmetadata" &&
      !wasStalled &&
      !isEnding(currentGap, currentTimings.range, currentTimings.duration) &&
      (currentGap <= STALL_GAP || currentGap === Infinity)
    );

    var stalled;
    if (hasStalled) {
      stalled = {
        name: currentTimings.name,
        playback: currentTimings.playback,
      };
    }
    else if (wasStalled && currentGap < Infinity && currentGap > resumeGap(wasStalled)) {
      stalled = null;
    }
    else {
      stalled = wasStalled;
    }

    currentTimings.stalled = stalled;
    return currentTimings;
  }

  return Observable.create((obs) => {
    var prevTimings = getTimings(video, "init");

    function emitSample(evt) {
      var timingEventType = evt && evt.type || "timeupdate";
      prevTimings = scanTimingsSamples(prevTimings, timingEventType);
      obs.next(prevTimings);
    }

    var samplerInterval = setInterval(emitSample, TIMINGS_SAMPLING_INTERVAL);

    video.addEventListener("play", emitSample);
    video.addEventListener("progress", emitSample);
    video.addEventListener("seeking", emitSample);
    video.addEventListener("seeked", emitSample);
    video.addEventListener("loadedmetadata", emitSample);

    obs.next(prevTimings);

    return () => {
      clearInterval(samplerInterval);

      video.removeEventListener("play", emitSample);
      video.removeEventListener("progress", emitSample);
      video.removeEventListener("seeking", emitSample);
      video.removeEventListener("seeked", emitSample);
      video.removeEventListener("loadedmetadata", emitSample);
    };
  })
    .shareValue({ name: "init", stalled: null });
}

function seekingsSampler(timingsSampling) {
  return timingsSampling
    .filter(t => (
      t.name == "seeking" &&
      ( t.gap === Infinity ||
        t.gap < -SEEK_GAP )
    ))
    // skip the first seeking event generated by the set of the
    // initial seeking time in the video
    .skip(1)
    .startWith(true);
}

function toWallClockTime(ts, manifest) {
  return new Date((ts + manifest.availabilityStartTime) * 1000);
}

function fromWallClockTime(timeInMs, manifest) {
  return normalizeWallClockTime(timeInMs, manifest) / 1000 - manifest.availabilityStartTime;
}

function normalizeWallClockTime(timeInMs, manifest) {
  var {
    suggestedPresentationDelay,
    presentationLiveGap,
    timeShiftBufferDepth
  } = manifest;

  if (typeof timeInMs != "number")
    timeInMs = timeInMs.getTime();

  var now = Date.now();
  var max = now - (presentationLiveGap + suggestedPresentationDelay) * 1000;
  var min = now - (timeShiftBufferDepth) * 1000;
  return Math.max(Math.min(timeInMs, max), min);
}

function getLiveGap(ts, manifest) {
  if (!manifest.isLive)
    return Infinity;

  var {
    availabilityStartTime,
    presentationLiveGap
  } = manifest;

  var liveGap = (Date.now() / 1000 - ts);
  return (liveGap - (availabilityStartTime + presentationLiveGap + LIVE_PROTECTION));
}

module.exports = {
  getEmptyTimings,
  getTimings,
  timingsSampler,
  seekingsSampler,
  getLiveGap,
  toWallClockTime,
  fromWallClockTime,
};
