[{"file":"./Getting_Started/Welcome.html","index":[{"h2":"The RxPlayer","body":"The RxPlayer is a media player library allowing to play DASH, Smooth streaming and other similar streaming contents in any application. The RxPlayer does not come with an UI in itself as the idea is to let you have a full control over your application’s experience. What happens here is that you provide only a <video> or <audio> element to it (and optionally a separate element to display text tracks) an URL to the content (for example, to the DASH’s MPD) and the configuration you want (the languages, control over the quality etc.) and the RxPlayer takes care of every little details to play the content inside that element: import RxPlayer from \"rx-player\";  // take the first video element on the page const videoElement = document.querySelector(\"video\");  const player = new RxPlayer({ videoElement });  player.loadVideo({   url: \"https://www.example.com/Manifest.mpd\",   transport: \"dash\",   autoPlay: true, }); ","anchorH2":"the_rxplayer"},{"h2":"The documentation pages","body":"Those pages are splitted into multiple categories:   You’re here in the “Getting Started” category which provides tutorials and other resources allowing to help you with basic usage of the RxPlayer.   You can also dive into the API, which specifies the behavior of everything that is possible with the RxPlayer.  ","anchorH2":"the_documentation_pages"}]},{"file":"./Getting_Started/Tutorials/Quick_Start.html","index":[{"h1":"Quick Start","body":"Because the RxPlayer exports a lot of functionnalities, you might want to quickly test basic use cases before you dive deep into the whole API documentation. We will here learn how to simply load a video and to react to basic events.","anchorH1":"quick_start"},{"h1":"Quick Start","h2":"Install","body":"The fastest way to use the player directly in your code is to add this repository as a dependency. You can do it via npm or yarn: npm install --save rx-player  or yarn add rx-player ","anchorH1":"quick_start","anchorH2":"install"},{"h1":"Quick Start","h2":"Instanciating a Player","body":"The first step is to instanciate a new RxPlayer. Each RxPlayer instance is attached to a single video (or audio) HTML element, and is able to play a single content at once. To instanciate it with a linked video element you can just do something along the lines of: import RxPlayer from \"rx-player\";  const videoElement = document.querySelector(\"video\"); const player = new RxPlayer({ videoElement });  videoElement is an RxPlayer option and will be the HTMLElement the RxPlayer will load your media on. Despite its name, you can also give it an <audio> element. It will still be able to play an audio content without issue. When you are ready to make use of more advanced features, you can look at the other possible options in the Player Options page.","anchorH1":"quick_start","anchorH2":"instanciating_a_player"},{"h1":"Quick Start","h2":"Loading a content","body":"The next logical step is to load a content (audio, video or both). Loading a new content is done through the loadVideo method. loadVideo takes an object as arguments. There is here also a lot of possible options, but to simplify we will start with just three:   transport: String describing the transport protocol (can be \"dash\", \"smooth\" or \"directfile\" for now).   url: URL to the content (to the Manifest for Smooth contents, to the MPD for DASH contents or to the whole file for DirectFile contents).   autoPlay: Boolean indicating if you want the content to automatically begin to play once loaded. false by default (which means, the player will not begin to play on its own).   Here is a quick example which will load and play a DASH content: player.loadVideo({   url:     \"http://vm2.dashif.org/livesim-dev/segtimeline_1/testpic_6s/Manifest.mpd\",   transport: \"dash\",   autoPlay: true, }); ","anchorH1":"quick_start","anchorH2":"loading_a_content"},{"h1":"Quick Start","h2":"Reacting to basic events","body":"Now that we are loading a content, we might want to know:  if it succeed if it failed when we are able to interact with the content  To do all three of those things, you will need to listen to player events. This is done through the addEventListener method. This method works the same way than the native one you might already use on HTML elements. For example, to know if a fatal error happened (this is an error which interrupted the playback of the current content), you will just have to do: player.addEventListener(\"error\", (err) => {   console.log(\"the content stopped with the following error\", err); });  And to know if the player successfully loaded a content and if you can now interact with it, you can just do: player.addEventListener(\"playerStateChange\", (state) => {   if (state === \"LOADED\") {     console.log(\"the content is loaded\");     // interact with the content...   } });  There is multiple other events, all documented in the events documentation. As the state is a central focus of our API, we also heavily documented states in the player states documentation.","anchorH1":"quick_start","anchorH2":"reacting_to_basic_events"},{"h1":"Quick Start","h2":"Interacting with the player","body":"We’re now ready to interact with the current content. There is a huge list of APIs you can use. Some are useful only when a content is currently loaded (like play, pause, seekTo or setAudioTrack) and others can be used in any case (like setVolume, getVideoElement or loadVideo). Here is a complete example where I:  Instanciate an RxPlayer load a content with it with autoPlay toggle between play and pause once the content is loaded and the user click on the video element.  import RxPlayer from \"rx-player\";  // take the first video element on the page const videoElement = document.querySelector(\"video\");  const player = new RxPlayer({ videoElement });  player.addEventListener(\"error\", (err) => {   console.log(\"the content stopped with the following error\", err); });  player.addEventListener(\"playerStateChange\", (state) => {   if (state === \"LOADED\") {     console.log(\"the content is loaded\");      // toggle between play and pause when the user clicks on the video     videoElement.onclick = function () {       if (player.getPlayerState() === \"PLAYING\") {         player.pause();       } else {         player.play();       }     };   } });  player.loadVideo({   url:     \"http://vm2.dashif.org/livesim-dev/segtimeline_1/testpic_6s/Manifest.mpd\",   transport: \"dash\",   autoPlay: true, }); ","anchorH1":"quick_start","anchorH2":"interacting_with_the_player"},{"h1":"Quick Start","h2":"And now?","body":"Now that you know the basic RxPlayer APIs, you might want to dive deep into the whole API documentation. You can also read our next tutorial, on how to play contents with DRM, here.","anchorH1":"quick_start","anchorH2":"and_now?"}]},{"file":"./Getting_Started/Tutorials/Content_with_DRM.html","index":[{"h1":"Tutorial: Playing contents with DRMs","body":"Because different applications and different devices can work completely differently when it comes to DRM, and because it is a complex feature, we have a large API allowing to manage it. This tutorial page is specifically there to help you navigate through this API. We will begin from the simplest of use cases to dive into the more complex ones. We recommend you to read the quick start tutorial first if you haven’t, to have a general grasp on how to basically run a content.","anchorH1":"tutorial:_playing_contents_with_drms"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Playing a simple encrypted content","body":"To be able to play a simple encrypted content, we will need at least two parameters:  type: the name of the “key system” you want to use. getLicense: the license-fetching logic  This chapter will explain both and provide examples on how to load a video with both of these properties.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"playing_a_simple_encrypted_content"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Playing a simple encrypted content","h3":"The key system","body":"The key system, also known as “DRM name”, will designate which Content Decryption Module (or CDM) to use. You might have heard of “Widevine”, “PlayReady” or “FairPlay”, that’s the name what we want to know: which system you want to use. Which of them you want to use depend on several factors, among which:  what the content allows what the content right holder wants what you/your company wants what the browser can do  In the RxPlayer’s API, we more especially expect the whole “reverse domain name” for that key systems (e.g. com.widevine.alpha or com.microsoft.playready). We also have shortcuts for Widevine or PlayReady, where you can just tell us respectively widevine or playready as the key system and we will try several corresponding reverse domain names. In any case, you can ask for several key systems, even including ones that are not available in the current browser. Those will be detected and automatically filtered out. rxPlayer.loadVideo({   // ...   keySystems: [     {       type: \"com.widevine.alpha\",       // ...     },     {       type: \"com.microsoft.playready\",       // ...     },   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"playing_a_simple_encrypted_content","anchorH3":"the_key_system"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Playing a simple encrypted content","h3":"The license-fetching logic","body":"The second needed argument is a callback allowing to fetch the content license. An encrypted content will need one or several keys to be able to decrypt a content. Those keys are contained in one or several license files. Those files usually need to be downloaded from a license server. As that logic sometimes depends on your application (i.e. you might want to add authentification to that request to know which user made that request), the RxPlayer team made the choice to let you write your logic entirely. This logic takes the form of a callback named getLicense. This function is in fact triggered everytime a message is sent by the Content Decryption Module (what is sometimes known as “Widevine” or “PlayReady”), which is usually a request to fetch or renew the license. It gets two arguments when called:  message (Uint8Array): The “message” messageType (string): String describing the type of message received. There is only 4 possible message types, all defined in the w3c specification.  In most cases, this function is triggered for license requests. You’re encouraged to read what the messageType can be, but don’t be scared by it, you’ll most likely never need to check it. What you will most likely need to do, is simply sending the first argument, message, to the license server to fetch the license. That message generally contains information about the license you want to fetch. You will then need to return a Promise, which resolves with the license in an ArrayBuffer or Uint8Array form. If you don’t want to communicate a license based on this message, you can just return null or a Promise resolving with null. Here is an example of a valid and simple getLicense implementation: function getLicense(challenge) {   return new Promise((resolve, reject) => {     const xhr = new XMLHttpRequest();     xhr.open(\"POST\", LICENSE_SERVER_URL, true);     xhr.onerror = (err) => {       reject(err);     };     xhr.onload = (evt) => {       if (xhr.status >= 200 && xhr.status < 300) {         const license = evt.target.response;         resolve(license);       } else {         const error = new Error(           \"getLicense's request finished with a \" + `${xhr.status} HTTP error`         );         reject(error);       }     };     xhr.responseType = \"arraybuffer\";     xhr.send(challenge);   }); } ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"playing_a_simple_encrypted_content","anchorH3":"the_license-fetching_logic"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Playing a simple encrypted content","h3":"Example with both properties","body":"Now that all that has been explained here’s an example to play a simple encrypted DASH content with either PlayReady or Widevine. // We will use the same logic for both PlayReady and Widevine function getLicense(challenge) {   return new Promise((resolve, reject) => {     const xhr = new XMLHttpRequest();     xhr.open(\"POST\", LICENSE_SERVER_URL, true);     xhr.onerror = (err) => {       reject(err);     };     xhr.onload = (evt) => {       if (xhr.status >= 200 && xhr.status < 300) {         const license = evt.target.response;         resolve(license);       } else {         const error = new Error(           \"getLicense's request finished with a \" + `${xhr.status} HTTP error`         );         reject(error);       }     };     xhr.responseType = \"arraybuffer\";     xhr.send(challenge);   }); }  rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,     },     {       type: \"playready\",       getLicense,     },   ], });  This code is sufficient for a majority of encrypted contents.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"playing_a_simple_encrypted_content","anchorH3":"example_with_both_properties"},{"h1":"Tutorial: Playing contents with DRMs","h2":"More control over the license-fetching logic","body":"There’s a lot of things that can go wrong during the license request:  The user could be temporarly disconnected The license server might be down The license server might refuse to deliver a license based on your rights The license server might refuse to deliver a license based on your CDM capabilities And like any request a lot of other errors can happen  From this, you could want to have a different behavior based on what happened:  When a user is temporarly disconnected, you could chose to retry indefinitely (the RxPlayer retry after a delay to not overload the client or the server). When the license server is down, you might want to fail directly. When the license server refuse to deliver a license based on your rights, you might want to throw an explicit error message that you will be able to display. If there’s a problem with your CDM capabilities, you might want to just fallback to another media quality with a different license.  All of this is possible with more advanced APIs that we will see in this chapter.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"more_control_over_the_license-fetching_logic"},{"h1":"Tutorial: Playing contents with DRMs","h2":"More control over the license-fetching logic","h3":"getLicenseConfig","body":"getLicenseConfig is an object allowing to configure two parameters:   retry, which will set the maximum number of retry. When setting 1, for example, we will try two times the request: A first original time and one retry. You can decide to by default retry indefinitely by setting it to Infinity (yes, that’s a valid number in JS and some other languages). Don’t worry, you will still be able to retry less time on some other events (explained in the getLicense error configuration chapter).   timeout, which is the maximum time in milliseconds the RxPlayer will wait until it considers a getLicense call to have failed. By default it is set to 10000 (10 seconds). You can set it to -1 to disable any timeout.   For example, for infinite retry and no timeout, you can set: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       getLicenseConfig: {         retry: Infinity,         timeout: -1,       },     },     // ...   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"more_control_over_the_license-fetching_logic","anchorH3":"getlicenseconfig"},{"h1":"Tutorial: Playing contents with DRMs","h2":"More control over the license-fetching logic","h3":"getLicense error configuration","body":"getLicenseConfig handle general configurations about every getLicense calls, but you can also have more specific configuration when a specific license request fails. This is done thanks to the rejected Promise returned by getLicense. You can reject an error (or just an object), with the following properties:   noRetry: when set to true, the getLicense call will not be retried.   message: a custom message string we will communicate through a warning or error event (depending if we will retry or not the call)   fallbackOnLastTry: When set to true and if we are doing or last try or retry (to be sure you can set noRetry to true), we will try to fallback to another quality, which might have a different license. This is only useful for contents which have a different license depending on the quality (for example having different rights for 4k video content than for 480p video content). It is also only useful if the license server can refuse to deliver a license for a particular quality but accept for another quality.   Here is an example showcasing all of those properties: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense(challenge) {         return new Promise((resolve, reject) => {           const xhr = new XMLHttpRequest();           xhr.open(\"POST\", LICENSE_SERVER_URL, true);           xhr.onerror = (err) => {             // Keep retrying on XHR errors.             // Instanciating an Error like that automatically set the             // message attribute to this Error's message. That way, the             // linked \"error\" or \"warning\" event sent by the RxPlayer             // will have the same message.             const error = new Error(\"Request error: \" + err.toString());             reject(err);           };           xhr.onload = (evt) => {             if (xhr.status >= 200 && xhr.status < 300) {               const license = evt.target.response;               resolve(license);             } else if (xhr.status >= 500 && xhr.status < 600) {               // Directly fails + fallbacks on a server error               const error = new Error(                 \"The license server had a problem and\" +                   ` responded with ${xhr.status} HTTP ` +                   \"error. We will now fallback to another\" +                   \"quality.\"               );               error.noRetry = true;               error.fallbackOnLastTry = true;               reject(error);             } else {               // else continue to retry               const error = new Error(                 \"getLicense's request finished with a \" +                   `${xhr.status} HTTP error`               );               reject(error);             }           };           xhr.responseType = \"arraybuffer\";           xhr.send(challenge);         });       },       getLicenseConfig: {         retry: Infinity,         timeout: -1,       },     },     // ...   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"more_control_over_the_license-fetching_logic","anchorH3":"getlicense_error_configuration"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","body":"","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"Why and how","body":"One of the issues arising with DRM is that not all devices, Operating systems or web browsers can provide a high level of guarantee that a content will be protected against unauthorized usages (such as illegal copy). In other words, some devices, OS or browsers might provide more guarantees than other. That’s the main reason why there’s sometime a compromise to have between accessibility of a content (the number of the people able to view it) and this guarantee. To be able to provide the best of both worlds, a content right holder might ask for a higher protection guarantee for higher video qualities. For example, it might ask that a 4k video content of a given film should be much harder to “pirate” than the 240p version of the same film. In return, the 240p version can be watched by a lot more people on a lot of different devices. To achieve that, one of the solution on the content-side is to have different decryption keys depending on the quality chosen. There’s then two main strategies:   Every keys are in the same license. A player will thus do only one license request for the whole content and the keys inside will be individually refused or accepted.   There is one or several keys per licenses, in several licenses. That way, a player might ask a different license when switching the current quality.   There’s pros and cons to both, but let’s not go too far into that! Let’s start from the principle that our content is under one of those two cases here and let’s find out what we have to do to handle it.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"why_and_how"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"The strategy adopted by the RxPlayer","body":"When playing a content, the RxPlayer by default stops and throws an error as soon as either a key is refused or as the license fetching logic (the getLicense function) fails (after enough retries). When playing a content with multiple keys, you might instead not care that much if a key is refused or if the license-fetching logic fails. What you can just do is to remove the quality for which we could not obtain a key and to instead fallback on another, decipherable, quality. That’s exactly what the RxPlayer does, when the right options are set:   when it detects a quality to be un-decipherable, it first emit a decipherabilityUpdate event through its API, to signal to an application which qualities have been blacklisted.   it automatically removes from the current media buffer the data linked to the un-decipherable quality and put it in a black list: we will not load this quality for the current content anymore.   it switches to another, hopefully decipherable, quality.   Let’s now talk about the API.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"the_strategy_adopted_by_the_rxplayer"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"fallbackOnLastTry","body":"This option was already explained in a previous chapter. Basically, it is a boolean you can set to true when rejecting an error from the getLicense callback. When set and if it was the last getLicense try or retry, the RxPlayer will stop to play every quality sharing the same “protection initialization data”. What that last part really means is a little complex, but it generally means that every qualities sharing the same license file will be considered as un-decipherable. For more information and an example on how to use it, you can go back on the concerned previous part of this tutorial. Please note that this option does not concern every errors linked to a refused key. It only concerns issues when the license server refuse to deliver a license. On most cases you will also need the API documented in the next part, fallbackOn.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"fallbackonlasttry"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"fallbackOn","body":"Where fallbackOnLastTry really is about the failure of a license request, the fallbackOn is about the refused keys themselves. As an example, the Content Decryption Module in the browser might decide that your current device cannot provide a high enough guarantee that the content cannot be copied. It might thus refuse to use one of the decryption key found in a license, especially the one needed for the higher content qualities. The fallbackOn object allows to fallback when this happens. There is two possible sub-properties in it:  keyInternalError: fallback when the corresponding key has the status \"internal-error\". We found that most widevine implementation use this error when a key is refused. keyOutputRestricted: fallback when the corresponding key has the status \"output-restricted\". This is the proper status for a key refused due to output restrictions.  Both are booleans, and for the moment we recommend to set both to true in most cases. For people on embedded devices with specific key systems, you can look a little more into what MediaKeyStatus is set when a key is refused, and just set one of both. Here is an example: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       fallbackOn: {         keyInternalError: true,         keyOutputRestricted: true,       },     },   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"fallbackon"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"decipherabilityUpdate event","body":"When the RxPlayer detects a quality to be un-decipherable (which can only happens when one of the properties explained here is set), it sends a decipherabilityUpdate event. This event allows an application to know that some key or license could not be used by the RxPlayer. The application could then infer that other contents from the same right holders will have the same issues. In that case, an optimization is possible by using the representationFilter API which is part of the transportOptions loadVideo option, documented here. By using this API, we can filter out un-decipherable quality to avoid downloading them in the first place.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"decipherabilityupdate_event"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Server certificate","body":"The “server Certificate” is a certificate allowing to encrypt messages coming from the Content Decryption module to the license server. They can be required by some key system as a supplementary security mechanism. Thankfully, an application is not obligated to set one, even if one is needed. If not set, the Content Decryption Module will download it itself by using the same route than a license request (the getLicense callback will be called). This means however, that we have to perform two round-trips to the license server instead of one:  one to fetch the “server certificate”. the other to fetch the license.  To avoid the first round-trip, it is possible for an application to directly indicate what the serverCertificate is when calling loadVideo. This is done through the serverCertificate property, in keySystems: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       serverCertificate,     },   ], });  The serverCertificate has to either be in an ArrayBuffer form or a TypedArray (i.e. Uint8Array, Uint16Array etc.)","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"server_certificate"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Persistent licenses","body":"A persistent license allows to store a license for it to be available even when a user quits the current page or restarts its computer. It can be used even if the user is offline. After loading a persistent license, it is automatically stored on the browser’s side, but the RxPlayer still has to store an ID to be able to retrieve the right session when reloading the same content later. Because of that, persistent-license management comes in two part in the RxPlayer API (as usual here, those should be set in keySystems):   You’ll have to set the persistentLicense boolean to true   You’ll have to provide a license storage mechanism and set it as the licenseStorage property.   rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       persistentLicense: true,       licenseStorage,     },   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"persistent_licenses"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Persistent licenses","h3":"licenseStorage property","body":"The licenseStorage property is an object allowing the RxPlayer to load and saved stored IDs. It needs to contain two functions:  save: Which sould store the argument given. The argument will be an array of Objects. load: Called without any argument, it has to return what was given to the last save call. Any return value which is not an Array will be ignored (example: when save has never been called).  This API can very simply be implemented with the localStorage browser API: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       persistentLicense: true,       licenseStorage: {         save(data) {           localStorage.setItem(\"RxPlayer-licenseStorage\", JSON.stringify(data));         },         load() {           const item = localStorage.getItem(\"RxPlayer-licenseStorage\");           return item === null ? [] : JSON.parse(item);         },       },     },   ], });  Do not be scared about security implications, the data saved is not secret and does not help to identify a user. You can also use every storage API at your disposition (some embedded devices might have their own). As a nice bonus, you can note that the data given is perfectly “serializable” through the JSON.stringify browser API. This means that, as the example shown above, you can call JSON.stringify on that data and retrieve it through a JSON.parse call. This is very useful for storage APIs which cannot store JavaScript objects.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"persistent_licenses","anchorH3":"licensestorage_property"}]},{"file":"./Getting_Started/Tutorials/Selecting_a_Track.html","index":[{"h1":"Tutorial: Selecting a track","body":"","anchorH1":"tutorial:_selecting_a_track"},{"h1":"Tutorial: Selecting a track","h2":"The goal of this tutorial","body":"The RxPlayer has an advanced API when it comes to track selection:   You can list the available audio, video and/or text tracks and chose one of them   You can disable the current video and / or text track   You can also give to the RxPlayer a set of preferences so it can make the best choice by itself without manually having to choose the right track for every contents. Those preferences can even be applied retro-actively (for example, to the content currently being played), depending on your need.   Because the RxPlayer declares multiple APIs to allow those different use cases, the track selection API can seem intimidating and confusing at first. This tutorial will help you understand what your options are, why you would use an API instead of another one and how to use them.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"the_goal_of_this_tutorial"},{"h1":"Tutorial: Selecting a track","h2":"What is a “track”?","body":"We should first agree on what is a track, as a concept. Let’s take for example an italian film presented to an english-speaking audience. For that film, let’s imagine those multiple “audio tracks”:  one being the original audio track, in italian one being a dub in the english language another in english with accessibility features such as an audio description of what visually happens in the film (for example, to give cues of what is happening to the visually-impaired).  There also could be multiple “text tracks”:  subtitles in english closed-captions in english (for example, for the hearing impaired)  And we could even imagine multiple video tracks:  one displaying the “regular” film another displaying either the same film from a different camera angle (seems far-fetched here but let’s just pretend we’re talking about some kind of experimental film!)  All those will provide to the user a different way to offer the same film. They even can technically be switched one independently of the other (though restrictions on possible combinations can exist) to give a large number of different experience for what is effectively the same content.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"what_is_a_%22track%22?"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","body":"","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","h3":"Preamble","body":"The RxPlayer does not “guess” the tracks available for a given content. It usually finds every information about them in a specific file, called the Manifest. Thus, the list of available tracks will only be available once the RxPlayer has loaded and parsed that Manifest. Moreover, a Manifest can have several lists of available tracks depending on the player’s position (for example, a live channel with multiple programs might have different audio languages available for different programs). This means both that the available tracks won’t generally be known just after a loadVideo call and that it can then change at any time. Thankfully, most of this complexity is abstracted by the RxPlayer API.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks","anchorH3":"preamble"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","h3":"Using methods","body":"Once the RxPlayer has loaded the content (meaning the RxPlayer is not in the STOPPED, LOADING or RELOADING player state) you can begin to ask it what is the current list of available tracks. This can be done through three RxPlayer methods:  getAvailableAudioTracks() to list audio tracks getAvailableVideoTracks() to list video tracks getAvailableTextTracks() to list text tracks  Those methods will all return arrays of objects, each object containing information about a single track. It should be noted that the information for an audio track won’t be the same than for a video or a text track. For example, you might be interested by the height and width available in a video track. Those notions make absolutely no sense for an audio track. For more information about the structure of the data returned by those methods, you can refer to their API documentation (a shortcut is available by clicking on the method name). Note that you can still ask for the current tracks when the RxPlayer does not have loaded any content (is in the STOPPED, LOADING or RELOADING player state), but you will most likely only get an empty array in those cases. Examples Those methods are straightforward, here are some examples of how they can be used: // Array of all available audio languages const availableLanguages = rxPlayer   .getAvailableAudioTracks()   .map((track) => track.language);  // List of audio tracks containing an audio description of what is visually // happening const audioDescriptionTracks = rxPlayer   .getAvailableAudioTracks()   .filter((track) => track.audioDescription);  // List of video tracks for which a profile with a 1080p resolution is available const highResVideoTracks = rxPlayer   .getAvailableVideoTracks()   .filter((track) => {     return track.representations.some(       (representation) =>         representation.height !== undefined && representation.height >= 1080     );   });  // List of text tracks available in french const frenchTextTracks = rxPlayer   .getAvailableTextTracks()   .filter((track) => track.normalized === \"fra\"); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks","anchorH3":"using_methods"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","h3":"Using events","body":"If you want to have the list of available tracks as soon as possible, it might be a good idea to rely on the related events. Here are the three events you will need to know:   \"availableAudioTracksChange\": the list of available audio tracks was just updated   \"availableVideoTracksChange\": idem for video tracks   \"availableTextTracksChange\": idem for video tracks   All of those events will have the corresponding available tracks as a payload, which will be the exact same data that what you would get when calling the corresponding getAvailable...Tracks method at this point. Note that no available...TracksChange event will be sent when the RxPlayer stops the content or temporarly goes through the RELOADING player state, despite the fact that in those cases there is no available tracks to choose from. Still, calling the getAvailable...Tracks methods in those cases will return an empty array (as it should). This has to be considered. Examples Like any RxPlayer event, you will need to add an event listener for those: let currentAudioTracks = []; let currentVideoTracks = []; let currentTextTracks = [];  rxPlayer.addEventListener(\"availableAudioTracksChange\", (audioTracks) => {   console.log(\"New audio tracks:\", audioTracks);   currentAudioTracks = audioTracks; });  rxPlayer.addEventListener(\"availableVideoTracksChange\", (videoTracks) => {   console.log(\"New video tracks:\", videoTracks);   currentVideoTracks = videoTracks; });  rxPlayer.addEventListener(\"availableTextTracksChange\", (textTracks) => {   console.log(\"New text tracks:\", textTracks);   currentTextTracks = textTracks; }); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks","anchorH3":"using_events"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","h3":"Should you use the methods or events?","body":"Both the exposed methods and events return the same data. Whether you should rely on the former or on the latter will depend on what corresponds the most to your codebase:   if you want to fetch that list at a given point in time - such as when the user clicks on a button - it can be easier to just call the methods.   if you want to know that list as soon as available and perform an action right after (such as selecting a track, displaying this list…), you might prefer relying on the events. Here you will also have to re-set that list yourself when the player has no content loaded anymore (in the STOPPED, LOADING or RELOADING player state).  ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks","anchorH3":"should_you_use_the_methods_or_events?"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","body":"You might also want to know which track is the one currently selected. There are several ways to do that.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Through methods","body":"The RxPlayer has a set of methods that just return the currently active tracks:   getAudioTrack: return information on the current audio track   getVideoTrack: return information on the current video track   getTextTrack: return information on the current text track   Those methods will return an object describing the attributes of the current tracks. They can also return null if no track has been enabled (for example, the user could have wanted to disable all text tracks) and undefined if the track is either unknown (which is a very rare occurence) or if no content is currently playing. Like the getAvailable...Tracks methods, the format of the objects returned will entirely depend on which method you call. You can refer to the API documentation to get more information on this. Also like the getAvailable...Tracks methods, the current text track will usually only be known once the RxPlayer has loaded a content (which means we are not in the STOPPED, LOADING or RELOADING player state). If no content is loaded, those APIs will just return undefined. Examples Here is an example on how you could use them: const currentTextTrack = rxPlayer.getTextTrack(); if (currentTextTrack === null) {   console.log(\"No text track is enabled\"); } else if (currentTextTrack === undefined) {   console.log(     \"We don't know the current text track. \" +       \"Are you sure a content is loaded?\"   ); } else {   const language = currentTextTrack.language;   console.log(\"We have a current text track in the \" + language + \"language\"); } ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"through_methods"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Through events","body":"Exactly like you would obtain the list of available tracks through the available...TracksChange events, you can know when the current track change as soon as possible through the following events:   \"audioTrackChange\": the currently-active audio track changed   \"videoTrackChange\": the currently-active video track changed   \"textTrackChange\": the currently-active text track changed   Those events just emit the current track information as soon as it changes, in the same format that the get...Track methods. Unlike for the get...Track methods however, its payload cannot be set to undefined: you won’t receive any ...TracksChange event if the track is unknown or if there is no content. This also means that you won’t have any event when the RxPlayer stops or re-load the current content, despite the fact that you don’t have any current track in that case. Calling the get...Track method in those cases will return undefined, as it should. This has to be considered. Example Like for any events, you will have to register an event listener: rxPlayer.addEventListener(\"textTrackChange\", (track) => {   if (track === null) {     console.log(\"No text track is active\");   } else {     console.log(       \"new active text track in the following language: \" + track.language     );   } }); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"through_events"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Through the list of available tracks","body":"As written earlier the available...TracksChange events and the getAvailable...Tracks methods both return arrays of objects, each object defining a single track. In each of those object, you will find an active boolean property, which will be set to true if the track is the currently chosen one and false otherwise. Note that it’s possible that none of the available tracks are active. This is for example the case when the track has been disabled (for example when the user wants no text tracks at all). // get the active audio track through `getAvailableAudioTracks` const activeAudioTrack1 = rxPlayer   .getAvailableAudioTracks()   .find((track) => track.active);  // get the active audio track through `availableAudioTracksChange` let activeAudioTrack2; rxPlayer.addEventListener(\"availableAudioTracksChange\", (tracks) => {   activeAudioTrack2 = tracks.find((track) => track.active); }); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"through_the_list_of_available_tracks"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Which one to use?","body":"As usual here, this is highly dependant on your application. All of those APIs give the same information through different means. Accessing with the get...Track method is simple to use, the events allow to know at the earliest possible time and relying on the list of available tracks can simplify your code if you want both of them.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"which_one_to_use?"},{"h1":"Tutorial: Selecting a track","h2":"Selecting a track","body":"Now that we have the list of available tracks and the current one, we might want to choose another one, or let the final user choose another one. To do that, you will have to use one of those three RxPlayer methods:  setAudioTrack(): change the current audio track setVideoTrack(): change the current video track setTextTrack(): change the current text track  Each of those methods take a single string as argument. That string should be the value of the id property of the chosen track. For example, to choose the first audio track with an audio description, you can do: const firstAudioTrackWithAD = rxPlayer   .getAvailableAudioTracks()   .find((track) => track.audioDescription);  if (firstAudioTrackWithAD !== undefined) {   rxPlayer.setAudioTrack(firstAudioTrackWithAD.id); }  It’s important to consider that those APIs only allow to change the current track and will have no impact on the other contents you will encounter in the future. Depending on your application, you might also want to set a global preference at some point, such as saying that the final user will prefer english audio tracks for now on. Although setAudioTrack can be used for this use case - by just setting an english audio track every times the available audio tracks list change (we can know that through the availableAudioTracksChange event) - it is much more efficient and less cumbersome to use audio track preference APIs for that. Those will be described later in this tutorial, so stay with me! After manually setting a track through the set...Track methods, you will receive the corresponding ...TrackChange event when the change is applied. Note that on some contents, changing a track from a given type might automatically also change the current track for another types. For example, switching to another audio language might also automatically turn on the subtitles. This is because some streaming protocols might “force” some combination. To detect those cases, you can either listen to every ...TrackChange events or call the corresponding get...Track method everytime you want to use them.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"selecting_a_track"},{"h1":"Tutorial: Selecting a track","h2":"Disabling a track","body":"Now what if you want no track at all? This is for example a frequent need for text tracks, where you might prefer to have no subtitles or closed captions appearing on the screen. You could also want to disable the video track, which is a trick often used to reduce the network bandwidth used by a content. You can disable respectively the current text track and the current video track by calling those methods:  disableTextTrack disableVideoTrack  However, like for selecting a track, this only concerns the current content being played. When playing a new content or even when just switching to another part of the content with a different track list, you might need to re-do the same method call. This is problematic most-of-all when disabling the video track, as going in and out of that usually requires a short but visible “re-loading” step by the RxPlayer. You want thus to limit the need to call disableVideoTrack every times a new content is encountered. Thankfully, the RxPlayer has another set of API to let you choose a track even for future contents: the “track preferences APIs”.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"disabling_a_track"},{"h1":"Tutorial: Selecting a track","h2":"Track preferences APIs","body":"All methods and events discussed until now only have an effect for the current content being played. This has multiple disadvantages:   that code has to be run each time a new content is loaded (and each time the track list changes, if there are multiple track lists for a single contents).   it is inefficient: In some cases the RxPlayer pre-load new content to allow a smooth transition between the current content and that new one. To do that, it chooses a track itself and begin to download it. If when reaching the new content a totally other track is finally chosen, we might have wasted network bandwidth for nothing as we would have to re-download a completely different track. Even more important, the transition won’t be smooth at all because we will have to stop to build some buffer with the wanted track instead.   Thankfully, there exists another set of APIs we call the “track preferences”. With those, you can tell the RxPlayer that you might always prefer the audio track to be in english - for example - or that you would prefer the video track to be in a given codec. Bear in mind that track preferences APIs are for a different use case than the classic track selection APIs:   the “classic” track selection APIs are here to select a precize track amongst available ones. This is probably the APIs you will use when displaying a list of available tracks to the final user and choosing one.   the track preferences APIs give hints of what the finally user generally wants, so that the right track is automatically chosen by the RxPlayer. It is also useful for optimizations such as when pre-loading the next content. This is the APIs you will use in most other use cases, where you want to give the general track settings the user wants to the RxPlayer.   The track preferences can be set in two manners:  During instanciation of the RxPlayer At any time, through specific methods ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"track_preferences_apis"},{"h1":"Tutorial: Selecting a track","h2":"Track preferences APIs","h3":"Setting a track preference on instanciation","body":"There are three options you can give to the RxPlayer on instanciation to set the track preferences:  preferredAudioTracks: set the preferences for the audio tracks preferredTextTracks: for the text tracks preferredVideoTracks: for the video tracks  You can click on the name of the option to be redirected to its corresponding API documentation. Each of those take an array of object which will define which track you want the RxPlayer to choose by default. As a simple example, to choose french audio tracks without audio description by default you could do: const rxPlayer = new RxPlayer({   preferredAudioTracks: [{ language: \"fra\", audioDescription: false }], });  Because not all contents could have a track matching that preferences, you can add even more elements in that array. For example, if you want to fallback to english if no french audio track is found you can do: const rxPlayer = new RxPlayer({   preferredAudioTracks: [     { language: \"fra\", audioDescription: false },     { language: \"eng\", audioDescription: false },   ], });  Here, the RxPlayer will enable a french audio track if it finds one, but if it does not, it will enable the english one instead. If none of your preferences is found for a given content, the RxPlayer will choose the content’s default (or first, if no default is announced in the content) track itself. Those options allow much more powerful configurations. You can refer to the API documentation for that.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"track_preferences_apis","anchorH3":"setting_a_track_preference_on_instanciation"},{"h1":"Tutorial: Selecting a track","h2":"Track preferences APIs","h3":"track preferences methods","body":"You can also update at any time those track preferences - even when no content is playing - by calling the following methods: - setPreferredAudioTracks: update the audio preferences - setPreferredTextTracks update the text preferences - setPreferredVideoTracks update the video preferences Those methods mostly work the same way than the constructor options. You give them an array of the wanted track configurations and the RxPlayer will try to choose a track that match with the earliest possible configuration in that array: rxPlayer.setPreferredAudioTracks([   { language: \"fra\", audioDescription: false },   { language: \"eng\", audioDescription: false }, ]);  But there’s another element to consider here. When calling the method (unlike when giving an option to the constructor), the RxPlayer may already be playing a content. So here, there’s a dilemma:   should the RxPlayer apply the new preferences to the current content? It could, but it might be unexpected if a track chosen explicitely by the user for the current content changes because it does not match the preferences.   or should the RxPlayer only apply it to new contents? In that case, it could also be an unexpected behavior. Especially for contents with multiple track lists - here you could inversely want your new preferences to be considered when seeking back to an already-played content.   There’s no good answer here, it all depends on the implementation you want to do. Because of that, those methods all can take a boolean as a second argument. When this second argument is set to true, the RxPlayer will also apply that preference to the already-loaded content: // disable the text tracks from every contents - the current one included rxPlayer.setPreferredTextTracks([null], true);  If not set or set to false, it will only be applied for content that have not been loaded yet. // Only disable the text tracks from the next encountered contents. rxPlayer.setPreferredTextTracks([null]); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"track_preferences_apis","anchorH3":"track_preferences_methods"},{"h1":"Tutorial: Selecting a track","h2":"Track preferences APIs","h3":"Obtaining the last set preferences","body":"The RxPlayer also has three methods which will return the last set preferences:  getPreferredAudioTracks: return the audio preferences getPreferredTextTracks: return the text preferences getPreferredVideoTracks: return the video preferences  The format of the returned array will be the exact same than the array given to the corresponding setPreferred...Tracks method (or the value of the preferred...Tracks constructor option if the method was never called - or just an empty array by default when neither was used).","anchorH1":"tutorial:_selecting_a_track","anchorH2":"track_preferences_apis","anchorH3":"obtaining_the_last_set_preferences"},{"h1":"Tutorial: Selecting a track","h2":"What set of APIs should you use","body":"The “classic” track selection APIs (getAvailable...Tracks, get...Track and set...Track) are the APIs you should use when explicitely exposing the current available tracks and selecting one precizely. The track preferences APIs should be used for anything else. This is because the track preferences APIs allow to completely move the task of selecting a track out of your code and into the RxPlayer and will allow some optimizations to take place. The “classic” track selection APIs still allow to make a much more precize choice and allow to know which tracks are currently available. Due to that, they are a perfect fit when you want to propose a track choice menu to the final user.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"what_set_of_apis_should_you_use"},{"h1":"Tutorial: Selecting a track","h2":"Notes about the “textTrackMode” option","body":"This tutorial was focused on track selection but there’s still a last point I want to approach, which is how subtitles will be displayed to the user. By default, text tracks will be displayed through <tracks> elements which will be contained in the media element where the content plays. This allows to display subtitles but may not be sufficient when wanting to display richer subtitles (such as closed-captions). This is why the RxPlayer has a textTrackMode concept. By setting the textTrackMode to \"html\" in a loadVideo call, you will be able to profit from much richer subtitles than what you could have by default. If you do that, you also need to set the textTrackElement property to an HTML element, that the RxPlayer will use to display subtitles into. More information on those options can be found in the RxPlayer API.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"notes_about_the_%22texttrackmode%22_option"}]},{"file":"./Getting_Started/Tutorials/EventStream_Handling.html","index":[{"h1":"Tutorial: Listening to stream events","body":"Some contents contain events a player will need to send at a particular point in time. We call those in the RxPlayer “stream events”. For example, stream events are often used jointly with ad-insertion, to allow a player to notify when an user begin to see a particular ad. Stream events are not only restrained to ad-related usages though. Any event you want to synchronize with the played content can be inserted.","anchorH1":"tutorial:_listening_to_stream_events"},{"h1":"Tutorial: Listening to stream events","h2":"Event Formats understood by the RxPlayer","body":"","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"event_formats_understood_by_the_rxplayer"},{"h1":"Tutorial: Listening to stream events","h2":"Event Formats understood by the RxPlayer","h3":"DASH EventStream elements","body":"For now, the RxPlayer only make use of DASH’ EventStream elements. Such elements are defined in a DASH MPD in the concerned Period. Here is an example of such element in an MPD: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <MPD   xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"   xmlns=\"urn:mpeg:dash:schema:mpd:2011\"   xsi:schemaLocation=\"urn:mpeg:dash:schema:mpd:2011 DASH-MPD.xsd\"   type=\"dynamic\"   minimumUpdatePeriod=\"PT2S\"   timeShiftBufferDepth=\"PT30M\"   availabilityStartTime=\"2011-12-25T12:30:00\"   minBufferTime=\"PT4S\"   profiles=\"urn:mpeg:dash:profile:isoff-live:2011\">      <Period id=\"1\">       <EventStream schemeIdUri=\"urn:uuid:XYZY\" timescale=\"1000\" value=\"call\">         <Event presentationTime=\"0\" duration=\"10000\" id=\"0\">           1 800 10101010         </Event>         <Event presentationTime=\"20000\" duration=\"10000\" id=\"1\">           1 800 10101011         </Event>         <Event presentationTime=\"40000\" duration=\"10000\" id=\"2\">           1 800 10101012         </Event>         <Event presentationTime=\"60000\" duration=\"10000\" id=\"3\">           1 800 10101013         </Event>       </EventStream>       <!-- ... -->     </Period>  </MPD>  Here the <EventStream /> elements and its <Event /> children elements will be parsed by the RxPlayer. Each <Event /> element can then be sent through a single RxPlayer events.","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"event_formats_understood_by_the_rxplayer","anchorH3":"dash_eventstream_elements"},{"h1":"Tutorial: Listening to stream events","h2":"How to listen to stream events","body":"The RxPlayer notify of such events through the usual RxPlayer events. As a reminder (or if you didn’t know), the RxPlayer can send a multitude of events that can be listened to by the usage of the addEventListener method. The events related to stream events are:   \"streamEvent\": an event has just been reached.   \"streamEventSkip\": an event has been skipped over. This usually means that a player seek operation resulted in the corresponds event being “missed”.   In any case, the corresponding event will be attached as a payload. Example: // listen to \"streamEvent\" events rxPlayer.addEventListener(\"streamEvent\", (evt) => {   console.log(\"An event has been reached:\", evt); });  // listen to \"streamEventSkip\" events rxPlayer.addEventListener(\"streamEventSkip\", (evt) => {   console.log(\"We just 'skipped' an event:\", evt); }); ","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"how_to_listen_to_stream_events"},{"h1":"Tutorial: Listening to stream events","h2":"The event format","body":"Whether you’re listening to the \"streamEvent\" or the \"streamEventSkip\" event, you will receive an object containing the corresponding event information. Here is an example of such events: {   start: 10, // start time of the event, in seconds.              //              // It is always defined, as a number.              //              // A start at `10` here means that the event began when the player              // reached the position at 10 seconds.    end: 25, // Optional end time of the event, in seconds.            //            // It can be undefined or unset for events without any duration.            // A end at `25` here indicates that this event only last from the            // position at 10 seconds (the `start`) to the position at 25            // seconds, or an event with a duration of 15 seconds.            //            // If `end` is defined, you can be notified when the end of this            // event is reached by adding an `onExit` callback to that event            // (continue reading this tutorial for more information).    data: { // The event's data itself.      type: EVENT_TYPE, // String describing the source of the event.      value: EVENT_VALUE, // This property's format and content depends on the                         // `type` property. For example, when the type property                         // is set to \"dash-event-stream\", this value will be the                         // <Event /> element corresponding to that DASH event.   } }  As written in this example, the underlying format of the event itself will depend on the source of the event. For example, an event generated from a DASH’s <EventStream /> won’t be in the same format that an event generated from a MP4’s emsg box. You can know which current format is used by checking the value of the data.type property. For now, we only have one format: DASH EventStream elements, which will have a data.type property equal to \"dash-event-stream\".","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"the_event_format"},{"h1":"Tutorial: Listening to stream events","h2":"The event format","h3":"DASH EventStream elements","body":"A DASH EventStream’s event will be parsed under the following format: {   start: 10, // As usual, the event start time in seconds    end: 15, // optional end position of the event, in seconds.            // Can be not set or set to `undefined` for events without a duration    data: {      type: \"dash-event-stream\", // Type corresponding to a DASH's EventStream's                                // Event element      value: {       schemeIdUri: SCHEME_ID_URI,       element: EVENT_ELEMENT,       timescale: EVENT_TIMESCALE,     }   } }  Where:   SCHEME_ID_URI will be the value of the corresponding EventStream’s schemeIdUri attribute   EVENT_ELEMENT will be the corresponding <Event /> element in the MPD.   EVENT_TIMESCALE will be the value of the corresponding EventStream’s timescale attribute. This indicates a way to convert some time information on an EVENT_ELEMENT into seconds (by dividing the value by timescale), though it can usually safely be ignored.   For example for the following EventStream: <EventStream schemeIdUri=\"urn:uuid:XYZY\" timescale=\"1000\" value=\"call\">   <Event presentationTime=\"0\" duration=\"10000\" id=\"0\">1 800 10101010</Event>   <Event presentationTime=\"40000\" duration=\"10000\" id=\"1\">1 800 10101012</Event>   <Event presentationTime=\"60000\" duration=\"10000\" id=\"2\">1 800 10101013</Event> </EventStream>  The RxPlayer will define those three events (note: I used custom syntax here to include a readable document format): // The first event: {   start: 0,   end: 10,   data: {     type: \"dash-event-stream\",     value: {       schemeIdUri: \"urn::uuid::XYZY\",       element: <Event presentationTime=\"0\" duration=\"10000\" id=\"0\">                  1 800 10101010                </Event>,       timescale: 1000,     }   } }  // The second event: {   start: 40,   end: 50,   data: {     type: \"dash-event-stream\",     value: {       schemeIdUri: \"urn::uuid::XYZY\",       element: <Event presentationTime=\"40000\" duration=\"10000\" id=\"1\">                  1 800 10101012                </Event>,       timescale: 1000,     }   } }  // The third event: {   start: 60,   end: 70,   data: {     type: \"dash-event-stream\",     value: {       schemeIdUri: \"urn::uuid::XYZY\",       element: <Event presentationTime=\"60000\" duration=\"10000\" id=\"2\">                  1 800 10101013                </Event>,       timescale: 1000,     }   } } ","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"the_event_format","anchorH3":"dash_eventstream_elements_(1)"},{"h1":"Tutorial: Listening to stream events","h2":"Listening when an event has ended","body":"Some stream events have a end property, you could thus need to know when an event that the RxPlayer reached is now ended. Thankfully, we planned this need in the API of the RxPlayer. Any event with a set end can be added an onExit callback. This callback will be called once the event has ended. So for example you can write: rxPlayer.addEventListener(\"streamEvent\", (evt) => {   console.log(\"An event has been reached:\", evt);   if (evt.end !== undefined) {     evt.onExit = () => {       console.log(\"An event has been exited:\", evt);     };   } });  When defined, that onExit callback will be called once the RxPlayer either reaches the end position of the event or seek outside of the scope of this event. Please note however that even if an event has an end property, it is possible that the onExit callback will never be called. For example, the user could stop the content while an event was “active” (we do not trigger onExit callbacks in that case) or the corresponding <Event /> could “disappear” from the MPD once it has been refreshed.","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"listening_when_an_event_has_ended"},{"h1":"Tutorial: Listening to stream events","h2":"Example","body":"To end this tutorial, lets define a complete example: rxPlayer.addEventListener(\"streamEvent\", (evt) => {   console.log(\"An event has been reached:\", evt);    console.log(\"This is an event of type:\", evt.data.type);   if (evt.data.type === \"dash-event-stream\") {     console.log(\"This is a DASH EventStream's Event element.\");      console.log(\"schemeIdUri:\", evt.data.schemeIdUri);     console.log(\"<Event /> element:\", evt.data.element);   }    if (evt.end !== undefined) {     evt.onExit = () => {       console.log(\"An event has been exited:\", evt);     };   } });  rxPlayer.addEventListener(\"streamEventSkip\", (evt) => {   console.log(\"We just 'skipped' an event:\", evt);    console.log(\"This was an event of type:\", evt.data.type);   // ... }); ","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"example"}]},{"file":"./Getting_Started/Minimal_Player.html","index":[{"h1":"Importing a minimal player with feature selection","body":"","anchorH1":"importing_a_minimal_player_with_feature_selection"},{"h1":"Importing a minimal player with feature selection","h2":"Overview","body":"The RxPlayer comes with many features, even some you might never need. For example, you may only care for DASH with TTML subtitles and not about Smooth streaming, VTT or SRT parsing. Because each implementation has its need, we permit multiple ways to import the player with limited features. This principally leads to a smaller file size. This customization can be done through two principal ways:   by importing a minimal version and then adding only the features your want   by setting environment variables at build time   The first solution is the most straightforward and should be used in most usecases. The main disadvantages of this solution are that to reduce file size:   you will need to use a module-bundler or minifier which performs tree-shaking, like webpack’s production mode or rollup.   you will need to use the package published on npm (as opposed to the git repository directly).   The second solution will always work but needs you to build the bundle yourself through our npm scripts.","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"overview"},{"h1":"Importing a minimal player with feature selection","h2":"Importing a minimal version","body":"","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"importing_a_minimal_version"},{"h1":"Importing a minimal player with feature selection","h2":"Importing a minimal version","h3":"How it works","body":"If you imported the RxPlayer library through the npm package (like via the npm install rx-player command), you can import a minimal version of the player by importing it from \"rx-player/minimal\": import MinimalRxPlayer from \"rx-player/minimal\";  // This player has the same API than the RxPlayer, but with no feature // (e.g. no DASH, Smooth or Directfile playback) const player = new MinimalRxPlayer();  // use the regular APIs... player.setVolume(0.5);  You then will need to add the features you want on it. Those can be accessed through the path \"rx-player/features\": // import the DASH and Smooth features, which will be added to the RxPlayer import { DASH, SMOOTH } from \"rx-player/features\";  At last you can add those features to the imported RxPlayer class by calling the special addFeatures static method, which is only present on the minimal version of the Player: // addFeatures takes an array of features as argument MinimalRxPlayer.addFeatures([DASH, SMOOTH]);  Here is the complete example: import MinimalRxPlayer from \"rx-player/minimal\"; import { DASH, SMOOTH } from \"rx-player/features\";  MinimalRxPlayer.addFeatures([DASH, SMOOTH]);  There is also “experimental” features. Such features can completely change from one version to the next - unlike regular features which just follows semantic versioning. This means that you may have to keep the concerned code up-to-date each time you depend on a new RxPlayer version. Such features are imported from \"rx-player/experimental/features\" instead: import MinimalRxPlayer from \"rx-player/minimal\"; import { DASH_WASM } from \"rx-player/experimental/features\";  MinimalRxPlayer.addFeatures([DASH_WASM]);  You can of course depend on both experimental and regular features: import MinimalRxPlayer from \"rx-player/minimal\"; import { DASH, SMOOTH } from \"rx-player/features\"; import { DASH_WASM } from \"rx-player/experimental/features\";  MinimalRxPlayer.addFeatures([DASH, SMOOTH, DASH_WASM]);  By using the minimal version, you will reduce the final bundle file if tree-shaking is performed on the final code (like in webpack’s production mode). The key is just to know which feature does what. The next chapter will list and explain the role of every one of them.","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"importing_a_minimal_version","anchorH3":"how_it_works"},{"h1":"Importing a minimal player with feature selection","h2":"Importing a minimal version","h3":"List of features","body":"Features, which are variables imported from the \"rx-player/features\" path, are all objects declared in upper-case. Here is the anotated exhaustive list (notes are at the bottom of the table):    Feature Description of the feature     SMOOTH Enable Smooth streaming (HSS) playback   DASH Enable DASH playback using a JavaScript-based MPD parser   DIRECTFILE Enable playback of “directfile” contents   EME Enable playback of encrypted contents   NATIVE_TEXT_BUFFER [1] Allow to display text tracks through <tracks> elements   HTML_TEXT_BUFFER [1] Allow to display richer text tracks through HTML elements   IMAGE_BUFFER [1] Allow to display thumbnails through the image buffer   NATIVE_SRT_PARSER [2] Parse SRT text tracks for the native text buffer   NATIVE_VTT_PARSER [2] Parse VTT text tracks for the native text buffer   NATIVE_TTML_PARSER [2] Parse TTML text tracks for the native text buffer   NATIVE_SAMI_PARSER [2] Parse SAMI text tracks for the native text buffer   HTML_SRT_PARSER [3] Parse SRT text tracks for the HTML text buffer   HTML_VTT_PARSER [3] Parse VTT text tracks for the HTML text buffer   HTML_TTML_PARSER [3] Parse TTML text tracks for the HTML text buffer   HTML_SAMI_PARSER [3] Parse SAMI text tracks for the HTML text buffer   BIF_PARSER [4] Parse BIF image tracks for the image buffer   DASH_WASM [5] [6] Enable DASH playback using a WebAssembly-based MPD parser   LOCAL_MANIFEST [5] Enable playback of “local” contents   METAPLAYLIST [5] Enable playback of “metaplaylist” contents    Notes: [1]: You will need to also add at least one parser for this type of buffer for those features to be useful. (example: NATIVE_SRT_PARSER will parse srt subtitles for the NATIVE_TEXT_BUFFER) [2]: Those features will only be used if NATIVE_TEXT_BUFFER is an added feature. [3]: Those features will only be used if HTML_TEXT_BUFFER is an added feature. [4]: This feature will only be used if IMAGE_BUFFER is an added feature. [5]: Those type of contents are experimental. They should be imported from rx-player/experimental/features. [6]: In cases where both the DASH and DASH_WASM features are added (which are both parsers for DASH contents), the RxPlayer will default using the WebAssembly parser (provided by DASH_WASM) and fallback on the JavaScript parser (provided by DASH) when it cannot do so.","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"importing_a_minimal_version","anchorH3":"list_of_features"},{"h1":"Importing a minimal player with feature selection","h2":"Importing a minimal version","h3":"Examples","body":"To help you choose your features, are some examples that represents common usecases. unencrypted DASH contents with native webVTT subtitles import RxPlayer from \"rx-player/minimal\"; import {   DASH,   NATIVE_TEXT_BUFFER,   NATIVE_VTT_PARSER, } from \"rx-player/features\";  RxPlayer.addFeatures([DASH, NATIVE_TEXT_BUFFER, NATIVE_VTT_PARSER]);  possibly-encrypted DASH contents with HMTL webVTT and TTML subtitles import RxPlayer from \"rx-player/minimal\"; import {   DASH,   EME,   HTML_TEXT_BUFFER,   HTML_VTT_PARSER,   HTML_HTML_PARSER, } from \"rx-player/features\";  RxPlayer.addFeatures([   DASH,   EME,   HTML_TEXT_BUFFER,   HTML_VTT_PARSER,   HTML_TTML_PARSER, ]);  Smooth contents with thumbnails (BIF) support import RxPlayer from \"rx-player/minimal\"; import { SMOOTH, IMAGE_BUFFER, BIF_PARSER } from \"rx-player/features\";  RxPlayer.addFeatures([SMOOTH, IMAGE_BUFFER, BIF_PARSER]); ","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"importing_a_minimal_version","anchorH3":"examples"},{"h1":"Importing a minimal player with feature selection","h2":"Building with environment variables","body":"","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"building_with_environment_variables"},{"h1":"Importing a minimal player with feature selection","h2":"Building with environment variables","h3":"How it works","body":"You can also include only the features you need on the RxPlayer library by building it while having specific environment variables. The code related to the unwanted features should be removed when the final code is minified (as the corresponding code is made unreachable). To avoid any conflict with other environment variables, they all are named RXP_<FEATURE-NAME>. For example, the following will remove all code related to Microsoft Smooth Streaming from the build: RXP_SMOOTH=false npm run build:min ","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"building_with_environment_variables","anchorH3":"how_it_works_(1)"},{"h1":"Importing a minimal player with feature selection","h2":"Building with environment variables","h3":"List of environment variables","body":"RXP_SMOOTH True by default. If set to “false”, all code relative to HSS streaming will be ignored during a build. RXP_DASH True by default. If set to “false”, all code relative to DASH streaming will be ignored during a build. RXP_DIRECTFILE True by default. If set to “false”, all code relative to directfile streaming will be ignored during a build. RXP_LOCAL_MANIFEST False by default. If set to “true”, all code relative to the “local” transport (to be able to play content offline for example) will be included during a build. RXP_METAPLAYLIST False by default. If set to “true”, all code relative to metaplaylist streaming will be included during a build. RXP_EME True by default. If set to “false”, all code relative to encrypted contents will be ignored during a build. RXP_NATIVE_TTML True by default. If set to “false”, all code relative to TTML parsing for native text tracks will be ignored during a build. RXP_NATIVE_SAMI True by default. If set to “false”, all code relative to SAMI parsing for native text tracks will be ignored during a build. RXP_NATIVE_VTT True by default. If set to “false”, all code relative to VTT parsing for native text tracks will be ignored during a build. RXP_NATIVE_SRT True by default. If set to “false”, all code relative to SRT parsing for native text tracks will be ignored during a build. RXP_HTML_TTML True by default. If set to “false”, all code relative to TTML parsing for html text tracks [1] will be ignored during a build. RXP_HTML_SAMI True by default. If set to “false”, all code relative to SAMI parsing for html text tracks [1] will be ignored during a build. RXP_HTML_VTT True by default. If set to “false”, all code relative to VTT parsing for html text tracks [1] will be ignored during a build. RXP_HTML_SRT True by default. If set to “false”, all code relative to SRT parsing for html text tracks [1] will be ignored during a build. RXP_BIF_PARSER True by default. If set to “false”, all code relative to BIF image parsing will be ignored during a build. RXP_BAREBONE If set to true, no feature is activated by default and all other environment variables are considered as false by default (unless set). For example, to only activate DASH, you could do: RXP_BAREBONE=true RXP_DASH=true npm run build:min  RXP_ENV Either “production” or “development”. “production” as a default. In the “development” case:  logs will be activated the code will be less tolerant towards unwanted behavior the code will be less optimized  Notes: DOM element instead of a <track> (the latter here being called “native”) tag for a richer formatting.","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"building_with_environment_variables","anchorH3":"list_of_environment_variables"}]},{"file":"./Getting_Started/Glossary.html","index":[{"h1":"Glossary","body":"","anchorH1":"glossary"},{"h1":"Glossary","h2":"Overview","body":"As the RxPlayer manages multiple type of streaming technologies, which can use their own definition and terminology, we had to find a compromise and use our own terminology, which try to take the best from these. We here define various terms used in the documentation which might not be obvious right along.","anchorH1":"glossary","anchorH2":"overview"},{"h1":"Glossary","h2":"Definitions","body":"","anchorH1":"glossary","anchorH2":"definitions"},{"h1":"Glossary","h2":"Definitions","h3":"Adaptation","body":"Simply put, what we call an “Adaptation” is just an audio, video or text track. More technically, it is an element of a Period (and by extension of the Manifest) which represents a single type of media. An adaptation can be for example any of those things:  A video track A french audio track An italian text track A thumbnail track …  Many Streaming Technology have this concept even though their name can change, an Adaptation is equivalent to:  DASH’s AdaptationSet Microsoft Smooth Streaming’s StreamIndex  Note: There is minor differences between the RxPlayer’s Adaptation and DASH’ AdaptationSet. Namely multiple AdaptationSets can be merged into a single Adaptation in very specific cases. You can find more infos on it here.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"adaptation"},{"h1":"Glossary","h2":"Definitions","h3":"Bitrate","body":"In the RxPlayer, a bitrate of a Representation indicates the number of bits per second of content described by that Representation. For example, let’s imagine a video Adaptation with two Representation:  one with a bitrate at 1,000,000 (which is 1 Megabit) the other with a bitrate at 500,000 (which is 500 kilobits)  Each seconds of content described by the first Representation will be represented by 1 megabit of data Each seconds for the second Representation will be represented by 500 kilobits. Both will represent the same data, but the first one will need that the RxPlayer fetch more data to show the same amount of content. In most cases, a higher bitrate means a higher quality. That’s why the RxPlayer has to compromise between having the best quality and choosing a Representation having a low-enough bitrate to be able to play on the user’s computer without needing to pause due to poor network conditions.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"bitrate"},{"h1":"Glossary","h2":"Definitions","h3":"Buffer","body":"When we talk about the “buffer” in the RxPlayer, we most likely refer to the structures in the browser holding media data, waiting to be decoded. Several layers of buffers can be defined in the browser-side to allow to have a smooth playback, fast seeking etc.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"buffer"},{"h1":"Glossary","h2":"Definitions","h3":"Buffer type","body":"RxPlayer’s buffer types describe a single “type” of media. Example of such types are:  “video”: which represents only the video content “audio”: the audio content without the video “text”: the subtitles, for example ","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"buffer_type"},{"h1":"Glossary","h2":"Definitions","h3":"Chunk","body":"Depending on the context, a chunk can be either a sub-part of a Media Segment or the Media segment itself.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"chunk"},{"h1":"Glossary","h2":"Definitions","h3":"Initialization segment","body":"An initialization segment is a specific type of media segment, which includes metadata necessary to initialize the browser’s internal decoder. Those are sometimes needed before we can actually begin to push any “real” media segment from the corresponding Representation. As such, when one is needed, the initialization segment is the first segment downloaded for a given Representation.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"initialization_segment"},{"h1":"Glossary","h2":"Definitions","h3":"Manifest","body":"The Manifest is the generic name for the document which describes the content you want to play. This is equivalent to the DASH’s Media Presentation Description (or MPD), the Microsoft Smooth Streaming’s Manifest and the HLS’ Master Playlist. Such document can describe for example:  multiple qualities for the same video or audio tracks multiple audio tracks in different languages presence of subtitles  Note that this concept is only used in Streaming technologies. You won’t interact with a Manifest if you’re directly playing a MP4 or webM file.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"manifest"},{"h1":"Glossary","h2":"Definitions","h3":"Media segment","body":"A media segment (or simply segment), is a small chunk of media data. In many streaming technologies, a content is separated into multiple chunks of small duration (usually between 2 and 10 seconds). This allows, for reasons to long to detail here, to easily implements many features:  live streaming, language switching adaptive streaming  When you play a content with the RxPlayer, it will most of the time download media segments of different types (audio, video, text…) progressively rather than the whole content at a single time.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"media_segment"},{"h1":"Glossary","h2":"Definitions","h3":"Period","body":"Simply put, a Period defines what the content will be from a starting time to an ending time. It is an element contained in the Manifest) and it will contain the Adaptations available for the corresponding time period. Depending on the transport used, they correspond to different concepts:  for DASH contents, it is more or less the same thing than an MPD’s <Period> element for “local” contents, it corresponds to a single object from the periods array. for “MetaPlaylist” contents, it corresponds to all the Period elements we retrieved after parsing the corresponding Manifest from the elements of the contents array. any other transport will have a single Period, describing the whole content.  – As an example, let’s take a manifest describing a live content with chronologically:  an english TV Show an old italian film with subtitles an American blockbuster with closed captions.  Let’s say that those sub-contents are drastically different:  they are all in different languages the american blockbuster has more available video bitrates than the old italian one  Because the available tracks and available qualities are different from sub-content to sub-content, we cannot just give a single list of Adaptations valid for all of them. They have to be in some way separated in the Manifest object. That’s a case where Periods will be used. Here is a visual representation of how the Periods would be divided here:         Period 1                Period 2                Period 3 08h05              09h00                       10h30                 now   |==================|===========================|====================|         TV Show               Italian Film        American Blockbuster  Each of these Periods will be linked to different audio, video and text Adaptations, themselves linked to different Representations.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"period"},{"h1":"Glossary","h2":"Definitions","h3":"Representation","body":"A Representation is an element of an Adaptation, and by extension of the Manifest) that describes an interchangeable way to represent the parent Adaptation. For example, a video Adaptation can have several Representations, each having its own bitrate, its own width or its own height. The idea behind a Representation is that it can be changed by any other one in the same Adaptation as the content plays. This is most often implemented to allow multiple bitrates for the same Adaptation, to be more flexible to poor network (low bandwidth) or computing (slow computer) conditions. A Representation has its equivalent in multiple Streaming technologies. It is roughly the same as:  DASH’s Representation Microsoft Smooth Streaming’s QualityIndex HLS’ variant (the notion of variant is actually a little more complex, so here it’s not an exact comparison) ","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"representation"}]},{"file":"./Getting_Started/Troubleshooting.html","index":[{"h1":"Troubleshooting","body":"This page regroups multiple frequent problems that have been encountered with the RxPlayer associated to the found solution. If that solution does not work for you, do not hesitate to create an issue.","anchorH1":"troubleshooting"},{"h1":"Troubleshooting","h2":"autoPlay doesn’t work","body":"  If the media plays automatically despite not setting the autoPlay loadVideo option or setting it to false, check that the media element does not already have an autoplay attribute. If it has, you should remove it so the autoPlay loadVideo option work as intended. We hesitated doing it ourselves but finally chose not to, to not break other applications putting it there for a reason   If the media does not play despite setting the autoPlay loadVideo option to true, it is probably due to the browser blocking it (and in that case, you should also have received a MEDIA_ERROR warning event, with the code MEDIA_ERR_BLOCKED_AUTOPLAY). In that scenario, the content will only be able to play after a user interaction is done on the page (e.g. user clicking on a “play” button). This is a behavior forced by multiple browsers to prevent annoying autoplaying video, generally those who have sound enabled (on that matter, muting the media element might also work).  ","anchorH1":"troubleshooting","anchorH2":"%60autoplay%60_doesn't_work"},{"h1":"Troubleshooting","h2":"Text tracks does not respect the format’s style","body":"  Check that you’re not in the default \"native\" textTrackMode (when either the textTrackMode loadVideo option is not set or is set to native, or when the textTrackElement loadVideo option is not set). If you’re in that case, style-enriched subtitles are only available in the \"html\" textTrackMode. Please set both textTrackMode to \"html\" and a textTrackElement to display text tracks into.  ","anchorH1":"troubleshooting","anchorH2":"text_tracks_does_not_respect_the_format's_style"},{"h1":"Troubleshooting","h2":"Issues when switching the audio track","body":"  If audio tracks take a LOT of time on some devices to change, it may be due to how often low-level audio buffers are updated (from higher-level browser audio buffers) on that device. To fix that solution, you might want to set the audioTrackSwitchingMode loadVideo option to \"direct\" or \"reload\", if you have issues with the former value.   If you lose sound after switching the audio track and you’re in the \"direct\" audioTrackSwitchingMode, this is a known issue on some browser versions. Please change the audioTrackSwitchingMode to any other value (the closest to \"direct\" being \"reload\".  ","anchorH1":"troubleshooting","anchorH2":"issues_when_switching_the_audio_track"},{"h1":"Troubleshooting","h2":"Parts of a content are automatically skipped/seeked over","body":"The RxPlayer has two complex inner mechanisms that may lead to subparts of a content being seemingly automatically skipped:   A buffer discontinuity detection mechanism that tend to prioritize uninterrupted content playback over content completeness   A browser’s garbage collection detection mechanism that also prioritize the same aspect   When some media data appears to be skipped, it generally means to the RxPlayer that either:  no media data was available at that position media data was available, but the browser stalled trying to play it media data was available at that position, but was immediately garbage collected by the browser, potentially multiple times in a row.  You can investigate in which scenario you are by looking at the RxPlayer’s logs. If you see logs about “GC” (garbage collector) before those skip happen, you might be in the last scenario. If it appears to be insistent, you may want to check the remaining available memory on the device when it happens. If it looks very low, you might want to configure the RxPlayer so less media data is buffered in advance, through either:   the maxVideoBufferSize constructor option, or   the setMaxVideoBufferSize method  ","anchorH1":"troubleshooting","anchorH2":"parts_of_a_content_are_automatically_skipped/seeked_over"},{"h1":"Troubleshooting","h2":"Codec switching does not work","body":"By default, codec switching is performed seamlessly but that does not work on all devices. Please check the onCodecSwitch loadVideo option, and set it to \"reload\" - if that’s not already the case - to see if it fixes the issue.","anchorH1":"troubleshooting","anchorH2":"codec_switching_does_not_work"},{"h1":"Troubleshooting","h2":"The RxPlayer uses a lot of memory","body":"By default the RxPlayer uses the most memory it can to provide the best experience. It may not always what you might want however. To let you configure how much media data is kept at maximum behind and ahead of the current position, you can set respectively a “maximum buffer behind” or a “maximum buffer ahead” in seconds through either:   the maxBufferBehind and maxBufferAhead constructor options.   the setMaxBufferBehind and the setMaxBufferAhead methods   If you’re setting a “maximum buffer ahead”, please keep in mind that it should always be higher than the set “wanted buffer ahead” option wantedBufferAhead constructor option or setWantedBufferAhead method). If you want even a more precize control over memory usage of media data, you can set the “maximum video buffer size” setting through either:   the maxVideoBufferSize constructor option, or   the setMaxVideoBufferSize method  ","anchorH1":"troubleshooting","anchorH2":"the_rxplayer_uses_a_lot_of_memory"},{"h1":"Troubleshooting","h2":"Playback issues related to DRMs","body":"There is a lot of compatibility issues that may be linked to DRMs. Here is some of them.","anchorH1":"troubleshooting","anchorH2":"playback_issues_related_to_drms"},{"h1":"Troubleshooting","h2":"Playback issues related to DRMs","h3":"Issues with fallbacking with the Edge browser and PlayReady","body":"We sometimes encountered a bug which makes the player loads indefinitely when fallbacking from an undecipherable quality, if done through the fallbackOnLastTry option. This was only constated on the Edge browser and appears to be a browser or CDM bug. Sadly, no work-around has been found for now for this issue. We’re currently trying to create a reproducible scenario and document that issue so it can hopefully be fixed in the future. In the meantime, you’re encouraged either to use Widevine (only on Chromium-based Edge) or to not make use of the fallBackOnLastTry option on that browser.","anchorH1":"troubleshooting","anchorH2":"playback_issues_related_to_drms","anchorH3":"issues_with_fallbacking_with_the_edge_browser_and_playready"},{"h1":"Troubleshooting","h2":"Playback issues related to DRMs","h3":"The Player do not download any segment when playing encrypted contents","body":"This is probably due to an issue we encountered several time on embedded devices. Basically, this behavior is due to a deadlock, where the RxPlayer is waiting for the CDM logic to be initialized to download segments but the CDM logic wait for the opposite: it will only initialize itself once segments have been downloaded. The RxPlayer is waiting for the CDM initialization for a very specific usage: playing a mix of unencrypted and encrypted data. We detected that on some Chrome versions we could not play encrypted data if we first played unencrypted data without the CDM logic in place. Fortunately, this usage is for very specific cases and you most likely won’t need it (or even if you will, you most likely will not encounter that problem). You can completely remove that deadlock with a property called disableMediaKeysAttachmentLock. Like other properties introduced here, you should put it in the keySystems object of loadVideo, like such: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       disableMediaKeysAttachmentLock: true,     },     {       type: \"playready\",       getLicense,       disableMediaKeysAttachmentLock: true,     },   ], }); ","anchorH1":"troubleshooting","anchorH2":"playback_issues_related_to_drms","anchorH3":"the_player_do_not_download_any_segment_when_playing_encrypted_contents"},{"h1":"Troubleshooting","h2":"Playback issues related to DRMs","h3":"After two or several loadVideo calls the RxPlayer refuses to play","body":"There’s a chance that you’re encountering another issue we found on embedded devices. By default, the RxPlayer maintains a cache containing the last loaded licenses. This allows to quickly switch to already-played contents, an important improvement when playing live contents for example. Rest assured, our cache size is not infinite, and as such it should work on most devices. However, we found that on some devices, this logic can be problematic, and it will just refuse to add a license at a given point. You can add a property which will flush that cache anytime the content changes, called closeSessionsOnStop. Like other properties introduced here, you should put it in the keySystems object of loadVideo, like such: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       closeSessionsOnStop: true,     },     {       type: \"playready\",       getLicense,       closeSessionsOnStop: true,     },   ], }); ","anchorH1":"troubleshooting","anchorH2":"playback_issues_related_to_drms","anchorH3":"after_two_or_several_loadvideo_calls_the_rxplayer_refuses_to_play"}]},{"file":"./api/Overview.html","index":[{"h1":"RxPlayer API","body":"The API documentation is a thorough guide through every feature exposed by the RxPlayer, in a logical order. If you are already familiar with the API, you might prefer the conciseness of the API reference instead. Conversely, If you are very new to the RxPlayer and don’t want to dive deep in the API for the moment, you might want to check the Getting Started pages instead.  Only variables and methods defined here are considered as part of the API. Any other property or method you might find in any other way are not considered as part of the API and can thus change without notice.   As some terms used here might be too foreign or slightly different than the one you’re used to, we also wrote a list of terms and definitions used by the RxPlayer in a \"Glossary\" page. ","anchorH1":"rxplayer_api"}]},{"file":"./api/Creating_a_Player.html","index":[{"h1":"Creating a RxPlayer","body":"","anchorH1":"creating_a_rxplayer"},{"h1":"Creating a RxPlayer","h2":"Instantiation","body":"Instantiating a new RxPlayer is necessary before being able to load a content. Doing so is straightforward: import RxPlayer from \"rx-player\"; const player = new RxPlayer(options); ","anchorH1":"creating_a_rxplayer","anchorH2":"instantiation"},{"h1":"Creating a RxPlayer","h2":"Player options","body":"Player options are options given to the player on instantiation. It’s an object with multiple properties. None of them are mandatory. For most usecase though, you might want to set at least the associated video element via the videoElement property.","anchorH1":"creating_a_rxplayer","anchorH2":"player_options"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"videoElement","body":"type: HTMLMediaElement|undefined The media element the player will use. // Instantiate the player with the first video element in the DOM const player = new Player({   videoElement: document.getElementsByTagName(\"VIDEO\")[0], });  If not defined, a <video> element will be created without being inserted in the document. You will have to do it yourself through the getVideoElement method to add it yourself: const player = new Player();  const videoElement = player.getVideoElement(); document.body.appendChild(videoElement); ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"videoelement"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"initialVideoBitrate","body":"type: Number|undefined defaults: 0 This is a ceil value for the initial video bitrate chosen. That is, the first video Representation chosen will be both:  inferior or equal to this value. the closest possible to this value (after filtering out the ones with a superior bitrate).  If no Representation is found to respect those rules, the Representation with the lowest bitrate will be chosen instead. Thus, the default value - 0 - will lead to the lowest bitrate being chosen at first. // Begin either by the video bitrate just below or equal to 700000 bps if found // or the lowest bitrate available if not. const player = new Player({   initialVideoBitrate: 700000, });   This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"initialvideobitrate"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"initialAudioBitrate","body":"type: Number|undefined defaults: 0 This is a ceil value for the initial audio bitrate chosen. That is, the first audio Representation chosen will be:  inferior or equal to this value. the closest possible to this value (after filtering out the ones with a superior bitrate).  If no Representation is found to respect those rules, the Representation with the lowest bitrate will be chosen instead. Thus, the default value - 0 - will lead to the lowest bitrate being chosen at first. // Begin either by the audio bitrate just below or equal to 5000 bps if found // or the lowest bitrate available if not. const player = new Player({   initialAudioBitrate: 5000, });   This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"initialaudiobitrate"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"minVideoBitrate","body":"type: Number|undefined defaults: 0 Minimum video bitrate reachable through adaptive streaming. When the bitrate is chosen through adaptive streaming (i.e., not enforced manually through APIs such as setVideoBitrate), the player will never switch to a video quality with a bitrate lower than that value. The exception being when no quality has a higher bitrate, in which case the maximum quality will always be chosen instead. For example, if you want that video qualities chosen automatically never have a bitrate lower than 100 kilobits per second you can call: const player = new Player({   minVideoBitrate: 100000, });  Any limit can be removed just by setting that value to 0: // remove video bitrate lower limit player.setMinVideoBitrate(0);  You can update this limit at any moment with the setMinVideoBitrate API call. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setVideoBitrate) bypass this limit completely.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"minvideobitrate"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"minAudioBitrate","body":"type: Number|undefined defaults: 0 Minimum audio bitrate reachable through adaptive streaming. When the bitrate is chosen through adaptive streaming (i.e., not enforced manually through APIs such as setAudioBitrate), the player will never switch to an audio quality with a bitrate higher than that value. The exception being when no quality has a higher bitrate, in which case the minimum quality will always be chosen instead. For example, if you want that audio qualities chosen automatically never have a bitrate higher than 100 kilobits per second you can call: const player = new Player({   minAudioBitrate: 100000, });  Any limit can be removed just by setting that value to 0: // remove audio bitrate lower limit player.setMinAudioBitrate(0);  You can update this limit at any moment with the setMinAudioBitrate API call. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setAudioBitrate) bypass this limit completely.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"minaudiobitrate"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"maxVideoBitrate","body":"type: Number|undefined defaults: Infinity Maximum video bitrate reachable through adaptive streaming. When the bitrate is chosen through adaptive streaming (i.e., not enforced manually through APIs such as setVideoBitrate), the player will never switch to an video quality with a bitrate higher than that value. The exception being when no quality has a lower bitrate, in which case the minimum quality will always be chosen instead. For example, if you want that video qualities chosen automatically never have a bitrate higher than 1 Megabits per second you can call: const player = new Player({   maxVideoBitrate: 1e6, });  Any limit can be removed just by setting that value to Infinity: // remove video bitrate higher limit player.setMaxVideoBitrate(Infinity);  You can update this limit at any moment with the setMaxVideoBitrate API call. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setVideoBitrate) bypass this limit completely.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"maxvideobitrate"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"maxAudioBitrate","body":"type: Number|undefined defaults: Infinity Maximum audio bitrate reachable through adaptive streaming. When the bitrate is chosen through adaptive streaming (i.e., not enforced manually through APIs such as setAudioBitrate), the player will never switch to an audio quality with a bitrate higher than that value. The exception being when no quality has a lower bitrate, in which case the minimum quality will always be chosen instead. For example, if you want that audio qualities chosen automatically never have a bitrate higher than 1 Megabits per second you can call: const player = new Player({   maxAudioBitrate: 1e6, });  Any limit can be removed just by setting that value to Infinity: // remove audio bitrate higher limit player.setMaxAudioBitrate(Infinity);  You can update this limit at any moment with the setMaxAudioBitrate API call. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setAudioBitrate) bypass this limit completely.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"maxaudiobitrate"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"wantedBufferAhead","body":"type: Number|undefined defaults: 30 Set the default buffering goal, as a duration ahead of the current position, in seconds. Once this size of buffer is reached, the player won’t try to download new segments anymore.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"wantedbufferahead"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"maxVideoBufferSize","body":"type: Number|undefined defaults: Infinity Set the maximum size the video buffer can take in the memory, in kilobytes (kb). Once this value is reached, the player won’t try to download new video segments anymore. The limit is approximative as it’s based on internal estimation.  The internal checks of the RxPlayer is based on an estimation of what the RxPlayer think is currently buffered and an estimation of the size of the next segments.   In DirectFile mode (see loadVideo options), this method has no effect.   This option will have no effects if we didn't buffer at least MIN_BUFFER_LENGTH ( defaults at 5sec )   This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"maxvideobuffersize"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"preferredAudioTracks","body":"type: Array.<Object|null> defaults: [] This option allows to help the RxPlayer choose an initial audio track based on either language preferences, codec preferences or both. It is defined as an array of objects, each object describing constraints a track should respect. If the first object - defining the first set of constraints - cannot be respected under the currently available audio tracks, the RxPlayer will skip it and check with the second object and so on. As such, this array should be sorted by order of preference: from the most wanted constraints to the least. Here is all the possible constraints you can set in any one of those objects (note that all properties are optional here, only those set will have an effect on which tracks will be filtered): {   language: \"fra\", // {string|undefined} The language the track should be in                    // (in preference as an ISO 639-1, ISO 639-2 or ISO 639-3                    // language code).                    // If not set or set to `undefined`, the RxPlayer won't                    // filter based on the language of the track.    audioDescription: false // {Boolean|undefined} Whether the audio track should                           // be an audio description for the visually impaired                           // or not.                           // If not set or set to `undefined`, the RxPlayer                           // won't filter based on that status.    codec: { // {Object|undefined} Constraints about the codec wanted.            // if not set or set to `undefined` we won't filter based on codecs.      test: /ec-3/, // {RegExp} RegExp validating the type of codec you want.      all: true, // {Boolean} Whether all the profiles (i.e. Representation) in a                // track should be checked against the RegExp given in `test`.                // If `true`, we will only choose a track if EVERY profiles for                // it have a codec information that is validated by that RegExp.                // If `false`, we will choose a track if we know that at least                // A SINGLE profile from it has codec information validated by                // that RegExp.   } }  This array of preferrences can be updated at any time through the setPreferredAudioTracks method, documented here. Examples Let’s imagine that you prefer to have french or italian over all other audio languages. If not found, you want to fallback to english: const player = new RxPlayer({   preferredAudioTracks: [     { language: \"fra\", audioDescription: false },     { language: \"ita\", audioDescription: false },     { language: \"eng\", audioDescription: false },   ], });  Now let’s imagine that you want to have in priority a track that contain at least one profile in Dolby Digital Plus (ec-3 codec) without caring about the language: const player = new RxPlayer({   preferredAudioTracks: [ { codec: { all: false, test: /ec-3/ } ] });  At last, let’s combine both examples by preferring french over itialian, italian over english while preferring it to be in Dolby Digital Plus: const player = new RxPlayer({   preferredAudioTracks: [     {       language: \"fra\",       audioDescription: false,       codec: { all: false, test: /ec-3/ }     },      // We still prefer non-DD+ french over DD+ italian     { language: \"fra\", audioDescription: false },      {       language: \"ita\",       audioDescription: false,       codec: { all: false, test: /ec-3/ }     },     { language: \"ita\", audioDescription: false },      {       language: \"eng\",       audioDescription: false,       codec: { all: false, test: /ec-3/ }     },     { language: \"eng\", audioDescription: false }   ]   This option will have no effect in Directfile mode (see loadVideo options) when either :  No audio track API is supported on the current browser The media file tracks are not supported on the browser  ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"preferredaudiotracks"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"preferredTextTracks","body":"type: Array.<Object|null> defaults: [] Set the initial text track languages preferences. This option takes an array of objects describing the languages wanted for subtitles: {   language: \"fra\", // {string} The wanted language                    // (ISO 639-1, ISO 639-2 or ISO 639-3 language code)   closedCaption: false // {Boolean} Whether the text track should be a closed                        // caption for the hard of hearing }  All elements in that Array should be set in preference order: from the most preferred to the least preferred. You can set null in that array for no subtitles. When loading a content, the RxPlayer will then try to choose its text track by comparing what is available with your current preferences (i.e. if the most preferred is not available, it will look if the second one etc.). This array of preferrences can be updated at any time through the setPreferredTextTracks method, documented here. Example Let’s imagine that you prefer to have french or italian subtitles.If not found, you want no subtitles at all. const player = new RxPlayer({   preferredTextTracks: [     { language: \"fra\", closedCaption: false },     { language: \"ita\", closedCaption: false },     null,   ], });   This option will have no effect in Directfile mode (see loadVideo options) when either :  No text track API is supported on the current browser The media file tracks are not supported on the browser  ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"preferredtexttracks"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"preferredVideoTracks","body":"type: Array.<Object|null> defaults: [] This option allows to help the RxPlayer choose an initial video track. It is defined as an array of objects, each object describing constraints a track should respect. If the first object - defining the first set of constraints - cannot be respected under the currently available video tracks, the RxPlayer will skip it and check with the second object and so on. As such, this array should be sorted by order of preference: from the most wanted constraints to the least. When the next encountered constraint is set to null, the player will simply disable the video track. If you want to disable the video track by default, you can just set null as the first element of this array (e.g. [null]). Here is all the possible constraints you can set in any one of those objects (note that all properties are optional here, only those set will have an effect on which tracks will be filtered): {   codec: { // {Object|undefined} Constraints about the codec wanted.            // if not set or set to `undefined` we won't filter based on codecs.      test: /hvc/, // {RegExp} RegExp validating the type of codec you want.      all: true, // {Boolean} Whether all the profiles (i.e. Representation) in a                // track should be checked against the RegExp given in `test`.                // If `true`, we will only choose a track if EVERY profiles for                // it have a codec information that is validated by that RegExp.                // If `false`, we will choose a track if we know that at least                // A SINGLE profile from it has codec information validated by                // that RegExp.   }   signInterpreted: true, // {Boolean|undefined} If set to `true`, only tracks                          // which are known to contains a sign language                          // interpretation will be considered.                          // If set to `false`, only tracks which are known                          // to not contain it will be considered.                          // if not set or set to `undefined` we won't filter                          // based on that status. }  This array of preferrences can be updated at any time through the setPreferredVideoTracks method, documented here. Examples Let’s imagine that you prefer to have a track which contains at least one H265 profile. You can do: const player = new RxPlayer({   preferredVideoTracks: [{ codec: { all: false, test: /^hvc/ } }], });  With that same constraint, let’s no consider that the current user is deaf and would thus prefer the video to contain a sign language interpretation. We could set both the previous and that new constraint that way: const player = new RxPlayer({   preferredVideoTracks: [     // first let's consider the best case: H265 + sign language interpretation     {       codec: { all: false, test: /^hvc/ }       signInterpreted: true,     },      // If not available, we still prefer a sign interpreted track without H265     { signInterpreted: true },      // If not available either, we would prefer an H265 content     { codec: { all: false, test: /^hvc/ } },      // Note: If this is also unavailable, we will here still have a video track     // but which do not respect any of the constraints set here.   ] });  For a totally different example, let’s imagine you want to start without any video track enabled (e.g. to start in an audio-only mode). To do that, you can simply do: const player = new RxPlayer({   preferredVideoTracks: [null], });   This option will have no effect in Directfile mode (see loadVideo options) when either :  No video track API is supported on the current browser The media file tracks are not supported on the browser  ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"preferredvideotracks"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"maxBufferAhead","body":"type: Number|undefined defaults: Infinity Set the maximum kept buffer ahead of the current position, in seconds. Everything superior to that limit (currentPosition + maxBufferAhead) will be automatically garbage collected. This feature is not necessary as the browser should by default correctly remove old segments from memory if/when the memory is scarce. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. Its default value, Infinity, will remove this limit and just let the browser do this job instead. The minimum value between this one and the one returned by getWantedBufferAhead will be considered when downloading new segments.  Bear in mind that a too-low configuration there (e.g. inferior to `10`) might prevent the browser to play the content at all.  You can update that limit at any time through the setMaxBufferAhead method.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"maxbufferahead"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"maxBufferBehind","body":"type: Number|undefined defaults: Infinity Set the maximum kept buffer before the current position, in seconds. Everything before that limit (currentPosition - maxBufferBehind) will be automatically garbage collected. This feature is not necessary as the browser should by default correctly remove old segments from memory if/when the memory is scarce. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. Its default value, Infinity, will remove this limit and just let the browser do this job instead. You can update that limit at any time through the setMaxBufferBehind method.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"maxbufferbehind"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"limitVideoWidth","body":"type: Boolean defaults: false With this feature, the possible video Representations considered are filtered by width: The maximum width considered is the closest superior or equal to the video element’s width. This is done because the other, “superior” Representations will not have any difference in glossary of pixels (as in most case, the display limits the maximum resolution displayable). It thus save bandwidth with no visible difference. To activate this feature, set it to true. const player = Player({   limitVideoWidth: true, });  For some reasons (displaying directly a good quality when switching to fullscreen, specific environments), you might not want to activate this limit.  This option will have no effect for contents loaded :  In DirectFile mode (see loadVideo options). On Firefox browsers (version >= 67) : We can’t know if the Picture-In-Picture feature or window is enabled and we can’t know PIP window size. Thus we can’t rely on video element size attributes, that may not reflect the real video size when PIP is enabled.  ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"limitvideowidth"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"throttleVideoBitrateWhenHidden","body":"type: Boolean defaults: false The player has a specific feature which throttle the video to the minimum bitrate when the current video element is considered hidden (e.g. the containing page is hidden and the Picture-In-Picture mode is disabled) for more than a minute. To activate this feature, set it to true. const player = Player({   throttleVideoBitrateWhenHidden: true, });   This option will have no effect for contents loaded :  In DirectFile mode (see loadVideo options). On Firefox browsers (version >= 67) : We can’t know if the Picture-In-Picture feature or window is enabled. Thus we can’t rely on document hiddenness attributes, as the video may be visible, through the PIP window.  ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"throttlevideobitratewhenhidden"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"stopAtEnd","body":"type: Boolean defaults: true By default, the player automatically unload the content once it reaches its end (the player goes to the \"ENDED\" state). In that case, the only way to play the content again is to (re-)call the loadVideo API, which will trigger another download of the Manifest and segments. If you want to be able to seek back in the content after it ended, you may want to deactivate this behavior. To do so, set stopAtEnd to false. const player = Player({   stopAtEnd: false, }); ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"stopatend"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"throttleWhenHidden","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). This option will have no effect for contents loaded :  In DirectFile mode (see loadVideo options). On Firefox browsers (version >= 67) : We can’t know if the Picture-In-Picture feature or window is enabled. Thus we can’t rely on document hiddenness attributes, as the video may be visible, through the PIP window.   Please use the throttleVideoBitrateWhenHidden property instead, which is better defined for advanced cases, such as Picture-In-Picture. type: Boolean defaults: false The player has a specific feature which throttle the video to the minimum bitrate when the current page is hidden for more than a minute. To activate this feature, set it to true. const player = Player({   throttleWhenHidden: true, }); ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"throttlewhenhidden"}]},{"file":"./api/Loading_a_Content.html","index":[{"h1":"Loading a Content","body":"","anchorH1":"loading_a_content"},{"h1":"Loading a Content","h2":"The loadVideo method","body":"The loadVideo method of the RxPlayer loads the content described in the argument. This is the central method to use when you want to play a new content. Options available are described in the next chapters. Despite its name, this method can also load audio-only content.","anchorH1":"loading_a_content","anchorH2":"the_%60loadvideo%60_method"},{"h1":"Loading a Content","h2":"The loadVideo method","h3":"Example","body":"player.loadVideo({   url: \"http://vm2.dashif.org/livesim-dev/segtimeline_1/testpic_6s/Manifest.mpd\",   transport: \"dash\",   autoPlay: true, }); ","anchorH1":"loading_a_content","anchorH2":"the_%60loadvideo%60_method","anchorH3":"example"},{"h1":"Loading a Content","h2":"loadVideo options","body":"loadVideo receives a single object in argument which can take several properties all defined here.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"transport","body":"type: string|undefined The transport protocol used for this content. This property is mandatory. Can be either:   \"dash\" - for DASH contents. If you’re using the minimal build of the player, you will need to add at least either one of the following features to be able to play DASH contents:   the DASH feature (rely on a generally-sufficient JavaScript parser)   the DASH_WASM experimental feature (backed by a WebAssembly parser, more efficient when handling very large MPDs). More information in the DASH_WASM experimental feature documentation.   or both (which will use the latter only when available)     \"smooth\" - for Microsoft Smooth Streaming contents If you’re using the minimal build of the player, you will need to add at least the SMOOTH feature to be able to play Smooth contents.   \"directfile\" - for loading a video in DirectFile mode, which allows to directly play media files (example: .mp4 or .webm files) without using a transport protocol. With that option, you can even play HLS contents on multiple browsers (mainly safari and iOS browsers). If you’re using the minimal build of the player, you will need to add at least the DIRECTFILE feature to be able to play those contents.      In that mode, multiple APIs won't have any effect.   This is documented in the documentation of each concerned method, option or   event in the API.    \"metaplaylist\" for MetaPlaylist streams, which are a concatenation of multiple smooth and DASH contents If you’re using the minimal build of the player, you will need to add at least the METAPLAYLIST experimental feature to be able to play those contents.   \"local\" for local manifests, which allows to play downloaded DASH, Smooth or MetaPlaylist contents (when offline for example). If you’re using the minimal build of the player, you will need to add at least the LOCAL_MANIFEST experimental feature to be able to play those contents.   Example: // play some dash content rxPlayer.loadVideo({   transport: \"dash\",   url: \"https://www.example.com/dash.mpd\", }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"transport"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"url","body":"type: string|undefined For Smooth, DASH or MetaPlaylist contents, the URL to the Manifest (or equivalent) For DirectFile mode contents, the URL of the content (the supported contents depends on the current browser). This property is mandatory unless either:   a manifestLoader is defined in the transportOptions, in which case that callback will be called instead any time we want to load the Manifest.   an initialManifest is defined in the transportOptions, in which case this will be used as the first version of the Manifest. Note however that if the Manifest needs to be refreshed and no url nor manifestLoader has been set, the RxPlayer will most likely fail and stop playback.   Example: // play some dash content rxPlayer.loadVideo({   url: \"https://www.example.com/dash.mpd\",   transport: \"dash\", }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"url"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"keySystems","body":"type: Array.<Object>|undefined keySystems allows to define every options relative to the encryption of the wanted content. This property is mandatory if the content relies on DRM and needs to be decrypted but unnecessary if the content is not encrypted. As keySystems options are numerous, they are described in its own documentation page, Decryption Options.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"keysystems"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"autoPlay","body":"type: Boolean|undefined defaults: false If set to true, the video will play immediately after being loaded.  On some browsers, auto-playing a media without user interaction is blocked due to the browser's policy.   In that case, the player won't be able to play (it will stay in a `LOADED` state) and you will receive a warning event containing a `MEDIA_ERROR` with the code: `MEDIA_ERR_BLOCKED_AUTOPLAY`.   A solution in that case would be to propose to your users an UI element to trigger the play with an interaction. ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"autoplay"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"startAt","body":"type: Object|undefined startAt allows to define a starting position in the played content whether it is a live content or not. This option is only defining the starting position, not the beginning of the content. The user will then be able to navigate anywhere in the content through the seekTo API. If defined, this property must be an object containing a single key. This key can be either:   position (Number): The starting position, in seconds.   wallClockTime (Number|Date): The starting wall-clock time (re-scaled position from Manifest information to obtain a timestamp on live contents), in seconds. Useful to use the type of time returned by the getWallClockTime API for live contents. If a Date object is given, it will automatically be converted into seconds.   fromFirstPosition (Number): relative position from the minimum possible one, in seconds. That is:  for dynamic (live) contents, from the beginning of the buffer depth (as defined by the Manifest). for non-dynamic (vod) contents, from the position 0 (this option should be equivalent to position)    fromLastPosition (Number): relative position from the maximum possible one, in seconds. Should be a negative number:  for dynamic (e.g. live) contents, it is the difference between the starting position and the currently last possible position, as defined by the manifest. for VoD contents, it is the difference between the starting position and the end position of the content.    percentage (Number): percentage of the wanted position. 0 being the minimum position possible (0 for static content, buffer depth for dynamic contents) and 100 being the maximum position possible (duration for VoD content, last currently possible position for dynamic contents).    Only one of those properties will be considered, in the same order of priority they are written here.  If the value set is inferior to the minimum possible position, the minimum possible position will be used instead. If it is superior to the maximum possible position, the maximum will be used instead as well. More information on how the initial position is chosen can be found in the specific documentation page on this subject. Notes for dynamic contents For dynamic contents, startAt could work not as expected:   Depending on the type of Manifest, it will be more or less precize to guess the current last position of the content. This will mostly affect the fromLastPosition option.   If the Manifest does not allow to go far enough in the past (not enough buffer, server-side) to respect the position wanted, the maximum buffer depth will be used as a starting time instead.   If the Manifest does not allow to go far enough in the future to respect the position wanted, the current last available position will be used to define the starting time instead.   If startAt is not set on live contents, the time suggested by the Manifest will be considered. If it is also not set, the initial position will be based on the real live edge. Example // using position player.loadVideo({   // ...   startAt: {     position: 10, // start at position == 10 (in seconds)   }, });  // using wall-clock time player.loadVideo({   // ...   startAt: {     wallClockTime: Date.now() / 1000 - 60, // 1 minute before what's broadcasted     // now   }, });  // using fromFirstPosition player.loadVideo({   // ...   startAt: {     fromFirstPosition: 30, // 30 seconds after the beginning of the buffer   }, });  // using fromLastPosition player.loadVideo({   // ...   startAt: {     fromLastPosition: -60, // 1 minute before the end   }, }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"startat"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"transportOptions","body":"type: Object|undefined  This option has no effect in DirectFile mode (see  transport option)  Options concerning the “transport”. That is, the part of the code:  performing Manifest and segment requests parsing the Manifest parsing/updating/creating segments  This Object can contain multiple properties. Only those documented here are considered stable:   minimumManifestUpdateInterval (number|undefined): Set the minimum time, in milliseconds, we have to wait between Manifest updates. A Manifest may need to be updated in regular intervals (e.g. many DASH dynamic contents depend on that behavior). The frequency at which we normally update a Manifest depends on multiple factors: the information taken from the Manifest, the transport chosen or the current playback conditions. You might want to use minimumManifestUpdateInterval to limit that frequency to a minimum. This option is principally useful on some embedded devices where resources are scarce. The request and data decompression done at each Manifest update might be too heavy for some and reducing the interval at which they are done might help. Please note however than reducing that frequency can raise the chance of rebuffering, as we might be aware of newly generated segments later than we would be without that option. Example: rxPlayer.loadVideo({   // ...   transportOptions: {     minimumManifestUpdateInterval: 5000, // Perform Manifest updates at most     // every 5 seconds   }, });    initialManifest (string|Document|Object|ArrayBuffer): Manifest that will be initially used (before any potential Manifest refresh). Some applications pre-load the Manifest to parse some information from it before calling loadVideo. As in that case the Manifest has already been loaded, an application can optimize content loading time by giving to the RxPlayer that already-loaded Manifest so the latter can avoid doing another request for it. The format accepted for that option depends on the current chosen transport:   for \"dash\" and \"smooth\" contents either a string (of the whole Manifest’s xml data) or a corresponding Document format is accepted.   for \"metaplaylist\", either a string (for the whole JSON) or the corresponding JS Object is accepted.   for \"local\", only the corresponding local Manifest as a JS object is accepted.   Note that using this option could have implications for live contents. Depending on the content, the initial playing position and maximum position could be calculated based on that option’s value. In a case where the corresponding Manifest request was performed long before the loadVideo call, the RxPlayer could be for example initially playing far from the real live edge. Because of that, it is recommended to only set that options for live/dynamic contents if its request was done immediately before the loadVideo call.   manifestUpdateUrl (string|undefined): Set a custom Manifest URL for Manifest updates. This URL can point to another version of the Manifest with a shorter timeshift window, to lighten the CPU, memory and bandwidth impact of Manifest updates. Example: rxPlayer.loadVideo({   transport: \"dash\",   url: \"https://example.com/full-content.mpd\",   transportOptions: {     manifestUpdateUrl: \"https://example.com/content-with-shorter-window.mpd\",   }, });  When the RxPlayer plays a live content, it may have to refresh frequently the Manifest to be aware of where to find new media segments. It generally uses the regular Manifest URL when doing so, meaning that the information about the whole content is downloaded again. This is generally not a problem though: The Manifest is generally short enough meaning that this process won’t waste much bandwidth memory or parsing time. However, we found that for huge Manifests (multiple MB uncompressed), this behavior could be a problem on some low-end devices (some set-top-boxes, chromecasts) where slowdowns can be observed when Manifest refresh are taking place. The manifestUpdateUrl will thus allow an application to provide a second URL, specifically used for Manifest updates, which can represent the same content with a shorter timeshift window (e.g. using only 5 minutes of timeshift window instead of 10 hours for the full Manifest). The content will keep its original timeshift window and the RxPlayer will be able to get information about new segments at a lower cost.   representationFilter (Function|undefined): Allows to filter out Representations (i.e. media qualities) from the Manifest to avoid playing them. rxPlayer.loadVideo({   // ...   transportOptions: {     representationFilter(representation, infos) {       // ...     },   }, });  More infos on it can be found here.   segmentLoader (Function|undefined): Defines a custom segment loader for when you want to perform the requests yourself. rxPlayer.loadVideo({   // ...   transportOptions: {     segmentLoader(infos, callbacks) {       // logic to download a segment     },   }, });  More info on it can be found here.   manifestLoader (function|undefined): Defines a custom Manifest loader (allows to set a custom logic for the Manifest request). rxPlayer.loadVideo({   // ...   transportOptions: {     manifestLoader(url, callbacks) {       // logic to fetch the Manifest     },   }, });  More info on it can be found here.   checkMediaSegmentIntegrity (boolean|undefined): If set to true, the RxPlayer will retry a media segment request if that segment seems corrupted. If not set or set to false, the RxPlayer might interrupt playback in the same situation. You can set this option if you suspect the CDN providing your contents to sometimes send you incomplete/corrupted segments. Example: rxPlayer.loadVideo({   // ...   transportOptions: {     checkMediaSegmentIntegrity: true,   }, });    serverSyncInfos (Object|undefined): Allows to provide a time synchronization mechanism between the client and the server. This value is mainly useful for live DASH contents based on a SegmentTemplate scheme without SegmentTimeline elements as those rely on having a synchronized clock on the client side. The serverSyncInfos object contains two keys:   serverTimestamp (number): Unix timestamp of the server at a given point in time, in milliseconds.   clientTime (number): Value of the performance.now() API at the time the serverTimestamp value was true. Please note that if your page contains multiple worker, the performance.now() call should be done on the same worker than the one in which loadVideo is called.  The `performance.now()` API is used here because it is the main API to obtain a monotically increasing clock on the client-side.    Example: const timeResponse = await fetch(timeServerURL); const clientTime = performance.now(); const serverTimestamp = await timeResponse.text(); const serverSyncInfos = { serverTimestamp, clientTime }; rxPlayer.loadVideo({   // ...   transportOptions: { serverSyncInfos }, });  If indicated, we will ignore any time indication on the MPD and only consider serverSyncInfos to calculate the time on the server side. This value is also very useful for low-latency contents, as some of them do not indicate any server’s time, relying on the client one instead. Note that there is a risk of us losing synchronization when leap seconds are added/substracted to unix time. However we consider those situations rare enough (and the effect should be relatively weak) to let this as is for the moment. For a complete explanation, you can look at the corresponding chapter of the low-latency documentation.   aggressiveMode (boolean|undefined): If set to true, we will try to download segments very early, even if we are not sure they had time to be completely generated. For the moment, this mode has only an effect for all Smooth contents and some DASH contents relying on a number-based SegmentTemplate segment indexing scheme. The upside is that you might have the last segments sooner. The downside is that requests for segments which did not had time to generate might trigger a NetworkError. Depending on your other settings (especially the networkConfig loadVideo options), those errors might just be sent as warnings and the corresponding requests be retried. Example: rxPlayer.loadVideo({   // ...   transportOptions: {     aggressiveMode: true,   }, });    referenceDateTime (number|undefined): Only useful for live contents. This is the default amount of time, in seconds, to add as an offset to a given media content’s time, to obtain the real live time. For example, if the media has it’s 0 time corresponding to the 30th of January 2010 at midnight, you can set the referenceDateTime to new Date(2010-01-30) / 1000. This value is useful to communicate back to you the “live time”, for example through the getWallClockTime method. This will only be taken into account for live contents, and if the Manifest / MPD does not already contain an offset (example: an “availabilityStartTime” attribute in a DASH MPD). Example: rxPlayer.loadVideo({   // ...   transportOptions: {     referenceDateTime: new Date(2015 - 05 - 29) / 1000,   }, });   ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"transportoptions"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"textTrackMode","body":"type: string defaults: \"native\"  This option has no effect in DirectFile mode (see  transport option)  This option allows to specify how the text tracks should be displayed. There is two possible values:  \"native\" \"html\"  In the default \"native\" mode, a <track> element will be created on the video and the subtitles will be displayed by it, with a minimal style. There is no action on your side, the subtitles will be correctly displayed at the right time. In \"html\" mode, the text tracks will be displayed on a specific HTML element. This mode allows us to do much more stylisation, such as the one defined by TTML styling attributes or SAMI’s CSS. It is particularly useful to correctly manage complex closed captions (with multiple colors, positionning etc.). With this mode, you will need to provide a wrapper HTML element with the textTrackElement option. All text track formats supported in \"native\" mode also work in \"html\" mode. More infos on supported text tracks can be found in the text track documentation.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"texttrackmode"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"textTrackElement","body":"type: HTMLElement  This option has no effect in DirectFile mode (see  transport option)  textTrackElement is only required and used if you provided a \"html\" textTrackMode. This property will be the element on which text tracks will be set, as child elements, at the right time. We expect that this element is the exact same size than the media element it applies to (this allows us to properly place the subtitles position without polling where the video is in your UI). You can however re-size or update the style of it as you wish, to better suit your UI needs.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"texttrackelement"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"audioTrackSwitchingMode","body":"type: string defaults: \"seamless\"  This option has no effect in DirectFile mode (see  transport option)  Behavior taken by the player when switching to a different audio track, through the setAudioTrack method. Those are the possible values for that option:   \"seamless\": The transition between the old audio track and the new one happens seamlessly, without interruption. This is the default behavior. As an inconvenient, you might have at worst a few seconds in the previous audio track before the new one can be heard.   \"direct\": The player will try to switch to the new audio track as soon as possible, which might lead to a brief interruption and rebuffering period (where the RxPlayer is in the BUFFERING state) while it is doing so.   \"reload\" The player will directly switch to the new audio track (like direct) but may reload the media to do so. During this reloading step, there might be a black screen instead of the video and the RxPlayer might go into the RELOADING state temporarily. Although it provides a more aggressive transition than the \"direct\" mode (because it goes through a reloading step with a black screen), the \"reload\" mode might be preferable in specific situations where \"direct\" is seen to have compatibility issues. We observed such issues with some contents and devices combinations, if you observe issues such as losing the audio or video glitches just after changing the audio track while the \"direct\" mode is used, you may want to use the \"reload\" mode instead. More information about the \"RELOADING\" state can be found in the player states documentation.  ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"audiotrackswitchingmode"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"manualBitrateSwitchingMode","body":"type: string defaults: \"seamless\"  This option has no effect in DirectFile mode (see  transport option)  Strategy you want to adopt when updating “manually” the video and audio quality through respectively the setVideoBitrate and setAudioBitrate API while the content is playing. There is two possible values:   \"seamless\": Manual quality updates will be only visible after a little time. This gives the advantage of a very smooth “seamless” transition. In this mode, you will have the following behavior:  there will be no visual “cut” between the previous and new quality parts of the content with a better (or the same) quality won’t be replaced. parts of the content with a lower quality will be only replaced when the better quality is downloaded.    \"direct\": Manual quality updates will be visible more directly, but with a complete reload of the current content. You might encounter a black screen while the player go through the \"RELOADING\" state [1]. In this mode, you will have the following behavior:  there will be a black screen between the previous and new quality the previous content will be entirely removed you will only have content with the new quality  [1] More information about the \"RELOADING\" state can be found in the player states documentation.  ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"manualbitrateswitchingmode"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"onCodecSwitch","body":"type: string defaults: \"continue\"  This option has no effect in DirectFile mode (see  transport option)  Behavior taken by the player when switching to either an audio or video track which has a codec “incompatible” with the previous one (for example going from avc, a.k.a h264 to hevc, a.k.a. h265). This switch can either after the user switches from one track to another or after encountering a new Period in some transport technologies (concept existing for DASH, “local” and MetaPlaylist contents). Can be set to one of those two values:   \"continue\": try to have a seamless transition between both codecs. This behavior works on most modern browsers but might lead to problems like infinite buffering and decoding errors on older browsers and peculiar platforms. This is the default behavior.   \"reload\": When switching from one codec to another - incompatible - one, the RxPlayer will “reload” the content: the player will go into the \"RELOADING\" state for a small amount of time, during which the video will disappear and many APIs will become unavailable, before playing the track with the new codec. That behavior has the advantage of working on any platform but disadvantage of having a visible transition when those type of codec switches happen. Use it if you have issues with codec switching on some platforms. More information about the \"RELOADING\" state can be found in the player states documentation.  ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"oncodecswitch"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"lowLatencyMode","body":"type: Boolean defaults: false Allow to play DASH low-latency contents (with Chunk-encoded and chunk-transferred CMAF segments) with a low latency efficiently. In the some rare browsers who do not support the fetch API (like IE11 or the BlackBerry browser), we might be more prone to rebuffering in that mode the first few seconds. If you want to have a better experience on those browsers, you might want to begin to play further from the live edge in those cases through the startAt option. More information on playing low-latency DASH contents can be found in the corresponding documentation page.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"lowlatencymode"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"networkConfig","body":"type: Object defaults: {}  This option has no effect in DirectFile mode (see  transport option)  Configuration linked to Manifest and segment requests. This object can take the following properties (all are optional):   segmentRetry (Number): Maximum number of times a segment request will be retried when an error happen - only on some condition [1]. Those retry will be done with a progressive delay, to avoid overloading a CDN. When this count is reached, the player will stop and throw a fatal error. Defaults to 4.   manifestRetry (Number): Maximum number of times a Manifest request will be retried when a request error happen - only on some condition [1]. Defaults to 4. Those retry will be done with a progressive delay, to avoid overloading a CDN. When this count is reached, the player will stop and throw a fatal error. Defaults to 4.   offlineRetry (Number): Maximum number of times a request will be retried when the request fails because the user is offline. Those retry will be done with a progressive delay, to avoid overloading the user’s ressources. When this count is reached, the player will stop and throw a fatal error. Defaults to Infinity.   [1] To retry a request, one of the following condition should be met:   The request failed because of a 404 HTTP code   The request failed because of an HTTP code in the 500 family   The request failed because of a timeout   the request failed because of an unknown request error (might be a parsing/interface error)  ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"networkconfig"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"enableFastSwitching","body":"type: boolean defaults: true  This option has no effect in DirectFile mode (see  transport option)  Enable (when set to true and by default) or disable (when set to false) the “fast-switching” feature. “Fast-switching” is an optimization which allows the RxPlayer to replace low-quality segments (i.e. with a low bitrate) with higher-quality segments (higher bitrate) in the buffer in some situations. This is used for example to obtain a faster quality transition when the user’s network bandwidth raise up: instead of pushing the new high-quality segments at the end of the current buffer, we push them much sooner - “on top” of already pushed low-quality segments - so the user can quickly see the better quality. In most cases, this is a feature you want. On some rare devices however, replacing segments is poorly supported. We’ve for example seen on a few devices that old replaced segments were still decoded (and not the new better-quality segments that should have replaced them). On other devices, replacing segments resulted in visible small decoding issues. Setting enableFastSwitching to false thus allows to disable the fast-switching behavior. Note that it is - sadly - difficult to know when you need to disable it. In the great majority of cases, enabling fast-switching (the default behavior) won’t lead to any problem. So we advise to only disable it when you suspect that segment replacement when the quality raises is at the source of some issues you’re having (in which case it will help to see if that’s really the case). It is also warning to add that setting enableFastSwitching to false only disable the fast-switching feature and not all the logic where the RxPlayer is replacing segments it already pushed to the buffer. Forbiding the RxPlayer to replace segments altogether is today not possible and would even break playback in some situations: when multi-Period DASH contents have overlapping segments, when the browser garbage-collect partially a segment…","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"enablefastswitching"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"hideNativeSubtitle","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs).  type: Boolean defaults: false  This option has no effect in DirectFile mode (see  transport option)  If set to true, the eventual <track> element will be put on mode hidden when added to the video element, so it won’t actually display the subtitles the rx-player add to it. This has an effect only if:   the current textTrackMode is equal to \"native\" (see textTrackMode option)   a text track is currently active   the text track format is understood by the rx-player  ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"hidenativesubtitle"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"supplementaryImageTracks","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). If you want to parse and display a BIF image track, you can use the parseBifThumbnails tool, which will also work for Directfile contents.  type: Array.<Object>|Object|undefined defaults: []  This option has no effect in DirectFile mode (see  transport option)  This option allows to specify information about supplementary image tracks you might want to add to those already declared in the Manifest. This only work under the following conditions:   the image track is not fragmented   the image track can be retrieved by fetching a single URL   the image track is in an understood format and enough information has been given to infer it.   Each of those can have the following properties: const supplementaryImageTracks = [   {     url: ImageTrackURL, // {string} The url on which the complete image track can     // be obtained      mimeType: \"application/bif\", // {string} A mimeType used to describe     // the image format.   }, ]; ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"supplementaryimagetracks"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"supplementaryTextTracks","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). If you want to use supplementary text tracks not defined in the content itself, you can use the TextTrackRenderer which also works for Directfile contents.  type: Array.<Object>|Object|undefined defaults: []  This option has no effect in DirectFile mode (see  transport option)  This option allows to specify information about supplementary text tracks you might want to add to those already declared in the Manifest. This only work under the following conditions:   the text track is not fragmented   the text track can be retrieved by fetching a single URL   the text track is in an understood format and enough information has been given to infer it.   Each of those can have the following properties: const supplementaryTextTracks = [{   url: textTrackURL, // {string} The url on which the complete text track can be                      // obtained    language: \"eng\", // {string} The language the text track is in                    // (ISO 639-1, ISO 639-2 or ISO 639-3 language code)                     // Note for SAMI subtitles:                    // For SAMI subtitles, you have to provide the same language                    // string than the one indicated in the CSS and p elements.                    // It usually follows the ISO639-ISO3166 naming conventions                    // (e.g. en-US or fr-FR).                    // If we cannot find the provided language in the downloaded                    // SAMI text track, it won't be displayed.    closedCaption: false // {Boolean} Whether the text track is a closed caption                        // for the hard of hearing    mimeType: \"application/mp4\", // {string} A mimeType used to describe                                // the text format. Can be \"application/mp4\" when                                // encapsulated in an mp4 file. In that case, the                                // \"codecs\" argument will be needed.    codecs: \"stpp\"               // {string|undefined} Depending on the mimeType,                                // you might need to add codec information.                                // Here the mimeType is too generic, the codec                                // helps us understand this is ttml in an mp4                                // container }];  To know which type of formats are supported and how to add them, you can read the text track documentation.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"supplementarytexttracks"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"defaultAudioTrack","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). Please use the  preferredAudioTracks constructor option or the  setPreferredAudioTracks method instead.  type: Object|string|undefined The starting default audio track. This can be under the form of an object with the following properties: const defaultAudioTrack = {   language: \"fra\", // {string} The wanted language   // (ISO 639-1, ISO 639-2 or ISO 639-3 language code)   audioDescription: false, // {Boolean} Whether the audio track should be an   // audio description for the visually impaired };  or under the form of the language string directly, in which case the \"audioDescription\" option is inferred to be false. // equivalent to the previous example const defaultAudioTrack = \"fra\";  If the corresponding audio track is not found, the first track defined will be taken instead.  This option might have no effect in DirectFile mode (see  transport option) ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"defaultaudiotrack"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"defaultTextTrack","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). Please use the  preferredTextTracks constructor option or the  setPreferredTextTracks method instead.  type: Object|string|undefined The starting default text track. This can be under the form of an object with the following properties: const defaultTextTrack = {   language: \"fra\", // {string} The wanted language   // (ISO 639-1, ISO 639-2 or ISO 639-3 language code)   closedCaption: false, // {Boolean} Whether the text track should be a closed   // caption for the hard of hearing };  or under the form of the language string directly, in which case the \"closedCaption\" option is inferred to be false: // equivalent to the previous example const defaultTextTrack = \"fra\";  If the corresponding text track is not found, the first track defined will be taken instead.  This option might have no effect in DirectFile mode (see  transport option) ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"defaulttexttrack"}]},{"file":"./api/Decryption_Options.html","index":[{"h1":"Decryption Options","body":"","anchorH1":"decryption_options"},{"h1":"Decryption Options","h2":"Overview","body":"The RxPlayer has a lot of decryption-related options that you can give when calling the loadVideo method, itself described in the previous documentation page. This page will desribe most of them. In the case you find this documentation hard to grasp, we’ve written a tutorial on DRM configuration here.","anchorH1":"decryption_options","anchorH2":"overview"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","body":"keySystems is a loadVideo option allowing to communicate your decryption-related preferences. It takes the form of an array of objects, themselves potentially containing any of the properties described here. Each object in the keySystems array will describe decryption configuration, from the most preferred (the one you wish to be apply) to the least preferred (the fallback configurations). That way, the RxPlayer will first try to apply the configuration linked to the first object. If it fails, it will try the second and so on. If all configurations fail, the RxPlayer will stop playback with an ENCRYPTED_MEDIA_ERROR with the INCOMPATIBLE_KEYSYSTEMS code (see error documentation). Mostly, the type and getLicense properties are usually mandatory for encrypted contents. Depending on your situation you might also want to set other options.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"type","body":"type: string Name of the DRM system used. Can be either one of:  \"widevine\" \"playready\" \"clearkey\"  For more specific (or just different ones), the full reverse domain name of the key system can be used instead, for example:  \"com.widevine.alpha\", \"com.microsoft.playready.hardware\" \"com.apple.fps.1_0\" etc.  Example rxPlayer.loadVideo({   // ...   keySystems: [     {       type: \"com.microsoft.playready.recommendation\",       // ...     }     // ...   ] }); ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"type"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"getLicense","body":"type: Function Callback which will be triggered everytime a message is sent by the Content Decryption Module (CDM), usually to fetch/renew the license. Gets two arguments when called:  the message (Uint8Array): The message, formatted to an Array of bytes. the messageType (string): String describing the type of message received. There is only 4 possible message types, all defined in the w3c specification.  This function should return either synchronously the license, null to not set a license for this message event or a Promise which should either:  resolve if the license was fetched, with the licence in argument resolve with null if you do not want to set a license for this message event reject if an error was encountered.  Note: We set a 10 seconds timeout by default on this request (configurable through the keySystems[].getLicenseConfig object). If the returned Promise do not resolve or reject under this limit, the RxPlayer will stop with an error. In any case, if a license is provided by this function it should be under a BufferSource type (example: an Uint8Array or an ArrayBuffer). If this callback throws or rejects, the RxPlayer will either:   retry if new retry attempts can be done according to the parameters given as getLicenseConfig and if the noRetry property of the last rejected/throwed value was not set to true. In that case an error with the KEY_LOAD_ERROR code will still be emitted through a warning event to indicate that this attempt as failed.   stop playback, emitting an error event with the KEY_LOAD_ERROR code, if no attempt is left to be done (or if the noRetry property of the last throwed/rejected error was set to true) AND if the fallbackOnLastTry property on the last throwed/rejected error was not set to true.   try to fallback to a different Representation (a.k.a. media profile) if no attempt is left to be done (or if the noRetry property of the last throwed/rejected error was set to true) AND if the fallbackOnLastTry property on the last throwed/rejected error WAS set to true. In that case an error with the KEY_LOAD_ERROR code will still be emitted through a warning event to indicate that this attempt as failed. If we have no Representation to fallback to anymore, we will throw a MediaError with a NO_PLAYABLE_REPRESENTATION code, as documented in the errors documentation.   If the getLicense call throws/rejects, you can add any of the following properties (none are mandatory) to configure the behavior of the RxPlayer relative to that failure:   noRetry (Boolean): If set to true, we won’t make another attempt to call getLicense. Its failure getLicense another time. This will result in: trigger a fallback to other Representations (and a KEY_LOAD_ERROR warning being sent) or th will throw directly a KEY_LOAD_ERROR. the current retry parameters will be applied (see getLicenseConfig)   message (string): If the message property is set as a “string”, this message will be set as the message property of the corresponding EncryptedMediaError (either communicated through an \"error\" event if we’re not retrying or through a \"warning\" event if we’re retrying). As every other getLicense-related errors, this error will have the KEY_LOAD_ERROR code property.   fallbackOnLastTry (boolean): If this getLicense is the last retry (if the noRetry property is set to true, this is always true), we will not throw immediately but rather try to fallback on other Representations (e.g. qualities) which might have a different decryption key. If no Representation is left, we will throw a MediaError with a NO_PLAYABLE_REPRESENTATION code, as documented in the errors documentation. You will receive a decipherabilityUpdate event when we fallback from a given Representation. You can find documentation on this event in the corresponding chapter of the events documentation. This option is thus only useful for contents depending on multiple licenses. When fallbacking, we might need to reload the current MediaSource, leading to a black screen during a brief instant. When reloading, the RxPlayer will have the \"RELOADING\" player state. on most situations, we will however not reload the media source but only perform a very little seek (of some milliseconds). you might see the stream stutter for a very brief instant at that point. On the Edge browser, we found an issue that can arise when this option is set if PlayReady is used. This issue can make the player loads the content indefinitely. Sadly, no work-around has been found for now for this issue. We’re currently trying to create a reproducible scenario and document that issue so it can hopefully be fixed in the future. In the meantime, you’re encouraged either to use Widevine (only on Chromium-based Edge) or to not make use of the fallBackOnLastTry option on that browser.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"getlicense"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"getLicenseConfig","body":"type: Object | undefined Optional configuration for the keySystems[].getLicense callback. Can contain the following properties:   retry (Number|undefined) (default: 2): number of time getLicense is retried on error or on timeout before we fail on a KEY_LOAD_ERROR   timeout (Number|undefined) (default: 10000): timeout, in milliseconds after which we consider the getLicense callback to have failed. Set it to -1 to disable any timeout.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"getlicenseconfig"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"serverCertificate","body":"type: BufferSource | undefined Eventual certificate used to encrypt messages to the license server. If set, we will try to set this certificate on the CDM. If it fails, we will still continue to try deciphering the content (albeit a warning will be emitted in that case with the code \"LICENSE_SERVER_CERTIFICATE_ERROR\").","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"servercertificate"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"persistentLicense","body":"type: Boolean | undefined Set it to true if you want the ability to persist the license for later retrieval. In that case, you will also need to set the licenseStorage attribute to be able to persist the license through your preferred method. Note that not all licenses can be persisted, this is dependent both on the loaded licenses and on the Content Decryption Module used in the browser.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"persistentlicense"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"licenseStorage","body":"type: Object | undefined Required only if persistentLicense has been set to true. This is an object containing the following properties:   save (Function): function which takes into argument an Array.<Object> which will contain information on all the DRM sessions the RxPlayer currently needs to save. No return value is needed.   load (Function): Function which takes no argument and returns the last stored Array.<Object> (the last one given to save).   disableRetroCompatibility (boolean): If set to true the RxPlayer might not be able to load licenses persisted through an older RxPlayer version. This will allow to unlock some optimizations, for example to allow a faster loading of the current content. We recommend setting that option to true if retrieving persisted licenses through older versions are not that warning to you.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"licensestorage"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"fallbackOn","body":"type: Object | undefined This advanced option allows to fallback on other Representations (a.k.a. quality) when one of them has its decription key refused. This option is thus only useful for contents depending on multiple keys. This object can have the following properties:   keyInternalError: fallback when the corresponding key has the \"internal-error\" status. We found that most widevine implementation use this status to signal that a key is refused.   keyOutputRestricted: fallback when the corresponding key has the \"output-restricted\" status. This is the proper status for a key refused due to output restrictions.   For most cases where you want to fallback in case of a refused key, we recommend setting both properties to true. You will receive a decipherabilityUpdate event when we fallback from a given Representation. You can find documentation on this event in the corresponding chapter of the events documentation. When fallbacking, we might need to reload the current MediaSource, leading to a black screen during a brief instant. When reloading, the RxPlayer will have the \"RELOADING\" player state. If we have no Representation to fallback to anymore, we will throw a MediaError with a NO_PLAYABLE_REPRESENTATION code, as documented in the errors documentation.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"fallbackon"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"maxSessionCacheSize","body":"type: number | undefined The RxPlayer maintains a cache of recently opened MediaKeySession (and consequently of recently fetched licenses) as an optimization measure. That way, loading a content whose license had already been fetched won’t necessitate a new license request, leading to shorter loading times and less requests. The size of this cache is usually kept relatively low (in the 10s) by the player. We found out however that some devices have an even lower limit for the number of MediaKeySession that can be created at the same time. The maxSessionCacheSize option allows to configure the maximum number of MediaKeySession that should be kept “alive” at the same time. Any supplementary older MediaKeySession will be closed, at least when the time comes to create a new one.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"maxsessioncachesize"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"closeSessionsOnStop","body":"type: Boolean | undefined If set to true, the MediaKeySession created for a content will be immediately closed when the content stops its playback. This might be required by your key system implementation (most often, it is not). If set to false or not set, the MediaKeySession can be reused if the same content needs to be re-decrypted. If you want to set this property because the current device has a limited number of MediaKeySession that can be created at the same time, prefer using maxSessionCacheSize instead.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"closesessionsonstop"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"singleLicensePer","body":"type: string | undefined Allows to use optimally a single license for multiple decryption keys. Can be set to the following values:   \"init-data\": This is the default value. Under that behavior, the RxPlayer will try to fetch a new license any time it encounters an unknown encryption initialization data in the current content. This usually means that a license will be fetched any time a new decryption key is encountered, which is the most sensible thing to do in most cases.   \"content\": Only fetch a single license for the whole content, even if the content has multiple keys. Under that behavior, only a single license will be fetched, with a “challenge” generated from the first encryption initialization data encountered. Not only that, all Representations (qualities) whose key was not present in the license will be fallbacked from[1], meaning that they won’t be played anymore.   \"periods\": Each license fetched will be assumed to be for a group of Periods. That is, the RxPlayer will assume that any license fetched:   will contain all the compatible keys for the Period of the Representation for which the license request was done. That is, if the license request was done for a Representation in the second Period, the license fetched will be assumed to contain all compatible keys linked to the second Period. This means that all expected keys which are absent will be considered as not compatible - thus their corresponding Representation will be fallbacked from[1]).   may contain all compatible keys for some other Periods (or all other Periods). The rule here is that as long as the license contain at least one decryption key linked to a Representation of any other Period, the RxPlayer will assume that the license server returned all compatible keys for that Period. Any other key linked to that Period but absent from the license will considered as not compatible - and thus their corresponding Representation will be fallbacked from[1].   This option allows to avoid doing too much license requests (compared to the default “init-data” mode) for contents encrypted with multiple keys, but also may be preferable to the “content” mode in any of the following situations:   You don’t know all upcoming keys in advance. Here you can just communicate them by groups of Periods   The devices on which the RxPlayer will play are not able to store all keys needed for a single content at once Here you can just provide a limited number of keys, linked to a limited number of Periods.     [1] Note that while fallbacking, it is possible that the player goes into the \"RELOADING\" state (during which the video will disappear and many APIs will become unavailable). More information about the \"RELOADING\" state can be found in the player states documentation. You can set this option as an optimization (to only perform a single license requests instead of many while playing contents encrypted with multiple keys) but only if the corresponding optimizations have also been performed on the side of the license server (to return a license for every keys even if one for a single key was asked for).","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"singlelicenseper"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"disableMediaKeysAttachmentLock","body":"type: Boolean | undefined In regular conditions, we might want to wait for the media element to have decryption capabilities (what we call here “MediaKeys attachment”) before beginning to load the actual content. Waiting for that capability validation first allows for example to play a content which contains both encrypted and unencrypted data on Chrome and Chromium-derived browsers. However, we found that on some peculiar devices (like some set-top boxes) this can create a deadlock: the browser might wait for some content to be loaded before validating the media element’s decryption capabilities. Because we didn’t find a good enough compromise for now, we added the disableMediaKeysAttachmentLock boolean. By setting it to true, we won’t wait for “MediaKeys attachment” before pushing the first content. The downside being that content of mixed unencrypted/encrypted data might not be playable with that configuration. You can try that property if your encrypted contents seems to be loading indefinitely on some peculiar targets.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"disablemediakeysattachmentlock"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"distinctiveIdentifierRequired","body":"type: Boolean | undefined When set to true, the use of Distinctive Indentifier(s) or Distinctive Permanent Identifier(s) will be required. This is not needed for most use cases.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"distinctiveidentifierrequired"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"persistentStateRequired","body":"type: Boolean | undefined Set it to true if the chosen CDM should have the ability to persist state. This includes session data and any other type of state, but does not include distinctive identifiers, for which there’s another keySystems option, distinctiveIdentifierRequired. If the persistentLicense keySystems option has been set to true, setting this value to true is redundant and therefore unnecessary (as exploiting persistent licenses already necessitate the ability to persist session state). This is very rarely needed.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"persistentstaterequired"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"throwOnLicenseExpiration","body":"type: Boolean | undefined true by default. If set to true or not set, the playback will be interrupted as soon as one of the current licenses expires. In that situation, you will be warned with an error event with, as a payload, an error with the code KEY_STATUS_CHANGE_ERROR. If set to false, the playback of the current content will not be interrupted even if one of the current licenses is expired. It might however stop decoding in that situation. It’s then up to you to update the problematic license, usually through the usual getLicense callback. You may want to set this value to false if a session expiration leads to a license renewal. In that case, content may continue to play once the license has been updated.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"throwonlicenseexpiration"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"onKeyStatusesChange","body":"type: Function | undefined Callback triggered each time one of the key’s status is updated except for the following statuses and conditions (in which cases the RxPlayer throws instead):  expired if (and only if) keySystems[].throwOnLicenseExpiration is not set to false internal-error if (and only if) keySystems[].fallbackOn.keyInternalError is not set set to true  This option is very rarely needed (if ever). Takes 2 arguments:  The keystatuseschange event {Event} The session associated with the event {MediaKeySession}  Like getLicense, this function should return a promise which either emits a license or null (for no license) when resolved. It can also return directly the license or null if it can be done synchronously. In the case this callback throws or rejects, the playback will stop and an \"error\" event will be sent with a KEY_STATUS_CHANGE_ERROR code property. You can set the message property on the rejected/thrown value as a string. In this case, that string will be used as the error message of the KEY_STATUS_CHANGE_ERROR error (and used at its message property).","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"onkeystatuseschange"},{"h1":"Decryption Options","h2":"Example","body":"Example of a simple DRM configuration for widevine and playready DRMs: player.loadVideo({   url: manifestURL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense(challenge) {         // ajaxPromise is here an AJAX implementation doing a POST request on the         // widevineLicenseServer with the challenge in its body.         return ajaxPromise(widevineLicenseServer, challenge);       },     },     {       type: \"playready\",       getLicense(challenge) {         // idem         // Note: you may need to format the challenge before doing the request         // depending on the server configuration.         return ajaxPromise(playreadyLicenseServer, challenge);       },     },   ], }); ","anchorH1":"decryption_options","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getPlayerState.html","index":[{"h1":"getPlayerState","body":"","anchorH1":"getplayerstate"},{"h1":"getPlayerState","h2":"Description","body":"Returns the “state” the player is currently in. Can be either one of those strings:   \"STOPPED\": The player is idle. No content is loading nor is loaded.   \"LOADING\": The player is loading a new content. Most APIs related to the current content are not yet available while the content is loading.   \"LOADED\": The player has loaded the new content, it is now ready to play. From this point onward you can use APIs interacting with the current content such as seekTo or setAudioTrack.   \"PLAYING\": The player is currently playing the content.   \"PAUSED\": The player has paused.   \"ENDED\": The player has reached the end of the current content.   \"BUFFERING\": the player has reached the end of the buffer and is waiting for data to be appended.   \"SEEKING\": The player has reached the end of the buffer because a seek has been performed, new segments are being loaded.   \"RELOADING\": The player needs to reload its current (for example, when switching the current video track). While this state is active, most API related to the currently playing content are not available. This state should be treated like the LOADING state.   As it is a central part of our API and can be difficult concept to understand, we have a special page of documentation on player states.","anchorH1":"getplayerstate","anchorH2":"description"},{"h1":"getPlayerState","h2":"Syntax","body":"const state = player.getPlayerState();   return value string:  The current state of the player. ","anchorH1":"getplayerstate","anchorH2":"syntax"},{"h1":"getPlayerState","h2":"Example","body":"switch (player.getPlayerState()) {   case \"STOPPED\":     console.log(\"No content is/will be playing\");     break;   case \"LOADING\":     console.log(\"A new content is currently loading\");     break;   case \"LOADED\":     console.log(\"The new content is loaded and ready to be played\");     break;   case \"PLAYING\":     console.log(\"The content is currently playing\");     break;   case \"PAUSED\":     console.log(\"The content is currently paused\");     break;   case \"BUFFERING\":     console.log(\"The content is buffering new data\");     break;   case \"SEEKING\":     console.log(\"The content is still seeking, waiting for new data\");     break;   case \"ENDED\":     console.log(\"The content has reached the end.\");     break;   case \"RELOADING\":     console.log(\"The content is currently reloading\");     break;   default:     console.log(\"This is impossible (issue material!).\");     break; } ","anchorH1":"getplayerstate","anchorH2":"example"}]},{"file":"./api/Basic_Methods/addEventListener.html","index":[{"h1":"addEventListener","body":"","anchorH1":"addeventlistener"},{"h1":"addEventListener","h2":"Description","body":"Add an event listener to trigger a callback as it happens. The callback will have the event payload as a single argument. The RxPlayer API is heavily event-based. As an example: to know when a content is loaded, the most straightforward way is to add an event listener for the \"playerStateChange\" event. This can be done only through this method. To have the complete list of player events, consult the Player events page.","anchorH1":"addeventlistener","anchorH2":"description"},{"h1":"addEventListener","h2":"Syntax","body":"player.addEventListener(event, callback);    arguments:   event string: The wanted event’s name.   callback Function: The callback for the event. The same callback may be used again when calling removeEventListener.    ","anchorH1":"addeventlistener","anchorH2":"syntax"},{"h1":"addEventListener","h2":"Example","body":"player.addEventListener(\"error\", function (err) {   console.log(`The player stopped with an error: ${err.message}`); }); ","anchorH1":"addeventlistener","anchorH2":"example"}]},{"file":"./api/Basic_Methods/removeEventListener.html","index":[{"h1":"removeEventListener","body":"","anchorH1":"removeeventlistener"},{"h1":"removeEventListener","h2":"Description","body":"Remove an event listener. That is, remove a callback previously registered with addEventListener from being triggered on the corresponding event. This also free-up the corresponding ressources. The callback given is optional: if not given, every registered callback to that event will be removed.","anchorH1":"removeeventlistener","anchorH2":"description"},{"h1":"removeEventListener","h2":"Syntax","body":"// Remove all callbacks linked to event player.removeEventListener(event);  // Remove specific listener player.removeEventListener(event, callback);    arguments:   event string: The event name.   callback (optional) Function|undefined: The callback given when calling the corresponding addEventListener API.    ","anchorH1":"removeeventlistener","anchorH2":"syntax"},{"h1":"removeEventListener","h2":"Example","body":"player.removeEventListener(\"playerStateChange\", listenerCallback); ","anchorH1":"removeeventlistener","anchorH2":"example"}]},{"file":"./api/Basic_Methods/play.html","index":[{"h1":"play","body":"","anchorH1":"play"},{"h1":"play","h2":"Description","body":"Play/resume the current loaded video. Equivalent to a video element’s play method. You might want to call that method either to start playing (when the content is in the \"LOADED\" state and auto-play has not been enabled in the last loadVideo call) or to resume when the content has been paused. The returned Promise informs you on the result:   if playback succeeds, the Promise is fulfilled   if playback fails, the Promise is rejected along with an error message explaining the failure - coming directly from the browser. Such failure can for example be due to your browser’s policy, which may forbid to call play on a media element without any user interaction. Please note that in that case, you will also receive a warning event containing a MEDIA_ERROR with the code: MEDIA_ERR_PLAY_NOT_ALLOWED.    On browsers which do not support Promises natively (such as Internet Explorer 11), a JavaScript implementation is provided instead. This implementation has the exact same implementation than ES2015 Promises.  You might want for a content to be loaded before being able to play (the current state has to be different than LOADING, RELOADING or STOPPED).","anchorH1":"play","anchorH2":"description"},{"h1":"play","h2":"Syntax","body":"player.play();   return value Promise.<void>: Resolves when the play operation succeeded or reject when it failed. ","anchorH1":"play","anchorH2":"syntax"},{"h1":"play","h2":"Example","body":"const resumeContent = () => {   player.play(); }; ","anchorH1":"play","anchorH2":"example"}]},{"file":"./api/Basic_Methods/pause.html","index":[{"h1":"pause","body":"","anchorH1":"pause"},{"h1":"pause","h2":"Description","body":"Pause the current loaded video. Equivalent to a video element’s pause method. Note that a content can be paused even if its current state is BUFFERING or SEEKING. You might want for a content to be loaded before being able to pause (the current state has to be different than LOADING, RELOADING or STOPPED).","anchorH1":"pause","anchorH2":"description"},{"h1":"pause","h2":"Syntax","body":"player.pause(); ","anchorH1":"pause","anchorH2":"syntax"},{"h1":"pause","h2":"Example","body":"const pauseContent = () => {   player.pause(); }; ","anchorH1":"pause","anchorH2":"example"}]},{"file":"./api/Basic_Methods/stop.html","index":[{"h1":"stop","body":"","anchorH1":"stop"},{"h1":"stop","h2":"Description","body":"Stop playback of the current content if one. This will totaly un-load the current content. To re-start playing the same content, you can either call the reload method or just call loadVideo again.","anchorH1":"stop","anchorH2":"description"},{"h1":"stop","h2":"Syntax","body":"player.stop(); ","anchorH1":"stop","anchorH2":"syntax"},{"h1":"stop","h2":"Example","body":"const stopVideo = () => {   player.stop(); }; ","anchorH1":"stop","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getPosition.html","index":[{"h1":"getPosition","body":"","anchorH1":"getposition"},{"h1":"getPosition","h2":"Description","body":"Returns the current media element’s playing position, in seconds. For live contents, the returned position will not be re-scaled to correspond to a live timestamp. If you want that behavior, you can call getWallClockTime instead. This is the only difference between the two. Generally, you can follow the following rule:   if you want to use that current position to use it with the other APIs (like seekTo, getMinimumPosition, getMaximumPosition etc.) use getPosition - as this is the real position in the media.   if you want to display the current position to the viewer/listener, use getWallClockTime instead - as it will be set in the proper scale for live contents to display the right live time.  ","anchorH1":"getposition","anchorH2":"description"},{"h1":"getPosition","h2":"Syntax","body":"const position = player.getPosition();   return value number: The current media element’s position. ","anchorH1":"getposition","anchorH2":"syntax"},{"h1":"getPosition","h2":"Example","body":"const pos = player.getPosition(); console.log(`The video element's current position is: ${pos} second(s)`); ","anchorH1":"getposition","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getWallClockTime.html","index":[{"h1":"getWallClockTime","body":"","anchorH1":"getwallclocktime"},{"h1":"getWallClockTime","h2":"Description","body":"Returns the current “wall-clock” playing position in seconds. That is:   for live contents, this is the current position scaled to correspond to a live timestamp, in seconds.   for non-live contents, returns the position from the absolute beginning time of the content, also in seconds. In the absolute majority of cases this will be equal to the value returned by getPosition.   Use this method to display the current position to the user.","anchorH1":"getwallclocktime","anchorH2":"description"},{"h1":"getWallClockTime","h2":"Syntax","body":"const wallClockTime = player.getWallClockTime();   return value number: Current “wall-clock” position. ","anchorH1":"getwallclocktime","anchorH2":"syntax"},{"h1":"getWallClockTime","h2":"Example","body":"const wallClockTime = player.getWallClockTime(); const nowInSeconds = Date.now() / 1000; const delta = nowInSeconds - wallClockTime;  if (delta < 5) {   // (5 seconds of margin)   console.log(\"You're playing live\"); } else {   console.log(`You're playing ${delta} seconds behind the live content`); } ","anchorH1":"getwallclocktime","anchorH2":"example"}]},{"file":"./api/Basic_Methods/seekTo.html","index":[{"h1":"seekTo","body":"","anchorH1":"seekto"},{"h1":"seekTo","h2":"Description","body":"Seek in the current content (i.e. change the current position). The argument can be an object with a single Number property, either:   relative: seek relatively to the current position   position: seek to the given absolute position (equivalent to player.getVideoElement().currentTime = newPosition)   wallClockTime: seek to the given wallClock position, as returned by getWallClockTime.   The argument can also just be a Number property, which will have the same effect than the position property (absolute position). Seeking should only be done when a content is loaded (i.e. the player isn’t in the STOPPED, LOADING or RELOADING state). The seek operation will start as soon as possible, in almost every cases directly after this method is called. You will know when the seek is being performed and has been performed respectively by listening to the seeking and seeked player events (see the player events page). While seeking, the RxPlayer might also switch to the SEEKING state.","anchorH1":"seekto","anchorH2":"description"},{"h1":"seekTo","h2":"Syntax","body":"player.seekTo(position);    arguments:  position Object|number: The position you want to seek to.   ","anchorH1":"seekto","anchorH2":"syntax"},{"h1":"seekTo","h2":"Examples","body":"// seeking to 54 seconds from the start of the content player.seekTo({ position: 54 });  // equivalent to just: player.seekTo(54);  // seeking 5 seconds after the current position player.seekTo({ relative: 5 });  // seeking 5 seconds before the current position player.seekTo({ relative: -5 });  // seeking to live content player.seekTo({ wallClockTime: Date.now() / 1000 }); ","anchorH1":"seekto","anchorH2":"examples"}]},{"file":"./api/Basic_Methods/getMinimumPosition.html","index":[{"h1":"getMinimumPosition","body":"","anchorH1":"getminimumposition"},{"h1":"getMinimumPosition","h2":"Description","body":"Returns the minimum seekable player position. Returns null if no content is loaded. This is useful for live contents, where the earliest time at which it is possible to seek usually evolves over time. This method allows to know the earliest possible time a seek can be performed at any point in time. As the given position is the absolute minimum position, you might add a security margin (like a few seconds) when seeking to this position in a live content. Not doing so could led to the player being behind the minimum position after some time (e.g. because of buffering or decoding issues), and thus unable to continue playing. You will be alerted if the player’s position fell behind the minimum possible position by receiving a warning event (see the player events page) with an error having a MEDIA_TIME_BEFORE_MANIFEST code property (see the player errors page). Note that you can also have those warnings without any seek operation, e.g. due to buffering for too long. For VoD contents, as the minimum position normally doesn’t change, seeking at the minimum position should not cause any issue.","anchorH1":"getminimumposition","anchorH2":"description"},{"h1":"getMinimumPosition","h2":"Syntax","body":"const minimumPosition = player.getMinimumPosition();   return value number|null: Minimum seekable position. null if no content is currently loaded. ","anchorH1":"getminimumposition","anchorH2":"syntax"},{"h1":"getMinimumPosition","h2":"Example","body":"// Seeking close to the minimum position (with a 5 seconds security margin) player.seekTo({ position: player.getMinimumPosition() + 5 }); ","anchorH1":"getminimumposition","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getMaximumPosition.html","index":[{"h1":"getMaximumPosition","body":"","anchorH1":"getmaximumposition"},{"h1":"getMaximumPosition","h2":"Description","body":"Returns the maximum seekable player position. Returns null if no content is currently loaded. This is useful for live contents, where this position might be updated continously as new content is generated. This method allows thus to seek directly at the live edge of the content. Please bear in mind that seeking exactly at the maximum position is rarely a good idea:  for VoD contents, the playback will end for live contents, the player will then need to wait until it can build enough buffer.  As such, we advise to remove a few seconds from that position when seeking.","anchorH1":"getmaximumposition","anchorH2":"description"},{"h1":"getMaximumPosition","h2":"Syntax","body":"const maximumPosition = player.getMaximumPosition();   return value number|null: Maximum seekable position. null if no content is currently loaded. ","anchorH1":"getmaximumposition","anchorH2":"syntax"},{"h1":"getMaximumPosition","h2":"Example","body":"// seeking 5 seconds before the end (or the live edge for live contents) player.seekTo({   position: player.getMaximumPosition() - 5, }); ","anchorH1":"getmaximumposition","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getVideoDuration.html","index":[{"h1":"getVideoDuration","body":"","anchorH1":"getvideoduration"},{"h1":"getVideoDuration","h2":"Description","body":"Returns the duration of the current content as taken from the media element.  This duration is in fact the maximum position possible for the content. As such, for contents not starting at the position 0, this value will not be equal to the difference between the maximum and minimum possible position, as would normally be expected from a property named \"duration\". ","anchorH1":"getvideoduration","anchorH2":"description"},{"h1":"getVideoDuration","h2":"Syntax","body":"const duration = player.getVideoDuration();   return value number: Current content duration, as taken from the media element. ","anchorH1":"getvideoduration","anchorH2":"syntax"},{"h1":"getVideoDuration","h2":"Example","body":"const pos = player.getPosition(); const dur = player.getVideoDuration();  console.log(`current position: ${pos} / ${dur}`); ","anchorH1":"getvideoduration","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getError.html","index":[{"h1":"getError","body":"","anchorH1":"geterror"},{"h1":"getError","h2":"Description","body":"Returns the current “fatal error” if one happenned for the last loaded content. Returns null otherwise. A “fatal error” is an error which led the current loading/loaded content to completely stop. Such errors are usually also sent through the \"error\" event when they happen. See the Player Error documentation for more information.","anchorH1":"geterror","anchorH2":"description"},{"h1":"getError","h2":"Syntax","body":"const currentError = player.getError();   return value Error|null: The current fatal Error or null if no fatal error happened yet. ","anchorH1":"geterror","anchorH2":"syntax"},{"h1":"getError","h2":"Example","body":"const error = player.getError();  if (!error) {   console.log(\"The player did not crash\"); } else if (error.code === \"PIPELINE_LOAD_ERROR\") {   console.error(\"The player crashed due to a failing request\"); } else {   console.error(`The player crashed: ${error.code}`); } ","anchorH1":"geterror","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getVideoElement.html","index":[{"h1":"getVideoElement","body":"","anchorH1":"getvideoelement"},{"h1":"getVideoElement","h2":"Description","body":"Returns the media element used by the RxPlayer. You’re not encouraged to use its APIs as they can enter in conflict with the RxPlayer’s API. Despite its name, this method can also return an audio element if the RxPlayer was instantiated with one.","anchorH1":"getvideoelement","anchorH2":"description"},{"h1":"getVideoElement","h2":"Syntax","body":"const elt = player.getVideoElement();   return value HTMLMediaElement: The media element attached to the RxPlayer. ","anchorH1":"getvideoelement","anchorH2":"syntax"},{"h1":"getVideoElement","h2":"Example","body":"const videoElement = player.getVideoElement(); videoElement.className = \"my-video-element\"; ","anchorH1":"getvideoelement","anchorH2":"example"}]},{"file":"./api/Basic_Methods/dispose.html","index":[{"h1":"dispose","body":"","anchorH1":"dispose"},{"h1":"dispose","h2":"Description","body":"Free the ressources used by the player. You can call this method if you know you won’t need the RxPlayer anymore.  The player won't work correctly after calling this method. ","anchorH1":"dispose","anchorH2":"description"},{"h1":"dispose","h2":"Syntax","body":"player.dispose(); ","anchorH1":"dispose","anchorH2":"syntax"}]},{"file":"./api/Basic_Methods/reload.html","index":[{"h1":"reload","body":"","anchorH1":"reload"},{"h1":"reload","h2":"Description","body":"Re-load the last loaded content as fast as possible. This API can be called at any time after a content has been loaded (the LOADED state has been reached), even if the player has been stopped since and even if it was due to a fatal error. The user may need to call this API in several cases. For example, it may be used in case of an error that will not reproduce or inversely when the error is consistent at a certain playback time (e.g. due to a specific chunk defect). The options argument is an object containing :  reloadAt (Object | undefined): The object contain directives about the starting playback position :  relative (string | undefined) : start playback relatively from the last playback position (last played position before entering into STOPPED or ENDED state). position (string|undefined) : absolute position at which we should start playback    If no reload position is defined, start playback at the last playback position. Note that despite this method’s name, the player will not go through the RELOADING state while reloading the content but through the regular LOADING state - as if loadVideo was called on that same content again.","anchorH1":"reload","anchorH2":"description"},{"h1":"reload","h2":"Syntax","body":"// without options player.reload();  // or with options player.reload(options)`    arguments:  options (optional) Object | undefined: Optional requirements, e.g. at which position the player should reload.   ","anchorH1":"reload","anchorH2":"syntax"},{"h1":"reload","h2":"Example","body":"player.addEventListener(\"error\", (error) => {   if (error.code === \"BUFFER_APPEND_ERROR\") {     // Try to reload after the last playback position, in case of defectuous     // media content at current time.     player.reload({ reloadAt: { relative: +5 } });   } else {     // Try to reload at the last playback position     player.reload();   } }); ","anchorH1":"reload","anchorH2":"example"}]},{"file":"./api/Player_States.html","index":[{"h1":"Player states","body":"The player state, that you can obtain either with the getPlayerState method or through the playerStateChange player event, is a central part of our API: it is from this value that you will know:  when a new content finished loading when the content is paused to build buffer when the content is ended as a generality, in what “state” is the player currently  As such, it is important this concept is understood when developping with the rx-player, which is exactly the point of this page.","anchorH1":"player_states"},{"h1":"Player states","h2":"List of possible states","body":"Today the player can have one of these 9 possible states:  STOPPED LOADING LOADED PLAYING PAUSED BUFFERING SEEKING ENDED RELOADING ","anchorH1":"player_states","anchorH2":"list_of_possible_states"},{"h1":"Player states","h2":"List of possible states","h3":"The STOPPED state","body":"STOPPED is the default state of the player. It indicates that no content is playing. To simplify state exploitation, STOPPED is also emitted as a transition state when loading a new content while another one was currently loaded (or loading). That way, you can just listen to the STOPPED state to know when the current content is not loaded anymore. When the player encounters an error, it will also stop and switch to the STOPPED state.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_stopped_state"},{"h1":"Player states","h2":"List of possible states","h3":"The LOADING state","body":"The LOADING state indicates that a new content is currently loading. It appears only after the STOPPED state. That means that the player is currently downloading enough of the content to be able to play it. While this state is active, most of the content-related APIs (like setAudioTrack) are not available. You have to wait for the LOADED state for that.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_loading_state"},{"h1":"Player states","h2":"List of possible states","h3":"The LOADED state","body":"LOADED appears only after a LOADING state, and indicates that the current content can now be played. From this point onward, most of the content-related APIs (like setAudioTrack) are now available. If the autoPlay loadVideo option has been set to true, the state will then switch to PLAYING directly. Else, the player will usually be paused and stay in the LOADED state (there is some edge cases, see the “Possible state transitions” chapter for more information).","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_loaded_state"},{"h1":"Player states","h2":"List of possible states","h3":"The PLAYING state","body":"Indicates that the player is currently playing the content.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_playing_state"},{"h1":"Player states","h2":"List of possible states","h3":"The PAUSED state","body":"Indicates that the player is currently paused in the content.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_paused_state"},{"h1":"Player states","h2":"List of possible states","h3":"The BUFFERING state","body":"The content is paused because it needs to build buffer. The player will not play until it gets out of this state.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_buffering_state"},{"h1":"Player states","h2":"List of possible states","h3":"The SEEKING state","body":"The content is paused because it needs to build buffer after seeking in the content (this can be seen as a special BUFFERING case). The player will not play until it gets out of this state.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_seeking_state"},{"h1":"Player states","h2":"List of possible states","h3":"The ENDED state","body":"The player reached the end of the content. If the stopAtEnd player option has been set to true or not set, the player will immediately stop the content. In that case, the ENDED state can be considered like the STOPPED state - in terms of what you can do. Else, it should now be paused at the last frame if a video content is available at this time and this state acts like what you can expect from HTML5 playback:   when seeking when the content is ended, you will be paused (even if you were playing before)   after calling play, you will play back from the beginning  ","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_ended_state"},{"h1":"Player states","h2":"List of possible states","h3":"The RELOADING state","body":"This state indicates that the player needs to “re-load” then content. This can happen for different reasons:   When you switch the video track for another one, when the previous one was currently decoding.   When you update manually the audio and video bitrate through respectively the setAudioBitrate and setVideoBitrate APIs (Only if you set the manualBitrateSwitchingMode loadVideo option to \"direct\").   In those cases, we need to stop and reload the content on the browser-side, due to browser limitation. While this state is active, multiple player API are unavailable:  you cannot play or pause you cannot seek you cannot obtain the position or duration you cannot get or switch the available video, text or audio tracks. you cannot get or switch the available video or audio bitrates.  This is why we sometime recommend to manage this state as if it was the LOADING state (where those APIs - and other - are also not available). However, the player won’t go to the LOADED state after RELOADING, you will instead know that it had finished reloading simply when it goes out of this state (see the “Possible state transitions” chapter for more information).","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_reloading_state"}]},{"file":"./api/Player_Events.html","index":[{"h1":"Player events","body":"","anchorH1":"player_events"},{"h1":"Player events","h2":"Overview","body":"To communicate about events (like an error or the update of the current video bitrate) the player use the event listener pattern. As documented in the API, you can call addEventListener to register a callback for a particular event, like: player.addEventListener(\"videoBitrateChange\", (newVideoBitrate) => {   console.log(\"the video bitrate changed to:\", newVideoBitrate); });  You can unregister a callback through the removeEventListener API, documented here.","anchorH1":"player_events","anchorH2":"overview"},{"h1":"Player events","h2":"Basic events","body":"This chapter describes the most important events sent by the player.","anchorH1":"player_events","anchorH2":"basic_events"},{"h1":"Player events","h2":"Basic events","h3":"playerStateChange","body":"payload type: string Emit the current state of the player, every time it changes. This is the event to catch if you want to know when the player is playing, is paused, is rebuffering, is ended or is stopped. As it is a central part of our API and can be difficult concept to understand, we have a special page of documentation on player states.","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"playerstatechange"},{"h1":"Player events","h2":"Basic events","h3":"error","body":"payload type: Error Triggered when a fatal error happened. A fatal error is an error that led the player to stop playing the current content. The payload is the corresponding error. See the Player Error documentation for more information.","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"error"},{"h1":"Player events","h2":"Basic events","h3":"warning","body":"payload type: Error Triggered each time a minor error happened. This error won’t lead the RxPlayer to stop the content. It can for example be an HTTP request error, some minor error detected in the content or the current position being to far below the minimum playable position. The payload is the corresponding error. See the Player Error documentation for more information.","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"warning"},{"h1":"Player events","h2":"Basic events","h3":"positionUpdate","body":"payload type: Object Emit information about the current position at most every seconds (also emits every time various player events are received). The object emitted as the following properties:   position (Number): The current position in the video, in seconds.   duration (Number): The duration of the content.   bufferGap (Number): The gap, in seconds, between the current position and the end of the current buffered range.   playbackRate (Number): The current playback rate the content is on.   liveGap (Number|undefined): Only for live contents. The gap between the current position and the “live edge”. Might not be set for directfile contents.   maximumBufferTime (Number|undefined): The maximum time until which the buffer can currently be filled. That is:   for static contents (like VoD), the duration.   for dynamic contents (like live contents), the current maximum available position (live edge for live contents) minus a security margin we added to avoid buffering ahead of it.     wallClockTime (Number|undefined): Only for live contents. The current time converted to wall-clock time in seconds. That is the real live position (and not the position as announced by the video element).  ","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"positionupdate"},{"h1":"Player events","h2":"Basic events","h3":"seeking","body":"Emitted when a “seek” operation (to “move”/“skip” to another position) begins on the currently loaded content.","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"seeking"},{"h1":"Player events","h2":"Basic events","h3":"seeked","body":"Emitted when a “seek” operation (to “move”/“skip” to another position) on the currently loaded content has finished","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"seeked"},{"h1":"Player events","h2":"Track selection events","body":"This chapter describes events linked to the current audio, video or text track.","anchorH1":"player_events","anchorH2":"track_selection_events"},{"h1":"Player events","h2":"Track selection events","h3":"availableAudioTracksChange","body":"payload type: Array.<Object> Triggered when the currently available audio tracks change (e.g.: at the beginning of the content, when period changes…). The array emitted contains object describing each available audio track:   active (Boolean): Whether the track is the one currently active or not.   id (string): The id used to identify the track. Use it for setting the track via setAudioTrack.   language (string): The language the audio track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   audioDescription (Boolean): Whether the track is an audio description of what is happening at the screen.   dub (Boolean|undefined): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between audio tracks. This information is usually set only if the current Manifest contains one.   This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"availableaudiotrackschange"},{"h1":"Player events","h2":"Track selection events","h3":"availableVideoTracksChange","body":"payload type: Array.<Object> Triggered when the currently available video tracks change (e.g.: at the beginning of the content, when period changes…). The array emitted contains object describing each available video track:   id (string): The id used to identify the track. Use it for setting the track via setVideoTrack.   active (Boolean): Whether this track is the one currently active or not.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between video tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation.   bitrate (Number): The bitrate of this Representation, in bits per seconds.   width (Number|undefined): The width of video, in pixels.   height (Number|undefined): The height of video, in pixels.   codec (string|undefined): The codec given in standard MIME type format.   frameRate (string|undefined): The video framerate.     This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"availablevideotrackschange"},{"h1":"Player events","h2":"Track selection events","h3":"availableTextTracksChange","body":"payload type: Array.<Object> Triggered when the currently available text tracks change (e.g.: at the beginning of the content, when period changes…). The array emitted contains object describing each available text track:   id (string): The id used to identify the track. Use it for setting the track via setTextTrack.   language (string): The language the text track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between text tracks. This information is usually set only if the current Manifest contains one.   closedCaption (Boolean): Whether the track is specially adapted for the hard of hearing or not.   active (Boolean): Whether the track is the one currently active or not.   This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"availabletexttrackschange"},{"h1":"Player events","h2":"Track selection events","h3":"audioTrackChange","body":"payload type: Object|null Information about the current audio track, each time it changes (the last received segment got a new one). The payload is an object describing the new track, with the following properties:   id (Number|string): The id used to identify the track.   language (string): The language the audio track is in.   audioDescription (Boolean): Whether the track is an audio description of what is happening at the screen.   dub (Boolean|undefined): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between audio tracks. This information is usually set only if the current Manifest contains one.   This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"audiotrackchange"},{"h1":"Player events","h2":"Track selection events","h3":"textTrackChange","body":"payload type: Object|null Information about the current text track, each time it changes (the last received segment got a new one). The payload is an object describing the new track, with the following properties:   id (Number|string): The id used to identify the track.   language (string): The language the text track is in.   closedCaption (Boolean): Whether the track is specially adapted for the hard of hearing or not.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between text tracks. This information is usually set only if the current Manifest contains one.   This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"texttrackchange"},{"h1":"Player events","h2":"Track selection events","h3":"videoTrackChange","body":"payload type: Object|null Information about the current video track, each time it changes (the last received segment got a new one). The payload is an object describing the new track, with the following properties:   id (string): The id used to identify the track. Use it for setting the track via setVideoTrack.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between video tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation.   bitrate (Number): The bitrate of this Representation, in bits per seconds.   width (Number|undefined): The width of video, in pixels.   height (Number|undefined): The height of video, in pixels.   codec (string|undefined): The codec given in standard MIME type format.   frameRate (string|undefined): The video framerate.     isTrickModeTrack (Boolean|undefined): If set to true, this track is a trick mode track. This type of tracks proposes video content that is often encoded with a very low framerate with the purpose to be played more efficiently at a much higher speed. To enter or exit a mode where trickmode tracks are used instead of regular non-trickmode ones, you can use the setPlaybackRate function.   trickModeTracks (Object | undefined): Trick mode video tracks attached to this video track. Each of those objects contain the same properties that a regular video track (same properties than what is documented here). It this property is either undefined or not set, then this track has no linked trickmode video track.   A null payload means that video track has been disabled. This event only concerns the currently-playing Period.  In DirectFile mode (see transport option), a `null` payload may be received even if the video track is still visually active. This seems due to difficult-to-detect browser bugs. We recommend not disabling video track when in directfile mode to avoid that case (this is documented in the corresponding APIs). ","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"videotrackchange"},{"h1":"Player events","h2":"Bitrate selection events","body":"This chapter describes events linked to audio and/or video bitrates and quality.","anchorH1":"player_events","anchorH2":"bitrate_selection_events"},{"h1":"Player events","h2":"Bitrate selection events","h3":"availableAudioBitratesChange","body":"payload type: Array.<Number> Triggered when the currently available audio bitrates change (e.g.: at the beginning of the content, when switching the current audio track, when period changes…). The payload is an array of the different bitrates available, in bits per seconds. This event only concerns the currently-playing Period.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"bitrate_selection_events","anchorH3":"availableaudiobitrateschange"},{"h1":"Player events","h2":"Bitrate selection events","h3":"availableVideoBitratesChange","body":"payload type: Array.<Number> Triggered when the currently available video bitrates change (e.g.: at the beginning of the content, when switching the current video track, when period changes…). The payload is an array of the different bitrates available, in bits per seconds. This event only concerns the currently-playing Period.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"bitrate_selection_events","anchorH3":"availablevideobitrateschange"},{"h1":"Player events","h2":"Bitrate selection events","h3":"audioBitrateChange","body":"payload type: Number The payload is the new audio bitrate, in bits per seconds. It is emitted every time it changes (based on the last received segment). -1 when the bitrate is not known. This event only concerns the currently-playing Period.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"bitrate_selection_events","anchorH3":"audiobitratechange"},{"h1":"Player events","h2":"Bitrate selection events","h3":"videoBitrateChange","body":"payload type: Number The payload is the new video bitrate, in bits per seconds. It is emitted every time it changes (based on the last received segment). -1 when the bitrate is not known. This event only concerns the currently-playing Period.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"bitrate_selection_events","anchorH3":"videobitratechange"},{"h1":"Player events","h2":"Bitrate selection events","h3":"bitrateEstimationChange","body":"payload type: Object Information about the last bitrate estimation performed, by type of buffer (audio, video etc.). Note that this event is sent only if the corresponding buffer type has multiple Representations for the given content (as bitrate estimations are only useful in that case). The payload is an object with the following properties:   type (string): The buffer type   bitrate (Number): The last estimated bandwidth for this buffer type, in bits per seconds. This bitrate is smoothed by doing a (complex) mean on an extended period of time, so it often does not link directly to the current calculated bitrate.    This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"bitrate_selection_events","anchorH3":"bitrateestimationchange"},{"h1":"Player events","h2":"Playback information","body":"This chapter describes events describing miscellaneous information about the current content.","anchorH1":"player_events","anchorH2":"playback_information"},{"h1":"Player events","h2":"Playback information","h3":"periodChange","body":"payload type: Object Triggered when the current Period being seen changes. The payload is the corresponding Period. See the Manifest documentation for more information.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"playback_information","anchorH3":"periodchange"},{"h1":"Player events","h2":"Playback information","h3":"decipherabilityUpdate","body":"payload type: Array.<Object> Triggered when a or multiple Representation’s decipherability status were updated. Which means either:  A Representation is found to be undecipherable (e.g. the key or license request is refused) A Representation is found to be decipherable A Representation’s decipherability becomes undefined  At this time, this event is only triggered if:  the current content is an encrypted content Either the fallbackOnLastTry property was set to true on a rejected getLicense call or one of the fallbackOn properties was set to true in the keySystems loadVideo option.  Following this event, the RxPlayer might remove from the current buffers any data linked to undecipherable Representation(s) (the video might twitch a little or reload) and update the list of available bitrates. The payload of this event is an Array of objects, each representating a Representation whose decipherability’s status has been updated. Each of those objects have the following properties:  representation: The Representation concerned (more information on its structure in the Manifest documentation). adaptation: The Adaptation linked to that Representation (more information on its structure in the Manifest documentation). period: The Period linked to that Representation (more information on its structure in the Manifest documentation). manifest: The current Manifest (more information on its structure in the Manifest documentation).  You can then know if any of those Representations are becoming decipherable or not through their decipherable property.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"playback_information","anchorH3":"decipherabilityupdate"},{"h1":"Player events","h2":"inbandEvents","body":"payload type: Object Event triggered when the player encounters inband events in the stream. These events are included in the loaded and parsed chunks, and are often used to carry content metadata. Each event contains :  type (type: String) : defines the type of the event, specific to an inband event from a streaming protocol. value (type: Object) : the actual parsed content of the event.  The supported inband event types are :   “emsg” : The emsg (Event message box) provides inband signaling for generic or MPEG-DASH specific events. One ISOBMFF media segment may contain one or several boxes. The parsed event contains :  schemeIdUri (String) value (String) timescale (Number) presentationTimeDelta (Number) eventDuration (Number) id (Number) messageData (Uint8Array)  These attributes are documented in the ISOBMFF specification.    This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"inbandevents"},{"h1":"Player events","h2":"inbandEvents","h3":"streamEvent","body":"payload type: Object Event triggered when the player enters the time boundaries of a “stream event”. “Stream events” are metadata that can be defined in various streaming protocols, which indicates that an application should trigger some action when a specific time is reached in the content. Those events can either have only a start time or both a start time and an end time:   in the case where an event only has a start time, the RxPlayer will trigger a streamEvent right when the user reaches that time. If we return multiple time at that position (for example, when a user seeks back to it), you will receive a streamEvent as many times for that same event.   in the case where an event has both a start and end time, the RxPlayer will trigger a streamEvent when the current position goes inside these time boundaries (between the start and end time). This can happen while reaching the start during regular playback but also when seeking at a position contained between the start and end time. The streamEvent event will not be re-sent until the current position “exits” those time boundaries. If the current position goes out of the boundaries of that event and then goes into it again (most likely due to the user seeking back into it), you will again receive a streamEvent for that same event.   The payload of a streamEvent depends on the source of the event. For example, it will not have the same format when it comes from a Manifest than when it comes from the media container. All possible formats are described in the stream event tutorial. Note: When an event has both a start and an end time, you can define a onExit callback on the payload. That callback will automatically be triggered when the current position goes after the end time or before the start time of that event. The onExit callback will only be called a single time at most and will only concern this iteration of the event (and not possible subsequent ones).  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"inbandevents","anchorH3":"streamevent"},{"h1":"Player events","h2":"inbandEvents","h3":"streamEventSkip","body":"payload type: Object Event triggered when the player skipped the time boundaries of a “stream event” (you can refer to the streamEvent event for a definition of what a “stream event” is). This means that the current position the player plays at, immediately changed from a time before the start time of a “stream event” to after its end time (or just after its end time for “stream event” without an end time). This is most likely due to the user seeking in the content. A “regular” content playback which continuously plays the content without seeking shouldn’t trigger any streamEventSkip event. The payload of a streamEventSkip is the same than for a streamEvent and as such depends on the source of the event. All possible formats are described in the stream event tutorial. Note that unlike streamEvent events, there’s no point to define an onExit callback on the payload of a streamEventSkip event. This is because this event was not entered, and will thus not be exited.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"inbandevents","anchorH3":"streameventskip"},{"h1":"Player events","h2":"Deprecated","body":"The following events are deprecated. They are still supported but we advise users to not use those as they might become not supported in the future.","anchorH1":"player_events","anchorH2":"deprecated"},{"h1":"Player events","h2":"Deprecated","h3":"imageTrackUpdate","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs).  payload type: Object Triggered each time the current image playlist changes (has new images). Has the following property in its payload: data (Array.<Object>): Every image data. Each image has a structure as defined in the Images structure page.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"deprecated","anchorH3":"imagetrackupdate"},{"h1":"Player events","h2":"Deprecated","h3":"fullscreenChange","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs).  payload type: Boolean Triggered each time the video player goes/exits fullscreen mode. The payload is true if the player entered fullscreen, false if it exited it.","anchorH1":"player_events","anchorH2":"deprecated","anchorH3":"fullscreenchange"},{"h1":"Player events","h2":"Deprecated","h3":"nativeTextTracksChange","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs).  payload type: Array.<TextTrackElement> Triggered each times a new <track> element is removed or added to the media element. The payload is the array of TextTrack elements. The RxPlayer will only set a single <track> when a text track is set.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"deprecated","anchorH3":"nativetexttrackschange"}]},{"file":"./api/Player_Errors.html","index":[{"h1":"Player errors and warnings","body":"","anchorH1":"player_errors_and_warnings"},{"h1":"Player errors and warnings","h2":"Overview","body":"Various errors can be triggered when playing a media content. Those can happen when:  The network is unreachable The codecs are not supported We have no mean to decrypt the data …  Some errors can be fatal to content playback in which case they will stop the player, others act more as warnings and are more along the line of a minor problem notification. You can know if a fatal error interrupted your playback by:   adding an event listener to the \"error\" event (see the player events documentation). This event listener will take the error directly in argument.   calling the getError API if the current state is STOPPED. If different from null, it means that a fatal error happened (see the documentation for getError).   You can also be warned of any non-fatal error by:  adding an event listener to the \"warning\" event (see the player events documentation). The event listener will take the non-fatal error directly in argument.  All of those are in essence Error instances with added information. Those supplementary information are described in this page.","anchorH1":"player_errors_and_warnings","anchorH2":"overview"},{"h1":"Player errors and warnings","h2":"Structure of an Error","body":"Each of RxPlayer’s error objects have at least those properties:   type (string): A large category for the error (e.g. NETWORK_ERROR, ENCRYPTED_MEDIA_ERROR …)   code (string): A set identification “code” for the error encountered   message (string): A displayable, human-readable, summary of the error.   fatal (boolean): If true, the error was fatal. Meaning that the playback was interrupted by it  ","anchorH1":"player_errors_and_warnings","anchorH2":"structure_of_an_error"},{"h1":"Player errors and warnings","h2":"Types","body":"The types are the different strings you can have as the type property of an error. This chapter provides an exhaustive list of the possible type of error encountered.","anchorH1":"player_errors_and_warnings","anchorH2":"types"},{"h1":"Player errors and warnings","h2":"Types","h3":"NETWORK_ERROR","body":"A NetworkError is any Network-related error (HTTP 404, request timeout…), they all have a type property equal to \"NETWORK_ERROR\". codes A NetworkError can only have the following code (code property):  \"PIPELINE_LOAD_ERROR\": the Manifest or segment request failed.  more information A NetworkError provide much more infos than this code. Among its properties, you have:   url (string): The url the request has been on   status (Number): Status code of the HTTP request.   errorType (string): Further precision about what went wrong. This string can either be:  \"TIMEOUT\": The request timeouted. \"ERROR_EVENT\": The XMLHttpRequest has sent an error event \"PARSE_ERROR\": No data could have been extracted from this request \"ERROR_HTTP_CODE\": The request finished with a status code not in the 2xx range.    xhr (XMLHttpRequest|undefined): The xhr associated with the request. Not defined if the current content has been launched in lowLatencyMode.    This last property is deprecated. It will disappear in the next major release, the `v4.0.0` (see Deprecated APIs). ","anchorH1":"player_errors_and_warnings","anchorH2":"types","anchorH3":"network_error"},{"h1":"Player errors and warnings","h2":"Types","h3":"MEDIA_ERROR","body":"Error related to the media itself. It can both come from the player itself (Manifest parsing) or from the browser itself (content playback). They all have a type property equal to \"MEDIA_ERROR\". codes A MediaError can have the following codes (code property):   \"BUFFER_APPEND_ERROR\": A media segment could not have been added to the corresponding media buffer. This often happens with malformed segments.   \"BUFFER_FULL_ERROR\": The needed segment could not have been added because the corresponding media buffer was full.   \"BUFFER_TYPE_UNKNOWN\": The type of buffer considered (e.g. “audio” / “video” / “text”) has no media buffer implementation in your build.   \"MANIFEST_INCOMPATIBLE_CODECS_ERROR\": An Adaptation (or track) has none of its Representations (read quality) in a supported codec.   \"MANIFEST_PARSE_ERROR\": Generic error to signal than the Manifest could not be parsed.   \"MANIFEST_UNSUPPORTED_ADAPTATION_TYPE\": One of the Adaptation has a type (e.g. “audio”, “text” or “video” which is not managed by the RxPlayer).   \"MEDIA_ERR_ABORTED\": A crucial browser-side fetching operation was aborted.   \"MEDIA_ERR_BLOCKED_AUTOPLAY\": The current browser has a policy which forbids us to autoPlay the content. As a consequence, the rx-player stays in a \"LOADED\" state. This code is always a warning and it never causes playback interruption.   \"MEDIA_ERR_PLAY_NOT_ALLOWED\": A play call on our API (coming from you) failed because the current browser does not allow it. The content should still be in a paused state. This is in almost any case due a browser policy which prevents a content to play without any user interaction. In those cases, we recommend to display a UI element on your page inviting the final user to manually play the content.   \"MEDIA_ERR_NOT_LOADED_METADATA\": The current browser falsely announce having loaded the content’s metadata. In that case, we cannot switch to the LOADED state directly (we will be blocked in either a LOADING or a RELOADING state) and you’re encouraged to call play manually when you want to play the content. This is a case only encountered in the Samsung browser (as found in Android) when loading a content in “directfile” mode.   \"MEDIA_ERR_DECODE\": A pushed segment/media could not be decoded by the browser. This happens most-of-all with malformed segments.   \"MEDIA_ERR_NETWORK\": A browser-side request failed.   \"MEDIA_ERR_SRC_NOT_SUPPORTED\": The media associated to the video element is not valid.   \"MEDIA_ERR_UNKNOWN\": Media error impossible to characterize.   \"MEDIA_KEYS_NOT_SUPPORTED\": The current browser has no MediaKeys implementation and the content is encrypted.   \"MEDIA_SOURCE_NOT_SUPPORTED\": No known MediaSource API is supported by your browser and we need to create one.   \"MEDIA_STARTING_TIME_NOT_FOUND\": The provided or calculated starting time was not found in the corresponding media.   \"MEDIA_TIME_BEFORE_MANIFEST\": The current time in the media is behind what is currently declared in the Manifest. This can lead to stalling indefinitely as the player won’t be able to download new segments arround the current time.   \"MEDIA_TIME_AFTER_MANIFEST\": The current time in the media is after what is currently declared in the Manifest. This can lead to stalling indefinitely as the player won’t be able to download new segments arround the current time.   \"DISCONTINUITY_ENCOUNTERED\": A discontinuity (i.e. a hole in the media buffer) has been encontered and seeked over. This is rarely a problem and may be encountered at a very start of a content when the initial segment’s start is much later than expected.   \"NO_PLAYABLE_REPRESENTATION\": The currently chosen Adaptation does not contain any playable Representation. This usually happen when every Representation has been blacklisted due to encryption limitations.   \"MANIFEST_UPDATE_ERROR\": This error should never be emitted as it is handled internally by the RxPlayer. Please open an issue if you encounter it. This error is triggered when an incoherent version of the Manifest was received during a partial update. The RxPlayer should catch the error and trigger a full update instead when that happens.   \"MEDIA_TIME_NOT_FOUND\": This error should never be emitted by the RxPlayer. Please open an issue if you encounter it. It is triggered when a time we initially thought to be in the bounds of the Manifest actually does not link to any “Period” of the Manifest.  ","anchorH1":"player_errors_and_warnings","anchorH2":"types","anchorH3":"media_error"},{"h1":"Player errors and warnings","h2":"Types","h3":"ENCRYPTED_MEDIA_ERROR","body":"Those errors are linked to the Encrypted Media Extensions. They concern various DRM-related problems. They all have a type property equal to \"ENCRYPTED_MEDIA_ERROR\". codes An EncryptedMediaError can have the following codes (code property):   \"INCOMPATIBLE_KEYSYSTEMS\": None of the provided key systems was compatible with the current browser.   \"INVALID_ENCRYPTED_EVENT\": An encountered encrypted event was not valid.   \"INVALID_KEY_SYSTEM\": One of the given key system was not accepted by the RxPlayer.   \"KEY_ERROR\": The MediaKeySession emitted an error.   \"KEY_GENERATE_REQUEST_ERROR\": An error happened when calling the generateRequest API to generate a challenge.   \"KEY_LOAD_ERROR\": An error was returned by the code fetching the license.   \"KEY_LOAD_TIMEOUT\": The request for fetching the license had a duration of more than 10 seconds.   \"KEY_STATUS_CHANGE_ERROR\": An error was detected when the MediaKeySession emitted a keyStatuseschange event (e.g. the key became \"expired\").   \"KEY_UPDATE_ERROR\": An error was detected after a message (like a license was given to the CDM).   \"LICENSE_SERVER_CERTIFICATE_ERROR\": The server certificate of a MediaKeys could not be set.   \"MEDIA_IS_ENCRYPTED_ERROR\": The media is encrypted and no key system was given to the RxPlayer’s APIs.   \"MULTIPLE_SESSIONS_SAME_INIT_DATA\": This error should never be emitted by the RxPlayer. Please open an issue if you encounter it. It is emitted when the RxPlayer try to open multiple MediaKeySession for the same initialization data (instead of using the exact same MediaKeySession).  ","anchorH1":"player_errors_and_warnings","anchorH2":"types","anchorH3":"encrypted_media_error"},{"h1":"Player errors and warnings","h2":"Types","h3":"OTHER_ERROR","body":"Those errors are various other errors which does not belong to other types. They all have a type property equal to \"OTHER_ERROR\". codes An OtherError can have the following codes (code property):   \"PIPELINE_LOAD_ERROR\": The Manifest or segment request failed and the request has been done through a given callback (i.e. not the RxPlayer’s XMLHttpRequest implementation).   \"PIPELINE_PARSE_ERROR\": The RxPlayer’s Manifest or segment parsing logic failed. This is most likely due to a malformed Manifest or segment.   \"INTEGRITY_ERROR\": An integrity-checking mechanism in the RxPlayer detected that there was an error with some loaded data. Such mechanism can be triggered for example when the checkMediaSegmentIntegrity transportOptions is set to loadVideo.   \"NONE\": The error cannot be characterized.  ","anchorH1":"player_errors_and_warnings","anchorH2":"types","anchorH3":"other_error"}]},{"file":"./api/Track_Selection/getAudioTrack.html","index":[{"h1":"getAudioTrack","body":"","anchorH1":"getaudiotrack"},{"h1":"getAudioTrack","h2":"Description","body":"Get information about the audio track currently set. null if no audio track is enabled right now. If an audio track is set and information about it is known, this method will return an object with the following properties:   id (Number|string): The id used to identify this track. No other audio track for the same Period will have the same id. This can be useful when setting the track through the setAudioTrack method.   language (string): The language the audio track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-3 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   audioDescription (Boolean): Whether the track is an audio description of what is happening at the screen.   dub (Boolean|undefined): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between audio tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation. No other Representation from this track will have the same id.   bitrate (Number): The bitrate of this Representation, in bits per seconds.   codec (string|undefined): The audio codec the Representation is in, as announced in the corresponding Manifest.     undefined if no audio content has been loaded yet or if its information is unknown.  Note for multi-Period contents:  This method will only return the chosen video track for the Period that is currently playing.   In DirectFile mode (see loadVideo options), if there is no audio tracks API in the browser, this method returns \"undefined\". ","anchorH1":"getaudiotrack","anchorH2":"description"},{"h1":"getAudioTrack","h2":"Syntax","body":"const audioTrack = player.getAudioTrack();   return value Object|null|undefined ","anchorH1":"getaudiotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getTextTrack.html","index":[{"h1":"getTextTrack","body":"","anchorH1":"gettexttrack"},{"h1":"getTextTrack","h2":"Description","body":"Get information about the text track currently set. null if no audio track is enabled right now. If a text track is set and information about it is known, this method will return an object with the following properties:   id (Number|string): The id used to identify this track. No other text track for the same Period will have the same id. This can be useful when setting the track through the setTextTrack method.   language (string): The language the text trac./…/Basic_Methods/loadVideo.md#transport set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-3 language codes). If the translation attempt fails (no corresponding ISO./…/Basic_Methods/loadVideo.md#transport found), it will equal the value of language   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between text tracks. This information is usually set only if the current Manifest contains one.   closedCaption (Boolean): Whether the track is specially adapted for the hard of hearing or not.   undefined if no text content has been loaded yet or if its information is unknown.  Note for multi-Period contents:  This method will only return the chosen video track for the Period that is currently playing.   In DirectFile mode (see loadVideo options), if there is no text tracks API in the browser, this method returns \"undefined\". ","anchorH1":"gettexttrack","anchorH2":"description"},{"h1":"getTextTrack","h2":"Syntax","body":"const textTrack = player.getTextTrack();   return value Object|null|undefined ","anchorH1":"gettexttrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getVideoTrack.html","index":[{"h1":"getVideoTrack","body":"","anchorH1":"getvideotrack"},{"h1":"getVideoTrack","h2":"Description","body":"Get information about the video track currently set.  null if no video track is enabled right now. undefined if no video content has been loaded yet or if its information is unknown.  If a video track is set and information about it is known, this method will return an object with the following properties:   id (Number|string): The id used to identify this track. No other video track for the same Period will have the same id. This can be useful when setting the track through the setVideoTrack method.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between video tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation. No other Representation from this track will have the same id.   bitrate (Number): The bitrate of this Representation, in bits per seconds.   width (Number|undefined): The width of video, in pixels.   height (Number|undefined): The height of video, in pixels.   codec (string|undefined): The video codec the Representation is in, as announced in the corresponding Manifest.   frameRate (string|undefined): The video frame rate.   hdrInfo (Object|undefined) Information about the hdr characteristics of the track. (see HDR support documentation)     signInterpreted (Boolean|undefined): If set to true, this track is known to contain an interpretation in sign language. If set to false, the track is known to not contain that type of content. If not set or set to undefined we don’t know whether that video track contains an interpretation in sign language.   isTrickModeTrack (Boolean|undefined): If set to true, this track is a trick mode track. This type of tracks proposes video content that is often encoded with a very low framerate with the purpose to be played more efficiently at a much higher speed. To enter or exit a mode where trickmode tracks are used instead of regular non-trickmode ones, you can use the setPlaybackRate function.   trickModeTracks (Array.<Object> | undefined): Trick mode video tracks attached to this video track. Each of those objects contain the same properties that a regular video track (same properties than what is documented here). It this property is either undefined or not set, then this track has no linked trickmode video track.    Note for multi-Period contents:  This method will only return the chosen video track for the Period that is currently playing.   In DirectFile mode (see loadVideo options), if there is no video tracks API in the browser, this method returns \"undefined\". ","anchorH1":"getvideotrack","anchorH2":"description"},{"h1":"getVideoTrack","h2":"Syntax","body":"const videoTrack = player.getVideoTrack();   return value Object|null|undefined ","anchorH1":"getvideotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getAvailableAudioTracks.html","index":[{"h1":"getAvailableAudioTracks","body":"","anchorH1":"getavailableaudiotracks"},{"h1":"getAvailableAudioTracks","h2":"Description","body":"Returns the list of available audio tracks for the current content. Each of the objects in the returned array have the following properties:   active (Boolean): Whether the track is the one currently active or not. Only maximum one audio track can be active at a time.   id (string): The id used to identify the track. Use it for setting the track via setAudioTrack.   language (string): The language the audio track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   audioDescription (Boolean): Whether the track is an audio description of what is happening at the screen.   dub (Boolean|undefined): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between audio tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation.   bitrate (Number): The bitrate of this Representation, in bits per seconds.   codec (string|undefined): The audio codec the Representation is in, as announced in the corresponding Manifest.      Note for multi-Period contents:  This method will only return the available tracks of the Period that is currently playing.   In DirectFile mode (see loadVideo options), if there is no supported tracks in the file or no track management API in the browser this method will return an empty Array. ","anchorH1":"getavailableaudiotracks","anchorH2":"description"},{"h1":"getAvailableAudioTracks","h2":"Syntax","body":"const audioTracks = player.getAvailableAudioTracks();   return value Array.<Object> ","anchorH1":"getavailableaudiotracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getAvailableTextTracks.html","index":[{"h1":"getAvailableTextTracks","body":"","anchorH1":"getavailabletexttracks"},{"h1":"getAvailableTextTracks","h2":"Description","body":"Returns the list of available text tracks (subtitles) for the current content. Each of the objects in the returned array have the following properties:   id (string): The id used to identify the track. Use it for setting the track via setTextTrack.   language (string): The language the text track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   closedCaption (Boolean): Whether the track is specially adapted for the hard of hearing or not.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between text tracks. This information is usually set only if the current Manifest contains one.   active (Boolean): Whether the track is the one currently active or not.    Note for multi-Period contents:  This method will only return the available tracks of the Period that is currently playing.   In DirectFile mode (see loadVideo options), if there is no supported tracks in the file or no track management API in the browser this method will return an empty Array. ","anchorH1":"getavailabletexttracks","anchorH2":"description"},{"h1":"getAvailableTextTracks","h2":"Syntax","body":"const textTracks = player.getAvailableTextTracks();   return value Array.<Object> ","anchorH1":"getavailabletexttracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getAvailableVideoTracks.html","index":[{"h1":"getAvailableVideoTracks","body":"","anchorH1":"getavailablevideotracks"},{"h1":"getAvailableVideoTracks","h2":"Description","body":"Returns the list of available video tracks for the current content. Each of the objects in the returned array have the following properties:   id (string): The id used to identify the track. Use it for setting the track via setVideoTrack.   active (Boolean): Whether this track is the one currently active or not.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between video tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation.   bitrate (Number): The bitrate of this Representation, in bits per seconds.   width (Number|undefined): The width of video, in pixels.   height (Number|undefined): The height of video, in pixels.   codec (string|undefined): The video codec the Representation is in, as announced in the corresponding Manifest.   frameRate (string|undefined): The video framerate.   hdrInfo (Object|undefined) Information about the hdr characteristics of the track. (see HDR support documentation)     signInterpreted (Boolean|undefined): If set to true, the track is known to contain an interpretation in sign language. If set to false, the track is known to not contain that type of content. If not set or set to undefined we don’t know whether that video track contains an interpretation in sign language.   trickModeTracks (Array.<Object> | undefined): Trick mode video tracks attached to this video track. Each of those objects contain the same properties that a regular video track (same properties than what is documented here). It this property is either undefined or not set, then this track has no linked trickmode video track.    Note for multi-Period contents:  This method will only return the available tracks of the Period that is currently playing.   In DirectFile mode (see loadVideo options), if there is no supported tracks in the file or no track management API in the browser this method will return an empty Array. ","anchorH1":"getavailablevideotracks","anchorH2":"description"},{"h1":"getAvailableVideoTracks","h2":"Syntax","body":"const videoTracks = player.getAvailableVideoTracks();   return value Array.<Object> ","anchorH1":"getavailablevideotracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setAudioTrack.html","index":[{"h1":"setAudioTrack","body":"","anchorH1":"setaudiotrack"},{"h1":"setAudioTrack","h2":"Description","body":"Change the current audio track. The argument to this method is the wanted track’s id property. This id can for example be obtained on the corresponding track object returned by the getAvailableAudioTracks method.  Note for multi-Period contents:  This method will only have an effect on the Period that is currently playing.  If you want to update the track for other Periods as well, you might want to either:     update the current video track once a `\"periodChange\"` event has been   received.   update first the preferred video tracks through the   setPreferredVideoTracks method.       If used on Safari, in _DirectFile_ mode, the track change may change the track on other track type (e.g. changing video track may change subtitle track too). This has two potential reasons :    The HLS defines variants, groups of tracks that may be read together   Safari may decide to enable a track for accessibility or user language   convenience (e.g. Safari may switch subtitle to your OS language if you pick   another audio language)   You can know if another track has changed by listening to the corresponding   events that the tracks have changed.  ","anchorH1":"setaudiotrack","anchorH2":"description"},{"h1":"setAudioTrack","h2":"Syntax","body":"player.setAudioTrack(audioTrackId);    arguments:  audioTrackId string|number: The id of the track you want to set   ","anchorH1":"setaudiotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setTextTrack.html","index":[{"h1":"setTextTrack","body":"","anchorH1":"settexttrack"},{"h1":"setTextTrack","h2":"Description","body":"Change the current text (subtitles) track. The argument to this method is the wanted track’s id property. This id can for example be obtained on the corresponding track object returned by the getAvailableTextTracks method.  Note for multi-Period contents:  This method will only have an effect on the Period that is currently playing.  If you want to update the track for other Periods as well, you might want to either:     update the current video track once a `\"periodChange\"` event has been   received.   update first the preferred video tracks through the   setPreferredVideoTracks method.       If used on Safari, in DirectFile mode, the track change may change the track on other track type (e.g. changing video track may change subtitle track too).  This has two potential reasons :   The HLS defines variants, groups of tracks that may be read together  Safari may decide to enable a track for accessibility or user language   convenience (e.g. Safari may switch subtitle to your OS language if you pick   another audio language)   You can know if another track has changed by listening to the corresponding   events that the tracks have changed.  ","anchorH1":"settexttrack","anchorH2":"description"},{"h1":"setTextTrack","h2":"Syntax","body":"player.setTextTrack(textTrackId);    arguments:  textTrackId string|number: The id of the track you want to set   ","anchorH1":"settexttrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setVideoTrack.html","index":[{"h1":"setVideoTrack","body":"","anchorH1":"setvideotrack"},{"h1":"setVideoTrack","h2":"Description","body":"Change the current video track. The argument to this method is the wanted track’s id property. This id can for example be obtained on the corresponding track object returned by the getAvailableVideoTracks method. If trickmode tracks are enabled (usually through the corresponding setPlaybackRate method option) and if that new video track is linked to trickmode tracks, one of the trickmode tracks will be loaded instead. Note that trickmode tracks cannot be forced through the setVideoTrack method by giving directly the trickmode tracks’ id. If you want to enable or disable trickmode tracks, you should use setPlaybackRate instead. etting a new video track when a previous one was already playing can lead the rx-player to “reload” this content. During this period of time:  the player will have the state RELOADING Multiple APIs linked to the current content might not work. Most notably:  play will not work pause will not work seekTo will not work getPosition will return 0 getWallClockTime will return 0 getVideoDuration will return NaN getAvailableAudioTracks will return an empty array getAvailableTextTracks will return an empty array getAvailableVideoTracks will return an empty array getTextTrack will return null getAudioTrack will return null setAudioTrack will throw setTextTrack will throw     Note for multi-Period contents:  This method will only have an effect on the Period that is currently playing.  If you want to update the track for other Periods as well, you might want to either:     update the current video track once a `\"periodChange\"` event has been   received.   update first the preferred video tracks through the   setPreferredVideoTracks method.       In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setvideotrack","anchorH2":"description"},{"h1":"setVideoTrack","h2":"Syntax","body":"player.setVideoTrack(videoTrackId);    arguments:  videoTrackId string|Number: The id of the track you want to set   ","anchorH1":"setvideotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/disableTextTrack.html","index":[{"h1":"disableTextTrack","body":"","anchorH1":"disabletexttrack"},{"h1":"disableTextTrack","h2":"Description","body":"Disable the current text track, if one. After calling that method, no subtitles track will be displayed until setTextTrack is called. Note for multi-Period contents: This method will only have an effect on the Period that is currently playing. If you want to disable the text track for other Periods as well, you might want to call setPreferredVideoTracks instead. With this method, you can globally apply a null text track preference - which means that you would prefer having no text track - by setting its second argument to true. More information can be found on that API’s documentation.","anchorH1":"disabletexttrack","anchorH2":"description"},{"h1":"disableTextTrack","h2":"Syntax","body":"player.disableTextTrack(); ","anchorH1":"disabletexttrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/disableVideoTrack.html","index":[{"h1":"disableVideoTrack","body":"","anchorH1":"disablevideotrack"},{"h1":"disableVideoTrack","h2":"Description","body":"Disable the current video track, if one. Might enter in RELOADING state for a short period after calling this API. Note for multi-Period contents: This method will only have an effect on the Period that is currently playing. If you want to disable the video track for other Periods as well, you might want to call setPreferredVideoTracks instead. With this method, you can globally apply a null video track preference - which means that you would prefer having no video track - by setting its second argument to true. More information can be found on that API’s documentation.  This option may have no effect in DirectFile mode (see loadVideo options).   The directfile mode is a special case here because when in it, the RxPlayer depends for track selection on the  corresponding HTML standard as implemented by the different browsers.  Though this standard says nothing about not being able to disable the video track (or to stay more in line with their terms: to not select any video track), no browser implementation actually seem to be able to do it, even when the corresponding browser APIs show that no video track is currently selected. This might be a bug on their parts.   Due to this fact, we do not recommend using this API in directfile mode for now. You might even receive a reassuring `videoTrackChange` event (with a `null` payload) while the video track is still actually active. ","anchorH1":"disablevideotrack","anchorH2":"description"},{"h1":"disableVideoTrack","h2":"Syntax","body":"player.disableVideoTrack(); ","anchorH1":"disablevideotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setPreferredAudioTracks.html","index":[{"h1":"setPreferredAudioTracks","body":"","anchorH1":"setpreferredaudiotracks"},{"h1":"setPreferredAudioTracks","h2":"Description","body":"Allows the RxPlayer to choose an initial audio track, based on language preferences, codec preferences or both. This method can be called at any time - even when no content is loaded, and will apply to every future loaded content in the current RxPlayer instance. The first argument should be set as an array of objects, each object describing constraints an audio track should respect. Here is all the possible constraints you can set in any one of those objects (note that all properties are optional here, only those set will have an effect on which tracks will be filtered): {   language: \"fra\", // {string|undefined} The language the track should be in                    // (in preference as an ISO 639-1, ISO 639-2 or ISO 639-3                    // language code).                    // If not set or set to `undefined`, the RxPlayer won't                    // filter based on the language of the track.    audioDescription: false // {Boolean|undefined} Whether the audio track should                           // be an audio description for the visually impaired                           // or not.                           // If not set or set to `undefined`, the RxPlayer                           // won't filter based on that status.    codec: { // {Object|undefined} Constraints about the codec wanted.            // if not set or set to `undefined` we won't filter based on codecs.      test: /ec-3/, // {RegExp} RegExp validating the type of codec you want.      all: true, // {Boolean} Whether all the profiles (i.e. Representation) in a                // track should be checked against the RegExp given in `test`.                // If `true`, we will only choose a track if EVERY profiles for                // it have a codec information that is validated by that RegExp.                // If `false`, we will choose a track if we know that at least                // A SINGLE profile from it has codec information validated by                // that RegExp.   } }  When encountering a new content or a new choice of tracks in a given content, the RxPlayer will look at each object in that array. If the first object in it defines constaints that cannot be respected under the currently available audio tracks, the RxPlayer will consider the second object in the array and so on. As such, this array should be sorted by order of preference: from the most wanted constraints to the least. The second argument to that function is an optional boolean which - when set to true - will apply that preference to the content and Period that have already been playing. By setting it to true, you might thus change the currently-active track and the active track of Periods (in DASH) or sub-contents (in MetaPlaylist) that have already been played in the current content. By setting it to false, undefined or not setting it, those preferences will only be applied each time a new Period or sub-content is loaded by the RxPlayer. Simply put, if you don’t set the second argument to true those preferences won’t be applied to:   the content being currently played. Here, the current audio preference will stay in place.   the Periods or sub-contents which have already been loaded for the current content. Those will keep the audio track chosen at the last time they were loaded.   If you want the preferences to also be applied to those, you can set the second argument to true. Examples Let’s imagine that you prefer to have french or italian over all other audio languages. If not found, you want to fallback to english: player.setPreferredAudioTracks([   { language: \"fra\", audioDescription: false },   { language: \"ita\", audioDescription: false },   { language: \"eng\", audioDescription: false }, ]);  Now let’s imagine that you want to have in priority a track that contain at least one profile in Dolby Digital Plus (ec-3 codec) without caring about the language: player.setPreferredAudioTracks([ { codec: { all: false, test: /ec-3/ } ]);  At last, let’s combine both examples by preferring french over itialian, italian over english while preferring it to be in Dolby Digital Plus: player.setPreferredAudioTracks([   {     language: \"fra\",     audioDescription: false,     codec: { all: false, test: /ec-3/ },   },    // We still prefer non-DD+ french over DD+ italian   { language: \"fra\", audioDescription: false },    {     language: \"ita\",     audioDescription: false,     codec: { all: false, test: /ec-3/ },   },   { language: \"ita\", audioDescription: false },    {     language: \"eng\",     audioDescription: false,     codec: { all: false, test: /ec-3/ },   },   { language: \"eng\", audioDescription: false }, ]);   This option will have no effect in DirectFile mode (see loadVideo options) when either:    No audio track API is supported on the current browser   The media file tracks are not supported on the browser  ","anchorH1":"setpreferredaudiotracks","anchorH2":"description"},{"h1":"setPreferredAudioTracks","h2":"Syntax","body":"player.setPreferredAudioTracks(preferences);  // or player.setPreferredAudioTracks(preferences, shouldApply);    arguments:   preferences (Array.<Object>): wanted audio track configurations by order of preference.   shouldApply (Boolean | undefined): Whether this should be applied to the content being played.    ","anchorH1":"setpreferredaudiotracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setPreferredTextTracks.html","index":[{"h1":"setPreferredTextTracks","body":"","anchorH1":"setpreferredtexttracks"},{"h1":"setPreferredTextTracks","h2":"Description","body":"Allows the RxPlayer to choose an initial text track, based on language and accessibility preferences. This method can be called at any time - even when no content is loaded, and will apply to every future loaded content in the current RxPlayer instance. – The first argument should be set as an array of objects, each object describing constraints a text track should respect. Here is all the properties that should be set in a single object of that array. {   language: \"fra\", // {string} The wanted language                    // (ISO 639-1, ISO 639-2 or ISO 639-3 language code)   closedCaption: false // {Boolean} Whether the text track should be a closed                        // caption for the hard of hearing }  When encountering a new content or a new choice of tracks in a given content, the RxPlayer will look at each object in that array. If the first object in it defines constaints that cannot be respected under the currently available text tracks, the RxPlayer will consider the second object in the array and so on. As such, this array should be sorted by order of preference: from the most wanted constraints to the least. You can set null instead of an object to mean that you want no subtitles. When reaching that point of the array, the RxPlayer will just disable the current text track. As such, if you never want any subtitles, you can just set this argument to [null] (an array with only the value null at the first position). The second argument to that function is an optional boolean which - when set to true - will apply that preference to the content and Period that have already been playing. By setting it to true, you might thus change the currently-active text track and the active text track of Periods (in DASH) or sub-contents (in MetaPlaylist) that have already been played in the current content. By setting it to false, undefined or not setting it, those preferences will only be applied each time a new Period or sub-content is loaded by the RxPlayer. Simply put, if you don’t set the second argument to true those preferences won’t be applied to:   the content being currently played. Here, the current text track preference will stay in place.   the Periods or sub-contents which have already been loaded for the current content. Those will keep the text track chosen at the last time they were loaded.   If you want the preferences to also be applied to those, you can set the second argument to true. Example Let’s imagine that you prefer to have french or italian subtitles.If not found, you want no subtitles at all. You will thus call setPreferredTextTracks that way. player.setPreferredTextTracks([   { language: \"fra\", closedCaption: false },   { language: \"ita\", closedCaption: false },   null, ]);  This won’t apply on the currently loaded content(s), if you also want that, you can add true as a second argument: player.setPreferredTextTracks(   [     { language: \"fra\", closedCaption: false },     { language: \"ita\", closedCaption: false },     null,   ],   true );   This option will have no effect in DirectFile mode (see loadVideo options) when either:    No text track API is supported on the current browser   The media file tracks are not supported on the browser  ","anchorH1":"setpreferredtexttracks","anchorH2":"description"},{"h1":"setPreferredTextTracks","h2":"Syntax","body":"player.setPreferredTextTracks(preferences);  // or player.setPreferredTextTracks(preferences, shouldApply);    arguments:   preferences (Array.<Object>): wanted text track configurations by order of preference.   shouldApply (Boolean | undefined): Whether this should be applied to the content being played.    ","anchorH1":"setpreferredtexttracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setPreferredVideoTracks.html","index":[{"h1":"setPreferredVideoTracks","body":"","anchorH1":"setpreferredvideotracks"},{"h1":"setPreferredVideoTracks","h2":"Description","body":"Allows the RxPlayer to choose an initial video track, based on codec preferences, accessibility preferences or both. This method can be called at any time - even when no content is loaded, and will apply to every future loaded content in the current RxPlayer instance. The first argument should be set as an array of objects, each object describing constraints a video track should respect. Here is all the possible constraints you can set in any one of those objects (note that all properties are optional here, only those set will have an effect on which tracks will be filtered): {   codec: { // {Object|undefined} Constraints about the codec wanted.            // if not set or set to `undefined` we won't filter based on codecs.      test: /hvc/, // {RegExp} RegExp validating the type of codec you want.      all: true, // {Boolean} Whether all the profiles (i.e. Representation) in a                // track should be checked against the RegExp given in `test`.                // If `true`, we will only choose a track if EVERY profiles for                // it have a codec information that is validated by that RegExp.                // If `false`, we will choose a track if we know that at least                // A SINGLE profile from it has codec information validated by                // that RegExp.   }   signInterpreted: true, // {Boolean|undefined} If set to `true`, only tracks                          // which are known to contains a sign language                          // interpretation will be considered.                          // If set to `false`, only tracks which are known                          // to not contain it will be considered.                          // if not set or set to `undefined` we won't filter                          // based on that status. }  If the first defined object in that array - defining the first set of constraints - cannot be respected under the currently available video tracks, the RxPlayer will check with the second object instead and so on. As such, this array should be sorted by order of preference: from the most wanted constraints to the least. When the next encountered constraint is set to null, the player will simply disable the video track. If you want to disable the video track by default, you can just set null as the first element of this array (e.g. like [null]). The second argument to that function is an optional boolean which - when set to true - will apply that preference to the content and Period that have already been playing. By setting it to true, you might thus change the currently-active track and the active track of Periods (in DASH) or sub-contents (in MetaPlaylist) that have already been played in the current content. By setting it to false, undefined or not setting it, those preferences will only be applied each time a new Period (or sub-content) is loaded by the RxPlayer. Simply put, if you don’t set the second argument to true those preferences won’t be applied to:   the content being currently played. Here, the current video preference will stay in place.   the Periods or sub-contents which have already been loaded for the current content. Those will keep the video track chosen at the last time they were loaded.   If you want the preferences to also be applied to those, you can set the second argument to true. Examples Let’s imagine that you prefer to have a track which contains only H265 profiles. You can do: player.setPreferredVideoTracks([{ codec: { all: false, test: /^hvc/ } }]);  With that same constraint, let’s no consider that the current user prefer in any case to have a sign language interpretation on screen: player.setPreferredVideoTracks([   // first let's consider the best case: H265 + sign language interpretation   {     codec: { all: false, test: /^hvc/ }     signInterpreted: true,   },    // If not available, we still prefer a sign interpreted track without H265   { signInterpreted: true },    // If not available either, we would prefer an H265 content   { codec: { all: false, test: /^hvc/ } },    // Note: If this is also available, we will here still have a video track   // but which do not respect any of the constraints set here. ]); would thus prefer the video to contain a sign language interpretation. We could set both the previous and that new constraint that way:  ---  For a totally different example, let's imagine you want to play without any video track enabled (e.g. to start in an audio-only mode). To do that, you can simply do: ```js player.setPreferredVideoTracks([null], true);   This option will have no effect in DirectFile mode (see loadVideo options) when either:    No video track API is supported on the current browser   The media file tracks are not supported on the browser  ","anchorH1":"setpreferredvideotracks","anchorH2":"description"},{"h1":"setPreferredVideoTracks","h2":"Syntax","body":"player.setPreferredVideoTracks(preferences);  // or player.setPreferredVideoTracks(preferences, shouldApply);    arguments:   preferences (Array.<Object>): wanted video track configurations by order of preference.   shouldApply (Boolean | undefined): Whether this should be applied to the content being played.    ","anchorH1":"setpreferredvideotracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getPreferredAudioTracks.html","index":[{"h1":"getPreferredAudioTracks","body":"","anchorH1":"getpreferredaudiotracks"},{"h1":"getPreferredAudioTracks","h2":"Description","body":"Returns the current list of preferred audio tracks - by order of preference. This returns the data in the same format that it was given to either the preferredAudioTracks constructor option or the last setPreferredAudioTracks if it was called. It will return an empty Array if none of those two APIs were used until now.","anchorH1":"getpreferredaudiotracks","anchorH2":"description"},{"h1":"getPreferredAudioTracks","h2":"Syntax","body":"const preferences = player.getPreferredAudioTracks();   return value Array.<Object> ","anchorH1":"getpreferredaudiotracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getPreferredTextTracks.html","index":[{"h1":"getPreferredTextTracks","body":"","anchorH1":"getpreferredtexttracks"},{"h1":"getPreferredTextTracks","h2":"Description","body":"Returns the current list of preferred text tracks - by order of preference. This returns the data in the same format that it was given to either the preferredTextTracks constructor option or the last setPreferredTextTracks if it was called: {   language: \"fra\", // {string} The wanted language                    // (ISO 639-1, ISO 639-2 or ISO 639-3 language code)   closedCaption: false // {Boolean} Whether the text track should be a closed                        // caption for the hard of hearing } ","anchorH1":"getpreferredtexttracks","anchorH2":"description"},{"h1":"getPreferredTextTracks","h2":"Syntax","body":"const preferences = player.getPreferredTextTracks();   return value Array.<Object|null> ","anchorH1":"getpreferredtexttracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getPreferredVideoTracks.html","index":[{"h1":"getPreferredVideoTracks","body":"","anchorH1":"getpreferredvideotracks"},{"h1":"getPreferredVideoTracks","h2":"Description","body":"Returns the current list of preferred video tracks - by order of preference. This returns the data in the same format that it was given to either the preferredVideoTracks constructor option or the last setPreferredVideoTracks if it was called. It will return an empty Array if none of those two APIs were used until now.","anchorH1":"getpreferredvideotracks","anchorH2":"description"},{"h1":"getPreferredVideoTracks","h2":"Syntax","body":"const preferences = player.getPreferredVideoTracks();   return value Array.<Object|null> ","anchorH1":"getpreferredvideotracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/isTrickModeEnabled.html","index":[{"h1":"isTrickModeEnabled","body":"","anchorH1":"istrickmodeenabled"},{"h1":"isTrickModeEnabled","h2":"Description","body":"It tells if the trick mode is currently enabled for the content playback : The trick mode allows to play content fast-forward in an efficient way, by exploiting trick mode tracks : on these specific tracks, video content is often encoded with a very low framerate because the content is not intended to be played at regular framerate and because the chunks must be faster to load for the client.","anchorH1":"istrickmodeenabled","anchorH2":"description"},{"h1":"isTrickModeEnabled","h2":"Syntax","body":"const isTrickModeEnabled = player.isTrickModeEnabled();   return value boolean ","anchorH1":"istrickmodeenabled","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getVideoBitrate.html","index":[{"h1":"getVideoBitrate","body":"","anchorH1":"getvideobitrate"},{"h1":"getVideoBitrate","h2":"Description","body":"Returns the bitrate of the video quality currently chosen, in bits per second. Returns undefined if no content is loaded.  Note for multi-Period contents: This method will only return the chosen video bitrate for the Period that is currently playing.   In DirectFile mode (see loadVideo options), this method returns \"undefined\". ","anchorH1":"getvideobitrate","anchorH2":"description"},{"h1":"getVideoBitrate","h2":"Syntax","body":"const bitrate = player.getVideoBitrate();   return value number|undefined: Bitrate of the current video quality chosen. undefined if none is chosen yet. ","anchorH1":"getvideobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getAudioBitrate.html","index":[{"h1":"getAudioBitrate","body":"","anchorH1":"getaudiobitrate"},{"h1":"getAudioBitrate","h2":"Description","body":"Returns the bitrate of the audio quality currently chosen, in bits per second. Returns undefined if no content is loaded.  Note for multi-Period contents: This method will only return the chosen audio bitrate for the Period that is currently playing.   In DirectFile mode (see loadVideo options), this method returns \"undefined\". ","anchorH1":"getaudiobitrate","anchorH2":"description"},{"h1":"getAudioBitrate","h2":"Syntax","body":"const bitrate = player.getAudioBitrate();   return value number|undefined: Bitrate of the current audio quality chosen. undefined if none is chosen yet. ","anchorH1":"getaudiobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getAvailableVideoBitrates.html","index":[{"h1":"getAvailableVideoBitrates","body":"","anchorH1":"getavailablevideobitrates"},{"h1":"getAvailableVideoBitrates","h2":"Description","body":"The different bitrates available for the current video track in bits per seconds.  Note for multi-Period contents: This method will only return the available video bitrates of the Period that is currently playing.   In DirectFile mode (see loadVideo options), this method returns an empty array. ","anchorH1":"getavailablevideobitrates","anchorH2":"description"},{"h1":"getAvailableVideoBitrates","h2":"Syntax","body":"const bitrates = player.getAvailableVideoBitrates();   return value Array.<Number>: the available video bitrates for the current track of the current Period. ","anchorH1":"getavailablevideobitrates","anchorH2":"syntax"},{"h1":"getAvailableVideoBitrates","h2":"Example","body":"const videoBitrates = player.getAvailableVideoBitrates(); if (videoBitrates.length) {   console.log(     \"The current video is available in the following bitrates\",     videoBitrates.join(\", \")   ); } ","anchorH1":"getavailablevideobitrates","anchorH2":"example"}]},{"file":"./api/Bitrate_Selection/getAvailableAudioBitrates.html","index":[{"h1":"getAvailableAudioBitrates","body":"","anchorH1":"getavailableaudiobitrates"},{"h1":"getAvailableAudioBitrates","h2":"Description","body":"The different bitrates available for the current audio track in bits per seconds.  Note for multi-Period contents: This method will only return the available audio bitrates of the Period that is currently playing.   In DirectFile mode (see loadVideo options), this method returns an empty array. ","anchorH1":"getavailableaudiobitrates","anchorH2":"description"},{"h1":"getAvailableAudioBitrates","h2":"Syntax","body":"const bitrates = player.getAvailableAudioBitrates();   return value Array.<Number>: the available audio bitrates for the current track of the current Period. ","anchorH1":"getavailableaudiobitrates","anchorH2":"syntax"},{"h1":"getAvailableAudioBitrates","h2":"Example","body":"const audioBitrates = player.getAvailableAudioBitrates(); if (audioBitrates.length) {   console.log(     \"The current audio is available in the following bitrates\",     audioBitrates.join(\", \")   ); } ","anchorH1":"getavailableaudiobitrates","anchorH2":"example"}]},{"file":"./api/Bitrate_Selection/setVideoBitrate.html","index":[{"h1":"setVideoBitrate","body":"","anchorH1":"setvideobitrate"},{"h1":"setVideoBitrate","h2":"Description","body":"Force the current video track to be of a certain bitrate. If a video quality in the current track is found with the exact same bitrate, this quality will be set. If no video quality is found with the exact same bitrate, either:   the video quality with the closest bitrate inferior to that value will be chosen.   if no video quality has a bitrate lower than that value, the video quality with the lowest bitrate will be chosen instead.   By calling this method with an argument set to -1, this setting will be disabled and the RxPlayer will chose the right quality according to its adaptive logic. You can use getAvailableVideoBitrates to get the list of available bitrates for the current video track. Note that the value set is persistent between loadVideo calls. As such, this method can also be called when no content is playing (the same rules apply for future contents).  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setvideobitrate","anchorH2":"description"},{"h1":"setVideoBitrate","h2":"Syntax","body":"player.setVideoBitrate(bitrate);    arguments:  bitrate Number: Optimal video bitrate (the quality with the maximum bitrate inferior to this value will be chosen if it exists).   ","anchorH1":"setvideobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/setAudioBitrate.html","index":[{"h1":"setAudioBitrate","body":"","anchorH1":"setaudiobitrate"},{"h1":"setAudioBitrate","h2":"Description","body":"Force the current audio track to be of a certain bitrate. If an audio quality in the current track is found with the exact same bitrate, this quality will be set. If no audio quality is found with the exact same bitrate, either:   the audio quality with the closest bitrate inferior to that value will be chosen.   if no audio quality has a bitrate lower than that value, the audio quality with the lowest bitrate will be chosen instead.   By calling this method with an argument set to -1, this setting will be disabled and the RxPlayer will chose the right quality according to its adaptive logic. You can use getAvailableAudioBitrates to get the list of available bitrates for the current audio track. Note that the value set is persistent between loadVideo calls. As such, this method can also be called when no content is playing (the same rules apply for future contents).  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setaudiobitrate","anchorH2":"description"},{"h1":"setAudioBitrate","h2":"Syntax","body":"player.setAudioBitrate(bitrate);    arguments:  bitrate Number: Optimal audio bitrate (the quality with the maximum bitrate inferior to this value will be chosen if it exists).   ","anchorH1":"setaudiobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getManualVideoBitrate.html","index":[{"h1":"getManualVideoBitrate","body":"","anchorH1":"getmanualvideobitrate"},{"h1":"getManualVideoBitrate","h2":"Description","body":"Get the last video bitrate manually set. Either via setVideoBitrate or via the initialVideoBitrate constructor option. This value can be different than the one returned by getVideoBitrate:  getManualVideoBitrate returns the last bitrate set manually by the user getVideoBitrate returns the actual bitrate of the current video track  -1 when no video bitrate is forced.","anchorH1":"getmanualvideobitrate","anchorH2":"description"},{"h1":"getManualVideoBitrate","h2":"Syntax","body":"const currentManualVideoBitrate = player.getManualVideoBitrate();   return value: Number: Last video bitrate manually set. -1 if nothing is manually set. ","anchorH1":"getmanualvideobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getManualAudioBitrate.html","index":[{"h1":"getManualAudioBitrate","body":"","anchorH1":"getmanualaudiobitrate"},{"h1":"getManualAudioBitrate","h2":"Description","body":"Get the last audio bitrate manually set. Either via setAudioBitrate or via the initialAudioBitrate constructor option. This value can be different than the one returned by getAudioBitrate:  getManualAudioBitrate returns the last bitrate set manually by the user getAudioBitrate returns the actual bitrate of the current audio track  -1 when no audio bitrate is forced.","anchorH1":"getmanualaudiobitrate","anchorH2":"description"},{"h1":"getManualAudioBitrate","h2":"Syntax","body":"const currentManualAudioBitrate = player.getManualAudioBitrate();   return value: Number: Last audio bitrate manually set. -1 if nothing is manually set. ","anchorH1":"getmanualaudiobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/setMinVideoBitrate.html","index":[{"h1":"setMinVideoBitrate","body":"","anchorH1":"setminvideobitrate"},{"h1":"setMinVideoBitrate","h2":"Description","body":"Set a minimum video bitrate reachable through adaptive streaming. When the bitrate is chosen through adaptive streaming (i.e., not enforced manually through APIs such as setVideoBitrate), the player will never switch to a video quality with a bitrate lower than that value. The exception being when no quality has a higher bitrate, in which case the maximum quality will always be chosen instead. For example, if you want that video qualities chosen automatically never have a bitrate below 100 kilobits per second you can call: player.setMinVideoBitrate(100000);  Any limit can be removed just by setting that value to 0: // remove video bitrate lower limit player.setMinVideoBitrate(0);  The effect of this method is persisted from content to content. As such, it can even be called when no content is currently loaded. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setVideoBitrate) bypass this limit completely.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setminvideobitrate","anchorH2":"description"},{"h1":"setMinVideoBitrate","h2":"Syntax","body":"player.setMinVideoBitrate(minBitrate);    arguments:  minBitrate number: Lower video bitrate limit when adaptive streaming is enabled.   ","anchorH1":"setminvideobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/setMinAudioBitrate.html","index":[{"h1":"setMinAudioBitrate","body":"","anchorH1":"setminaudiobitrate"},{"h1":"setMinAudioBitrate","h2":"Description","body":"Set a minimum audio bitrate reachable through adaptive streaming. When the bitrate is chosen through adaptive streaming (i.e., not enforced manually through APIs such as setAudioBitrate), the player will never switch to an audio quality with a bitrate lower than that value. The exception being when no quality has a higher bitrate, in which case the maximum quality will always be chosen instead. For example, if you want that audio qualities chosen automatically never have a bitrate below 100 kilobits per second you can call: player.setMinAudioBitrate(100000);  Any limit can be removed just by setting that value to 0: // remove audio bitrate lower limit player.setMinAudioBitrate(0);  The effect of this method is persisted from content to content. As such, it can even be called when no content is currently loaded. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setAudioBitrate) bypass this limit completely.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setminaudiobitrate","anchorH2":"description"},{"h1":"setMinAudioBitrate","h2":"Syntax","body":"player.setMinAudioBitrate(minBitrate);    arguments:  minBitrate number: Lower audio bitrate limit when adaptive streaming is enabled.   ","anchorH1":"setminaudiobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/setMaxVideoBitrate.html","index":[{"h1":"setMaxVideoBitrate","body":"","anchorH1":"setmaxvideobitrate"},{"h1":"setMaxVideoBitrate","h2":"Description","body":"Set a maximum video bitrate reachable through adaptive streaming. When the bitrate is chosen through adaptive streaming (i.e., not enforced manually through APIs such as setVideoBitrate), the player will never switch to a video quality with a bitrate higher than that value. The exception being when no quality has a lower bitrate, in which case the minimum quality will always be chosen instead. For example, if you want that video qualities chosen automatically never have a bitrate higher than 1 Megabits per second you can call: player.setMaxVideoBitrate(1e6);  Any limit can be removed just by setting that value to Infinity: // remove video bitrate higher limit player.setMaxVideoBitrate(Infinity);  The effect of this method is persisted from content to content. As such, it can even be called when no content is currently loaded. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setVideoBitrate) bypass this limit completely.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setmaxvideobitrate","anchorH2":"description"},{"h1":"setMaxVideoBitrate","h2":"Syntax","body":"player.setMaxVideoBitrate(maxBitrate);    arguments:  maxBitrate number: Upper video bitrate limit when adaptive streaming is enabled.   ","anchorH1":"setmaxvideobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/setMaxAudioBitrate.html","index":[{"h1":"setMaxAudioBitrate","body":"","anchorH1":"setmaxaudiobitrate"},{"h1":"setMaxAudioBitrate","h2":"Description","body":"Set a maximum audio bitrate reachable through adaptive streaming. When the bitrate is chosen through adaptive streaming (i.e., not enforced manually through APIs such as setAudioBitrate), the player will never switch to an audio quality with a bitrate higher than that value. The exception being when no quality has a lower bitrate, in which case the minimum quality will always be chosen instead. For example, if you want that audio qualities chosen automatically never have a bitrate higher than 1 Megabits per second you can call: player.setMaxAudioBitrate(1e6);  Any limit can be removed just by setting that value to Infinity: // remove audio bitrate higher limit player.setMaxAudioBitrate(Infinity);  The effect of this method is persisted from content to content. As such, it can even be called when no content is currently loaded. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setAudioBitrate) bypass this limit completely.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setmaxaudiobitrate","anchorH2":"description"},{"h1":"setMaxAudioBitrate","h2":"Syntax","body":"player.setMaxAudioBitrate(maxBitrate);    arguments:  maxBitrate number: Upper audio bitrate limit when adaptive streaming is enabled.   ","anchorH1":"setmaxaudiobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getMinVideoBitrate.html","index":[{"h1":"getMinVideoBitrate","body":"","anchorH1":"getminvideobitrate"},{"h1":"getMinVideoBitrate","h2":"Description","body":"Returns the minimum video bitrate reachable through adaptive streaming, in bits per second. This minimum limit has usually been set either through the setMinVideoBitrate method or through the minVideoBitrate constructor option. This limit can be further updated by calling the setMinVideoBitrate method. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setVideoBitrate) bypass this limit completely.","anchorH1":"getminvideobitrate","anchorH2":"description"},{"h1":"getMinVideoBitrate","h2":"Syntax","body":"const minBitrate = player.getMinVideoBitrate();   return value number ","anchorH1":"getminvideobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getMinAudioBitrate.html","index":[{"h1":"getMinAudioBitrate","body":"","anchorH1":"getminaudiobitrate"},{"h1":"getMinAudioBitrate","h2":"Description","body":"Returns the minimum audio bitrate reachable through adaptive streaming, in bits per second. This minimum limit has usually been set either through the setMinAudioBitrate method or through the minAudioBitrate constructor option. This limit can be further updated by calling the setMinAudioBitrate method. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setAudioBitrate) bypass this limit completely.","anchorH1":"getminaudiobitrate","anchorH2":"description"},{"h1":"getMinAudioBitrate","h2":"Syntax","body":"const minBitrate = player.getMinAudioBitrate();   return value number ","anchorH1":"getminaudiobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getMaxVideoBitrate.html","index":[{"h1":"getMaxVideoBitrate","body":"","anchorH1":"getmaxvideobitrate"},{"h1":"getMaxVideoBitrate","h2":"Description","body":"Returns the maximum video bitrate reachable through adaptive streaming, in bits per second. This maximum limit has usually been set either through the setMaxVideoBitrate method or through the maxVideoBitrate constructor option. This limit can be further updated by calling the setMaxVideoBitrate method. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setVideoBitrate) bypass this limit completely.","anchorH1":"getmaxvideobitrate","anchorH2":"description"},{"h1":"getMaxVideoBitrate","h2":"Syntax","body":"const maxBitrate = player.getMaxVideoBitrate();   return value number ","anchorH1":"getmaxvideobitrate","anchorH2":"syntax"}]},{"file":"./api/Bitrate_Selection/getMaxAudioBitrate.html","index":[{"h1":"getMaxAudioBitrate","body":"","anchorH1":"getmaxaudiobitrate"},{"h1":"getMaxAudioBitrate","h2":"Description","body":"Returns the maximum audio bitrate reachable through adaptive streaming, in bits per second. This maximum limit has usually been set either through the setMaxAudioBitrate method or through the maxAudioBitrate constructor option. This limit can be further updated by calling the setMaxAudioBitrate method. Note that this only affects adaptive strategies. Forcing the bitrate manually (for example by calling setAudioBitrate) bypass this limit completely.","anchorH1":"getmaxaudiobitrate","anchorH2":"description"},{"h1":"getMaxAudioBitrate","h2":"Syntax","body":"const maxBitrate = player.getMaxAudioBitrate();   return value number ","anchorH1":"getmaxaudiobitrate","anchorH2":"syntax"}]},{"file":"./api/Speed_Control/setPlaybackRate.html","index":[{"h1":"setPlaybackRate","body":"","anchorH1":"setplaybackrate"},{"h1":"setPlaybackRate","h2":"Description","body":"Updates the current playback rate, i.e. the speed at which contents are played. As its name hints at, the value indicates the rate at which contents play:   Setting it to 2 allows to play at a speed multiplied by 2 relatively to regular playback.   Setting that value to 1 reset the playback rate to its “normal” rythm.   Setting it to 0.5 allows to play at half the speed relatively to regular playback.   etc.   This method’s effect is persisted from content to content, and can be called even when no content is playing (it will still have an effect for the next contents). If you want to reverse effects provoked by setPlaybackRate before playing another content, you will have to call setPlaybackRate first with the default settings you want to set. As an example, to reset the speed to “normal” (x1) speed and to disable trickMode video tracks (which may have been enabled by a previous setPlaybackRate call), you can call: player.setPlaybackRate(1, { preferTrickModeTracks: false });  – This method can be used to switch to or exit from “trickMode” video tracks, which are tracks specifically defined to mimic the visual aspect of a VCR’s fast forward/rewind feature, by only displaying a few video frames during playback. This behavior is configurable through the second argument, by adding a property named preferTrickModeTracks to that object. You can set that value to true to switch to trickMode video tracks when available, and set it to false when you want to disable that logic. Note that like any configuration given to setPlaybackRate, this setting is persisted through all future contents played by the player. If you want to stop enabling trickMode tracks, you will have to call setPlaybackRate again with preferTrickModeTracks set to false. You can know at any moment whether this behavior is enabled by calling the areTrickModeTracksEnabled method. This will only means that the RxPlayer will select in priority trickmode video tracks, not that the currently chosen video tracks is a trickmode track (for example, some contents may have no trickmode tracks available). If you want to know about the latter instead, you can call getVideoTrack and/or listen to videoTrackChange events. The track returned may have an isTrickModeTrack property set to true, indicating that it is a trickmode track. Note that switching to or getting out of a trickmode video track may lead to the player being a brief instant in a \"RELOADING\" state (notified through playerStateChange events and the getPlayerState method). When in that state, a black screen may be displayed and multiple RxPlayer APIs will not be usable. This method can be called at any time, even when no content is loaded and is persisted from content to content. You can set it to 1 to reset its value to the “regular” default. It is possible to try to enable the trick mode track by setting the second argument to true (and disable it when setting false). If available, the RxPlayer will switch the current video track to the trick mode one. The trick mode track proposes video content that is often encoded with a very low framerate because the content is not intended to be played at regular framerate and because the chunks must be faster to load for the client. Examples // plays three times faster than normal player.setPlaybackRate(3);  // plays five times faster than normal, and enable trickmode tracks if they exist player.setPlaybackRate(5, { preferTrickModeTracks: true });  // reset the speed to \"normal\" (x1) speed and to disable trickMode video tracks player.setPlaybackRate(1, { preferTrickModeTracks: false }); ","anchorH1":"setplaybackrate","anchorH2":"description"},{"h1":"setPlaybackRate","h2":"Syntax","body":"player.setPlaybackRate(speed);  // or, with trickmode settings player.setPlaybackRate(speed, { preferTrickModeTracks });    arguments:  speed number: The speed / playback rate you want to set. options (optional) Object|undefined: Options related to the speed update.   ","anchorH1":"setplaybackrate","anchorH2":"syntax"}]},{"file":"./api/Speed_Control/getPlaybackRate.html","index":[{"h1":"getPlaybackRate","body":"","anchorH1":"getplaybackrate"},{"h1":"getPlaybackRate","h2":"Description","body":"Returns the current playback rate. 1 for normal playback, 2 when playing at double the speed, etc. Example const currentPlaybackRate = player.getPlaybackRate(); console.log(`Playing at a x${currentPlaybackRate}} speed`); ","anchorH1":"getplaybackrate","anchorH2":"description"},{"h1":"getPlaybackRate","h2":"Syntax","body":"const rate = player.getPlaybackRate();   return value number ","anchorH1":"getplaybackrate","anchorH2":"syntax"}]},{"file":"./api/Speed_Control/areTrickModeTracksEnabled.html","index":[{"h1":"areTrickModeTracksEnabled","body":"","anchorH1":"aretrickmodetracksenabled"},{"h1":"areTrickModeTracksEnabled","h2":"Description","body":"Returns true if trickmode playback is active (it is usually enabled through the setPlaybackRate method), which means that the RxPlayer selects “trickmode” video tracks in priority. Returns false in other cases. Note that this doesn’t mean that the player is currently playing a trickmode track nor that it is even playing a content, only that it selects trickmode tracks in priority. To switch on or off this mode, you can use the setPlaybackRate method.","anchorH1":"aretrickmodetracksenabled","anchorH2":"description"},{"h1":"areTrickModeTracksEnabled","h2":"Syntax","body":"const areEnabled = player.areTrickModeTracksEnabled();   return value boolean ","anchorH1":"aretrickmodetracksenabled","anchorH2":"syntax"}]},{"file":"./api/Volume_Control/setVolume.html","index":[{"h1":"setVolume","body":"","anchorH1":"setvolume"},{"h1":"setVolume","h2":"Description","body":"Set the current volume, from 0 (no sound) to 1 (the maximum sound level). Note that the volume set here is persisted even when loading another content. As such, this method can also be called when no content is currently playing.","anchorH1":"setvolume","anchorH2":"description"},{"h1":"setVolume","h2":"Syntax","body":"player.setVolume(volume);    arguments:  volume number: Volume from 0 to 1.   ","anchorH1":"setvolume","anchorH2":"syntax"},{"h1":"setVolume","h2":"Example","body":"// set the full volume player.setVolume(1); ","anchorH1":"setvolume","anchorH2":"example"}]},{"file":"./api/Volume_Control/getVolume.html","index":[{"h1":"getVolume","body":"","anchorH1":"getvolume"},{"h1":"getVolume","h2":"Description","body":"Current volume of the player, from 0 (no sound) to 1 (maximum sound). 0 if muted through the mute API. As the volume is not dependent on a single content (it is persistent), this method can also be called when no content is playing.","anchorH1":"getvolume","anchorH2":"description"},{"h1":"getVolume","h2":"Syntax","body":"const volume = player.getVolume();   return value number ","anchorH1":"getvolume","anchorH2":"syntax"},{"h1":"getVolume","h2":"Example","body":"const volume = player.getVolume();  if (volume === 1) {   console.log(\"You're playing at maximum volume\"); } else if (volume === 0) {   console.log(\"You're playing at no volume\"); } else if (volume > 0.5) {   console.log(\"You're playing at a high volume\"); } else {   console.log(\"You're playing at a low volume\"); } ","anchorH1":"getvolume","anchorH2":"example"}]},{"file":"./api/Volume_Control/mute.html","index":[{"h1":"mute","body":"","anchorH1":"mute"},{"h1":"mute","h2":"Description","body":"Mute the volume. Basically set the volume to 0 while keeping in memory the previous volume to reset it at the next unMute call. As the volume is not dependent on a single content (it is persistent), this method can also be called when no content is playing.","anchorH1":"mute","anchorH2":"description"},{"h1":"mute","h2":"Syntax","body":"player.mute(); ","anchorH1":"mute","anchorH2":"syntax"},{"h1":"mute","h2":"Example","body":"// mute the current volume player.mute(); ","anchorH1":"mute","anchorH2":"example"}]},{"file":"./api/Volume_Control/isMute.html","index":[{"h1":"isMute","body":"","anchorH1":"ismute"},{"h1":"isMute","h2":"Description","body":"Returns true if the volume is set to 0.","anchorH1":"ismute","anchorH2":"description"},{"h1":"isMute","h2":"Syntax","body":"const isMute = player.isMute();   return value boolean ","anchorH1":"ismute","anchorH2":"syntax"},{"h1":"isMute","h2":"Example","body":"if (player.isMute()) {   console.log(\"The content plays with no sound.\"); } ","anchorH1":"ismute","anchorH2":"example"}]},{"file":"./api/Volume_Control/unMute.html","index":[{"h1":"unMute","body":"","anchorH1":"unmute"},{"h1":"unMute","h2":"Description","body":"When muted, restore the volume to the one previous to the last mute call. When the volume is already superior to 0, this call won’t do anything. As the volume is not dependent on a single content (it is persistent), this method can also be called when no content is playing.","anchorH1":"unmute","anchorH2":"description"},{"h1":"unMute","h2":"Syntax","body":"player.unMute(); ","anchorH1":"unmute","anchorH2":"syntax"},{"h1":"unMute","h2":"Example","body":"// mute the current volume player.mute();  // unmute and restore the previous volume player.unMute(); ","anchorH1":"unmute","anchorH2":"example"}]},{"file":"./api/Buffer_Control/setWantedBufferAhead.html","index":[{"h1":"setWantedBufferAhead","body":"","anchorH1":"setwantedbufferahead"},{"h1":"setWantedBufferAhead","h2":"Description","body":"Set the buffering goal, as a duration ahead of the current position, in seconds. Once this size of buffer reached, the player won’t try to download new segments anymore. By default, this value is set to 30.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setwantedbufferahead","anchorH2":"description"},{"h1":"setWantedBufferAhead","h2":"Syntax","body":"player.setWantedBufferAhead(bufferGoal);    arguments:  bufferGoal number: Ideal amount of buffer that should be pre-loaded, in seconds.   ","anchorH1":"setwantedbufferahead","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/getWantedBufferAhead.html","index":[{"h1":"getWantedBufferAhead","body":"","anchorH1":"getwantedbufferahead"},{"h1":"getWantedBufferAhead","h2":"Description","body":"returns the buffering goal, as a duration ahead of the current position, in seconds. This is the amount of seconds after the current position that the RxPlayer will try to preload in the buffer. Once that value is reached, the RxPlayer won’t normally request new media data until the value comes down again (due e.g. to the current position evolving or to a seeking operation). By default, this value is set to 30.","anchorH1":"getwantedbufferahead","anchorH2":"description"},{"h1":"getWantedBufferAhead","h2":"Syntax","body":"const bufferGoal = player.getWantedBufferAhead();   return value number: current “buffering goal”, in seconds. ","anchorH1":"getwantedbufferahead","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/setMaxBufferBehind.html","index":[{"h1":"setMaxBufferBehind","body":"","anchorH1":"setmaxbufferbehind"},{"h1":"setMaxBufferBehind","h2":"Description","body":"Set the maximum kept buffer before the current position, in seconds. Everything before that limit (currentPosition - maxBufferBehind) will be automatically garbage collected. This feature is not necessary as the browser should by default correctly remove old segments from memory if/when the memory is scarce. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. You can set it to Infinity to remove this limit and just let the browser do this job instead.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setmaxbufferbehind","anchorH2":"description"},{"h1":"setMaxBufferBehind","h2":"Syntax","body":"player.setMaxBufferBehind(bufferSize);    arguments:  bufferSize number: Maximum amount of buffer behind the current position, in seconds.   ","anchorH1":"setmaxbufferbehind","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/getMaxBufferBehind.html","index":[{"h1":"getMaxBufferBehind","body":"","anchorH1":"getmaxbufferbehind"},{"h1":"getMaxBufferBehind","h2":"Description","body":"Returns the maximum kept buffer before the current position, in seconds. This setting can be updated either by:  calling the setMaxBufferBehind method. instanciating an RxPlayer with a maxBufferBehind property set. ","anchorH1":"getmaxbufferbehind","anchorH2":"description"},{"h1":"getMaxBufferBehind","h2":"Syntax","body":"const bufferSize = player.getMaxBufferBehind();   return value number: Maximum kept buffer before the  current position, in seconds. ","anchorH1":"getmaxbufferbehind","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/setMaxBufferAhead.html","index":[{"h1":"setMaxBufferAhead","body":"","anchorH1":"setmaxbufferahead"},{"h1":"setMaxBufferAhead","h2":"Description","body":"Set the maximum kept buffer ahead of the current position, in seconds. Everything superior to that limit (currentPosition + maxBufferAhead) will be automatically garbage collected. This feature is not necessary as the browser should by default correctly remove old segments from memory if/when the memory is scarce. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. You can set it to Infinity to remove any limit and just let the browser do this job instead. The minimum value between this one and the one returned by getWantedBufferAhead will be considered when downloading new segments.  Bear in mind that a too-low configuration there (e.g. inferior to 10) might prevent the browser to play the content at all.   In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setmaxbufferahead","anchorH2":"description"},{"h1":"setMaxBufferAhead","h2":"Syntax","body":"player.setMaxBufferAhead(bufferSize);    arguments:  bufferSize number: Maximum amount of buffer ahead of the current position, in seconds.   ","anchorH1":"setmaxbufferahead","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/getMaxBufferAhead.html","index":[{"h1":"getMaxBufferAhead","body":"","anchorH1":"getmaxbufferahead"},{"h1":"getMaxBufferAhead","h2":"Description","body":"Returns the maximum kept buffer ahead of the current position, in seconds. This setting can be updated either by:  calling the setMaxBufferAhead method. instanciating an RxPlayer with a maxBufferAhead property set. ","anchorH1":"getmaxbufferahead","anchorH2":"description"},{"h1":"getMaxBufferAhead","h2":"Syntax","body":"const bufferSize = player.getMaxBufferAhead();   return value number: Maximum kept buffer in front of the  current position, in seconds. ","anchorH1":"getmaxbufferahead","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/setMaxVideoBufferSize.html","index":[{"h1":"setMaxVideoBufferSize","body":"","anchorH1":"setmaxvideobuffersize"},{"h1":"setMaxVideoBufferSize","h2":"Description","body":"Set the maximum memory the video buffer can take up in the memory, in kilobytes Defaults at Infinity Once this value is reached, the player won’t try to download new video segments anymore. This feature was designed with devices that have limited memory and trying to play very high bitrates representations in minds. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. You can set it to Infinity to remove this limit and just let the browser do this job instead.  The limit set by `setMaxVideoBufferSize` is approximative, and bypassed in edge case scenarios if we dont have enough buffer because of this limitation.   In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setmaxvideobuffersize","anchorH2":"description"},{"h1":"setMaxVideoBufferSize","h2":"Syntax","body":"player.setMaxVideoBufferSize(bufferSize);    arguments:  bufferSize number: Maximum amount of memory the buffer can download, in kilobytes   ","anchorH1":"setmaxvideobuffersize","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/getMaxVideoBufferSize.html","index":[{"h1":"getMaxBufferSize","body":"","anchorH1":"getmaxbuffersize"},{"h1":"getMaxBufferSize","h2":"Description","body":"Returns the maximum video buffer memory size limit , in kilobytes. This setting can be updated either by:  calling the setMaxVideoBufferSize method. instanciating an RxPlayer with a maxVideoBufferSize property set. ","anchorH1":"getmaxbuffersize","anchorH2":"description"},{"h1":"getMaxBufferSize","h2":"Syntax","body":"const bufferSize = player.getMaxBufferSize();   return value number: Maximum buffer memory size limit, in kilobytes. ","anchorH1":"getmaxbuffersize","anchorH2":"syntax"}]},{"file":"./api/Buffer_Information/getVideoBufferGap.html","index":[{"h1":"getVideoBufferGap","body":"","anchorH1":"getvideobuffergap"},{"h1":"getVideoBufferGap","h2":"Description","body":"Returns in seconds the difference between:  the current time. the end of the current contiguous loaded range.  In other words, this is the amount of seconds left in the buffer before the end of the current contiguous range of media data. If we’re currently playing at the position at 51 seconds, and there is media data from the second 40 to the second 60, then getVideoPlayedTime() will return 9 (60 - 51).","anchorH1":"getvideobuffergap","anchorH2":"description"},{"h1":"getVideoBufferGap","h2":"Syntax","body":"const bufferGap = player.getVideoBufferGap();   return value number ","anchorH1":"getvideobuffergap","anchorH2":"syntax"}]},{"file":"./api/Buffer_Information/getVideoLoadedTime.html","index":[{"h1":"getVideoLoadedTime","body":"","anchorH1":"getvideoloadedtime"},{"h1":"getVideoLoadedTime","h2":"Description","body":"Returns in seconds the difference between:  the start of the current contiguous loaded range. the end of it.  In other words, this is the duration of the current contiguous range of media data the player is currently playing: If we’re currently playing at the position at 51 seconds, and there is media data from the second 40 to the second 60, then getVideoLoadedTime() will return 20 (60 - 40). 0 if there’s no data loaded for the current position.","anchorH1":"getvideoloadedtime","anchorH2":"description"},{"h1":"getVideoLoadedTime","h2":"Syntax","body":"const loadedTime = player.getVideoLoadedTime();   return value number ","anchorH1":"getvideoloadedtime","anchorH2":"syntax"}]},{"file":"./api/Buffer_Information/getVideoPlayedTime.html","index":[{"h1":"getVideoPlayedTime","body":"","anchorH1":"getvideoplayedtime"},{"h1":"getVideoPlayedTime","h2":"Description","body":"Returns in seconds the difference between:  the start of the current contiguous loaded range. the current time.  In other words, this is the amount of time in the current contiguous range of media data the player has already played. If we’re currently playing at the position at 51 seconds, and there is media data from the second 40 to the second 60, then getVideoPlayedTime() will return 11 (51 - 40). 0 if there’s no data loaded for the current position.","anchorH1":"getvideoplayedtime","anchorH2":"description"},{"h1":"getVideoPlayedTime","h2":"Syntax","body":"const playedTime = player.getVideoPlayedTime();   return value number ","anchorH1":"getvideoplayedtime","anchorH2":"syntax"}]},{"file":"./api/Content_Information/getUrl.html","index":[{"h1":"getUrl","body":"","anchorH1":"geturl"},{"h1":"getUrl","h2":"Description","body":"Returns the URL of the downloaded Manifest.  In DirectFile mode (see  loadVideo options), returns the URL of the content being played.  Returns undefined if no content is loaded yet. Example const url = player.getUrl(); if (url) {   console.log(\"We are playing the following content:\", url); } ","anchorH1":"geturl","anchorH2":"description"},{"h1":"getUrl","h2":"Syntax","body":"const url = player.getUrl();   return value string ","anchorH1":"geturl","anchorH2":"syntax"}]},{"file":"./api/Content_Information/isLive.html","index":[{"h1":"isLive","body":"","anchorH1":"islive"},{"h1":"isLive","h2":"Description","body":"Returns true if the content is a “live” content (e.g. a live TV Channel). false otherwise. Also false if no content is loaded yet. Example if (player.isLive()) {   console.log(\"We're playing a live content\"); } ","anchorH1":"islive","anchorH2":"description"},{"h1":"isLive","h2":"Syntax","body":"const isLive = player.isLive();   return value boolean ","anchorH1":"islive","anchorH2":"syntax"}]},{"file":"./api/Content_Information/getCurrentKeySystem.html","index":[{"h1":"getCurrentKeySystem","body":"","anchorH1":"getcurrentkeysystem"},{"h1":"getCurrentKeySystem","h2":"Description","body":"Returns the type of keySystem used for DRM-protected contents.","anchorH1":"getcurrentkeysystem","anchorH2":"description"},{"h1":"getCurrentKeySystem","h2":"Syntax","body":"const keySystemName = player.getCurrentKeySystem();   return value string|undefined ","anchorH1":"getcurrentkeysystem","anchorH2":"syntax"}]},{"file":"./api/Static_Properties.html","index":[{"h1":"RxPlayer Static Properties","body":"The RxPlayer has multiple static properties allowing to read or modify global RxPlayer attributes.","anchorH1":"rxplayer_static_properties"},{"h1":"RxPlayer Static Properties","h2":"version","body":"The version static property returns a string corresponding to the current version of the RxPlayer:","anchorH1":"rxplayer_static_properties","anchorH2":"version"},{"h1":"RxPlayer Static Properties","h2":"version","h3":"example","body":"import RxPlayer from \"rx-player\";  console.log(\"Current RxPlayer version:\", RxPlayer.version); ","anchorH1":"rxplayer_static_properties","anchorH2":"version","anchorH3":"example"},{"h1":"RxPlayer Static Properties","h2":"LogLevel","body":"The current level of verbosity for the RxPlayer logs, as a string. Those logs all use the console. From the less verbose to the most:   \"NONE\": no log   \"ERROR\": unexpected errors (via console.error)   \"WARNING\": The previous level + minor problems encountered (via console.warn)   \"INFO\": The previous levels + noteworthy events (via console.info)   \"DEBUG\": The previous levels + normal events of the player (via console.log)   If the value set to this property is different than those, it will be automatically set to \"NONE\".","anchorH1":"rxplayer_static_properties","anchorH2":"loglevel"},{"h1":"RxPlayer Static Properties","h2":"LogLevel","h3":"Example","body":"import RxPlayer from \"rx-player\"; RxPlayer.LogLevel = \"WARNING\"; ","anchorH1":"rxplayer_static_properties","anchorH2":"loglevel","anchorH3":"example_(1)"},{"h1":"RxPlayer Static Properties","h2":"ErrorTypes","body":"The different “types” of Error you can get on playback error, See the Player Error documentation for more information.","anchorH1":"rxplayer_static_properties","anchorH2":"errortypes"},{"h1":"RxPlayer Static Properties","h2":"ErrorCodes","body":"The different Error “codes” you can get on playback error, See the Player Error documentation for more information.","anchorH1":"rxplayer_static_properties","anchorH2":"errorcodes"}]},{"file":"./api/Typescript_Types.html","index":[{"h1":"Exported TypeScript Types","body":"The RxPlayer being written in TypeScript, it has type definitions attached to its source code that can be helpful if you develop an application in TypeScript yourself.","anchorH1":"exported_typescript_types"},{"h1":"Exported TypeScript Types","h2":"“Using” types","body":"Because we follow the usual way of adding definition files (as d.ts file alongside our sources), those typings should be auto-exported when importing our library in your favorite editor (as long as it is linked to a TSServer of some sort).","anchorH1":"exported_typescript_types","anchorH2":"%22using%22_types"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","body":"As some APIs can have pretty complicated arguments, you might also want to import some of our internal type definitions into your code. To simplify this process, we export some type definitions which can be imported through the following line in your file: import { SOME_TYPE } from \"rx-player/types\"  Here are the list of exported types, per category.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"RxPlayer Constructor","body":"The type IConstructorOptions corresponds to the interface that the RxPlayer constructor accepts as an argument. Example: import RxPlayer from \"rx-player\"; import { IConstructorOptions } from \"rx-player/types\";  function generateConstructorOptions() : IConstructorOptions {   const videoElement = document.querySelector(\"video\");   return {     stopAtEnd: false,     videoElement,   }; }  const options = generateConstructorOptions(); const player = new RxPlayer(options);  export default player;  Two constructor options have also their type definition exported, those are:   IAudioTrackPreference: which is the type of a single element in the preferredAudioTracks array.   ITextTrackPreference: which is the type of a single element in the preferredTextTracks array.   IVideoTrackPreference: which is the type of a single element in the preferredVideoTracks array.  ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"rxplayer_constructor"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"loadVideo","body":"The ILoadVideoOptions type corresponds to the argument to give to the RxPlayer’s method loadVideo. Example: // the type wanted import { ILoadVideoOptions } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  function generateLoadVideoOptions(url : string) : ILoadVideoOptions {   return {     url,     transport: \"dash\",     autoPlay: true,   }; }  const loadVideoOpts = generateLoadVideoOptions(config.DEFAULT_URL); rxPlayer.loadVideo(loadVideoOpts);  Speaking of loadVideo, some subparts of ILoadVideoOptions are also exported:   IKeySystemOption: type for an element of the keySystems array, which is an optional property given to loadVideo. To clarify, the keySystems property in a loadVideo call is an optional array of one or multiple IKeySystemOption.   IPersistentSessionStorage: type of the licenseStorage property of the keySystems option given to loadVideo.   IPersistentSessionInfo: type used by an IPersistentSessionStorage.   ITransportOptions: type for the transportOptions property optionally given to loadVideo.   IManifestLoader: type for the manifestLoader function optionally set on the transportOptions option of loadVideo.   IRepresentationFilter: type for the representationFilter function optionally set on the transportOptions option of loadVideo.   IRepresentationInfos: type for the second argument of the representationFilter function (defined by IRepresentationFilter.)   IServerSyncInfos: type for the serverSyncInfos property optionally set on the transportOptions option of loadVideo.   IInitialManifest: type for the initialManifest property optionally set on the transportOptions option of loadVideo.   ISegmentLoader: type for the segmentLoader function optionally set on the transportOptions option of loadVideo.   ISupplementaryTextTrackOption: type for an element of the supplementaryTextTracks array, which is an optional property given to loadVideo.   ISupplementaryImageTrackOption: type for an element of the supplementaryImageTracks array, which is an optional property given to loadVideo.   IDefaultAudioTrackOption: type for the defaultAudioTrack property optionally given to loadVideo.   IDefaultTextTrackOption: type for the defaultAudioTrack property optionally given to loadVideo.   INetworkConfigOption: type for the networkConfig property optionally given to loadVideo.   IStartAtOption: type for the startAt property optionally given to loadVideo.   IAudioTrackSwitchingMode: The various values accepted on the audioTrackSwitchingMode property optionally given to loadVideo.  ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"loadvideo"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"Manifest structure","body":"Several RxPlayer methods rely on a Manifest structure and one of its “children”: the Period, the Adaptation, the Representation or the Segment. All of those can be imported from \"rx-player/types\" respectively as IManifest, IPeriod, IAdaptation, IRepresentation and ISegment","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"manifest_structure"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getPlayerState method / playerStateChange event","body":"The return type of the getPlayerState state method and of the playerStateChange events is a string describing the current state of the RxPlayer. All values possible are defined through the IPlayerState type: // the type(s) wanted import { IPlayerState } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function getPlayerState() : IPlayerState {   return rxPlayer.getPlayerState(); } ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getplayerstate_method_/_playerstatechange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getAvailableAudioTracks method / availableAudioTracksChange event","body":"The return type of the getAvailableAudioTracks method is an array of objects. Each of this objects corresponds to the IAvailableAudioTrack interface. Example: // the type(s) wanted import { IAvailableAudioTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function getAvailableAudioTracks() : IAvailableAudioTrack[] {   return rxPlayer.getAvailableAudioTracks(); }  The property of each track’s representations property corresponds to the IAudioRepresentation type.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getavailableaudiotracks_method_/_availableaudiotrackschange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getAvailableTextTracks method / availabletextTracksChange event","body":"The return type of the getAvailableTextTracks method is an array of objects. Each of this objects corresponds to the IAvailableTextTrack interface. Example: // the type(s) wanted import { IAvailableTextTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  function getAvailableTextTracks() : IAvailableTextTrack[] {   return rxPlayer.getAvailableTextTracks(); } ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getavailabletexttracks_method_/_availabletexttrackschange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getAvailableVideoTracks method / availableVideoTracksChange event","body":"The return type of the getAvailableVideoTracks method is an array of objects. Each of this objects corresponds to the IAvailableVideoTrack interface. Example: // the type(s) wanted import { IAvailableVideoTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  function getAvailableVideoTracks() : IAvailableVideoTrack[] {   return rxPlayer.getAvailableVideoTracks(); }  The property of each track’s representations property corresponds to the IVideoRepresentation type.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getavailablevideotracks_method_/_availablevideotrackschange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getAudioTrack method /audioTrackChange event","body":"The IAudioTrack corresponds to both the type returned by the getAudioTrack method and emitted as the payload of the audioTrackChange event. Example: // the type(s) wanted import { IAudioTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  rxPlayer.addEventListener(\"audioTrackChange\", (track : IAudioTrack) => {   console.log(\"current track:\", track); });  function getCurrentlyDownloadedAudioTrack() : IAudioTrack {   return rxPlayer.getAudioTrack(); }  The representations property also has an exported type: IAudioRepresentation.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getaudiotrack_method_/audiotrackchange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getTextTrack method / textTrackChange event","body":"The ITextTrack corresponds to both the type returned by the getTextTrack method and emitted as the payload of the textTrackChange event. Example: // the type(s) wanted import { ITextTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  rxPlayer.addEventListener(\"textTrackChange\", (track : ITextTrack) => {   console.log(\"current track:\", track); });  function getCurrentlyDownloadedTextTrack() : ITextTrack {   return rxPlayer.getTextTrack(); } ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"gettexttrack_method_/_texttrackchange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getVideoTrack method / videoTrackChange event","body":"The IVideoTrack corresponds to both the type returned by the getVideoTrack method and emitted as the payload of the videoTrackChange event. Example: // the type(s) wanted import { IVideoTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  rxPlayer.addEventListener(\"videoTrackChange\", (track : IVideoTrack) => {   console.log(\"current track:\", track); });  function getCurrentlyDownloadedVideoTrack() : IVideoTrack {   return rxPlayer.getVideoTrack(); }  The representations property also has an exported type: IAudioRepresentation.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getvideotrack_method_/_videotrackchange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"positionUpdate event","body":"The type IPositionUpdate corresponds to the payload of a positionUpdate event. Example: // the type(s) wanted import { IPositionUpdate } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"positionUpdate\", (evt : IPositionUpdate) {   console.log(evt); }); ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"positionupdate_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"streamEvent / streamEventSkip events","body":"The type IStreamEvent corresponds to the payload of either a streamEvent or a streamEventSkip event. The type IStreamEventData is the type of its data property. Example: // the type(s) wanted import { IStreamEvent, IStreamEventData } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function processEventData(eventData : IStreamEventData) {   if (eventData.type === \"dash-event-stream\") {     console.log(\"DASH EventStream's event received!\");   } }  rxPlayer.addEventListener(\"streamEvent\", (evt : IStreamEvent) {   processEventData(evt.data); }); ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"streamevent_/_streameventskip_events"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"bitrateEstimationChange event","body":"The type IBitrateEstimate corresponds to the payload of a bitrateEstimationChange event. Example: // the type(s) wanted import { IBitrateEstimate } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"bitrateEstimationChange\", (evt : IBitrateEstimate) {   console.log(evt); }); ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"bitrateestimationchange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"decipherabilityUpdate event","body":"The type IDecipherabilityUpdateContent corresponds to the payload of a decipherabilityUpdate event. Example: // the type(s) wanted import { IDecipherabilityUpdateContent } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"decipherabilityUpdate\", (evt : IDecipherabilityUpdateContent) {   console.log(evt); }); ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"decipherabilityupdate_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"RxPlayer errors and warnings","body":"RxPlayer errors and warnings may for now be either a plain Error instance or a special RxPlayer-defined error (which extends the Error Object). All RxPlayer-defined error are compatible with the exported IPlayerError type. Which means that you could write the following: // the type wanted import { IPlayerError } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"error\", (err : Error | IPlayerError) => {   // ... });  rxPlayer.addEventListener(\"warning\", (err : Error | IPlayerError) => {   // ... });  ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"rxplayer_errors_and_warnings"}]},{"file":"./api/Tools/TextTrackRenderer.html","index":[{"h1":"TextTrackRenderer","body":"","anchorH1":"texttrackrenderer"},{"h1":"TextTrackRenderer","h2":"Overview","body":"The TextTrackRenderer is a tool allowing to render subtitles synchronized with a video element (or any HTMLMediaElement). For now it supports the following formats:  TTML webVTT srt sami  The video does not need to be played through the RxPlayer for the TextTrackRenderer to work. It is a completely independent tool which just rely on the video element for synchronization information.","anchorH1":"texttrackrenderer","anchorH2":"overview"},{"h1":"TextTrackRenderer","h2":"Brief summary","body":"If you don’t want to read all this documentation, here is a complete example of how it can be used: // import TextTrackRenderer and the parsers we want import TextTrackRenderer, {   TTML_PARSER,   VTT_PARSER,   SRT_PARSER,   SAMI_PARSER, } from \"rx-player/tools/TextTrackRenderer\";  // Add the needed parsers to the TextTrackRenderer TextTrackRenderer.addParsers([   TTML_PARSER,   VTT_PARSER,   SRT_PARSER,   SAMI_PARSER, ]);  // get video element the subtitles has to be synchronized to const videoElement = document.querySelector(\"video\");  // get HTML element in which the text track will be displayed // Should generally be on top of the video, with the same size than it (but can // also be in any shape, corresponding to your UI needs). const textTrackElement = document.querySelector(\".text-track-container\");  const textTrackRenderer = new TextTrackRenderer({   videoElement,   textTrackElement, });  // example: a \".srt\" track const exampleSRT = `1 00:00:01,600 --> 00:00:04,200 English (US)  2 00:00:05,900 --> 00:00:07,999 This is a subtitle in American English  3 00:00:10,000 --> 00:00:14,000 Adding subtitles is very easy to do `;  try {   textTrackRenderer.setTextTrack({     data: exampleSRT,     type: \"srt\", // or \"ttml\" / \"vtt\" / \"sami\"     // timeOffset: 2.3, // optional offset in seconds to add to the subtitles   }); } catch (e) {   console.error(`Could not parse the subtitles: ${e}`); } ","anchorH1":"texttrackrenderer","anchorH2":"brief_summary"},{"h1":"TextTrackRenderer","h2":"How to import it","body":"The TextTrackRenderer alone can be imported as such: import TextTrackRenderer from \"rx-player/tools/TextTrackRenderer\";  But just importing the TextTrackRenderer alone is pointless, you also have to import the text track parsers you want to use manually (this is a choice we made to avoid wasting space for subtitles formats you might not want). To import the parsers you want, you just have to do something along the line of: // Add two parsers to the TextTrackRenderer: one for TTML subtitles and one for // srt subtitles import TextTrackRenderer, {   TTML_PARSER,   SRT_PARSER, } from \"rx-player/tools/TextTrackRenderer\"; TextTrackRenderer.addParsers([TTML_PARSER, SRT_PARSER]);  Here are the different available parsers:    Import name Subtitles format parsed     TTML_PARSER TTML   VTT_PARSER WebVTT   SRT_PARSER SubRip (.srt)   SAMI_PARSER SAMI   ","anchorH1":"texttrackrenderer","anchorH2":"how_to_import_it"},{"h1":"TextTrackRenderer","h2":"How to use it","body":"","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Preamble","body":"Now that it is imported, we can begin to use it. We will need three items:   The video element our subtitles has to be synchronized to.   Another HTML element, in which the various subtitles will be rendered by the TextTrackRenderer. In general, you want that element to be on top of the video element, with the same dimensions. You might however set it in the shape and size you want. It can even be reduced dynamically at any time (for example, to reduce this element’s height when a UI element appear at the bottom of the screen, thus avoiding the subtitles from overlapping that new element).   The whole text track data, as a string (you will have to download the subtitles yourself).   To simplify, let’s give a name to all those 3 elements:  the videoElement the textTrackElement the textTrackData ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"preamble"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Creating a TextTrackRenderer","body":"We first have to create a new TextTrackRenderer with the first two items: const textTrackRenderer = new TextTrackRenderer({   videoElement,   textTrackElement, }); ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"creating_a_texttrackrenderer"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Setting a text track on it","body":"With textTrackRenderer, the TextTrackRenderer instance, we can now add at any time a text track through its setTextTrack method: try {   textTrackRenderer.setTextTrack({     data: textTrackData,     type: SUBTITLES_FORMAT,   }); } catch (e) {   console.error(`Could not parse the subtitles: ${e}`); }  Here, SUBTITLES_FORMAT is a string indicating in which format the subtitles are. It can be any of those strings:    type Corresponding subtitles format     \"ttml\" TTML   \"vtt\" WebVTT   \"srt\" SubRip (.srt)   \"sami\" SAMI    (Each format needs the corresponding parser to be imported. See the previous chapter for more information.) Note that the setTextTrack method can throw if the subtitles are found to be invalid. Any subsequent call to setTextTrack will remove the current text track and replace them with the new text track instead: // Add TTML subtitles textTrackRenderer.setTextTrack({   data: textTrackData1,   type: \"ttml\", });  // Completely removes the TTML subtitles and replace them by other subtitles, in // webVTT this time textTrackRenderer.setTextTrack({   data: textTrackData2,   type: \"vtt\", });  If your subtitles have a delay or are in advance relatively to the video, you can also set an offset in seconds through the timeOffset property. For example, this will display each subtitles 1.3 seconds later (for when subtitles appear and disappear too much in advance): textTrackRenderer.setTextTrack({   data: textTrackData,   type: \"srt\",   timeOffset: 1.3, });  And this will display each subtitles 1.3 seconds before they normally appear and disappear (for when subtitles are too late): textTrackRenderer.setTextTrack({   data: textTrackData,   type: \"srt\",   timeOffset: -1.3, }); ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"setting_a_text_track_on_it"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Removing the current text track","body":"If you just want to completely remove the current text track, you can call the removeTextTrack method: textTrackRenderer.removeTextTrack(); ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"removing_the_current_text_track"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Disposing of the TextTrackRenderer","body":"If you’re sure that you won’t need the TextTrackRenderer anymore, you can dispose of most ressources (which is not much) it took on your page by calling the dispose method: textTrackRenderer.dispose();  That TextTrackRenderer instance won’t be usable once you’ve call this method, so be sure you don’t need it anymore before calling it.","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"disposing_of_the_texttrackrenderer"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Notes on the SAMI format","body":"The SAMI subtitles format might necessitate you to specify the language you want to parse. This can be done on the setTextTrack call like this: textTrackRenderer.setTextTrack({   data: textTrackData,   type: \"sami\",   language: \"en-US\", // or fr-FR... }); ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"notes_on_the_sami_format"},{"h1":"TextTrackRenderer","h2":"About logs","body":"The TextTrackRenderer can display logs to the console. It relies on the exact same logger instance than the RxPlayer. This logger can be independently imported from \"rx-player/logger\": import logger from \"rx-player/logger\";  You can then set its verbosity through its setLevel method: logger.setLevel(LOGGER_LEVEL);  LOGGER_LEVEL can be any of those strings (from the less verbose to the most):   \"NONE\": no log   \"ERROR\": unexpected errors (via console.error)   \"WARNING\": The previous level + minor problems encountered (via console.warn)   \"INFO\": The previous levels + noteworthy events (via console.info)   \"DEBUG\": The previous levels + regular events (via console.log)    Updating the logger level will also update the RxPlayer's logger level as it is the exact same logger that is used there. ","anchorH1":"texttrackrenderer","anchorH2":"about_logs"}]},{"file":"./api/Tools/VideoThumbnailLoader.html","index":[{"h1":"VideoThumbnailLoader","body":"","anchorH1":"videothumbnailloader"},{"h1":"VideoThumbnailLoader","h2":"Overview","body":"The VideoThumbnailLoader is a tool that can help exploiting a trickmode video track to provide thumbnails for a video content. The goal is to make a thumbnail out of HTML5 video element, by :  Managing the loading / appending of resources from a given track (video segments). Exploiting the Media Source Extension API to make it invisible to user.  The tool will need the loaded manifest to contain trickmode tracks. These kind of track exists in MPEG-DASH and HLS, and contains lightweight video tracks, most of the time including one unique frame for each video segments. As video segments from trickmode tracks may be quicker to load and easier to decode, they are preferred over standard video tracks for creating thumbnails.","anchorH1":"videothumbnailloader","anchorH2":"overview"},{"h1":"VideoThumbnailLoader","h2":"How to use it","body":"As an experimental tool, the VideoThumbnailLoader won’t be included in a default RxPlayer build. Instead, it should be imported by adding the RxPlayer through a dependency trough the npm registry (e.g. by doing something like npm install rx-player) and then specifically importing this tool from \"rx-player/experimental/tools\": import VideoThumbnailLoader, {   DASH_LOADER, } from \"rx-player/experimental/tools/VideoThumbnailLoader\"; import RxPlayer from \"rx-player\";  const player = new RxPlayer({   /* some options */ });  // Link logic to handle DASH segments VideoThumbnailLoader.addLoader(DASH_LOADER);  // Video element used to display thumbnails. const thumbnailVideoElement = document.createElement(\"video\");  // Link VideoThumbnailLoader to the RxPlayer instance const videoThumbnailLoader = new VideoThumbnailLoader(   thumbnailVideoElement,   player );  player.loadVideo({   /* some options */ });  // Ask for the VideoThumbnailLoader to fetch a thumbnail for the current // content that should be displayed at presentation time = 200 seconds. videoThumbnailLoader.setTime(200); ","anchorH1":"videothumbnailloader","anchorH2":"how_to_use_it"},{"h1":"VideoThumbnailLoader","h2":"Static methods","body":"","anchorH1":"videothumbnailloader","anchorH2":"static_methods"},{"h1":"VideoThumbnailLoader","h2":"Static methods","h3":"addLoader","body":"arguments:  loader (Object): Imported loader from VideoThumbnailLoader package.  To be able to load and parse segments from a specific streaming format, you must import the corresponding loader and add it to the related instance : /!\\ Note that this is a static method, it has to be called on the VideoThumbnailLoader class and will add the corresponding logic to all VideoThumbnailLoader instances (even those already created). Example import VideoThumbnailLoader, {   DASH_LOADER,   MPL_LOADER, } from \"rx-player/experimental/tools/VideoThumbnailLoader\"; VideoThumbnailLoader.addLoader(DASH_LOADER); VideoThumbnailLoader.addLoader(MPL_LOADER); ","anchorH1":"videothumbnailloader","anchorH2":"static_methods","anchorH3":"addloader"},{"h1":"VideoThumbnailLoader","h2":"Instance methods","body":"","anchorH1":"videothumbnailloader","anchorH2":"instance_methods"},{"h1":"VideoThumbnailLoader","h2":"Instance methods","h3":"setTime","body":"arguments:  time (number): Time for which we want to display a thumbnail, in seconds.  return value: Promise Display thumbnail for the corresponding time (in seconds). Note: this tool rely on “trickmode” tracks to be present for the corresponding content at the corresponding time. Return value The return value is a Promise. It :  resolve when the thumbnail for given time has been loaded. reject in case of error : return an error.  The promise does not only rejects when setting thumbnail has failed. There are some cases where the thumbnail loader decides not to load. Here is a list of every failure code (error.code) :  NO_MANIFEST : No manifest available on current RxPlayer instance. NO_TRACK : In the player manifest, there are either no period or no representation to get video chunks. NO_THUMBNAIL : No segments are available for this time of the track. LOADING_ERROR : An error occured when loading a thumbnail into the video element. ABORTED : The loading has been aborted (probably because of another loading started) NO_LOADER : Trickmode track can’t be loaded as no loader was imported, or exists for this type of content (e.g. HSS content)  Example videoThumbnailLoader   .setTime(3000)   .then(() => {     console.log(\"Success :)\");   })   .catch((err) => {     console.log(\"Failure :(\", err);   }); ","anchorH1":"videothumbnailloader","anchorH2":"instance_methods","anchorH3":"settime"},{"h1":"VideoThumbnailLoader","h2":"Instance methods","h3":"dispose","body":"Dispose the tool resources. It has to be called when the tool is not used anymore. Example   onComponentUnmount() {     videoThumbnailLoader.dispose();   } ","anchorH1":"videothumbnailloader","anchorH2":"instance_methods","anchorH3":"dispose"}]},{"file":"./api/Tools/StringUtils.html","index":[{"h1":"StringUtils","body":"","anchorH1":"stringutils"},{"h1":"StringUtils","h2":"Overview","body":"Tools to convert strings into bytes and vice-versa. The RxPlayer internally has a lot of code dealing with strings to bytes conversion (and vice-versa). This tool exports that logic so you don’t have to rewrite it yourself. You might need one of those functions for example when dealing with challenge and licenses, which are often under a binary format.","anchorH1":"stringutils","anchorH2":"overview"},{"h1":"StringUtils","h2":"How to import it","body":"The simplest way to import the StringUtils is by importing it as a named export from “rx-player/tools”, like so: import { StringUtils } from \"rx-player/tools\";  console.log(StringUtils.strToUtf8(\"hello😀\"));  You can also import only the function(s) you want to use by importing it directly from “rx-player/tools/string-utils”: import { strToUtf8 } from \"rx-player/tools/string-utils\"; console.log(strToUtf8(\"hello😀\")); ","anchorH1":"stringutils","anchorH2":"how_to_import_it"},{"h1":"StringUtils","h2":"StringUtils functions","body":"StringUtils is an object containing the following functions:   strToUtf8: Convert a JS string passed as argument to an Uint8Array of its corresponding representation in UTF-8. Example: import { StringUtils } from \"rx-player/tools\"; StringUtils.strToUtf8(\"hello😀\"); // => Uint8Array(9) [ 104, 101, 108, 108, 111, 240, 159, 152, 128 ] //                    \"h\"  \"e\"  \"l\"  \"l\"  \"o\"  \"grinning face\" emoji    utf8ToStr: Convert a Uint8Array containing a string encoded with UTF-8 into a JS string. Example: import { StringUtils } from \"rx-player/tools\"; const uint8Arr = new Uint8Array([   104,   101,   108,   108,   111,   240,   159,   152,   128, ]); StringUtils.utf8ToStr(uint8Arr); // => \"hello😀\"  Note: if what you have is an ArrayBuffer, you have to convert it to an Uint8Array first: import { StringUtils } from \"rx-player/tools\"; const toUint8Array = new Uint8Array(myArrayBuffer); console.log(StringUtils.utf8ToStr(toUint8Array));    strToUtf16LE: Convert a JS string passed as argument to an Uint8Array containing its corresponding representation in UTF-16-LE (little endian UTF-16). Example: import { StringUtils } from \"rx-player/tools\"; StringUtils.strToUtf16LE(\"hi😀\"); // => Uint8Array(9) [ 104, 0, 105, 0, 61, 216, 0, 222 ] //                    \"h\"     \"i\"     \"grinning face\" emoji    utf16LEToStr: Convert a Uint8Array containing a string encoded with UTF-16-LE (little endian UTF-16) into a JS string. Example: import { StringUtils } from \"rx-player/tools\"; const uint8Arr = new Uint8Array([104, 0, 105, 0, 61, 216, 0, 222]); StringUtils.utf16LEToStr(uint8Arr); // => \"hi😀\"  Note: if what you have is an ArrayBuffer, you have to convert it to an Uint8Array first: import { StringUtils } from \"rx-player/tools\"; const toUint8Array = new Uint8Array(myArrayBuffer); console.log(StringUtils.utf16LEToStr(toUint8Array));    strToUtf16BE: Convert a JS string passed as argument to an Uint8Array containing its corresponding representation in UTF-16-BE (big endian UTF-16). Example: import { StringUtils } from \"rx-player/tools\"; StringUtils.strToUtf16BE(\"hi😀\"); // => Uint8Array(9) [ 0, 104, 0, 105, 216, 61, 222, 0 ] //                    \"h\"     \"i\"     \"grinning face\" emoji    utf16BEToStr: Convert a Uint8Array containing a string encoded with UTF-16-BE (big endian UTF-16) into a JS string. Example: import { StringUtils } from \"rx-player/tools\"; const uint8Arr = new Uint8Array([0, 104, 0, 105, 216, 61, 222, 0]); StringUtils.utf16BEToStr(uint8Arr); // => \"hi😀\"  Note: if what you have is an ArrayBuffer, you have to convert it to an Uint8Array first: import { StringUtils } from \"rx-player/tools\"; const toUint8Array = new Uint8Array(myArrayBuffer); console.log(StringUtils.utf16BEToStr(toUint8Array));   ","anchorH1":"stringutils","anchorH2":"stringutils_functions"}]},{"file":"./api/Tools/parseBifThumbnails.html","index":[{"h1":"parseBifThumbnails","body":"","anchorH1":"parsebifthumbnails"},{"h1":"parseBifThumbnails","h2":"Overview","body":"parseBifThumbnails is a function allowing to easily parse BIF files, which is a file format crafted to contain video thumbnails. Those are usually used to give a visual indication of where in a given media you will seek to when hovering a progress bar.","anchorH1":"parsebifthumbnails","anchorH2":"overview"},{"h1":"parseBifThumbnails","h2":"About BIF files","body":"The BIF format is straightforward. It contains several metadata and then all the images for the whole content, in their original format (e.g. “jpeg”), concatenated.","anchorH1":"parsebifthumbnails","anchorH2":"about_bif_files"},{"h1":"parseBifThumbnails","h2":"How to import it","body":"parseBifThumbnails is for now considered an “experimental” tool. This means that its API could change at any new version of the RxPlayer (don’t worry, we would still document all changes made to it in the corresponding release note). As an experimental tool, it is imported as such: import { parseBifThumbnails } from \"rx-player/experimental/tools\";  You can then begin to use it right away.","anchorH1":"parsebifthumbnails","anchorH2":"how_to_import_it"},{"h1":"parseBifThumbnails","h2":"How to use it","body":"As a simple parser, parseBifThumbnails takes the downloaded BIF file in an ArrayBuffer form and returns its content under an object format, like this: import { parseBifThumbnails } from \"rx-player/experimental/tools\";  // optionally, fetch the BIF resource through the usual APIs fetch(\"http://www.example.com/thumbnails.bif\").then(function(response) {   return response.arrayBuffer(); // obtain an ArrayBuffer response }).then(function(buffer) {   const parsedBif = parseBifThumbnails(buffer);   console.log(\"parsed BIF:\", parsedBif); };  Here is an example of the returned data: {   version: \"0.0.0.0\", // BIF version. For the moment, only \"0.0.0.0\" is                       // specified.   images: [    // Array of thumbnails for this content     {       startTime: 0, // Start position at which the thumbnail should be applied                     // to, in milliseconds.                     // For example, a time of `5000`, indicates that this                     // thumbnail should be shown from the 5 second mark in the                     // content (until the next image is displayed instead)       image: ArrayBuffer() // The thumbnail itself, in an ArrayBuffer form.     },     {       startTime: 10000,       endTime: 20000,       thumbnail: ArrayBuffer()     },     {       startTime: 20000,       endTime: 30000,       thumbnail: ArrayBuffer()     },     // ...   ], } ","anchorH1":"parsebifthumbnails","anchorH2":"how_to_use_it"}]},{"file":"./api/Tools/MediaCapabilitiesProber.html","index":[{"h1":"MediaCapabilitiesProber","body":"","anchorH1":"mediacapabilitiesprober"},{"h1":"MediaCapabilitiesProber","h2":"Overview","body":"The MediaCapabilitiesProber is a tool probing what your browser can do, especially:   Which DRM system is supported   Check for HDCP support   which codecs are available   Check the color space support    This tool is still in an experimental phase, meaning that its API can change at any new release. This is not because it is not stable (it is actually) or should not be used in production. This is just because we want to receive your feedbacks before locking definitely the API.  We can for example add supplementary information of even explode the MediaCapabilitiesProber into several tools to lower the size of the import. We’re waiting for your feedbacks!","anchorH1":"mediacapabilitiesprober","anchorH2":"overview"},{"h1":"MediaCapabilitiesProber","h2":"How to use it","body":"As an experimental tool, the MediaCapabilitiesProber won’t be included in a default RxPlayer build. Instead, it should be imported by adding the RxPlayer through a dependency trough the npm registry (e.g. by doing something like npm install rx-player) and then specifically importing this tool from \"rx-player/experimental/tools\": import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  mediaCapabilitiesProber.getStatusForHDCP(\"1.1\").then((hdcp11Status) => {   if (hdcp11Status === \"Supported\") {     console.log(\"HDCP 1.1 is supported\");   } }); ","anchorH1":"mediacapabilitiesprober","anchorH2":"how_to_use_it"},{"h1":"MediaCapabilitiesProber","h2":"Properties","body":"","anchorH1":"mediacapabilitiesprober","anchorH2":"properties"},{"h1":"MediaCapabilitiesProber","h2":"Properties","h3":"LogLevel","body":"type: string default: \"WARNING\" The current level of verbosity for this prober logs. Those logs all use the console. From the less verbose to the most:   \"NONE\": no log   \"ERROR\": unexpected errors (via console.error)   \"WARNING\": The previous level + minor problems encountered (via console.warn)   \"INFO\": The previous levels + noteworthy events (via console.info)   \"DEBUG\": The previous levels + normal events of the prober (via console.log)   If the value set to this property is different than those, it will be automatically set to \"NONE\". It is set to \"WARNING\" by default as it allows you to know if you forgot to set required information on each APIs, if some APIs are missing in your browser, etc. You might want to set it to \"NONE\" when in production. Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\"; mediaCapabilitiesProber.LogLevel = \"NONE\"; ","anchorH1":"mediacapabilitiesprober","anchorH2":"properties","anchorH3":"loglevel"},{"h1":"MediaCapabilitiesProber","h2":"Functions","body":"","anchorH1":"mediacapabilitiesprober","anchorH2":"functions"},{"h1":"MediaCapabilitiesProber","h2":"Functions","h3":"getCompatibleDRMConfigurations","body":"arguments:   keySystems (Array.<Object>): An array of key system configurations. Those objects have the following properties:   type (string): Key system string identifying it in the browser. Always a reverse domain name (e.g. “org.w3.clearkey”).   configuration (Object): Wanted MediaKeySystemConfiguration for this key system, as defined in the EME w3c specification.     return value: Array.<Object> Probe the support of various key sytems and for each compatible ones, returns the corresponding configuration that will be used. Return value The returned value is an array of object with the same number of elements than the one given in argument. It indicates the support for each Key System given in argument in the same order. Due to that, the objects in this array look like the ones given in argument (but with an added property):   type (string): Corresponding key system string given in input.   configuration (Object): Corresponding wanted MediaKeySystemConfiguration given in input.   compatibleConfiguration (undefined|Object): if the type and configuration are both compatible with the browser, this is the corresponding actual MediaKeySystemConfiguration that will be effectively used. It will often correspond to a subset of the inputted configuration object (for example, you might have there fewer videoCapabilities that in the configuration object). If the type and/or the configuration are not compatible, this property will not be defined.   Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  const mksConfiguration = {   initDataTypes: [\"cenc\"],   videoCapabilities: [     {       contentType: 'video/mp4;codecs=\"avc1.4d401e\"', // standard mp4 codec       robustness: \"HW_SECURE_CRYPTO\",     },     {       contentType: 'video/mp4;codecs=\"avc1.4d401e\"',       robustness: \"SW_SECURE_DECODE\",     },   ], };  const keySystems = [   // Let's consider this one as a compatible key system configuration   { type: \"com.widevine.alpha\", configuration: mksConfiguration },    // Let's consider this one as not compatible   { type: \"com.microsoft.playready\", configuration: mksConfiguration }, ];  mediaCapabilitiesProber   .getCompatibleDRMConfigurations(keySystems)   .then((drmConfigs) => {     drmConfigs.forEach((config) => {       const { type, configuration, compatibleConfiguration } = config;        if (compatibleConfiguration !== undefined) {         console.log(\"# Compatible configuration #############################\");         console.log(\"Key System:\", type);         console.log(\"Wanted configuration:\", configuration);         console.log(\"Compatible configuration:\", compatibleConfiguration);         console.log(\"########################################################\");         console.log(\"\");       } else {         console.log(\"# Incompatible configuration ###########################\");         console.log(\"Key System:\", type);         console.log(\"Wanted configuration:\", configuration);         console.log(\"########################################################\");         console.log(\"\");       }     });   });  // Example output (please note that in this example, one of the widevine // robustness is not supported): // // # Compatible configuration ############################# // Key System: com.widevine.alpha // Wanted configuration: // { //   \"initDataTypes\":[\"cenc\"], //   \"videoCapabilities\": [ //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\": \"HW_SECURE_CRYPTO\" //     }, //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\": \"SW_SECURE_DECODE\" //     } //   ] // } // Compatible configuration: // { //   \"audioCapabilities\": [], //   \"distinctiveIdentifier\": \"not-allowed\", //   \"initDataTypes\": [\"cenc\"], //   \"label\": \"\", //   \"persistentState\": \"not-allowed\", //   \"sessionTypes\": [\"temporary\"], //   \"videoCapabilities\": [ //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\":\"SW_SECURE_DECODE\" //     } //   ] // } // ######################################################## // // # Incompatible configuration ########################### // Key System: com.microsoft.playready // Wanted configuration: // { //   \"initDataTypes\":[\"cenc\"], //   \"videoCapabilities\": [ //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\": \"HW_SECURE_CRYPTO\" //     }, //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\": \"SW_SECURE_DECODE\" //     } //   ] // } // ######################################################## ","anchorH1":"mediacapabilitiesprober","anchorH2":"functions","anchorH3":"getcompatibledrmconfigurations"},{"h1":"MediaCapabilitiesProber","h2":"Functions","h3":"getStatusForHDCP","body":"arguments:  type (string): The HDCP type (e.g. “1.0”, “1.1” or “2.0”)  return value: string Test for an HDCP configuration. The returned string of this function is either:   \"Supported\": This HDCP configuration is supported.   \"NotSupported\": The HDCP configuration is not supported.   \"Unknown\": The API is not available or it is but could not check if the HDCP type is supported.    As of the 2018-july-03, this feature is very poorly supported (with only some support on the EDGE browser).  We should have a real support of it in the coming months on Chrome and Firefox.  Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  mediaCapabilitiesProber.getStatusForHDCP(\"1.1\").then((hdcpStatus) => {   switch (hdcpStatus) {     case \"Supported\":       console.log(\"This HDCP version is supported\");       break;      case \"NotSupported\":       console.log(\"This HDCP version is not supported\");       break;      case \"Unknown\":       console.log(\"We could'nt tell if this HDCP version is supported.\");       break;   } }); ","anchorH1":"mediacapabilitiesprober","anchorH2":"functions","anchorH3":"getstatusforhdcp"},{"h1":"MediaCapabilitiesProber","h2":"Functions","h3":"getDecodingCapabilities","body":"arguments:  config (Object): Object with type, video and audio configuration.  return value: string Probe for audio/video decoding capabilities. Argument The object in argument is inspired from the concerned API configurations. All its properties are optional, here are what you can set.   type (string): The media is either buffered in MediaSource, or directly as a file. As such, you can specify which one you want to probe through one of the following strings:  “media-source” “file”.    video (Object): The video capabilities you want to probe.  contentType (string): Media codec in mimeType format. width (number): Video width. height (number): Video Height. bitrate (number): Bitrate of the video (in bits per second). framerate (string): Number of frames used in one second. bitsPerComponent (number): Number of bits used to encode one component par pixel.    audio (Object): The video capabilities you want to probe.  contentType (string): Media codec in mimeType format. channels (string): Audio channels used by the track. bitrate (number): Bitrate from stream (bits/second). samplerate (number): Number of samples of audio carried per second.    Return value The returned string of this function is either:   \"Supported\": This configuration is supported.   \"MaybeSupported\": Some set configuration could not be probed because not enough information was provided, but what has been probed is supported.   \"NotSupported\": The configuration is not supported.   Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  mediaCapabilitiesProber   .getDecodingCapabilities({     type: \"media-source\",     video: {       contentType: 'video/webm; codecs=\"vp09.00.10.08\"',       width: 1920,       height: 1080,       bitrate: 3450000,       framerate: \"25\",       bitsPerComponent: 8,     },     audio: {       contentType: 'audio/webm; codecs=\"opus\"',       channels: 6,       bitrate: 1200,       samplerate: 44100,     },   })   .then((status) => {     switch (status) {       case \"Supported\":         console.log(\"The configuration is supported\");         break;        case \"MaybeSupported\":         console.log(\"The configuration may be supported\");         break;        case \"NotSupported\":         console.log(\"The configuration is not supported\");         break;     }   }); ","anchorH1":"mediacapabilitiesprober","anchorH2":"functions","anchorH3":"getdecodingcapabilities"},{"h1":"MediaCapabilitiesProber","h2":"Functions","h3":"getDisplayCapabilities","body":"arguments:  config (Object): Object with display configuration.  return value: string Probe what can be displayed on the screen. Argument The object in argument is inspired from the concerned API configurations. All its properties are optional, here are what you can set.  colorSpace (string): Wanted color space (“srgb”, “p3”, etc). width (number): Wanted display horizontal resolution. height (number): Wanted display vertical resolution. bitsPerComponent (number): Wanted display bpc capability.  Return Value The returned string of this function is either:   \"Supported\": This configuration is supported.   \"MaybeSupported\": Some set configuration could not be probed because not enough information was provided, but what has been probed is supported.   \"NotSupported\": The configuration is not supported.   Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  mediaCapabilitiesProber   .getDisplayCapabilities({     colorSpace: \"p3\",     width: 3840,     height: 2160,     bitsPerComponent: 10,   })   .then((status) => {     switch (status) {       case \"Supported\":         console.log(\"The configuration is supported\");         break;        case \"MaybeSupported\":         console.log(\"The configuration may be supported\");         break;        case \"NotSupported\":         console.log(\"The configuration is not supported\");         break;     }   }); ","anchorH1":"mediacapabilitiesprober","anchorH2":"functions","anchorH3":"getdisplaycapabilities"},{"h1":"MediaCapabilitiesProber","h2":"Exploited browser APIs","body":"The tool probes media capabilities from browsers (Chrome, Firefox, etc.) exploiting current available media API:   mediaCapabilities - Chrome >= 64 (https://github.com/WICG/media-capabilities)  Check for decoding capabilites from video and audio attributes.    isTypeSupportedWithFeatures - Microsoft EDGE  Check for DRM support + decoding and displaying capabilites from video, audio, display and media protection configuration.    isTypeSupported - Chrome >= 31 / Firefox >= 41 / EDGE / IE >= 11 / Safari  = 8 (https://developer.mozilla.org/en-US/docs/Web/API/MediaSource/isTypeSupported)   Check for video and audio decoding support from content type.    matchMedia (with color gamut support) - Chrome >= 58.  Check for color space support.    requestMediaKeySystemAccess - Chrome >= 42 / Firefox / EDGE / Safari (https://developer.mozilla.org/fr/docs/Web/API/Navigator/requestMediaKeySystemAccess)  Check for DRM support.    getStatusForPolicy - ? (https://github.com/WICG/hdcp-detection/blob/master/explainer.md)  Query a hypothetical status associated with an HDCP policy.   ","anchorH1":"mediacapabilitiesprober","anchorH2":"exploited_browser_apis"}]},{"file":"./api/Tools/createMetaplaylist.html","index":[{"h1":"createMetaplaylist","body":"","anchorH1":"createmetaplaylist"},{"h1":"createMetaplaylist","h2":"Overview","body":"createMetaplaylist is a function that allows to build a [metaplaylist] (./metaplaylist.md) object from given contents information. You may need to use this function because not all information about contents are known by the user when wanting to create a metaplaylist. For example, the end of a content will be found thanks to the content duration, that can be parsed from the content manifest.","anchorH1":"createmetaplaylist","anchorH2":"overview"},{"h1":"createMetaplaylist","h2":"How to import it","body":"createMetaplaylist is for now considered an “experimental” tool. This means that its API could change at any new version of the RxPlayer (don’t worry, we would still document all changes made to it in the corresponding release note). As an experimental tool, it is imported as such: import { createMetaplaylist } from \"rx-player/experimental/tools\";  You can then begin to use it right away.","anchorH1":"createmetaplaylist","anchorH2":"how_to_import_it"},{"h1":"createMetaplaylist","h2":"How to use it","body":"createMetaplaylist takes two arguments :   contentInfos (Array<Object>) : The list of content information, in the playback order they should have in the metaplaylist. The list is an array of objects with this attributes :  url (string): The URL of the source content transport (string): The transport type of the content (dash, smooth or even metaplaylist)    timeOffset (number|undefined) : the optionnal time offset that applies to the metaplaylist start time (default is 0).   Example: createMetaplaylist(   [     // dash content, 10mn long     {       url: \"https://somedashcontent.mpd\",       transport: \"dash\",     },     // smooth content, 35s long     {       url: \"https://somesmoothcontent.ism\",       transport: \"smooth\",     },     // metaplaylist content, 100mn long     {       url: \"https://somemetaplaylistcontent\",       transport: \"metaplaylist\",     },   ],   1000 );  The returned metaplaylist will look like :     {         type: \"MPL\",         version: \"0.1\",         dynamic: false,         contents: [             {                 url: \"https://somedashcontent.mpd\",                 transport: \"dash\",                 startTime: 1000,                 endTime: 1600,             },             {                 url: \"https://somesmoothcontent.ism\",                 transport: \"smooth\",                 startTime: 1600,                 endTime: 1635,             },             {                 url: \"https://somemetaplaylistcontent\",                 transport: \"metaplaylist\",                 startTime: 1635,                 endTime: 7635,             },         ],     } ","anchorH1":"createmetaplaylist","anchorH2":"how_to_use_it"}]},{"file":"./api/Miscellaneous/plugins.html","index":[{"h1":"Plugins","body":"","anchorH1":"plugins"},{"h1":"Plugins","h2":"Overview","body":"To allow the player to be extended, a system of “plugins” has been added. Those plugins are often under the form of functions passed as an argument to the loadVideo API call.","anchorH1":"plugins","anchorH2":"overview"},{"h1":"Plugins","h2":"segmentLoader","body":"The segmentLoader is a function that can be included in the transportOptions of the loadVideo API call. A segmentLoader allows to define a custom audio/video segment loader (it might on the future work for other types of segments, so always check the type if you only want those two). The segment loader is the part performing the segment request. One usecase where you might want to set your own segment loader is to integrate Peer-to-Peer segment downloading through the player. Before the complete documentation, let’s write an example which will just use an XMLHttpRequest (it has no use, as our implementation does the same thing and more): /**  * @param {Object} infos - infos about the segment to download  * @param {Object} callbacks - Object containing several callbacks to indicate  * that the segment has been loaded, the loading operation has failed or to  * fallback to our default implementation. More information on this object below  * this code example.  * @returns {Function|undefined} - If a function is defined in the return value,  * it will be called if and when the request is canceled.  */ const customSegmentLoader = (infos, callbacks) => {    // we will only use this custom loader for videos segments.   if (infos.adaptation.type !== \"video\") {     callbacks.fallback();     return;   }    const xhr = new XMLHttpRequest();   const sendingTime = performance.now();    xhr.onload = function onXHRLoaded(r) {     if (200 <= xhr.status && xhr.status < 300) {       const duration = performance.now() - sendingTime;       const size = r.total;       const data = xhr.response;       callbacks.resolve({ duration, size, data });     } else {       const err = new Error(\"didn't work\");       err.xhr = xhr;       callbacks.reject(err);     }   };    xhr.onprogress = function onXHRProgress(event) {     const currentTime = performance.now();     callbacks.progress({ type: \"progress\",                          value: { duration: currentTime - sendingTime,                                   size: event.loaded,                                   totalSize: event.total } });   };    xhr.onerror = function onXHRError() {     const err = new Error(\"didn't work\");     err.xhr = xhr;     callbacks.reject(err);   };    xhr.open(\"GET\", infos.url);   xhr.responseType = \"arraybuffer\";    const range = infos.segment.range;   if (range) {     if (range[1] && range[1] !== Infinity) {       xhr.setRequestHeader(\"Range\", `bytes=${range[0]}-${range[1]}`);     } else {       xhr.setRequestHeader(\"Range\", `bytes=${range[0]}-`);     }   }    xhr.send();    return () => {     xhr.abort();   }; };  As you can see, this function takes two arguments:   infos: An Object giving information about the wanted segments. This object contains the following properties:   url (string): The URL the segment request should normally be performed at.   manifest (Object) - the Manifest object containing the segment. More information on its structure can be found on the documentation linked below [1].   period (Object) - the Period object containing the segment. More information on its structure can be found on the documentation linked below [2].   adaptation (Object) - the Adaptation object containing the segment. More information on its structure can be found on the documentation linked below [3].   representation (Object) - the Representation object containing the segment. More information on its structure can be found on the documentation linked below [4].   segment (Object) - the segment object related to this segment. More information on its structure can be found on the documentation linked below [5].   [1] Manifest structure [2] Period structure [3] Adaptation structure [4] Representation structure [5] Segment structure   callbacks: An object containing multiple callbacks to allow this segmentLoader to communicate various events to the RxPlayer. This Object contains the following functions:   resolve: To call after the segment is loaded, to communicate it to the RxPlayer. When called, it should be given an object with the following properties:   data (ArrayBuffer|Uint8Array) - the segment data.   duration (Number|undefined) - the duration the request took, in milliseconds. This value may be used to estimate the ideal user bandwidth.   size (Number|undefined) size, in bytes, of the total downloaded response.     progress - Callback to call when progress information is available on the current request. This callback allows to improve our adaptive streaming logic by better predicting the bandwidth before the request is finished and whether a request is stalling. When called, it should be given an object with the following properties:   duration (Number) - The duration since the beginning of the request, in milliseconds.   size (Number) - the current size loaded, in bytes.   totalSize (Number|undefined) - the whole size of the wanted data, in bytes. Can be let to undefined when not known.     reject: Callback to call when an error is encountered which made loading the segment impossible. It is recommended (but not enforced) to give it an Object or error instance with the following properties:   canRetry (boolean|undefined): If set to true, the RxPlayer may retry the request (depending on the configuration set by the application). If set to false, the RxPlayer will never try to retry this request and will probably just stop the current content. If not set or set to undefined, the RxPlayer might retry or fail depending on other factors.   xhr (XMLHttpRequest|undefined): If an XMLHttpRequest was used to perform this request, this should be the corresponding instance. This can be used for example by the RxPlayer to know whether retrying should be done when the canRetry property is not set.   isOfflineError (boolean|undefined): If set to true, this indicates that this error is due to the user being offline (disconnected from the needed network). If set to false, this indicates that it wasn’t. If not known or not applicable, you can just set it to undefined or not define it at all. The RxPlayer might retry a segment request due to the user being offline a different amount of time than when the error is due to another issue, depending on its configuration.     fallback: Callback to call if you want to call our default implementation instead for loading this segment. No argument is needed.     The segmentLoader can also return a function, which will be called if/when the request is aborted. You can define one to clean-up or dispose all resources.","anchorH1":"plugins","anchorH2":"segmentloader"},{"h1":"Plugins","h2":"manifestLoader","body":"The manifestLoader is a function that can be included in the transportOptions of the loadVideo API call. A manifestLoader allows to define a custom Manifest loader. Before the complete documentation, let’s write an example which will just use an XMLHttpRequest (it has no use, as our implementation does the same thing and more): /**  * @param {string|undefined} url - the url the Manifest request should normally  * be on.  * Can be undefined in very specific conditions, like in cases when the  * `loadVideo` call had no defined URL (e.g. \"local\" manifest, playing a locally  * crafted \"Metaplaylist\" content).  * @param {Object} callbacks - Object containing several callbacks to indicate  * that the manifest has been loaded, the loading operation has failed or to  * fallback to our default implementation. More information on this object below  * this code example.  * @returns {Function|undefined} - If a function is defined in the return value,  * it will be called if and when the request is canceled.  */ const customManifestLoader = (url, callbacks) => {   const xhr = new XMLHttpRequest();   const baseTime = performance.now();    xhr.onload = (r) => {     if (200 <= xhr.status && xhr.status < 300) {       const duration = performance.now() - baseTime;        const now = Date.now();       const receivingTime = now;        // Note: We could have calculated `sendingTime` before the request, but       // that date would be wrong if the user updated the clock while the       // request was pending.       // `performance.now` doesn't depend on the user's clock. It is thus a       // better candidate here.       // This is why we re-calculate the sendingTime a posteriori, we are now       // sure to be aligned with the current clock.       const sendingTime = now - duration;        // the request could have been redirected,       // we have to feed back the real URL       const _url = xhr.responseURL || url;        const size = r.total;       const data = xhr.response;       callbacks.resolve({         url: _url,         sendingTime,         receivingTime,         duration,         size,         data,       });     } else {       const err = new Error(\"didn't work\");       err.xhr = xhr;       callbacks.reject(err);     }   };    xhr.onerror = () => {     const err = new Error(\"didn't work\");     err.xhr = xhr;     callbacks.reject(err);   };    xhr.open(\"GET\", url);   xhr.responseType = \"document\";    xhr.send();    return () => {     xhr.abort();   }; };  As you can see, this function takes two arguments:   url: The URL the Manifest request should normally be performed at. This argument can be undefined in very rare and specific conditions where the Manifest URL doesn’t exist or has not been communicated by the application.   callbacks: An object containing multiple callbacks to allow this manifestLoader to communicate the loaded Manifest or an encountered error to the RxPlayer. This Object contains the following functions:   resolve: To call after the Manifest is loaded, to communicate it to the RxPlayer. When called, it should be given an object with the following properties:   data - the Manifest data. Many formats are accepted depending on what makes sense in the current transport: string, Document, ArrayBuffer, Uint8Array, object.   duration (Number|undefined) - the duration of the request, in milliseconds.   size (Number|undefined) size, in bytes, of the total downloaded response.   url (string|undefined) - url of the Manifest (after any potential redirection if one).   sendingTime (number|undefined) - Time at which the manifest request was done as a unix timestamp in milliseconds.   receivingTime (number|undefined) - Time at which the manifest request was finished as a unix timestamp in milliseconds.     reject: Callback to call when an error is encountered which made loading the Manifest impossible. It is recommended (but not enforced) to give it an Object or error instance with the following properties:   canRetry (boolean|undefined): If set to true, the RxPlayer may retry the request (depending on the configuration set by the application). If set to false, the RxPlayer will never try to retry this request and will probably just stop the current content. If not set or set to undefined, the RxPlayer might retry or fail depending on other factors.   xhr (XMLHttpRequest|undefined): If an XMLHttpRequest was used to perform this request, this should be the corresponding instance. This can be used for example by the RxPlayer to know whether retrying should be done when the canRetry property is not set.   isOfflineError (boolean|undefined): If set to true, this indicates that this error is due to the user being offline (disconnected from the needed network). If set to false, this indicates that it wasn’t. If not known or not applicable, you can just set it to undefined or not define it at all. The RxPlayer might retry a Manifest request due to the user being offline a different amount of time than when the error is due to another issue, depending on its configuration.     fallback: Callback to call if you want to call our default implementation instead for this Manifest. No argument is needed.     The manifestLoader can also return a function, which will be called if/when the request is aborted. You can define one to clean-up or dispose all resources.","anchorH1":"plugins","anchorH2":"manifestloader"},{"h1":"Plugins","h2":"representationFilter","body":"The representationFilter is a function that can be included in the transportOptions of the loadVideo API call. A representationFilter allows you to filter out Representations (i.e. media qualities) based on its attributes. The representationFilter will be called each time we load a Manifest with two arguments:   representation {Representation}: The concerned Representation. A Representation structure’s is described in the Manifest structure documentation.   representationInfos {Object}: Basic information about this Representation. Contains the following keys:   bufferType {string}: The concerned type of buffer. Can be \"video\", \"audio\", \"text\" (for subtitles) or \"image\" (for thumbnail).   language {string|undefined}: The language the Representation is in, as announced by the Manifest.   normalizedLanguage {string|undefined}: An attempt to translate the language into an ISO 639-3 code. If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   isClosedCaption {Boolean|undefined}: If true, the Representation links to subtitles with added hints for the hard of hearing.   isAudioDescription {Boolean|undefined}: If true, the Representation links to an audio track with added commentary for the visually impaired.   isDub {Boolean|undefined}): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.     This function should then returns true if the Representation should be kept or false if it should be removed. For example, here is a representationFilter that removes video Representations with a video resolution higher than HD (1920x1080): /**  * @param {Object} representation - The Representation object, as defined in  * the documentation linked bellow [1]  * @param {Object} infos - supplementary information about the given  * Representation.  * @returns {boolean}  */ function representationFilter(representation, infos) {   if (infos.bufferType === \"video\") {     // If video representation, allows only those for which the height and width     // is known to be below our 1920x1080 limit     const { width, height } = representation;     return width != null && height != null && width <= 1920 && height <= 1080;   }    // Otherwise, allow all non-video representations   return true; }  [1] Representation structure","anchorH1":"plugins","anchorH2":"representationfilter"}]},{"file":"./api/Miscellaneous/Low_Latency.html","index":[{"h1":"Playing Low-Latency contents","body":"","anchorH1":"playing_low-latency_contents"},{"h1":"Playing Low-Latency contents","h2":"Overview","body":"The RxPlayer can play DASH contents specifically crafted to be played with a low latency (read close to the live edge) through a technology called something along the lines of “Chunked-encoded CMAF and Chunked transfer encoding”. Such contents are backward-compatible DASH contents (meaning they can be played in a regular non-low-latency way) which serves CMAF segment with an HTTP 1.1 transfer mechanism called “Chunked transfer encoding”. To vulgarize, such segments are divided into multiple chunks which can be requested while the whole segment is still being encoded - through Chunked transfer encoding HTTP requests. If you want more information on this technology, the best for us is probably to redirect you to the multiple resources you can probably find with your favorite search engine!","anchorH1":"playing_low-latency_contents","anchorH2":"overview"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","body":"","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","h3":"lowLatencyMode option","body":"To play a low-latency DASH content with - well - a low latency, you will need to set the lowLatencyMode loadVideo option. rxPlayer.loadVideo({   url: \"https://www.example.com/low-latency-content.mpd\",   transport: \"dash\",   lowLatencyMode: true, });  When set, this option will perform multiple optimizations specific to low-latency contents. For live contents:   it will by default play much closer to the live edge   it will begin to play faster and seek in non-buffered parts faster   it will do safer choices when choosing the right video / audio quality (to avoid the higher chances of rebuffering)   the delay we use when retrying a failed segment or manifest request will be lower   and multiple other minor optimizations   Note that you can also set the lowLatencyMode mode for VoD (non-live) contents. In that case, the main advantage would be to be able to play and seek faster as long as the content is compatible (again, with CMAF and Chunked Transfer Encoding).","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content","anchorH3":"lowlatencymode_option"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","h3":"Playing even closer to the live edge!","body":"By default, we set a distance of 3.5 seconds relative to the live edge when we start a low latency content. We found that value to be just at the right boundary between rebuffering risks, and delay to the live edge. However, you can still provide a lower distance through the startAt loadVideo option (documented here): rxPlayer.loadVideo({   url: \"https://www.example.com/content.mpd\",   transport: \"dash\",   lowLatencyMode: true,   startAt: { fromLastPosition: 2 }, // Play 2 seconds from the live edge instead   // (beware of much more frequent rebuffering   // risks) }); ","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content","anchorH3":"playing_even_closer_to_the_live_edge!"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","h3":"Note about time synchronization","body":"In most cases, DASH low-latency contents rely on time synchronization between the server and the client without providing a synchronization mechanism. This means that, on poorly configurated client (with bad clock settings), you could lose latency or worse: obtain playback issues. To work around that problem, the RxPlayer allows you to provide a synchronization mechanism to loadVideo. This is done through the serverSyncInfos transportOptions. Which itself is a loadVideo option. TL;DR You can look at the API documentation for a quick explanation of what to put in it. Here how it works: Imagine you have an URL allowing you to know the UTC time on the server’s side. Let’s call it serverTimeURL. Now you can have the server’s time at a particular point in time (!). The problem is that time continously changes: a time synchronization mechanism will have to be aware of how much time passed since the last request to obtain that time. We could asks for the client’s timestamp - obtained thanks to the Date.now() API - at the time of the request. This would allow us to know how much time have passed since that event by calling Date.now() again in the future and calculating the difference. The problem however is that Date.now() will instantly change if the user updates its system clock. If that happens, we will lose the ability to know how much time has elapsed since the request. To workaround this issue, we can use instead performance.now(), which does not rely on the system’s clock. However, we are still left with two other issues:   performance.now() comparisons are useful only if both values were obtained in the same JS worker. So we have to make sure each performance.now() call is done in the same worker.   performance.now() doesn’t integrate the notion of leap seconds whereas unix time (the server’s time) does. This could mean small time de-synchronization when leap seconds are added or substracted.   We however consider those last two problems minor when compared to Date.now()'s problem (which is the fact that it “breaks” if the system clock is updated). If you would prefer to provide Date.now() anyway, you can open an issue and we will think about a possible implementation. So we now have two values:  serverTimestamp (number): Unix timestamp of the server at a given point in time. clientTime (number): Value of the performance.now() API at the time the serverTimestamp value was true. Please note that if your page contains multiple worker, the performance.now() call should be done on the same worker than the one in which loadVideo is called.  Those two values can be combined in the serverSyncInfos option like this: const timeResponse = await fetch(serverTimeURL); const serverTimestamp = await timeResponse.text(); const clientTime = performance.now(); const serverSyncInfos = { serverTimestamp, clientTime }; rxPlayer.loadVideo({   // ...   transportOptions: { serverSyncInfos }, }); ","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content","anchorH3":"note_about_time_synchronization"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","h3":"Note about rebuffering and other delay-creating situations","body":"When playing in low latency mode, it is still possible to rebuffer or pause the content, which could lead the user to being far from the live edge. As several applications could want several workaround to that possible issue (like updating the speed, seeking or just signaling the delay to the user), we choose to let that happen by default with the RxPlayer. As an example, ou demo page choose the following strategy for now:   When falling between 6 to 15 seconds behind the live edge, the playback rate is updated proportionally to our delay until we reach 3 seconds behind the live edge.   When falling to 15 seconds behind the live edge or more, we will simply seek to 3 seconds behind the live edge.   When seeking manually or pausing, this logic is disabled (with the possibility to re-enable it).   The live edge is obtainable through the rxPlayer.getMaximumPosition() API, the current position thanks to the rxPlayer.getPosition() API. The distance to the live edge is thus easily computable: rxPlayer.getMaximumPosition() - rxPlayer.getPosition(); ","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content","anchorH3":"note_about_rebuffering_and_other_delay-creating_situations"}]},{"file":"./api/Miscellaneous/DASH_WASM_Parser.html","index":[{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","body":"The RxPlayer provides two different “parsers” for DASH’s Manifest format, a.k.a. the “MPD”:   A JavaScript parser. Provided in the default “bundled” builds and through the DASH feature in the minimal build.   A generally-faster WebAssembly parser. Only provided through the DASH_WASM experimental feature in the minimal build.   This page is the API documentation page for the second parser.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"Do I need this?","body":"When playing DASH contents, parsing its MPD file often become the most expensive operation in terms of performance. This is especially true when the MPD is sufficiently large (for example, we often encounter MPD of several megabytes in size at Canal+) and when it needs to be refreshed (e.g. some live contents). Even for smaller MPDs, we observed that on some low-end devices (ChromeCast, set-top box, some smart TVs) the parsing operation can noticeably lengthen the content’s loading time and in some rare occasions trigger brief rebuffering periods. If you encouter large MPDs and/or you noticed poor performance when playing DASH contents, you may have a better experience with this parser. Note however that your browser has to be compatible with WebAssembly. In case WebAssembly is not supported on the current platform and both the WebAssembly and default JavaScript DASH parsers are imported through their respective features, the RxPlayer will automatically fallback on the latter.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"do_i_need_this?"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"Do I need this?","h3":"Why “experimental”?","body":"As every other “experimental” features in the RxPlayer, the WebAssembly MPD parser should be stable in functional terms. The “experimental” notion has more to do with the fact that its API can evolve without impacting too much RxPlayer’s semantic versioning. For example, a new minor RxPlayer version could bring with it a complete API change regarding this feature. Still, potential changes would be fully documented and at least a link will be added both to that release’s release note and changelog file. The choice of labeling this feature as experimental has been made so we can have more freedom if we find ways to provide sensible improvements to it in the future, in case they necessitate some incompatible API change.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"do_i_need_this?","anchorH3":"why_%22experimental%22?"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","body":"To use the WebAssembly-based parser you will need to do two things:   the WebAssembly file will have to be stored somewhere, accessible through an URL that can be then communicated to the RxPlayer.   the DASH_WASM experimental feature has to be initialized with it and added to the RxPlayer   Don’t worry, it is relatively straightforward. The current chapter will explain everything you need to do.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Quick code example","body":"Let’s begin by an heavily commented example of a code adding the DASH-WASM feature to the RxPlayer. It might be a lot to grasp now, we will focus on what has been done here step by step in the next chapters. // Import the minimal RxPlayer import RxPlayer from \"rx-player/minimal\";  // Import the function allowing to create the DASH-WASM parser import { DASH_WASM } from \"rx-player/experimental/features\";  // Trigger request for the WebAssembly file. // This function can be called at any point in time. // // Before it is called, the regular JS parser will be used instead // (if it was added as a feature). // // As soon as both this function is called and the DASH_WASM feature is added // (through RxPlayer's `addFeatures` static method) - in any order you wish - // the RxPlayer will begin // to use the DASH_WASM parser for almost all // future encountered MPDs (excluding some extremely rare conditions, such as // non-UTF-8 MPDs). DASH_WASM.initialize({ wasmUrl: \"https://path/to/webassembly.wasm\" });  // Add the DASH_WASM feature to the RxPlayer. // // This can be done before or after calling the `initialize` method on the // `DASH_WASM` object, both actions will be needed to be able to use the // WebAssembly parser. RxPlayer.addFeatures([DASH_WASM]); ","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"quick_code_example"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 1: Obtaining the WebAssembly file","body":"The RxPlayer will need to fetch the WebAssembly file to be able to run the DASH-WASM parser. You can find it at any of the following places:   With every release note published on GitHub (you should only use the files linked to the RxPlayer’s version you’re using), as mpd-parser.wasm.   It is also available as dist/mpd-parser.wasm from the root directory of the project. This file is also published on npm, which mean they might already be loaded in your project, for example in the node_modules directory (most probably in node_modules/rx-player/dist/mpd-parser.wasm depending on your project). `   Once you’ve retrieved the right WebAssembly file linked to your RxPlayer version, you will need to store it and give its URL to the RxPlayer so it will be able to load it.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_1:_obtaining_the_webassembly_file"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 2: using the minimal build of the RxPlayer","body":"The DASH_WASM feature is only available when using the “minimal” version of the RxPlayer. That is, when the player is imported through the \"rx-player/minimal\" path: import RxPlayer from \"rx-player/minimal\";  If you weren’t using the minimal RxPlayer before, note that it necessitates that you add the features you want to it. More information about any of that can be found in the minimal player documentation. This documentation will especially dive into the DASH_WASM feature, which is the WebAssembly parser for MPDs.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_2:_using_the_minimal_build_of_the_rxplayer"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 3: importing the DASH_WASM feature","body":"As indicated before, the DASH-WASM feature is an “experimental” feature. This is because although the feature is considered stable, its API may still change at any new RxPlayer version (if this happens, changes on its API will be explained on our CHANGELOG and this documentation will be updated). As any experimental features, it needs to be imported through the rx-player/experimental/features path: import { DASH_WASM } from \"rx-player/experimental/features\"; ","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_3:_importing_the_%60dash_wasm%60_feature"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 4: Initializing the feature","body":"– This step can be done before or after adding the DASH_WASM feature to the RxPlayer (described as the next step) – This step allows to provide the WebAssembly file to the DASH_WASM feature. This is done through a method call on the imported DASH_WASM function called initialize: DASH_WASM.initialize({ wasmUrl: \"https://path/to/webassembly.wasm\" });  As you can see, this function takes an object in argument which has for now a single required property, wasmUrl, which should be the URL to the WebAssembly file. An important thing to consider is that initialize will immediately request the WebAssembly file. Once this function is called and once the feature is added to the RxPlayer (next described step), the RxPlayer will try to use the WebAssembly parser when possible (even if the WebAssembly request hasn’t yet finished). Note that initialization can fail, for example when WebAssembly is not available or when the request fails. initialize returns a Promise so you can be notified of a possible error if you wish: DASH_WASM.initialize({ wasmUrl: \"https://path/to/webassembly.wasm\" })   .then(() => { console.log(\"everything went well!\"); }),   .catch((err) => { console.warn(\"Could not initialize WebAssembly\", err); });  In the case where initialization fails, the RxPlayer will try to use the regular DASH js parser instead, if that feature has been added. If it has not, an error will be thrown when playing DASH contents.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_4:_initializing_the_feature"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 4bis: Adding the feature to the RxPlayer","body":"– This step can be done before or after “initializing” the DASH_WASM feature (the aforementioned “step 4”). – To “link” the RxPlayer to the parser, you will need to call the addFeatures static function on the minimal RxPlayer build, like every other features. import RxPlayer from \"rx-player/minimal\";  RxPlayer.addFeatures([DASH_WASM]);  Once both this step an the initialize method (on the DASH_WASM object) is called, the RxPlayer will try to use the WebAssembly DASH_WASM parser by default when encountering DASH contents.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_4bis:_adding_the_feature_to_the_rxplayer"}]},{"file":"./api/Miscellaneous/hdr.html","index":[{"h1":"HDR support","body":"","anchorH1":"hdr_support"},{"h1":"HDR support","h2":"Overview","body":"HDR (High Dynamic Range) is a video technology that improves the way light is represented by permitting to render brighter highlights, darker shadows and more details between both ends. Sometimes, it allows to reproduce richer colors than with the standard dynamic range.","anchorH1":"hdr_support","anchorH2":"overview"},{"h1":"HDR support","h2":"API","body":"Behind this principle, several formats exists (HDR10, HLG, Dolby Vision) and implements specific media and stream encoding and packaging technologies. When using streaming technologies, both streaming manifest and codecs strings can provide information about the technical HDR characteristics of the content. These information are parsed and exposed through the hdrInfo attribute that can be found in the periods/adaptation/representation path of the RxPlayer manifest object. Also, the getAvailableVideoTracks and getVideoTrack functions and the videoTrackChange event carries the hdrInfo.","anchorH1":"hdr_support","anchorH2":"api"},{"h1":"HDR support","h2":"API","h3":"hdrInfo","body":" colorDepth: number|undefined : It is the bit depth used for encoding the color for a pixel. The more bits are used for encoding, the more color shades could be rendered. It allows to increase rendering dynamic range without color banding. eotf: string|undefined : It is the HDR eotf. It is the transfer function having the video signal as input and converting it into the linear light output of the display. For example, pq (published as standard SMPTE2084) is an eotf developped by Dolby for HDR contents and capable of rendering brightness until 10000 nits (the derived SI unit of luminance). colorSpace: string|undefined : It is the video color space used for encoding. An HDR content may not have a wide color gamut. HD TV standards define the use of the rec709 color space for content. Most of HDR standards define the use of rec2020, which is a color space that contains rec709 color space and more. In other words, rec2020 can reproduce colors that cannot be shown with the rec709. ","anchorH1":"hdr_support","anchorH2":"api","anchorH3":"hdrinfo"},{"h1":"HDR support","h2":"Exploiting the API","body":"HDR do not specify new display’s capabilities. However, it allows to make better use of the display brightness, contrast and color capabilities. HDR will not be rendered the same way on each used display. It is possible through several APIs to query the browser about its screen characteristics, to speculate about the quality of the HDR rendering. Here are the available APIs now :","anchorH1":"hdr_support","anchorH2":"exploiting_the_api"},{"h1":"HDR support","h2":"Exploiting the API","h3":"Color depth","body":"In HDR, more colors and brightness levels have to be encoded. More than 8 bits par component are used in most of standards. It is possible to check how many bits are used for reproducing colors on the output display, to ensure the color shades could be rendered. /**  * It is the bit depth used for encoding one color. Example :  * screen.colorDepth = 48 :  * - 12 bits for the red component  * - 12 bits for the blue component  * - 12 bits for the green component  * - 12 bits for the alpha component (optional)  */ const colorDepth = screen.colorDepth;  /**  * The media query tells if the current output device is compatible  * with the given media characteristics.  * Here, it tells if the given color depth for one component is supported.  */ const is10bitsSupported = window.matchMedia(\"(min-color: 10)\").matches; ","anchorH1":"hdr_support","anchorH2":"exploiting_the_api","anchorH3":"color_depth"},{"h1":"HDR support","h2":"Exploiting the API","h3":"Color gamut","body":"It is possible to check if the output device is capable of displaying standard color gamut that are used in HDR formats. /**  * The media query tells if the current output device is compatible  * with the given media characteristics.  * Here, it tells if the output device is capable of displaying approximatively  * the given color space.  */ const isRec2020Supported = window.matchMedia(\"(color-gamut: rec2020)\").matches; ","anchorH1":"hdr_support","anchorH2":"exploiting_the_api","anchorH3":"color_gamut"}]},{"file":"./api/Miscellaneous/Local_Contents.html","index":[{"h1":"Local contents (offline playback)","body":"","anchorH1":"local_contents_(offline_playback)"},{"h1":"Local contents (offline playback)","h2":"Preamble","body":"The RxPlayer is also able to load downloaded DASH, Smooth, MetaPlaylist or even HLS (CMAF-based) contents, whether it is for offline playback or just for an online seamless playback without buffering. This documentation page will be about how to load already downloaded contents. We suppose the content is already downloaded and that you just want to play it through the RxPlayer. However, a tool to download DASH/Smooth/MetaPlaylist contents compatible to this API is under way.","anchorH1":"local_contents_(offline_playback)","anchorH2":"preamble"},{"h1":"Local contents (offline playback)","h2":"Overview","body":"To play contents stored locally, the RxPlayer uses its own Manifest format - the “local manifest” which is close in semantics to DASH’s own Manifest file, the MPD. This new Manifest format will be the only element you will need to generate on your side to play stored contents. As such, this what most of this documentation page is about. Note that the wanted content does not need to be completely downloaded before creating this local manifest. Playback can even begin while the content is still downloading. You will just need to:  indicate that this is a “local” content by setting the transport option in loadVideo to \"local\" As the generated Manifest object most likely won’t be available through an URL but directly as a JavaScript object, you will need to communicate it through the manifestLoader property in the transportOptions loadVideo option.  Here is an example: rxPlayer.loadVideo({   transport: \"local\",   transportOptions: {     // Note: `_url` here will be `undefined`     manifestLoader(_url, callbacks) {       // where `localManifest` is the local Manifest in object form       callbacks.resolve({ data: localManifest });     },   },   // ... });  More infos on the manifestLoader can be found here.","anchorH1":"local_contents_(offline_playback)","anchorH2":"overview"},{"h1":"Local contents (offline playback)","h2":"How to import this feature","body":"The \"LOCAL_MANIFEST\" feature is not included in the default RxPlayer build. There’s two way you can import it, depending on if you’re relying on the minimal version or if you prefer to make use of environment variables and build the player manually. Through the minimal version of the RxPlayer If you’re using the “minimal” version of the RxPlayer (through the \"rx-player/minimal\" import), you will need to import the LOCAL_MANIFEST experimental feature: import RxPlayer from \"rx-player/minimal\"; import { LOCAL_MANIFEST } from \"rx-player/experimental/features\";  RxPlayer.addFeatures([LOCAL_MANIFEST]);  Through environment variables If you don’t want to go the minimal version’s route and you have no problem with building yourself a new version of the RxPlayer, you can make use of environment variables to activate it. This can be done through the RXP_LOCAL_MANIFEST environment variable, which you have to set to true: RXP_LOCAL_MANIFEST=true npm run build:min  More information about any of that can be found in the minimal player documentation.","anchorH1":"local_contents_(offline_playback)","anchorH2":"how_to_import_this_feature"},{"h1":"Local contents (offline playback)","h2":"The Manifest format","body":"As explained in the overview, offline playback by the RxPlayer mainly rely on a specific sort of manifest, called the “local manifest”. It is not the task of the RxPlayer to download and store the content here (a tool to do just that is on its way), this page only explains how to play a stored content once it has been stored. The local manifest looks like a DASH MPD in its structure and as such is very hierarchical. It has the following structure: manifest Object   ...manifest properties   period Object     ...period properties     adaptation Object       ...adaptation properties       representation Object         ...representation properties  We will go progressively from the elements higher in the hierarchy (the manifest object) to the lower ones (the representation Object).","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_manifest_format"},{"h1":"Local contents (offline playback)","h2":"The manifest Object","body":"The manifest object describes information about the whole local content:  its duration whether it is still downloading or if its completely available the different “parts” (or “periods”) the content is divided in  First, let’s go into an example, before describing what each property is for: {   type: \"local\", // always set to \"local\"   version: \"0.2\", // version number, in a MAJOR.MINOR form   minimumPosition: 0, // Minimum possible reachable position in the content,                       // in seconds   maximumPosition: 120, // Maximum possible reachable position in the content,                         // in seconds   isFinished: true, // if `false`, the content is still downloading   periods: [ // different \"periods\" in the content - see below     // ...   ], }  As you can see, it is a simple JavaScript object with few properties we’re going to dive into just now.","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_manifest_object"},{"h1":"Local contents (offline playback)","h2":"The manifest Object","h3":"properties","body":"Here is the description about all the properties encountered in a local manifest object:   type (string): Must be set to \"local\". This property indicates to the RxPlayer that the current content is a local manifest.   version (string): Version number, in a MAJOR.MINOR form. The present documentation is for the \"0.2\" version. A parser for a version with the a given MAJOR version should be able to parse and play contents for any of the corresponding MINOR versions. The exception is the 0 MAJOR version (i.e. experimental versions). A parser for a version with that major (let’s say 0.1) might be unable to parse local Manifests of another version (e.g. 0.2).   minimumPosition (number|undefined): Optional minimum position reachable in this content once it has been fully loaded, in seconds. If not set or set to undefined, the RxPlayer will assume that the content starts at a 0 position.   maximumPosition (number): Maximum position reachable in this content once it has been fully loaded, in seconds.   isFinished (boolean): true indicates that the content has been completely downloaded and can now be played as a whole. false indicates that the whole content is not available yet and that the RxPlayer may have to refresh the local manifest while playing (to get the new data).   periods (Array.<Object>): The different “periods” available in the content. We will explain what a “period” is in the following chapter.   expired (Promise.<undefined>|undefined): Optional Promise which should resolve when a newer local manifest is available. This is for example useful when playing a content which is still downloading. Here expired could resolve once a new segment is available, the RxPlayer would then request the new local manifest (through the same API than for the initial request, e.g. through the manifestLoader property indicated in loadVideo) and would obtain a new local manifest with this new segment included and a new expired property set. This can go on until the content is completely downloaded at which time expired can be set to undefined or just omitted from the last local manifest.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_manifest_object","anchorH3":"properties"},{"h1":"Local contents (offline playback)","h2":"The period object","body":"As seen in the previous chapter, the local manifest contains a periods property. The concept of period comes from DASH and allow to separate a content into multiple sub-parts, each with their own configurations. For example, you could have in the same content a TV Show in german followed by an american film, each with its own language choices and qualities. If you don’t need that kind of granularity, you can just create a single period for your local manifest. Here’s an example of a period object: {   start: 10, // starting position in the whole content, in seconds   end: 20, // ending position, in seconds   adaptations: [ // available tracks for this period     // ***   ] }  In the context of a local manifest with multiple periods, here is how it can look like: {   type: \"local\",   version: \"0.2\",   minimumPosition: 0,   maximumPosition: 60,   isFinished: true,   periods: [ // Here we have 3 consecutive periods:     {       start: 0,       end: 10,       adaptations: [ /* ... */ ]     },     {       start: 10,       end: 30,       adaptations: [ /* ... */ ]     },     {       start: 30,       end: 60,       adaptations: [ /* ... */ ]     },   ], } ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_period_object"},{"h1":"Local contents (offline playback)","h2":"The period object","h3":"properties","body":"The following properties are found in a period object:   start (number): The position in seconds at which the period starts.   end (number): The position in seconds at which the period ends.   adaptations (Array.<Object>): The different tracks available. See below for more information.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_period_object","anchorH3":"properties_(1)"},{"h1":"Local contents (offline playback)","h2":"the adaptation object","body":"An adaptation is roughly a “track” of the content. It can for the moment be one of those three types:  “audio” “video” “text” (subtitles)  The form of the adaptation object depends on the type of track. Let’s just start with a simple video track example: {   type: \"video\",   language: \"eng\", // optional language code   representations: [ // describes the different available qualities     // ...   ] }  Let’s continue with an audio track example: {   type: \"audio\",   language: \"fra\", // language code for this audio track   audioDescription: false, // if `true`, that audio track is a track adapted for                            // the visually impaired   representations: [ /* ... */ ] }  We’ll finish with a text track example: {   type: \"text\",   language: \"fra\", // language code for this audio track   closedCaption: false, // if `true`, that text track contains supplementary                         // cues about the audio content (generally used for the                         // hard of hearing)   representations: [ /* ... */ ] }  Here how it looks when adaptations are integrated in a given period: {   start: 0,   end: 10,   adaptations: [     {       type: \"video\",       representations: [ /* ... */ ],     },     {       type: \"audio\",       language: \"eng\",       audioDescription: false,       representations: [ /* ... */ ]     },     {       type: \"audio\",       language: \"fra\",       audioDescription: false,       representations: [ /* ... */ ]     },     {       type: \"audio\",       language: \"fra\",       audioDescription: true,       representations: [ /* ... */ ]     },     {       type: \"text\",       language: \"fra\",       closedCaption: false,       representations: [ /* ... */ ]     },     {       type: \"text\",       language: \"fra\",       closedCaption: true,       representations: [ /* ... */ ]     }   ] },  Let’s now describes precizely every properties encountered here.","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_adaptation_object"},{"h1":"Local contents (offline playback)","h2":"the adaptation object","h3":"properties","body":"The following properties are found in an adaptation object:   type (string): The “type” of the current adaptation. Can be one of three strings:  audio video text The two first ones are straightforward to understand, the third one designates subtitles.    language (string|undefined): When relevant, this string allows to define the language code for the language the track is in. This is mostly useful for audio and text adaptations but can also be defined for video tracks.   audioDescription (boolean|undefined): If true, the track contains audio indications helping to understand what’s on the screen. Mostly useful for the visually impaired, this property is generally only relevant for audio tracks.   closedCaption (boolean|undefined): If true, that text track contains supplementary text cues about the audio content. Mostly useful for the hard of hearing, this property is generally only relevant for text tracks helping to understand what’s on the screen. Mostly useful for the visually impaired, this property is generally only relevant for audio tracks.   representations (Array.<Object>): The different available qualities for this track. Will be described below.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_adaptation_object","anchorH3":"properties_(2)"},{"h1":"Local contents (offline playback)","h2":"The representation object","body":"The representation object will describe the different qualities for a given track (or adaptation). It will also contains logic to fetch segments corresponding to that quality. The representation object is very similar to the Representation element in a DASH MPD. As usual, let’s look into an example. {   bitrate: 5000000, // bitrate of the quality, in bits per seconds   mimeType: \"video/mp4\",   codecs: \"avc1.64001f\",   width: 1280, // default width of the quality, in pixels.                // Mostly relevant for video tracks   height: 720, // default height of the quality, in pixels.                // Mostly relevant for video tracks   index: { // declaration of all the linked segments as well as methods to            // retrieve them     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  For audio tracks, it can looks like: {   bitrate: 200000,   mimeType: \"audio/mp4\",   codecs: \"mp4a.40.5\",   index: {     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  At last, an example for text tracks (here ttml in an mp4 container): {   bitrate: 3000, // bitrate of the quality, in bits per seconds   mimeType: \"application/mp4\",   codecs: \"stpp\",   index: {     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  We’ll now explain what each property is for, before going deeper into the index attribute, which allows the RxPlayer to fetch the media segments.","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_representation_object"},{"h1":"Local contents (offline playback)","h2":"The representation object","h3":"properties","body":"  bitrate (number): The bitrate the quality is in, in bits per seconds. For example, a bitrate of 5000000 (5.10^6 == 5 MegaBit) would indicate that each second of the content does on average a size of 5 MegaBit.   mimeType (string): As its name suggests, this is the appropriate mime-type for the media. Generally, it is either:  \"video/mp4\" or \"video/webm\" for a video content (depending on the container) \"audio/mp4\" or \"audio/webm\" for an audio content (depending on the container) \"application/mp4\" or \"text/plain\" for a text content (depending on the container / the absence of container)    codecs (string): The codec necessary to be able to play the content. The syntax here is taken from the RFC6381.   width (number|undefined): When relevant (mostly video contents), the width of the media, in pixels   height (number|undefined): When relevant (mostly video contents), the height of the media, in pixels   index (object): Object allowing the RxPlayer to know the list of segments as well as to fetch them. Described in the next chapter.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_representation_object","anchorH3":"properties_(3)"},{"h1":"Local contents (offline playback)","h2":"the index object","body":"As just seen, the index object is a property of a given representation. it contains itself three properties:   segments (Array.<Object>): the list of every available media segments for that representation. Does not include the initialization segment. Do not include in this Array the segments that are not downloaded yet.   loadInitSegment (function): Returns the initialization segment or null if this notion is not relevant, like for subtitles.   loadSegment (function): Returns a specific media segment.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_index_object"},{"h1":"Local contents (offline playback)","h2":"the index object","h3":"the segments array","body":"Let’s start by the first one, segments. segments is an array of objects, each object describing a single segment of media data. Each object has the following properties:  time (number): starting position of the segment, in seconds duration (number): duration of the segment, in seconds timestampOffset (number|undefined): optional time offset to add to the segment’s internal time in seconds to convert its media time to its presentation time, in seconds. If you don’t know what it is, you will most likely not need it.  Let’s see a simple example with four segments of 2 seconds: [   {     time: 0,     duration: 2,   },   {     time: 2,     duration: 2,   },   {     time: 4,     duration: 2,   },   {     time: 6,     duration: 2,   }, ]; ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_index_object","anchorH3":"the_segments_array"},{"h1":"Local contents (offline playback)","h2":"the index object","h3":"the loadInitSegment callback","body":"The loadInitSegment callback allows the RxPlayer to request the initialization segment of this representation. Most audio and video representation have an initialization segment which allows to obtain information about the representation’s data without containing data in itself. For text representations, where it is most likely not needed, this callback can emit null instead of the segment. This callback is given a single argument, which is an object containing callbacks the function should call either when it has fetched the content or when it failed on error. There is two callbacks in that object:   resolve: allows loadInitSegment to communicate the initialization segment in an ArrayBuffer form. Can call resolve with null if no initialization segment is available for that representation.   reject: allows loadInitSegment to communicate an error which made the fetching of the initialization segment impossible.   The loadInitSegment callback can also returns a function which will be called if the caller want to abort the fetch operation. Here is an example of how a loadInitSegment function can look like: async function loadInitSegment(callbacks) {   try {     const initSegment = await getStoredInitSegmentForTheCurrentRepresentation();     callbacks.resolve(initSegment);   } catch (e) {     callbacks.reject(e);   }    // Note: in this example, there is no mean to abort the operation, as a result   // we do not return a function here    // // Here is how it would look like if we could:   // return function abort() {   //   abortStoredInitSegmentRequest();   // } } ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_index_object","anchorH3":"the_loadinitsegment_callback"},{"h1":"Local contents (offline playback)","h2":"the index object","h3":"the loadSegment callback","body":"The loadSegment callback is the callback called by the RxPlayer when it wants any segment in the content. Note that the segment data returned by loadSegment should contain all the data and metadata necessary to play them on the browser. Downloaded DASH segments - for example - are generally sufficient but segments linked to Smooth contents should be updated before being returned by loadSegment. This callback is very similar to loadInitSegment with two differences:   it receives two arguments:  The first being the segment object (from the segments array) of the segment we want to recuperate. You can generally discriminate which segment we want from the time property of the given segment, which should be unique for that representation. The second being the callbacks object, which has the exact same form than the one in loadInitSegment (two properties resolve and reject).    it cannot return null. It has to return an ArrayBuffer corresponding to the wanted segment.   Here is an example of how a loadSegment function can look like: async function loadSegment(segment, callbacks) {   try {     const segmentData = await getStoredSegment(segment);     callbacks.resolve(segmentData);   } catch (e) {     callbacks.reject(e);   }    // Note: in this example, there is no mean to abort the operation, as a result   // we do not return a function here    // // Here is how it would look like if we could:   // return function abort() {   //   abortStoredSegmentRequest();   // } } ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_index_object","anchorH3":"the_loadsegment_callback"},{"h1":"Local contents (offline playback)","h2":"About DRMs","body":"Content with DRMs should be supported as long as the encryption information is specified in the corresponding containers (e.g. in PSSH boxes for mp4 and other ISOBMFF containers). We also look into adding supplementary encryption information into the local manifest format, but this is not available for now.","anchorH1":"local_contents_(offline_playback)","anchorH2":"about_drms"},{"h1":"Local contents (offline playback)","h2":"Difference with the 0.1 format","body":"The previous 0.1 version of the local Manifest is now obsolete and is not compatible with the new versions of the RxPlayer. Its documentation can be found here. If you were relying on this version before and would like to switch the the 0.2 version, to be able to play it on newer versions of the RxPlayer, here is the exhaustive list of what changed:   a minimumPosition has been added to the “period object”   a maximumPosition has been added to the “period object”   the duration property of the “period object” has been removed   the start property from a “period object” is now expressed in seconds instead of in milliseconds.   the end property from a “period object” is now expressed in seconds instead of in milliseconds.   the time property from a segment in the “segments array” is now expressed in seconds instead of in milliseconds.   the duration property from a segment in the “segments array” is now expressed in seconds instead of in milliseconds.   the timestampOffset property from a segment in the “segments array” is now expressed in seconds. In the 0.1 version the unit of time was unclear.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"difference_with_the_%600.1%60_format"}]},{"file":"./api/Miscellaneous/Local_Manifest_v0.1.html","index":[{"h1":"Local Manifest format version 0.1","body":" The `0.1` version of the local Manifest format is an old version which is not properly understood by the RxPlayer anymore.  The last version of this specification can be found here. ","anchorH1":"local_manifest_format_version_0.1"},{"h1":"Local Manifest format version 0.1","h2":"Preamble","body":"The RxPlayer is also able to load downloaded DASH, Smooth, MetaPlaylist or even HLS (CMAF-based) contents, whether it is for offline playback or just for an online seamless playback without buffering. This documentation page will be about how to load already downloaded contents. We suppose the content is already downloaded and that you just want to play it through the RxPlayer. However, a tool to download DASH/Smooth/MetaPlaylist contents compatible to this API is under way.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"preamble"},{"h1":"Local Manifest format version 0.1","h2":"Overview","body":"To play contents stored locally, the RxPlayer uses its own Manifest format - the “local manifest” which is close in semantics to DASH’s own Manifest file, the MPD. This new Manifest format will be the only element you will need to generate on your side to play stored contents. As such, this what most of this documentation page is about. Note that the wanted content does not need to be completely downloaded before creating this local manifest. Playback can even begin while the content is still downloading. You will just need to:  indicate that this is a “local” content by setting the transport option in loadVideo to \"local\" As the generated Manifest object most likely won’t be available through an URL but directly as a JavaScript object, you will need to communicate it through the manifestLoader property in the transportOptions loadVideo option.  Here is an example: rxPlayer.loadVideo({   transport: \"local\",   transportOptions: {     // Note: `_url` here will be `undefined`     manifestLoader(_url, callbacks) {       // where `localManifest` is the local Manifest in object form       callbacks.resolve({ data: localManifest });     },   },   // ... });  More infos on the manifestLoader can be found here.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"overview"},{"h1":"Local Manifest format version 0.1","h2":"How to import this feature","body":"The \"LOCAL_MANIFEST\" feature is not included in the default RxPlayer build. There’s two way you can import it, depending on if you’re relying on the minimal version or if you prefer to make use of environment variables and build the player manually. Through the minimal version of the RxPlayer If you’re using the “minimal” version of the RxPlayer (through the \"rx-player/minimal\" import), you will need to import the LOCAL_MANIFEST experimental feature: import RxPlayer from \"rx-player/minimal\"; import { LOCAL_MANIFEST } from \"rx-player/experimental/features\";  RxPlayer.addFeatures([LOCAL_MANIFEST]);  Through environment variables If you don’t want to go the minimal version’s route and you have no problem with building yourself a new version of the RxPlayer, you can make use of environment variables to activate it. This can be done through the RXP_LOCAL_MANIFEST environment variable, which you have to set to true: RXP_LOCAL_MANIFEST=true npm run build:min  More information about any of that can be found in the minimal player documentation.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"how_to_import_this_feature"},{"h1":"Local Manifest format version 0.1","h2":"The Manifest format","body":"As explained in the overview, offline playback by the RxPlayer mainly rely on a specific sort of manifest, called the “local manifest”. It is not the task of the RxPlayer to download and store the content here (a tool to do just that is on its way), this page only explains how to play a stored content once it has been stored. The local manifest looks like a DASH MPD in its structure and as such is very hierarchical. It has the following structure: manifest Object   ...manifest properties   period Object     ...period properties     adaptation Object       ...adaptation properties       representation Object         ...representation properties  We will go progressively from the elements higher in the hierarchy (the manifest object) to the lower ones (the representation Object).","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_manifest_format"},{"h1":"Local Manifest format version 0.1","h2":"The manifest Object","body":"The manifest object describes information about the whole local content:  its duration whether it is still downloading or if its completely available the different “parts” (or “periods”) the content is divided in  First, let’s go into an example, before describing what each property is for: {   type: \"local\", // always set to \"local\"   version: \"0.1\", // version number, in a MAJOR.MINOR form   duration: 60000, // duration of the whole content, in ms   isFinished: true, // if `false`, the content is still downloading   periods: [ // different \"periods\" in the content - see below     // ...   ], }  As you can see, it is a simple JavaScript object with few properties we’re going to dive into just now.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_manifest_object"},{"h1":"Local Manifest format version 0.1","h2":"The manifest Object","h3":"properties","body":"Here is the description about all the properties encountered in a local manifest object:   type (string): Must be set to \"local\". This property indicates to the RxPlayer that the current content is a local manifest.   version (string): Version number, in a MAJOR.MINOR form. The present documentation is for the \"0.1\" version. A parser for a version with the a given MAJOR version should be able to parse and play contents for any of the corresponding MINOR versions. The exception is the 0 MAJOR version (i.e. experimental versions). A parser for a version with that major (let’s say 0.1) might be unable to parse local Manifests of another version (e.g. 0.2).   duration (number): duration of the whole content, in milliseconds. This means the difference between the absolute maximum position and the absolute minimum position.   isFinished (boolean): true indicates that the content has been completely downloaded and can now be played as a whole. false indicates that the whole content is not available yet and that the RxPlayer may have to refresh the local manifest while playing (to get the new data).   periods (Array.<Object>): The different “periods” available in the content. We will explain what a “period” is in the following chapter.   expired (Promise.<undefined>|undefined): Optional Promise which should resolve when a newer local manifest is available. This is for example useful when playing a content which is still downloading. Here expired could resolve once a new segment is available, the RxPlayer would then request the new local manifest (through the same API than for the initial request, e.g. through the manifestLoader property indicated in loadVideo) and would obtain a new local manifest with this new segment included and a new expired property set. This can go on until the content is completely downloaded at which time expired can be set to undefined or just omitted from the last local manifest.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_manifest_object","anchorH3":"properties"},{"h1":"Local Manifest format version 0.1","h2":"The period object","body":"As seen in the previous chapter, the local manifest contains a periods property. The concept of period comes from DASH and allow to separate a content into multiple sub-parts, each with their own configurations. For example, you could have in the same content a TV Show in german followed by an american film, each with its own language choices and qualities. If you don’t need that kind of granularity, you can just create a single period for your local manifest. Here’s an example of a period object: {   start: 10000, // starting position in the whole content, in ms   end: 20000, // ending position, in ms   adaptations: [ // available tracks for this period     // ***   ] }  In the context of a local manifest with multiple periods, here is how it can look like: {   type: \"local\",   version: \"0.1\",   duration: 60000,   isFinished: true,   periods: [ // Here we have 3 consecutive periods:     {       start: 0,       end: 10000,       adaptations: [ /* ... */ ]     },     {       start: 10000,       end: 30000,       adaptations: [ /* ... */ ]     },     {       start: 30000,       end: 60000,       adaptations: [ /* ... */ ]     },   ], } ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_period_object"},{"h1":"Local Manifest format version 0.1","h2":"The period object","h3":"properties","body":"The following properties are found in a period object:   start (number): The position in milliseconds at which the period starts.   end (number): The position in milliseconds at which the period ends.   adaptations (Array.<Object>): The different tracks available. See below for more information.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_period_object","anchorH3":"properties_(1)"},{"h1":"Local Manifest format version 0.1","h2":"the adaptation object","body":"An adaptation is roughly a “track” of the content. It can for the moment be one of those three types:  “audio” “video” “text” (subtitles)  The form of the adaptation object depends on the type of track. Let’s just start with a simple video track example: {   type: \"video\",   language: \"eng\", // optional language code   representations: [ // describes the different available qualities     // ...   ] }  Let’s continue with an audio track example: {   type: \"audio\",   language: \"fra\", // language code for this audio track   audioDescription: false, // if `true`, that audio track is a track adapted for                            // the visually impaired   representations: [ /* ... */ ] }  We’ll finish with a text track example: {   type: \"text\",   language: \"fra\", // language code for this audio track   closedCaption: false, // if `true`, that text track contains supplementary                         // cues about the audio content (generally used for the                         // hard of hearing)   representations: [ /* ... */ ] }  Here how it looks when adaptations are integrated in a given period: {   start: 0,   end: 10000,   adaptations: [     {       type: \"video\",       representations: [ /* ... */ ],     },     {       type: \"audio\",       language: \"eng\",       audioDescription: false,       representations: [ /* ... */ ]     },     {       type: \"audio\",       language: \"fra\",       audioDescription: false,       representations: [ /* ... */ ]     },     {       type: \"audio\",       language: \"fra\",       audioDescription: true,       representations: [ /* ... */ ]     },     {       type: \"text\",       language: \"fra\",       closedCaption: false,       representations: [ /* ... */ ]     },     {       type: \"text\",       language: \"fra\",       closedCaption: true,       representations: [ /* ... */ ]     }   ] },  Let’s now describes precizely every properties encountered here.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_adaptation_object"},{"h1":"Local Manifest format version 0.1","h2":"the adaptation object","h3":"properties","body":"The following properties are found in an adaptation object:   type (string): The “type” of the current adaptation. Can be one of three strings:  audio video text The two first ones are straightforward to understand, the third one designates subtitles.    language (string|undefined): When relevant, this string allows to define the language code for the language the track is in. This is mostly useful for audio and text adaptations but can also be defined for video tracks.   audioDescription (boolean|undefined): If true, the track contains audio indications helping to understand what’s on the screen. Mostly useful for the visually impaired, this property is generally only relevant for audio tracks.   closedCaption (boolean|undefined): If true, that text track contains supplementary text cues about the audio content. Mostly useful for the hard of hearing, this property is generally only relevant for text tracks helping to understand what’s on the screen. Mostly useful for the visually impaired, this property is generally only relevant for audio tracks.   representations (Array.<Object>): The different available qualities for this track. Will be described below.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_adaptation_object","anchorH3":"properties_(2)"},{"h1":"Local Manifest format version 0.1","h2":"The representation object","body":"The representation object will describe the different qualities for a given track (or adaptation). It will also contains logic to fetch segments corresponding to that quality. The representation object is very similar to the Representation element in a DASH MPD. As usual, let’s look into an example. {   bitrate: 5000000, // bitrate of the quality, in bits per seconds   mimeType: \"video/mp4\",   codecs: \"avc1.64001f\",   width: 1280, // default width of the quality, in pixels.                // Mostly relevant for video tracks   height: 720, // default height of the quality, in pixels.                // Mostly relevant for video tracks   index: { // declaration of all the linked segments as well as methods to            // retrieve them     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  For audio tracks, it can looks like: {   bitrate: 200000,   mimeType: \"audio/mp4\",   codecs: \"mp4a.40.5\",   index: {     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  At last, an example for text tracks (here ttml in an mp4 container): {   bitrate: 3000, // bitrate of the quality, in bits per seconds   mimeType: \"application/mp4\",   codecs: \"stpp\",   index: {     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  We’ll now explain what each property is for, before going deeper into the index attribute, which allows the RxPlayer to fetch the media segments.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_representation_object"},{"h1":"Local Manifest format version 0.1","h2":"The representation object","h3":"properties","body":"  bitrate (number): The bitrate the quality is in, in bits per seconds. For example, a bitrate of 5000000 (5.10^6 == 5 MegaBit) would indicate that each second of the content does on average a size of 5 MegaBit.   mimeType (string): As its name suggests, this is the appropriate mime-type for the media. Generally, it is either:  \"video/mp4\" or \"video/webm\" for a video content (depending on the container) \"audio/mp4\" or \"audio/webm\" for an audio content (depending on the container) \"application/mp4\" or \"text/plain\" for a text content (depending on the container / the absence of container)    codecs (string): The codec necessary to be able to play the content. The syntax here is taken from the RFC6381.   width (number|undefined): When relevant (mostly video contents), the width of the media, in pixels   height (number|undefined): When relevant (mostly video contents), the height of the media, in pixels   index (object): Object allowing the RxPlayer to know the list of segments as well as to fetch them. Described in the next chapter.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_representation_object","anchorH3":"properties_(3)"},{"h1":"Local Manifest format version 0.1","h2":"the index object","body":"As just seen, the index object is a property of a given representation. it contains itself three properties:   segments (Array.<Object>): the list of every available media segments for that representation. Does not include the initialization segment. Do not include in this Array the segments that are not downloaded yet.   loadInitSegment (function): Returns the initialization segment or null if this notion is not relevant, like for subtitles.   loadSegment (function): Returns a specific media segment.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_index_object"},{"h1":"Local Manifest format version 0.1","h2":"the index object","h3":"the segments array","body":"Let’s start by the first one, segments. segments is an array of objects, each object describing a single segment of media data. Each object has the following properties:  time (number): starting position of the segment, in milliseconds duration (number): duration of the segment, in milliseconds timestampOffset (number|undefined): optional time offset to add to the segment’s internal time to convert its media time to its presentation time, in milliseconds. If you don’t know what it is, you will most likely not need it.  Let’s see a simple example with four segments of 2 seconds: [   {     time: 0,     duration: 2000,   },   {     time: 2000,     duration: 2000,   },   {     time: 4000,     duration: 2000,   },   {     time: 6000,     duration: 2000,   }, ]; ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_index_object","anchorH3":"the_segments_array"},{"h1":"Local Manifest format version 0.1","h2":"the index object","h3":"the loadInitSegment callback","body":"The loadInitSegment callback allows the RxPlayer to request the initialization segment of this representation. Most audio and video representation have an initialization segment which allows to obtain information about the representation’s data without containing data in itself. For text representations, where it is most likely not needed, this callback can emit null instead of the segment. This callback is given a single argument, which is an object containing callbacks the function should call either when it has fetched the content or when it failed on error. There is two callbacks in that object:   resolve: allows loadInitSegment to communicate the initialization segment in an ArrayBuffer form. Can call resolve with null if no initialization segment is available for that representation.   reject: allows loadInitSegment to communicate an error which made the fetching of the initialization segment impossible.   The loadInitSegment callback can also returns a function which will be called if the caller want to abort the fetch operation. Here is an example of how a loadInitSegment function can look like: async function loadInitSegment(callbacks) {   try {     const initSegment = await getStoredInitSegmentForTheCurrentRepresentation();     callbacks.resolve(initSegment);   } catch (e) {     callbacks.reject(e);   }    // Note: in this example, there is no mean to abort the operation, as a result   // we do not return a function here    // // Here is how it would look like if we could:   // return function abort() {   //   abortStoredInitSegmentRequest();   // } } ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_index_object","anchorH3":"the_loadinitsegment_callback"},{"h1":"Local Manifest format version 0.1","h2":"the index object","h3":"the loadSegment callback","body":"The loadSegment callback is the callback called by the RxPlayer when it wants any segment in the content. Note that the segment data returned by loadSegment should contain all the data and metadata necessary to play them on the browser. Downloaded DASH segments - for example - are generally sufficient but segments linked to Smooth contents should be updated before being returned by loadSegment. This callback is very similar to loadInitSegment with two differences:   it receives two arguments:  The first being the segment object (from the segments array) of the segment we want to recuperate. You can generally discriminate which segment we want from the time property of the given segment, which should be unique for that representation. The second being the callbacks object, which has the exact same form than the one in loadInitSegment (two properties resolve and reject).    it cannot return null. It has to return an ArrayBuffer corresponding to the wanted segment.   Here is an example of how a loadSegment function can look like: async function loadSegment(segment, callbacks) {   try {     const segmentData = await getStoredSegment(segment);     callbacks.resolve(segmentData);   } catch (e) {     callbacks.reject(e);   }    // Note: in this example, there is no mean to abort the operation, as a result   // we do not return a function here    // // Here is how it would look like if we could:   // return function abort() {   //   abortStoredSegmentRequest();   // } } ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_index_object","anchorH3":"the_loadsegment_callback"},{"h1":"Local Manifest format version 0.1","h2":"About DRMs","body":"Content with DRMs should be supported as long as the encryption information is specified in the corresponding containers (e.g. in PSSH boxes for mp4 and other ISOBMFF containers). We also look into adding supplementary encryption information into the local manifest format, but this is not available for now.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"about_drms"}]},{"file":"./api/Miscellaneous/Text_Tracks.html","index":[{"h1":"Text Tracks","body":"","anchorH1":"text_tracks"},{"h1":"Text Tracks","h2":"Overview","body":"The rx-player allows to display text tracks - such as subtitles or closed captions - directly over your content: Adding text tracks to contents can be done by two means:  by using a Manifest declaring those text tracks by manually adding text track(s) when you call the loadVideo API  You can then choose the right track through the different text track-related API, all documented in the general API documentation.","anchorH1":"text_tracks","anchorH2":"overview"},{"h1":"Text Tracks","h2":"Supported text track formats","body":"The rx-player supports the following formats:  TTML (TTML1, EBU-TT and IMSC1) WebVTT SAMI SRT TTML embedded in an MP4 file WebVTT embedded in an MP4 file ","anchorH1":"text_tracks","anchorH2":"supported_text_track_formats"},{"h1":"Text Tracks","h2":"Text tracks indicated in a manifest","body":"Each streaming technology supported by the Manifest defines a way to add text track directly in their Manifests files. This chapter explains what is supported by the RxPlayer.","anchorH1":"text_tracks","anchorH2":"text_tracks_indicated_in_a_manifest"},{"h1":"Text Tracks","h2":"Text tracks indicated in a manifest","h3":"In DASH","body":"In DASH, text tracks are defined by AdaptationSet elements, which have a contentType attribute equal to text. Those AdaptationSet can also define a lang, codecs and mimeType, which are then exploited by the RxPlayer. The lang attribute is used to know the language the track is in. The RxPlayer understands the following standards:  ISO 639-1 (2 letters) ISO 639-2 (3 letters) ISO 639-3 (3 letters)  More complex combined formats are also understood, as long as it begins by one of the understood standards, followed by a dash (“-”). For example “en-US” is translated into just “en”, and then inferred to be english. The mimeType attribute is used to know in which format the track is in. The RxPlayer understands the following ones:  application/ttml+xml: TTML in plain text text/vtt: WebVTT in plain text application/x-sami: SAMI in plain text application/mp4: Text track embedded in an MP4 container. text/plain: Generic plain text mimeType  For the last two, the codecs attribute of the AdaptationSet will be exploited to know the exact format. The rx-player uses the codecs attribute for text tracks in only two cases:  the mimeType is equal to application/mp4 the mimeType is equal to text/plain  For the first case, both WebVTT and TTML can be embedded in an MP4 file. To know which one we’re dealing with, the codecs attribute should be equal to:  stpp for TTML wvtt for WebVTT  For the second case (\"text/plain\"), this is specifically to support plain SubRip (SRT) subtitles. To use them you need to set codecs simply to srt. To know if we’re dealing with a closed caption text track, the RxPlayer uses the DVB-DASH specification. That is, an AdaptationSet is inferred to be a closed caption for the hard of hearing, if it contains an Accessibility descriptor with the following attributes:  SchemeIdUri set to urn:tva:metadata:cs:AudioPurposeCS:2007 value set to 2 ","anchorH1":"text_tracks","anchorH2":"text_tracks_indicated_in_a_manifest","anchorH3":"in_dash"},{"h1":"Text Tracks","h2":"Text tracks indicated in a manifest","h3":"In Microsoft Smooth Streaming","body":"In Smooth Manifests, a StreamIndex is inferred to be for a text track if its Type attribute is equal to text. The FourCC attribute is used to infer the format of the text track. Only TTML is understood, and is translated to be a TTML track embedded in an MP4 container. Adding support for other formats is very simple, open an issue if you want us to add a standardized FourCC code for another supported format. The Language is used to know the language the track is in. The rules are the same than for DASH: The rx-player understand the following standards:  ISO 639-1 (2 letters) ISO 639-2 (3 letters) ISO 639-3 (3 letters) More complex combined formats are also understood, as long as it begins by one of the understood standards, followed by a dash (“-”).  For example “en-US” is translated into just “en”, and then inferred to be english. The Subtype attribute is used to know if the language is a closed caption or not. At the moment, the RxPlayer infers the track to be a closed caption only if its value is DESC.","anchorH1":"text_tracks","anchorH2":"text_tracks_indicated_in_a_manifest","anchorH3":"in_microsoft_smooth_streaming"},{"h1":"Text Tracks","h2":"Text tracks added manually","body":"It is also possible to add a supplementary text track dynamically, by using the TextTrackRenderer tool. You can read its documentation here.","anchorH1":"text_tracks","anchorH2":"text_tracks_added_manually"},{"h1":"Text Tracks","h2":"Text track display modes","body":"There is two ways the text track can be displayed:   \"native\": The text track is displayed in <track> elements, which are directly in the linked videoElement.   \"html\": The text track is displayed in a separate <div> element.   The second ones allows for a better track stylisation. The distinction between those two is pretty simple and is explained here, in the loadVideo options documentation.","anchorH1":"text_tracks","anchorH2":"text_track_display_modes"}]},{"file":"./api/Miscellaneous/images.html","index":[{"h1":"Images","body":"","anchorH1":"images"},{"h1":"Images","h2":"Overview","body":"The RxPlayer defines its own image playlist format, the bif format. This format allows to transmit playlist of thumbnails for linear (live) and non-linear (VOD) contents. The usecase is mostly to allow an improved “seeking” experience. It is understood and parsed by the player, which offers API to easily integrate those features in an application.","anchorH1":"images","anchorH2":"overview"},{"h1":"Images","h2":"Format specification","body":"This documentation is not yet finished. It will be very soon.","anchorH1":"images","anchorH2":"format_specification"},{"h1":"Images","h2":"Using bif for DASH and smooth contents","body":"This documentation is not yet finished. It will be very soon.","anchorH1":"images","anchorH2":"using_bif_for_dash_and_smooth_contents"},{"h1":"Images","h2":"APIs","body":"Images can be retreived through two APIs for now:   getImageTrackData, which returns directly an array of objects describing the images in the playlist.   the imageTrackUpdate event, which emits each time the image playlist is updated with the complete playlist as an array of objects in its data property.  ","anchorH1":"images","anchorH2":"apis"},{"h1":"Images","h2":"APIs","h3":"Structure","body":"In both of those cases you receive an array of Objects, each defining a single image. An image object has the following property:   data (Uint8Array): the raw data for the image object. You can display the corresponding image on your page thanks to the browser window.URL.createObjectURL API.   ts (Number): the position (relatively to the player’s getPosition API) the image should be displayed at, in milliseconds.   duration (Number): the duration, in s, until a new image can be considered.   This array should be ordered by position.","anchorH1":"images","anchorH2":"apis","anchorH3":"structure"},{"h1":"Images","h2":"APIs","h3":"Example","body":"Here is an example of setting the image corresponding to the current position, considering a player instance player and an image element with the id current-image: const position = player.getPosition(); const imagePlaylist = player.getImageTrackData();  const currentImage = imagePlaylist.find((p) => p.ts / 1000 > position);  if (currentImage) {   const blob = new Blob([currentImage], { type: \"image/jpeg\" });   const url = URL.createObjectURL(blob);   document.getElementById(\"current-image\").src = url; } ","anchorH1":"images","anchorH2":"apis","anchorH3":"example"}]},{"file":"./api/Miscellaneous/MetaPlaylist.html","index":[{"h1":"MetaPlaylist v0.1","body":"","anchorH1":"metaplaylist_v0.1"},{"h1":"MetaPlaylist v0.1","h2":"Overview","body":"The MetaPlaylist is a file allowing to define a content composed of multiple DASH or Smooth contents played one after another. It allows advanced use cases for an extremely low cost for the server infrastructure, the main one being creating a linear (live) contents from multiple non-linear (VOD) ones, without touching the original contents. You can also construct a new non-linear contents as a concatenation of multiple non-linear contents put one after the other. This method allows for example for a completely smooth streaming between multiple programs (e.g. when binge-watching a serie).","anchorH1":"metaplaylist_v0.1","anchorH2":"overview"},{"h1":"MetaPlaylist v0.1","h2":"Differences with plain DASH contents","body":"The same result could be approximated with some advanced DASH features, but the MetaPlaylist has several advantages. Some of them are:   it supports DASH and HSS contents (technically HLS would also be possible) without modifying the original MPD/Manifest nor segments.   the Manifest/MPD/Playlist corresponding to the original contents can be lazy-loaded (loaded only when the content will play). This is also possible in DASH with a feature called XLinks but it’s not always doable on the client-side, depending on the other elements present in that MPD. A MetaPlaylist file is much more strict in this regard. This is still a work-in-progress.   it’s a format especially intended to be a concatenation of multiple contents to be played on the web. As such, advanced features such as declaring segments before they should be played or avoiding many customers doing the same manifest request at the exact same time are much easier to implement.   this file rarely needs to be updated, improving the caching of this ressource.   its format is very simple and in JSON, which is easy to integrate with JavaScript codebases. The file can even be very easily generated directly on the client’s page. This paves the way for contents personalized to a single customer.   Digital right management is also much more flexible than with a DASH MPD. For example, different license servers for different contents could be integrated. This is still a work-in-progress.   the specification is simple, try to allow no interpretation and is strict on what is permitted.   All its features have been tested on web applications, meaning that you have the guarantee everything will work on most MSE-compatible browsers, even IE11.  ","anchorH1":"metaplaylist_v0.1","anchorH2":"differences_with_plain_dash_contents"},{"h1":"MetaPlaylist v0.1","h2":"Structure of a MetaPlaylist","body":"A MetaPlaylist file is a simple JSON file. To jump into it right away, let me introduce some examples. For a VOD content: {   \"type\": \"MPL\",   \"version\": \"0.1\",   \"contents\": [     {       \"url\": \"http://url.to.some/DASH/first_content.mpd\",       \"startTime\": 0,       \"endTime\": 100.38,       \"transport\": \"dash\"     },     {       \"url\": \"http://url.to.some/DASH/second_content.Manifest\",       \"startTime\": 100.38,       \"endTime\": 372,       \"transport\": \"smooth\"     },     {       \"url\": \"http://url.to.some/Smooth/third_content.mpd\",       \"startTime\": 372,       \"endTime\": 450.787,       \"transport\": \"dash\"     }   ] }  For a live content: {   \"type\": \"MPL\",   \"version\": \"0.1\",   \"dynamic\": true,   \"pollInterval\": 5,   \"contents\": [     {       \"url\": \"http://url.to.some/DASH/content.mpd\",       \"startTime\": 1545845950.176,       \"endTime\": 1545845985.571,       \"transport\": \"dash\"     },     {       \"url\": \"http://url.to.some/other/DASH/content.mpd\",       \"startTime\": 1545845985.571,       \"endTime\": 1545845998.71,       \"transport\": \"dash\"     },     {       \"url\": \"http://url.to.some/Smooth/content.Manifest\",       \"startTime\": 1545845998.71,       \"endTime\": 1545845117,       \"transport\": \"smooth\"     }   ] }  You may already have a basic understanding of it how works. Let’s define nonetheless every property in that JSON file.","anchorH1":"metaplaylist_v0.1","anchorH2":"structure_of_a_metaplaylist"},{"h1":"MetaPlaylist v0.1","h2":"Structure of a MetaPlaylist","h3":"the header","body":"What I call the “header” here is roughly all root properties but “contents”. Here is an exhaustive list of what you should put there:   type (string): should always be equal to \"MPL\", for “MetaPlayList”. The purpose of this value is to facilitate the checks a player might want to perform to verify that it is handling a MetaPlaylist file. The end goal would be for example to improve error reporting for very frequent mistakes like not providing the URL of the right content.   version (string): version of the MetaPlaylist file. Separated in two parts by a point (‘.’). The first part indicates the major version. If its number is higher than what the client presently manage, the client should not try to read that file. The last part indicates the minor version: A new feature or fix have been added but its support is not needed by a client (a client written for the 1.0 version can be used even for the 1.99 version). Please note that there is an exception for 0.x versions, where each minor versions could have a breaking change (as it is in that case considered an experimental format). At the moment, there is only one version the version \"0.1\". Thus, this is what you have to set in your JSON if you integrate this specification.   dynamic (boolean|undefined): If true, the MetaPlaylist file is not finished, and might need to be updated. If false, the MetaPlaylist could still need to be updated but its current content indicates a finished content: A player should end when the end of the last content has been reached. This property is not mandatory and as such can be omitted. By default, it is considered as not dynamic (so false).   pollInterval (number|undefined): If not set or set to a negative number, the MetaPlaylist file does not need to be reloaded. If set to a positive number, this is the maximum interval in seconds at which the MetaPlaylist file should be fetched from the server (which means that the MetaPlaylist could be refreshed more often depending on the current conditions). This should only be defined for dynamic contents. This property is not mandatory and as such can be omitted. By default, it is equivalent to -1 (which means no reload).  ","anchorH1":"metaplaylist_v0.1","anchorH2":"structure_of_a_metaplaylist","anchorH3":"the_header"},{"h1":"MetaPlaylist v0.1","h2":"Structure of a MetaPlaylist","h3":"The contents","body":"The contents are all defined as a property called contents at the top level of our MetaPlaylist file. It is an array of one or multiple objects (an empty contents array is not a valid MetaPlaylist file). Each of its objects are linked to a single content, here are the exhaustive list of its properties:   url (string): the URL to the original DASH’s MPD or Smooth’s Manifest. For now, only a subset of such contents is supported, mainly:  DASH contents that have their MPD@type set to \"static\" Smooth content that have their isLive attribute not set to true (Simply put, only on-demand contents are supported for the moment).    startTime (number): time, in seconds, at which the beginning of this content should be played. This will correspond to the start time of the first Period in DASH or the first Chunk defined for Smooth content.   endTime (number): time, in seconds, at which the content should end. It the original content is longer, it will be finished at that time instead. The original content should not be shorter.   transport (string): indicates the original streaming protocol. Can be either of those values for now:  \"dash\": the URL points to a DASH’s MPD \"smooth\": the URL points to a Microsoft Smooth Streaming’s Manifest. \"metaplaylist\": Yes, it is possible to put MetaPlaylist files inside other MetaPlaylist files!    All those contents should be contiguous (meaning that the endTime of one should be the same value than the startTime of the following one).","anchorH1":"metaplaylist_v0.1","anchorH2":"structure_of_a_metaplaylist","anchorH3":"the_contents"},{"h1":"MetaPlaylist v0.1","h2":"How to actually play a MetaPlaylist content","body":"","anchorH1":"metaplaylist_v0.1","anchorH2":"how_to_actually_play_a_metaplaylist_content"},{"h1":"MetaPlaylist v0.1","h2":"How to actually play a MetaPlaylist content","h3":"Importing the METAPLAYLIST feature","body":"The \"METAPLAYLIST\" feature is not included in the default RxPlayer build. There’s two way you can import it, depending on if you’re relying on the minimal version or if you prefer to make use of environment variables and build the player manually. Through the minimal version of the RxPlayer If you’re using the “minimal” version of the RxPlayer (through the \"rx-player/minimal\" import), you will need to import:  the METAPLAYLIST experimental feature every transport protocol you might want to use.  For example if you need to use MetaPlaylist with both Smooth and DASH contents, you have to import at least all three as such: import RxPlayer from \"rx-player/minimal\"; import { METAPLAYLIST } from \"rx-player/experimental/features\"; import { DASH, SMOOTH } from \"rx-player/features\";  RxPlayer.addFeatures([METAPLAYLIST, DASH, SMOOTH]);  Through environment variables If you don’t want to go the minimal version’s route and you have no problem with building yourself a new version of the RxPlayer, you can make use of environment variables to activate it. This can be done through the RXP_METAPLAYLIST environment variable, which you have to set to true: RXP_METAPLAYLIST=true npm run build:min  More information about any of that can be found in the minimal player documentation.","anchorH1":"metaplaylist_v0.1","anchorH2":"how_to_actually_play_a_metaplaylist_content","anchorH3":"importing_the_metaplaylist_feature"},{"h1":"MetaPlaylist v0.1","h2":"How to actually play a MetaPlaylist content","h3":"Loading a MetaPlaylist content","body":"A MetaPlaylist content can simply be played by setting a \"metaplaylist\" transport in loadVideo: player.loadVideo({   url: \"http://www.example.com/metaplaylist.json\",   transport: \"metaplaylist\", });  If you declare locally your MetaPlaylist file and do not want to set a URL for it, you can serve directly the file through the use of a Manifest Loader: player.loadVideo({   transport: \"metaplaylist\",   transportOptions: {     // Note: `_url` here will be `undefined`     manifestLoader(_url, callbacks) {       // where `myMetaPlaylistObject` is the MetaPlaylist in either Object or       // String form       callbacks.resolve({ data: myMetaPlaylistObject });     },   }, });  More infos on the manifestLoader can be found here.","anchorH1":"metaplaylist_v0.1","anchorH2":"how_to_actually_play_a_metaplaylist_content","anchorH3":"loading_a_metaplaylist_content"},{"h1":"MetaPlaylist v0.1","h2":"How to actually play a MetaPlaylist content","h3":"Defining an initial position for a dynamic MetaPlaylist","body":"As already explained, a MetaPlaylist can either be dynamic or static. For calculating the initial position of those contents, the RxPlayer will obey the same rules than for other contents. As such, dynamic MetaPlaylist contents will by default start just before the end of the last defined content which might not be what you want. In those cases, you can make usage of the serverSyncInfos transport options when calling loadVideo to indicate the current time and construct the MetaPlaylist by using unix time for each content’s startTime and endTime. The serverSyncInfos option is explained in the transportOptions documentation. For example, if you trust the user’s system clock to indicate the current live time (in most cases this is risky however), you can use the Date.now() api: const serverSyncInfos = {   serverTimestamp: Date.now(),   clientTime: performance.now(), };  player.loadVideo({   transport: \"metaplaylist\",   url: \"https://www.example.com/metaplaylist\",   transportOptions: { serverSyncInfos }, }); ","anchorH1":"metaplaylist_v0.1","anchorH2":"how_to_actually_play_a_metaplaylist_content","anchorH3":"defining_an_initial_position_for_a_dynamic_metaplaylist"}]},{"file":"./api/Miscellaneous/Manifest_Object.html","index":[{"h1":"Manifest Object","body":"","anchorH1":"manifest_object"},{"h1":"Manifest Object","h2":"Overview","body":"A Manifest Object and its sub-parts are data structures returned by multiple APIs of the player. Its data represents the corresponding streaming protocol’s Manifest equivalent (MPD for DASH, Manifest for Microsoft Smooth Streaming etc.). Basically, the structure of a Manifest file has the following hierarchy: Manifest Object   ...Manifest data and methods   Period Object     ...Period properties     Adaptation Object       ...Adaptation data and methods       Representation Object         ...Representation data and methods         RepresentationIndex Object           ...RepresentationIndex data and methods             SegmentObject             ...SegmentObject data  Due to this highly hierachical structure, each level will be described in its own chapter here.  Like in the rest of this documentation, any variable or method not defined here can change without notice.  Only use the documented variables and open an issue if you think it’s not enough.","anchorH1":"manifest_object","anchorH2":"overview"},{"h1":"Manifest Object","h2":"Structure of a Manifest Object","body":"The manifest Object represents the Manifest file of the content loaded.","anchorH1":"manifest_object","anchorH2":"structure_of_a_manifest_object"},{"h1":"Manifest Object","h2":"Structure of a Manifest Object","h3":"properties","body":"The manifest Object has the following properties. periods type: Array.<Period> A single Manifest instance can contain multiple Periods, which are periods of time for which the list of available type of contents (audio tracks, subtitles, video tracks…) can be different. Such example of Periods could be multiple Programs of a live contents, which can be each in different languages, for example. The player will switch smoothly across subsequent Periods within playback. Most Streaming technologies (e.g. HLS and Smooth) do not have a “Period” concept. For those, the Manifest will only have one Period for the whole content. adaptations  This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs).  type: Object Adaptation objects for the first Period. Both of those lines have the same effect: console.log(manifest.adaptations); console.log(manifest.periods[0].adaptations);  See the Period chapter for more information on Adaptations. isLive type: Boolean true if the content is a “live” content (e.g. a live TV Channel). false otherwise. uris type: Array.<string> The list of uris that can be used to refer to the Manifest file. transport type: string The type of transport used. For now, this can only be equal to either dash or smooth.","anchorH1":"manifest_object","anchorH2":"structure_of_a_manifest_object","anchorH3":"properties"},{"h1":"Manifest Object","h2":"Structure of a Period Object","body":"A Period is an object describing what to play during a certain time periods. A Manifest can have a single Period, which means that the played content do not change its characteristics (same languages, same bitrates etc.) or multiple ones. A good example of a content with multiple Periods would be a live channel broadcasting multiple foreign films. Each film, being in a different language, will need to be part of a new Period.","anchorH1":"manifest_object","anchorH2":"structure_of_a_period_object"},{"h1":"Manifest Object","h2":"Structure of a Period Object","h3":"properties","body":"id type: string This id should be a string unique to that Period. It serves identifications purpose, when updating the Manifest for example. start type: Number Start time at which the Period begins in the whole content, in seconds. end type: Number|undefined End time at which the Period ends in the whole content, in seconds. If not set or set to undefined, it means that the end is unknown, in which case it is the current last content of the current Manifest. adaptations type: Object The Adaptations (tracks if you want) for the current content, per-type (audio/video/text/image). See the Adaptation chapter for more info about an Adaptation’s structure. The Adaptation object can contain any of the following keys:  audio (Array.<Adaptation>): The audio Adaptation(s) available. video (Array.<Adaptation>): The video Adaptation(s) available. text (Array.<Adaptation>): The text Adaptation(s) available. image (Array.<Adaptation>): The image Adaptation(s) available. ","anchorH1":"manifest_object","anchorH2":"structure_of_a_period_object","anchorH3":"properties_(1)"},{"h1":"Manifest Object","h2":"Structure of an Adaptation Object","body":"An Adaptation is a set of streams representing the exact same contents in multiple forms (different sizes, different bitrates…). Concretely, a frequent usecase is to have a single video Adaptation and multiple audio ones, one for each language available. As such, it is also often called in the API a track.","anchorH1":"manifest_object","anchorH2":"structure_of_an_adaptation_object"},{"h1":"Manifest Object","h2":"Structure of an Adaptation Object","h3":"properties","body":"id type: string This id should be a string unique to that Adaptation. It serves identifications purpose, when updating the Manifest for example. type type: string The type of the Adaptation. The possible types are:  \"video\" \"audio\" \"text\" \"image\"  language type: string|undefined The language of the Adaptation. This is particularly useful for audio and text Adaptations. Note that this property is not always present in an Adaptation. normalizedLanguage type: string|undefined An attempt to translate the language of the Adaptation into an ISO 639-3 code. If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language Note that this property is not always present in an Adaptation. isAudioDescription type: Boolean|undefined This property only makes sense for audio Adaptations. In this case, if true it means that the audio track has added commentaries for the visually impaired. isClosedCaption type: Boolean|undefined This property only makes sense for text Adaptations. In this case, if true it means that the text track has added hints for the hard of hearing. isTrickMode type : Boolean|undefined This property only makes sense for video Adaptations. In this case, if true it means that the video track is a trick mode track that will be played only if the user start the trick mode on the respective main adaptation. representations type: Array.<Representation> The Represesentations for this Adaptation. See the Representation chapter for more info about a Representation’s structure.","anchorH1":"manifest_object","anchorH2":"structure_of_an_adaptation_object","anchorH3":"properties_(2)"},{"h1":"Manifest Object","h2":"Structure of an Adaptation Object","h3":"methods","body":"getAvailableBitrates return value: Array.<Number> Returns every bitrates available for this Adaptation.","anchorH1":"manifest_object","anchorH2":"structure_of_an_adaptation_object","anchorH3":"methods"},{"h1":"Manifest Object","h2":"Structure of a Representation Object","body":"A Representation is an Adaptation encoded in a certain way. It is defined by multiple values (a codec, a bitrate). Only some of them are documented here (as stated before, open an issue if you would like to access other properties).","anchorH1":"manifest_object","anchorH2":"structure_of_a_representation_object"},{"h1":"Manifest Object","h2":"Structure of a Representation Object","h3":"properties","body":"id type: string This id should be a string unique to that Representation. bitrate type: Number The bitrate of the Representation. codec type: string|undefined The codec of the Representation. decipherable type: boolean|undefined Whether we are able to decrypt this Representation / unable to decrypt it or if we don’t know yet:  if true, it means that we know we were able to decrypt this Representation in the current content. if false, it means that we know we were unable to decrypt this Representation if undefined there is no certainty on this matter  height type: Number|undefined This property makes the most sense for video Representations. It defines the height of the video, in pixels. width type: Number|undefined This property makes the most sense for video Representations. It defines the width of the video, in pixels. index type: RepresentationIndex The represesentation index for this Representation. See the RepresentationIndex chapter for more info about a RepresentationIndex’s structure. frameRate type: string|undefined The represesentation frame rate for this Representation. It defines either the number of frames per second as an integer (24), or as a ratio (24000 / 1000). hdrInfo type: Object|undefined Information about the hdr characteristics of the track. (see HDR support documentation)","anchorH1":"manifest_object","anchorH2":"structure_of_a_representation_object","anchorH3":"properties_(3)"},{"h1":"Manifest Object","h2":"Structure of a RepresentationIndex Object","body":"A RepresentationIndex is an uniform way of declaring the segment index in any Manifest. That’s the part that calculates which segments will be needed. Because the index can be different depending on the type of contents/transport most interactions here are done through few methods which hide the complexity underneath.","anchorH1":"manifest_object","anchorH2":"structure_of_a_representationindex_object"},{"h1":"Manifest Object","h2":"Structure of a RepresentationIndex Object","h3":"methods","body":"getSegments arguments:   up (Number): The position, in seconds from which you want to get the segment.   duration (Number): The duration in seconds from the asked position   return value: Array.<Segment> Returns the needed segments as defined by the current Manifest during an asked timeframe. See the Segment chapter for more info about a Segment’s structure.","anchorH1":"manifest_object","anchorH2":"structure_of_a_representationindex_object","anchorH3":"methods_(1)"},{"h1":"Manifest Object","h2":"Structure of a Segment Object","body":"A Segment object defines a segment, as generated by the RepresentationIndex. Those segments can have multiple useful properties which for the most part are described here.","anchorH1":"manifest_object","anchorH2":"structure_of_a_segment_object"},{"h1":"Manifest Object","h2":"Structure of a Segment Object","h3":"properties","body":"id type: string This id should be a string unique to that segment. timescale type: Number The timescale in which the duration and time are expressed. Basically, divide any of those by the timescale to obtain seconds. duration type: Number|undefined The duration, timescaled, of the Segments in s. time type: Number The start time, timescaled, of the Segments in s. isInit type: Boolean|undefined If true, the segment concerned is an init segment. range type: Array.<Number>|null|undefined If defined, it means that the segment is defined in a certain byte range remotely. In this case, the array contains two elements, the start byte and the end byte. indexRange type: Array.<Number>|null|undefined If defined, it means that a segment index is defined in a certain byte range remotely. In this case, the array contains two elements, the start byte and the end byte. number type: Number|undefined The number of the segment (if numbered), useful with certain types of index.","anchorH1":"manifest_object","anchorH2":"structure_of_a_segment_object","anchorH3":"properties_(4)"}]},{"file":"./api/Miscellaneous/Deprecated_APIs.html","index":[{"h1":"Deprecated APIs","body":"This documentation lists APIs deprecated in the v3.x.x. As we guarantee API compatibility in the v3.x.x, those API won’t disappear until we switch to a v4.x.x version. You will find here which APIs are deprecated, why, and depending on the concerned API, how to replace it.","anchorH1":"deprecated_apis"},{"h1":"Deprecated APIs","h2":"Fullscreen APIs","body":"All fullscreen APIs have been deprecated, namely:  the isFullscreen method the setFullscreen method the exitFullscreen method the fullscreenChange event  This is because of several things:   fullscreen management has now become a lot more complex with features such as advanced subtitles management, were the text track HTMLElement is controlled by the application.   most application developpers also wants to put their own controls into fullscreen mode. Those APIs only put the media element into fullscreen mode and not any other element. This can be misleading.   The fullscreen logic should now be entirely on the application-side. Replacement code is provided for each of those APIs below.","anchorH1":"deprecated_apis","anchorH2":"fullscreen_apis"},{"h1":"Deprecated APIs","h2":"Image (BIF) APIs","body":"The following properties methods and events have been deprecated:  the imageTrackUpdate event the getImageTrackData method the supplementaryImageTracks loadVideo option  This is because most code linked to image management will be moved outside the RxPlayer. Doing that will both be more flexible for users and much easier to maintain for us (albeit with a small time of transition for the application). You can replace those API by this new exported function: parseBifThumbnails. To give more details about why those APIs have been deprecated, there are multiple reasons:  How it should be specified for live contents of for multi-Period DASH contents is not clear enough. Integrating it in the RxPlayer’s API means that it had to take multiple choices that we prefer to let to the application: whether to retry the request if the it fails or if it is unavailable, whether to do the request at all for users with a low bitrate… The task of displaying those thumbnails is ultimately on the UI-side (the part that know where the user wants to seek) The biggest part of the code related to it was a simple BIF parser, that can easily be re-implemented by any application. ","anchorH1":"deprecated_apis","anchorH2":"image_(bif)_apis"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","body":"The following RxPlayer methods are deprecated.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","h3":"getManifest","body":"getManifest returns our internal representation we have of a given “manifest” document. Though it was first exposed to allow users to have access to more precize information on the current content, this method also limited us on the possible evolutions we could do, as changing what this function returns would mean breaking the API. We also realized that that method was not used for now by the implementation we know of. For now, we decided we will simply remove that API in the next major version. If that’s a problem for you, please open an issue.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods","anchorH3":"getmanifest"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","h3":"getCurrentAdaptations","body":"getCurrentAdaptations returns an object describing each tracks available for the current Period in the current content. Like getManifest, we found that this API was not much used and limited us on the possible evolutions we can do on the RxPlayer. Again like getManifest, we plan to remove that API completely without replacing it. If that’s a problem for you, please open an issue.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods","anchorH3":"getcurrentadaptations"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","h3":"getCurrentRepresentations","body":"getCurrentRepresentations returns an object describing each “qualities” available in the current chosen tracks. Exactly like getCurrentAdaptations and getManifest, we found that this API:  was not used as far as we know limited the evolutions we could do on the RxPlayer’s code without breaking the API.  We thus plan to remove that API completely without replacing it. If that’s a problem for you, please open an issue.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods","anchorH3":"getcurrentrepresentations"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","h3":"getNativeTextTrack","body":"getNativeTextTrack returned the first TextTrack element attached to the media element or null  if it did not exist. This API was originally created to allow users to manipulate the TextTrack element themselves. For example, to “catch” cues as they appear and display them differently. What changed is that we now have two text track modes:  html, which allow advanced subtitle management native, the old mode, which display subtitles natively through a TextTrack element.  This API will only return an element for the native mode, but none for the html mode because its element is not attached to the media element. We heavily insist on people wanting advanced usecases to use the html mode, as many formatting options do not work in native mode. As we considered that getNativeTextTrack API was more confusing than it was helpful in our current API, we decided to deprecate it. Do not hesitate to open an issue if you use this API.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods","anchorH3":"getnativetexttrack"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","h3":"isFullscreen","body":"isFullscreen has been deprecated as it is part of our Fullscreen APIs, see the related chapter for more information. isFullscreen just checked that ANY element was fullscreen. As such, it can easily be replace for the majority of browsers with the following code: function isFullscreen() {   return !!(     document.fullscreenElement ||     document.mozFullScreenElement ||     document.webkitFullscreenElement ||     document.msFullscreenElement   ); } ","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods","anchorH3":"isfullscreen"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","h3":"setFullscreen","body":"setFullscreen has been deprecated as it is part of our Fullscreen APIs, see the related chapter for more information. setFullscreen allowed to set the media element in fullscreen mode (or exit fullscreen mode, if false was given as argument). If you want to just put the media element on fullscreen mode, you can use the following code: function setFullscreen(goFull) {   if (goFull === \"false\") {     exitFullscreen();     return;   }   if (isFullscreen()) {     // see code above     return;   }    const mediaElement = player.getVideoElement();   if (!mediaElement) {     throw new Error(\"No media element\");   }   if (mediaElement.requestFullscreen) {     mediaElement.requestFullscreen();   } else if (mediaElement.msRequestFullscreen) {     mediaElement.msRequestFullscreen();   } else if (mediaElement.mozRequestFullScreen) {     mediaElement.mozRequestFullScreen();   } else if (mediaElement.webkitRequestFullscreen) {     mediaElement.webkitRequestFullscreen(Element.ALLOW_KEYBOARD_INPUT);   } }  Please consider however that this function will only put the media element in full screen mode, without the eventual controls and HTML text tracks you might also want to set in fullscreen. The code is easily adaptable however to put your own element into fullscreen mode instead.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods","anchorH3":"setfullscreen"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","h3":"exitFullscreen","body":"exitFullscreen has been deprecated as it is part of our Fullscreen APIs, see the related chapter for more information. exitFullscreen just exited any element put in fullscreen mode. As such, its code can easily be replaced by: function exitFullscreen() {   if (isFullscreen()) {     if (document.exitFullscreen) {       document.exitFullscreen();     } else if (document.msExitFullscreen) {       document.msExitFullscreen();     } else if (document.mozCancelFullScreen) {       document.mozCancelFullScreen();     } else if (document.webkitExitFullscreen) {       document.webkitExitFullscreen();     }   } } ","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods","anchorH3":"exitfullscreen"},{"h1":"Deprecated APIs","h2":"RxPlayer Methods","h3":"getImageTrackData","body":"getImageTrackData has been deprecated like most API related to BIF thumbnail parsing. You can read the related chapter for more information. You can replace this API by using the parseBifThumbnails tool.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_methods","anchorH3":"getimagetrackdata"},{"h1":"Deprecated APIs","h2":"RxPlayer Events","body":"The following RxPlayer events has been deprecated.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_events"},{"h1":"Deprecated APIs","h2":"RxPlayer Events","h3":"nativeTextTracksChange","body":"nativeTextTracksChange events are deprecated. Which means they probably won’t be sent in a v4.x.x version. The reasons are basically the same than for the getNativeTextTracks method. It should not be needed anymore as most advanced needs should be better answered by an html text track mode.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_events","anchorH3":"nativetexttrackschange"},{"h1":"Deprecated APIs","h2":"RxPlayer Events","h3":"fullscreenChange","body":"fullscreenChange events have been deprecated as it is part of our Fullscreen APIs, see the related chapter for more information. The fullscreenChange event was sent when the media element got in or out of fullscreen mode, with agg boolean as a payload:  if true, the element entered fullscreen mode if false, the element exited fullscreen mode  This behavior can easily be recreated through the following code: const mediaElement = player.getVideoElement(); mediaElement.addEventListener(\"fullscreenChange\", () => {   if (isFullscreen()) {     // see isFullscreen implementation above     // do things   } else {     // do other things   } }); ","anchorH1":"deprecated_apis","anchorH2":"rxplayer_events","anchorH3":"fullscreenchange"},{"h1":"Deprecated APIs","h2":"RxPlayer Events","h3":"imageTrackUpdate","body":"imageTrackUpdate events have been deprecated like most API related to BIF thumbnail parsing. You can read the related chapter for more information. You can replace this API by using the parseBifThumbnails tool.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_events","anchorH3":"imagetrackupdate"},{"h1":"Deprecated APIs","h2":"loadVideo options","body":"The following loadVideo options are deprecated.","anchorH1":"deprecated_apis","anchorH2":"loadvideo_options"},{"h1":"Deprecated APIs","h2":"loadVideo options","h3":"defaultAudioTrack","body":"The preferredAudioTracks loadVideo option is now the preferred (no pun intended) solution to set the default audio track. This new option allows to handle much more complex use cases and can even be updated at any time through the setPreferredAudioTracks method. How to replace that option It is very easy to replace defaultAudioTrack by preferredAudioTracks. For example, if you want to have a default french audio language, you probably previously did: player.loadVideo({   url: myURL,   transport: myTransport,    defaultAudioTrack: { language: \"fra\", audioDescription: false },   // or just `defaultAudioTrack: \"fra\"`, both are equivalent });  Now you will have to set it through an array either when creating a new RxPlayer: const player = new RxPlayer({   preferredAudioTracks: [{ language: \"fra\", audioDescription: false }], });  Or at any time, through the setPreferredAudioTracks method: player.setPreferredAudioTracks([{ language: \"fra\", audioDescription: false }]); ","anchorH1":"deprecated_apis","anchorH2":"loadvideo_options","anchorH3":"defaultaudiotrack"},{"h1":"Deprecated APIs","h2":"loadVideo options","h3":"defaultTextTrack","body":"defaultTextTrack is replaced by the preferredTextTracks constructor option for the same reason than defaultAudioTrack. How to replace that option It is very easy to replace defaultTextTrack by preferredTextTracks. For example, if you want to have a default swedish subtitle language, you probably previously did: player.loadVideo({   url: myURL,   transport: myTransport,    defaultTextTrack: { language: \"swe\", closedCaption: false },   // or just `defaultTextTrack: \"swe\"`, both are equivalent });  Now you will have to set it through an array either when creating a new RxPlayer: const player = new RxPlayer({   preferredTextTracks: [{ language: \"swe\", closedCaption: false }], });  Or at any time, through the setPreferredTextTracks method: player.setPreferredTextTracks([{ language: \"fra\", closedCaption: false }]); ","anchorH1":"deprecated_apis","anchorH2":"loadvideo_options","anchorH3":"defaulttexttrack"},{"h1":"Deprecated APIs","h2":"loadVideo options","h3":"supplementaryTextTracks","body":"The supplementaryTextTracks has been deprecated for multiple reasons:   The main reason is that the behavior of this API is not defined for multi-Period DASH contents (nor for MetaPlaylist contents): Should we only add the subtitles for the first Period or should it be for every Period? How to define a different subtitles track for the first and for the second Period? Adding an external tool much less coupled to the RxPlayer move those questions entirely to the application, which should know more than us what to do in those different cases.   Its API was a little arcane because we had to make it compatible with every possible type of contents (i.e. DASH, Smooth, MetaPlaylist etc.) out there.   It did not work for Directfile contents yet. Although we could have made it compatible with them, we thought that this was the occasion to define a better API to replace it.   Its behavior was more complex that you would initially think of. For example, we could have to re-download multiple times the same subtitles file if manual garbage collecting was enabled.   All usages of that API that we know of were for Smooth or DASH VoD contents which sadly just omitted those subtitles tracks in their Manifest. The true “clean” way to fix the problem in that case is to do it at the source: the content. In this case, fixing it on the player-side should only be a temporary work-around (don’t be scared, we still have an API replacement).   The new TextTrackRenderer tool which replace it is much more straightforward. As an external tool which just reads and renders already-downloaded text subtitles, its API and the extent of what it does should be much more simple. It’s also compatible with any type of contents, even when playing through an other player. How to replace that option Every supplementaryTextTracks feature can be replaced by the TextTrackRenderer tool. Please bear in mind however that they are two completely different APIs, doing the transition might take some time. The TextTrackRenderer tool is documented here.","anchorH1":"deprecated_apis","anchorH2":"loadvideo_options","anchorH3":"supplementarytexttracks"},{"h1":"Deprecated APIs","h2":"loadVideo options","h3":"supplementaryImageTracks","body":"The supplementaryImageTracks events have been deprecated like most API related to BIF thumbnail parsing. You can read the related chapter for more information. You can replace this API by using the parseBifThumbnails tool.","anchorH1":"deprecated_apis","anchorH2":"loadvideo_options","anchorH3":"supplementaryimagetracks"},{"h1":"Deprecated APIs","h2":"loadVideo options","h3":"hideNativeSubtitle","body":"The hideNativeSubtitle option is deprecated and won’t be replaced. This is because it was added at a time when our text track API was much less advanced. Some applications wanted to handle subtitles themselves and thus hid the true “native” subtitles to display them themselves in a better way. However, this API seems to not be used anymore. Please open an issue if you need it.","anchorH1":"deprecated_apis","anchorH2":"loadvideo_options","anchorH3":"hidenativesubtitle"},{"h1":"Deprecated APIs","h2":"RxPlayer constructor options","body":"The following RxPlayer constructor options are deprecated.","anchorH1":"deprecated_apis","anchorH2":"rxplayer_constructor_options"},{"h1":"Deprecated APIs","h2":"RxPlayer constructor options","h3":"throttleWhenHidden","body":"throttleWhenHiddenhas been deprecated as video visibility relies only on page visibility API and document hiddenness. A video should be visible if the Picture-In-Picture mode is activated, even if the hidden attribute of document is set to true. throttleVideoBitrateWhenHidden relies on both and can be used like this : const rxPlayer = new RxPlayer({   // ... RxPlayer options   // throttleWhenHidden: true [deprecated]   throttleVideoBitrateWhenHidden: true, }); ","anchorH1":"deprecated_apis","anchorH2":"rxplayer_constructor_options","anchorH3":"throttlewhenhidden"},{"h1":"Deprecated APIs","h2":"Other properties","body":"Some very specific properties from various methods are deprecated. You will find them here.","anchorH1":"deprecated_apis","anchorH2":"other_properties"},{"h1":"Deprecated APIs","h2":"Other properties","h3":"Manifest","body":"The adaptations property returned by the Manifest object you can obtain through the getManifest call is deprecated. This corresponds to the adaptations property of the first element in the periods object from the same Manifest object, so it’s very easy to replace: const manifest = player.getManifest();  if (manifest && manifest.periods.length) {   console.log(manifest.adaptations === manifest.periods[0].adaptations); // true } ","anchorH1":"deprecated_apis","anchorH2":"other_properties","anchorH3":"manifest"},{"h1":"Deprecated APIs","h2":"Other properties","h3":"Smooth","body":"Setting a *.wsx, a *.ism or a *.isml URL as an url property in loadVideo is now deprecated when we’re talking about a Smooth Streaming content. We recommend to only set a Manifest URL in that property when the transport is equal to smooth.","anchorH1":"deprecated_apis","anchorH2":"other_properties","anchorH3":"smooth"},{"h1":"Deprecated APIs","h2":"Other properties","h3":"NetworkError","body":"The xhr property from a NetworkError is deprecated. This is to prepare the support of low-latency streaming, with CMAF, where the fetch API has to be used instead of an XMLHttpRequest. We recommend to not rely on this property anymore. You still should have access to the status and url properties.","anchorH1":"deprecated_apis","anchorH2":"other_properties","anchorH3":"networkerror"}]},{"file":"./api/Miscellaneous/Initial_Position.html","index":[{"h1":"Initial Position","body":"","anchorH1":"initial_position"},{"h1":"Initial Position","h2":"Overview","body":"When you give it a content to load, the RxPlayer has to set at one point the starting playback position. This documentation page explain how that position is calculated. Basically, we can be in one of those four different situations:   a valid startAt option has been set to loadVideo, in which case we use it to define the initial position.   no startAt option has been set and we’re playing a VoD content.   no startAt option has been set and we’re playing a live content.   no startAt option has been set and we’re playing a directfile content.  ","anchorH1":"initial_position","anchorH2":"overview"},{"h1":"Initial Position","h2":"About the minimum and maximum position","body":"Regardless of your current situation, the minimum and maximum position of the content might be calculated and used when defining that starting position. Those positions are inferred directly from the Manifest (when not playing a directfile content). Most Manifests declare every segments currently available. In that case, we can simply use the start of the first announced segment as a minimum position and the end of the last one as a maximum. In some other Manifest files, segment availability is not clearly announced. In those cases, the minimum and maximum positions use other properties declared in the Manifest, often by making usage of a synchronized clock between the client and the server. For “directfile” contents, we directly interrogate the browser to obtain the duration of the content. The minimum position here is always inferred to be 0 (for the moment at least).","anchorH1":"initial_position","anchorH2":"about_the_minimum_and_maximum_position"},{"h1":"Initial Position","h2":"When a startAt option has been set","body":"You can define yourself the start position at which we should play. This is configurable thanks to the startAt option, documented here in the API documentation. Please note however that there is a catch: every of the possible values you will set will be “bounded” to the maximum and minimum position actually detected for the content. This means that if your startAt indicate that we should start at a position of 10 seconds but the content starts at 15 seconds, we will actually start at 15 seconds instead. You can check at which position we actually loaded when the player’s state (accessible either through the getPlayerState method or through the playerStateChanged event) changed to \"LOADED\".","anchorH1":"initial_position","anchorH2":"when_a_startat_option_has_been_set"},{"h1":"Initial Position","h2":"When no startAt option has been set and we’re playing a VoD content","body":"For VoD contents, we will just start to play at the minimum detected position in the Manifest.","anchorH1":"initial_position","anchorH2":"when_no_startat_option_has_been_set_and_we're_playing_a_vod_content"},{"h1":"Initial Position","h2":"When no startAt option has been set and we’re playing a live content","body":"For live contents, we have here three cases:   In the case where we have a clock synchronization mechanism with the server[1] and if the current date can be seeked to (i.e. segments are available for that position), we will try to play close to[2] that date.   if either we do not have a clock synchronization mechanism[1] or if we have one but no segment is defined for the current date, we will play close to[2] the maximum calculated position instead.   Third case, if we do not have any clock synchronization mechanism[1] and if the Manifest does not announce clearly a maximum position, we will use the system clock and play close to[2] that time instead.   [1] We can obtain a synchronized clock allowing us to to know which content should be broadcasted at which time by either of those means:  the Manifest document defines one (e.g. UTCTiming elements for DASH contents). One was provided to loadVideo thanks to the serverSyncInfos transport option see loadVideo documentation.  [2] I wrote “close to” in every cases as we might substract some seconds from that value. How much we might do, depends on:  if the manifest suggest us a delay relative to the live, in which case we apply it if not, we set it to the default: 10 seconds ","anchorH1":"initial_position","anchorH2":"when_no_startat_option_has_been_set_and_we're_playing_a_live_content"},{"h1":"Initial Position","h2":"When no startAt option has been set and we’re playing a directfile content","body":"For directfile contents, we for now just start at 0 if no startAt is defined.","anchorH1":"initial_position","anchorH2":"when_no_startat_option_has_been_set_and_we're_playing_a_directfile_content"}]},{"file":"./api/Miscellaneous/presentationTimeOffset.html","index":[{"h1":"Presentation Time Offset","body":"The presentationTimeOffset is an attribute which can be encountered in an MPD (the “manifest” of the DASH streaming technology).","anchorH1":"presentation_time_offset"},{"h1":"Presentation Time Offset","h2":"Overview","body":"Simply put, this attribute allows to correct an offset present in the media segments once those are decoded. One of the possible usecase would be creating an on demand MPD from a subsection of an already-existing content, without modifying directly the concerned segments nor their (possibly time-based) URLs. Another main usecase is when handling multi-Periods MPDs. Segments in newer Periods already need to consider an offset, corresponding to the start of the given Period. In those cases, the presentationTimeOffset might allows to “cancel” out this offset. This can be useful if the corresponding segments already define the right time.","anchorH1":"presentation_time_offset","anchorH2":"overview"},{"h1":"Presentation Time Offset","h2":"Simple example","body":"For example, let’s imagine some on-demand content with a duration of 2 hours. To stay simple, this content begins at 00:00:00.000 and ends at 01:08:00.000 (1 hour and 8 minutes). CONTENT:  00:00:00.000                                                        01:08:00.000     |====================================================================|   Now let’s say that we want to create a new on-demand content, which is only a sub-part from this content. For example, we will take the subpart going from 00:05:24.000 to 00:12:54.000 (for a duration of 00:07:30.000).  00:00:00.000                                                        02:00:00.000     |====|------|========================================================|             ^       Subpart going from 00:05:24 to 00:12:54.000   Because we might not want to use money uselessly, we want to create this new content simply by creating a new MPD, and without touching the already created segments, nor their URLs. In that condition, we will still need the client to know that this content actually have an offset of 00:05:24.000. If it does not know that, we will just think that the content begins at a default 00:00:00.000 time. Letting the client think that the content begins at the default 00:00:00.000 time could lead to several issues:   it might not be able to request the right first segments (as the URLs could be time-based)   even if it does, it might not be able to actually play the content, as we’re pushing segments corresponding to a 00:05:24.000 while the browser is still waiting for the 00:00:00.000 ones (in that case, we would just have an infinite buffering state).   even if it does, the client timeline will announce a wrong time, offseted 5 minutes and 24 seconds too late.   This is where the presentationTimeOffset comes into play. In our simple example, this value will just announce an offset of 00:05:24.000 (under the form of an integer with a timescale to convert it into seconds), and the client will know what to do. What the client has to do here is:  begin to play at 0 secods ask the right segments, by adding this offset to the one it thinks it needs remove the offset from the segment before decoding it ","anchorH1":"presentation_time_offset","anchorH2":"simple_example"},{"h1":"Presentation Time Offset","h2":"Time conversions","body":"The presentationTimeOffset is linked to multiple other time attributes of an MPD, especially the start of the Period concerned, and of course the time of the segment. We will enounce below a simple equation which put their relation into perspective. To understand this equation, we will need to define some variables:    Variable Definition     PTO The “presentationTimeOffset” attribute of the MPD   mediaTime The start time announced in the segment   TS Timescale used by PTO and segmentTime, to transform them into seconds   periodStart Start time of the given period, in seconds   presentationTime The time at which the segment will be shown, in seconds        mediaTime        PTO   -------------  -  -----  +  periodStart  =  presentationTime        TS            TS ","anchorH1":"presentation_time_offset","anchorH2":"time_conversions"},{"h1":"Presentation Time Offset","h2":"Time conversions","h3":"Easier conversion: the timestampOffset","body":"As seen in the previous chapter, to convert the media time (time announced in the segments) into the presentation time (time that will be shown to the user), you will need to use both also include three other variables:   the start of the period   the presentationTimeOffset   the timescale used by the presentationTimeOffset and the media time   As a convenient plus, those three variables rarely change for a given period. To simplify the conversion, we can thus define a new variable using those three. This is what the timestampOffset is all about. Let’s go back to the equations in the previous chapters, to isolate those three into the really simple equation: mediaTime/TS + timestampOffset = presentationTime (you can refer to the previous chapter to understand what those variables means)    mediaTime       PTO  -----------  -  -----  +  periodStart  =  presentationTime      TS           TS    mediaTime           PTO  -----------  + ( -  -----  +  periodStart ) =  presentationTime      TS               TS                            PTO                                       PTO   timestampOffset  =  -  -----  +  periodStart  =  periodStart  -  -----                           TS                                        TS   With timestampOffset defined, it becomes easy to go back and forth between the mediaTime and the presentationTime:                        mediaTime presentationTime  =   -----------  +  timestampOffset                           TS  mediaTime  =  (  presentationTime  -  timestampOffset  )  *  TS   As an added bonus, SourceBuffers defined in the HTML5 MediaSource Extentions also have a timestampOffset property , which means exactly the same thing as defined here!","anchorH1":"presentation_time_offset","anchorH2":"time_conversions","anchorH3":"easier_conversion:_the_timestampoffset"},{"h1":"Presentation Time Offset","h2":"In the RxPlayer","body":"Now that we have all of those concepts out of the way, how are we going to use it, in the RxPlayer? The RxPlayer has A LOT of time-related values defined for a given segment:   the time defined in the segment itself (mediaTime)   the time displayed when playing it in the HTMLMediaElement (presentationTime)   the time possibly set in the request (requestSegmentTime)   the time as announced in the corresponding attribute of the manifest (manifestTime)   the time used in the corresponding Segment Object in the RxPlayer (playerTime)   the time used in the buffered APIs of a HTMLMediaElement or SourceBuffer (bufferedTime)   …   As it turns out it’s a lot simpler once you make two isolated groups:   the manifest group, which uses the non-offseted mediaTime. In this group you have:  the mediaTime (duh) the manifestTime the requestSegmentTime    the real time group, which uses the offseted presentationTime. In this group you have:  the presentationTime the playerTime the bufferedTime    The manifest group is then only used in the transports code of the RxPlayer. Meanwhile, the real time group is used everywhere else. It’s actually the transports code that does most of the conversion for the rest of the code (removing the offset when requesting new segments, re-adding it once the segment is downloaded. To be able to offset those segments in the SourceBuffer, those are still informed of course of the timestampOffset by the transports code. Then, this timestampOffset will be exploited only by the final decoding code.","anchorH1":"presentation_time_offset","anchorH2":"in_the_rxplayer"}]},{"file":"./api/Miscellaneous/DASH_Adaptation_Difference.html","index":[{"h1":"Differences between DASH’ AdaptationSets and the rx-player “Adaptation”","body":"The RxPlayer defines an Adaptation object (also sometimes called Track) which follow as close as possible the concept of the AdaptationSet in the DASH protocol. However, to answer practically to some of the features allowed by DASH while still respecting the DASH-IF “IOP”, we had to take some (minor) freedom with our interpretation of it.","anchorH1":"differences_between_dash'_adaptationsets_and_the_rx-player_%22adaptation%22"},{"h1":"Differences between DASH’ AdaptationSets and the rx-player “Adaptation”","h2":"Merging of multiple AdaptationSets into a single Adaptation","body":"The main difference is that all similar AdaptationSet which are marked as “seamlessly switchable” between one another are merged into a single Adaptation in the player.","anchorH1":"differences_between_dash'_adaptationsets_and_the_rx-player_%22adaptation%22","anchorH2":"merging_of_multiple_adaptationsets_into_a_single_adaptation"},{"h1":"Differences between DASH’ AdaptationSets and the rx-player “Adaptation”","h2":"Merging of multiple AdaptationSets into a single Adaptation","h3":"Why do we do that","body":"This “switchable” concept is for example used in cases were multiple encryption keys are present for different Representation (e.g. due to limitations coming from right holders). The problem is that the DASH-IF tells us that all Representation in a given AdaptationSet have to use the same license. This means that in the aforementioned case, the concerned Representation have to be divided into multiple AdaptationSet. In a player, different AdaptationSet means different “tracks” and thus a player won’t try to automatically switch between them. This means that our adaptive algorithm won’t be able to set the right quality and that the library user would have to manually manage that instead. Fortunately, the DASH-IF IOP planned a work-around for that kind of situation: To allow a player to seamlessly switch between multiple AdaptationSets, the DASH-IF allows a specific node, called SupplementalProperty to be added as children of the concerned AdaptationSets (with a specific value). However, this brings another set of issues in the rx-player, where this separation would lead to an excessively complicated API.","anchorH1":"differences_between_dash'_adaptationsets_and_the_rx-player_%22adaptation%22","anchorH2":"merging_of_multiple_adaptationsets_into_a_single_adaptation","anchorH3":"why_do_we_do_that"},{"h1":"Differences between DASH’ AdaptationSets and the rx-player “Adaptation”","h2":"Merging of multiple AdaptationSets into a single Adaptation","h3":"What do we do","body":"We thus decided to “merge” the AdaptationSets into a single Adaptation if all those conditions are filled:   they both support seamless-switching between one-another (i.e. they both contain a SupplementalProperty node with the right values)   they represent the same type of content (“audio”, “video” or “text”)   they are of the same language, if one (letter-for-letter in the manifest)   they have the same accessibility information (e.g. both are closed captions or audio description for the visually impaired).   If any of these conditions is not filled, the concerned AdaptationSets stay separated and the player will not try to switch between them.","anchorH1":"differences_between_dash'_adaptationsets_and_the_rx-player_%22adaptation%22","anchorH2":"merging_of_multiple_adaptationsets_into_a_single_adaptation","anchorH3":"what_do_we_do"}]},{"file":"./api/Deprecated/getManifest.html","index":[{"h1":"getManifest","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). ","anchorH1":"getmanifest"},{"h1":"getManifest","h2":"Description","body":"Returns the current loaded Manifest if one. The Manifest object structure is relatively complex and is described in the Manifest Object structure page. null if the player is either stopped or not loaded. null in DirectFile mode (see loadVideo options). The Manifest will be available before the player reaches the \"LOADED\" state.","anchorH1":"getmanifest","anchorH2":"description"},{"h1":"getManifest","h2":"Syntax","body":"const manifest = player.getManifest();   return value Object|null: The current Manifest object. ","anchorH1":"getmanifest","anchorH2":"syntax"}]},{"file":"./api/Deprecated/getCurrentAdaptations.html","index":[{"h1":"getCurrentAdaptations","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). ","anchorH1":"getcurrentadaptations"},{"h1":"getCurrentAdaptations","h2":"Description","body":"Returns the Adaptations being loaded per type if a Manifest is loaded. The returned object will have at most a key for each type (“video”, “audio”, “text” and “image”) which will each contain an array of Adaptation Objects. The Adaptation object structure is relatively complex and is described in the Manifest Object structure page. null if the current Adaptations are not known yet. null in DirectFile mode (see loadVideo options).","anchorH1":"getcurrentadaptations","anchorH2":"description"},{"h1":"getCurrentAdaptations","h2":"Syntax","body":"const adaptations = player.getCurrentAdaptations();   return value Object|null: The current Adaptation objects, per type. null if not known. ","anchorH1":"getcurrentadaptations","anchorH2":"syntax"}]},{"file":"./api/Deprecated/getCurrentRepresentations.html","index":[{"h1":"getCurrentRepresentations","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). ","anchorH1":"getcurrentrepresentations"},{"h1":"getCurrentRepresentations","h2":"Description","body":"Returns the Representations being loaded per type if a Manifest is loaded. The returned object will have at most a key for each type (“video”, “audio”, “text” and “image”) which will each contain an array of Representation Objects. The Representation object structure is relatively complex and is described in the Manifest Object structure page. null if the current Representations are not known yet. null in DirectFile mode (see loadVideo options).","anchorH1":"getcurrentrepresentations","anchorH2":"description"},{"h1":"getCurrentRepresentations","h2":"Syntax","body":"const representations = player.getCurrentRepresentations();   return value Object|null: The current Representation objects, per type. null if not known. ","anchorH1":"getcurrentrepresentations","anchorH2":"syntax"}]},{"file":"./api/Deprecated/setFullscreen.html","index":[{"h1":"setFullscreen","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). ","anchorH1":"setfullscreen"},{"h1":"setFullscreen","h2":"Description","body":"Switch or exit the <video> element to fullscreen mode. The argument is an optional boolean:   if set:  true: enters fullscreen false: exit fullscreen    if not set: enter fullscreen   Note that only the video element will be set to fullscreen mode. You might prefer to implement your own method to include your controls in the final UI.","anchorH1":"setfullscreen","anchorH2":"description"},{"h1":"setFullscreen","h2":"Syntax","body":"player.setFullscreen();   arguments (optional) Boolean|undefined: If not defined or true, set the attached media element in fullscreen mode. If false, exit fullscreen mode. ","anchorH1":"setfullscreen","anchorH2":"syntax"}]},{"file":"./api/Deprecated/isFullscreen.html","index":[{"h1":"isFullscreen","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). ","anchorH1":"isfullscreen"},{"h1":"isFullscreen","h2":"Description","body":"Returns true if the video element is in fullscreen mode, false otherwise. Example if (player.isFullscreen()) {   console.log(\"The player is in fullscreen mode\"); } ","anchorH1":"isfullscreen","anchorH2":"description"},{"h1":"isFullscreen","h2":"Syntax","body":"const isFullscreen = player.isFullscreen();   return value Boolean ","anchorH1":"isfullscreen","anchorH2":"syntax"}]},{"file":"./api/Deprecated/exitFullscreen.html","index":[{"h1":"exitFullscreen","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). ","anchorH1":"exitfullscreen"},{"h1":"exitFullscreen","h2":"Description","body":"Exit fullscreen mode. Same than setFullscreen(false).","anchorH1":"exitfullscreen","anchorH2":"description"},{"h1":"exitFullscreen","h2":"Syntax","body":"player.exitFullscreen(); ","anchorH1":"exitfullscreen","anchorH2":"syntax"}]},{"file":"./api/Deprecated/getImageTrackData.html","index":[{"h1":"getImageTrackData","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). ","anchorH1":"getimagetrackdata"},{"h1":"getImageTrackData","h2":"Description","body":"The current image track’s data, null if no content is loaded / no image track data is available. The returned array follows the usual image playlist structure, defined here. null in DirectFile mode (see loadVideo options).","anchorH1":"getimagetrackdata","anchorH2":"description"},{"h1":"getImageTrackData","h2":"Syntax","body":"const data = player.getImageTrackData();   return value Array.<Object>|null: The image playlist. ","anchorH1":"getimagetrackdata","anchorH2":"syntax"}]},{"file":"./api/Deprecated/getNativeTextTrack.html","index":[{"h1":"getNativeTextTrack","body":" This option is deprecated, it will disappear in the next major release `v4.0.0` (see Deprecated APIs). ","anchorH1":"getnativetexttrack"},{"h1":"getNativeTextTrack","h2":"Description","body":"Returns the first text track of the video’s element, null if none. This is equivalent to: const el = player.getVideoElement(); const textTrack = el.textTracks.length ? el.textTracks[0] : null; ","anchorH1":"getnativetexttrack","anchorH2":"description"},{"h1":"getNativeTextTrack","h2":"Syntax","body":"player.getNativeTextTrack()   return value TextTrack|null ","anchorH1":"getnativetexttrack","anchorH2":"syntax"}]},{"file":"./reference/API_Reference.html","index":[{"h1":"API reference","body":"","anchorH1":"api_reference"},{"h1":"API reference","h2":"Overview","body":"This is the API reference which presents every RxPlayer API in a single page. The point of this page is to provide an easier-to-navigate page than the API documentation for when you’re already familiar with it. API are splitted here in multiple categories depending on if they are properties, methods, events and so on.","anchorH1":"api_reference","anchorH2":"overview"},{"h1":"API reference","h2":"Constructor","body":" new RxPlayer(): Create a new RxPlayer. ","anchorH1":"api_reference","anchorH2":"constructor"},{"h1":"API reference","h2":"Constructor options","body":"  videoElement: specifies the media element on which the content will play.   initialVideoBitrate: Ceil value for the initial video bitrate wanted.   initialAudioBitrate: Ceil value for the initial audio bitrate wanted.   minVideoBitrate: Minimum video bitrate reachable through adaptive streaming.   minAudioBitrate: Minimum audio bitrate reachable through adaptive streaming.   maxVideoBitrate: Maximum video bitrate reachable through adaptive streaming.   maxAudioBitrate: Maximum audio bitrate reachable through adaptive streaming.   wantedBufferAhead: Set the default buffering goal.   preferredAudioTracks: Set default audio tracks preferences based on tracks characteristics.   preferredTextTracks: Set default text tracks preferences based on tracks characteristics.   preferredVideoTracks: Set default video tracks preferences based on tracks characteristics.   maxBufferAhead: Set the default maximum kept buffer ahead of the current position, in seconds.   maxBufferBehind: Set the default maximum kept buffer before the current position, in seconds.   maxVideoBufferSize: Set the default maximum size the video buffer can take in the memory, in kilobytes (kb).   limitVideoWidth: Limit the maximum video width according to the video element’s current width.   throttleVideoBitrateWhenHidden: Limit the maximum video bitrate when the current video is hidden to the user.   stopAtEnd: Stop automatically when the end of a content is reached.   throttleWhenHidden: [Deprecated] Limit the maximum video bitrate when the current video is hidden to the user.  ","anchorH1":"api_reference","anchorH2":"constructor_options"},{"h1":"API reference","h2":"loadVideo options","body":"  transport: The adaptive streaming technology (e.g. “dash”, “smooth” etc.) used.   url: URL to the content (e.g. DASH’s MPD, Smooth’s Manifest etc.)   keySystems: DRM configuration for the content.   keySystems[].type: Name of the DRM technology wanted.   keySystems[].getLicense: Logic to fetch the license.   keySystems[].getLicenseConfig: Supplementary configuration linked to the getLicense function.   keySystems[].serverCertificate: Eventual certificate encrypting exchanges between the CDM and license server.   keySystems[].persistentLicense: Allows to ask for the DRM session to persist the license.   keySystems[].licenseStorage: Allows to ask for the DRM session to persist the license.   keySystems[].fallbackOn: Allows to fallback to another quality when a key is refused.   keySystems[].maxSessionCacheSize: Maximum number of DRM sessions cached by the RxPlayer.   keySystems[].closeSessionsOnStop: Closes DRM sessions when the content stops.   keySystems[].singleLicensePer: Allows to use a single getLicense call for keys linked to multiple qualities.   keySystems[].disableMediaKeysAttachmentLock: Disable a lock that may cause the RxPlayer to deadlock on encrypted contents on some peculiar devices.   keySystems[].distinctiveIdentifierRequired: Allows the configuration of the Distinctive Indentifier(s) property.   keySystems[].persistentStateRequired: Allows the configuration of the persistentState property.   keySystems[].throwOnLicenseExpiration: Allows to stop or not when the current license has expired.   keySystems[].onKeyStatusesChange: Callback triggered when on of the key’s status is updated.     autoPlay: Allows to automatically play after a content is loaded.   startAt: Define the position at which the RxPlayer should start.   transportOptions: Options relative to the current “transport”.   transportOptions.minimumManifestUpdateInterval: Allows to limit the frequency of Manifest updates.   transportOptions.initialManifest: Allows to provide an initial Manifest to speed-up the content loading   transportOptions.manifestUpdateUrl: Provide another URL, potentially to a shorter Manifest, used only for Manifest updates   transportOptions.representationFilter: Filter out qualities from the Manifest based on its characteristics.   transportOptions.segmentLoader: Provide a custom logic to fetch segments.   transportOptions.manifestLoader: Provide a custom logic to fetch the Manifest.   transportOptions.checkMediaSegmentIntegrity: Enable supplementary checks to retry a request if a segment appears corrupted.   transportOptions.serverSyncInfos: Provide time synchronization mechanism between the client and server.   transportOptions.aggressiveMode: Allows to ask to download the segments early.   transportOptions.referenceDateTime: Default offset to add to the segment’s time to obtain a live time. This is in most cases not needed.     textTrackMode: The way in which the text tracks should be displayed.   textTrackElement: HTMLElement in which text tracks should be displayed.   audioTrackSwitchingMode: Behavior when switching the audio track.   manualBitrateSwitchingMode: Behavior when switching manually the video or audio quality.   onCodecSwitch: Behavior when the codec changes between incompatible ones.   lowLatencyMode: Allows to play low-latency contents efficiently.   networkConfig: Configuration linked to the Manifest and segment requests.   networkConfig.segmentRetry: Maximum number of retries when a segment request fails.   networkConfig.manifestRetry: Maximum number of retries when a Manifest request fails.   networkConfig.offlineRetry: Maximum number of retries when a Manifest or segment request fails due to the user being offline.     enableFastSwitching: Enable or disable an optimization replacing segments of poor quality with segments of a better quality.   hideNativeSubtitle: [Deprecated] hide subtitles in <track> elements.   supplementaryImageTracks: [Deprecated] Add supplementary tracks in the content for thumbnails.   supplementaryTextTracks: [Deprecated] Add supplementary tracks in the content for text.   defaultAudioTrack: [Deprecated] Default characteristics wanted for the audio track.   defaultTextTrack: [Deprecated] Default characteristics wanted for the text track.  ","anchorH1":"api_reference","anchorH2":"%60loadvideo%60_options"},{"h1":"API reference","h2":"Methods","body":"  loadVideo: Load a content.   getPlayerState: Get the current player’s state.   addEventListener: Add a listener to one of the RxPlayer’s event.   removeEventListener: Remove a listener to one of the RxPlayer’s event.   play: Resume paused content.   pause: Pause the current content.   stop: Stop playing the current content.   getPosition: Get the current playback condition.   getWallClockTime: Get the current playback condition offseted to be relative to the the current date.   seekTo: Seek in the current content.   getMinimumPosition: Get the minimum seekable position.   getMaximumPosition: Get the maximum seekable position.   getVideoDuration: Get the duration linked to the media element.   getError: Returns the current “fatal” error.   getVideoElement: Returns the media element linked to the RxPlayer.   dispose: Dispose of most resources taken by the RxPlayer.   reload: Reload the last loade content as fast as possible.   getAudioTrack: Get information on the current audio track.   getTextTrack: Get information on the current text track.   getVideoTrack: Get information on the current video track.   getAvailableAudioTracks: Get information on all the available audio tracks.   getAvailableTextTracks: Get information on all the available text tracks.   getAvailableVideoTracks: Get information on all the available video tracks.   setAudioTrack: Set the current audio track.   setTextTrack: Set the current text track.   setVideoTrack: Set the current video track.   disableTextTrack: Disable the current text track.   disableVideoTrack: Disable the current video track.   setPreferredAudioTracks: Update the current audio tracks preferences.   setPreferredTextTracks: Update the current text tracks preferences.   setPreferredVideoTracks: Update the current video tracks preferences.   getPreferredAudioTracks: Return the current audio tracks preferences.   getPreferredTextTracks: Return the current text tracks preferences.   getPreferredVideoTracks: Return the current video tracks preferences.   isTrickModeEnabled: Returns true if trick mode tracks are currently enabled by default.   getVideoBitrate: Returns the bitrate of the current video quality.   getAudioBitrate: Returns the bitrate of the current audio quality.   getAvailableVideoBitrates: Returns all available bitrates for the current video track.   getAvailableAudioBitrates: Returns all available bitrates for the current audio track.   setVideoBitrate: Set the bitrate for the current video track.   setAudioBitrate: Set the bitrate for the current audio track.   getManualVideoBitrate: Returns the last video bitrate manually set.   getManualAudioBitrate: Returns the last audio bitrate manually set.   setMinVideoBitrate: Set the minimum video bitrate reachable through adaptive streaming.   setMinAudioBitrate: Set the minimum audio bitrate reachable through adaptive streaming.   setMaxVideoBitrate: Set the maximum video bitrate reachable through adaptive streaming.   setMaxAudioBitrate: Set the maximum audio bitrate reachable through adaptive streaming.   getMinVideoBitrate: Returns the minimum video bitrate reachable through adaptive streaming.   getMinAudioBitrate: Returns the minimum audio bitrate reachable through adaptive streaming.   getMaxVideoBitrate: Returns the maximum video bitrate reachable through adaptive streaming.   getMaxAudioBitrate: Returns the maximum audio bitrate reachable through adaptive streaming.   setPlaybackRate: Update the speed at which the content is played.   getPlaybackRate: Read the speed at which the content is played.   areTrickModeTracksEnabled: Indicates if the tricmode tracks are active by default.   setVolume: Update the audio volume.   getVolume: Get the current audio volume.   mute: Mute the audio volume.   isMute: Return true if the audio volume is set to 0.   isMute: Return true if the audio volume is set to 0.   unMute: Restore the volume as it was before it was muted.   setWantedBufferAhead: Update the buffering goal, in seconds.   getWantedBufferAhead: Get the current buffering goal, in seconds   setMaxBufferBehind: Remove automatically old media data.   getMaxBufferBehind: Get the current maximum kept buffer behind the current position, in seconds.   setMaxBufferAhead: Remove automatically media data too far ahead.   getMaxBufferAhead: Get the current maximum kept buffer ahead of the current position, in seconds.   setMaxVideoBufferSize: Set the maximum memory the video buffer can take up in the memory, in kilobytes.   getMaxVideoBufferSize: Get the maximum memory the video buffer can take up in the memory, in kilobytes.   getVideoBufferGap: Returns in seconds the difference between the current position and the end of the current media time range.   getVideoLoadedTime: Returns in seconds the difference between the start and the end of the current media time range.   getVideoPlayedTime: Returns in seconds the difference between the start of the current media time range and the current position.   getUrl: Get URL of the currently-played content.   isLive: Returns true if the content is a “live” content.   getCurrentKeySystem: Returns the name of the current key system.   getManifest: [Deprecated] Information on the current Manifest.   getCurrentAdaptations: [Deprecated] Information on the current Adaptations.   getCurrentRepresentations: [Deprecated] Information on the current Representations.   setFullscreen: [Deprecated] Switch media element into fullscreen mode.   isFullscreen: [Deprecated] Returns true if the current media element is in fullscreen mode.   exitFullscreen: [Deprecated] Exit fullscreen mode.   getImageTrackData: [Deprecated] Returns the data of the current image track.   getNativeTextTrack: [Deprecated] Returns the first <track> element attached to the media element.  ","anchorH1":"api_reference","anchorH2":"methods"},{"h1":"API reference","h2":"Static Properties","body":"  version: The current version of the RxPlayer.   LogLevel: Update the verbosity of the RxPlayer logger.   ErrorTypes: All Error types that can be encountered.   ErrorCodes: All Error codes that can be encountered.  ","anchorH1":"api_reference","anchorH2":"static_properties"},{"h1":"API reference","h2":"Events","body":"  playerStateChange: The current state of the player has changed.   error: A fatal error happened.   warning: A non-fatal error happened.   positionUpdate: Regular event about the current position evolving.   seeking: A seek operation began.   seeked: A seek operation ended.   availableAudioTracksChange: The list of available audio tracks changed.   availableVideoTracksChange: The list of available video tracks changed.   availableTextTracksChange: The list of available text tracks changed.   audioTrackChange: The current audio track changed.   videoTrackChange: The current video track changed.   textTrackChange: The current text track changed.   availableAudioBitratesChange: The list of available audio bitrates changed.   availableVideoBitratesChange: The list of available video bitrates changed.   audioBitrateChange: The current audio bitrate changed.   videoBitrateChange: The current video track changed.   bitrateEstimationChange: A new bitrate estimate is available.   periodChange: A new Period begins.   decipherabilityUpdate: A Representation’s decipherability status has been updated.   inbandEvents: Events in the media have been encountered.   streamEvent: A “stream event” just started.   streamEventSkip: A “stream event” was just skipped.   imageTrackUpdate: [Deprecated] The current image track changed.   fullscreenChange: [Deprecated] The player went into or exited fullscreen mode.   nativeTextTracksChange: [Deprecated] A <track> element is added or removed to the media element.  ","anchorH1":"api_reference","anchorH2":"events"},{"h1":"API reference","h2":"Error types","body":"  NETWORK_ERROR: A network-related error.   MEDIA_ERROR: A media-related error.   ENCRYPTED_MEDIA_ERROR: An error related to media decryption.   OTHER_ERROR: Another non-categorized error.  ","anchorH1":"api_reference","anchorH2":"error_types"},{"h1":"API reference","h2":"Tools","body":"  TextTrackRenderer: Render external text tracks on top of the video.   VideoThumbnailLoader: Display seeking preview thumbnails from trick mode video tracks.   StringUtils: Various string conversion utils.   parseBifThumbnails: Parse thumbnails in the “BIF” format.   MediaCapabilitiesProber: Tool to probe several media-related browser APIs.   createMetaplaylist: Generate a MetaPlaylist content.  ","anchorH1":"api_reference","anchorH2":"tools"}]}]