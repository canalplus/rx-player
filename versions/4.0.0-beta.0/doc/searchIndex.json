[{"file":"./Getting_Started/Welcome.html","index":[{"h2":"The RxPlayer","body":"The RxPlayer is a media player library allowing to play DASH, Smooth streaming and other similar streaming contents in any application. The RxPlayer does not come with an UI in itself as the idea is to let you have a full control over your application’s experience. What happens here is that you provide only a <video> or <audio> element to it (and optionally a separate element to display text tracks) an URL to the content (for example, to the DASH’s MPD) and the configuration you want (the languages, control over the quality etc.) and the RxPlayer takes care of every little details to play the content inside that element: import RxPlayer from \"rx-player\";  // take the first video element on the page const videoElement = document.querySelector(\"video\");  const player = new RxPlayer({ videoElement });  player.loadVideo({   url: \"https://www.example.com/Manifest.mpd\",   transport: \"dash\",   autoPlay: true, }); ","anchorH2":"the_rxplayer"},{"h2":"The documentation pages","body":"Those pages are splitted into multiple categories:   You’re here in the “Getting Started” category which provides tutorials and other resources allowing to help you with basic usage of the RxPlayer.   You can also dive into the API, which specifies the behavior of everything that is possible with the RxPlayer.  ","anchorH2":"the_documentation_pages"}]},{"file":"./Getting_Started/Tutorials/Quick_Start.html","index":[{"h1":"Quick Start","body":"Because the RxPlayer exports a lot of functionnalities, you might want to quickly test basic use cases before you dive deep into the whole API documentation. We will here learn how to simply load a video and to react to basic events.","anchorH1":"quick_start"},{"h1":"Quick Start","h2":"Install","body":"The fastest way to use the player directly in your code is to add this repository as a dependency. You can do it via npm or yarn: npm install --save rx-player  or yarn add rx-player ","anchorH1":"quick_start","anchorH2":"install"},{"h1":"Quick Start","h2":"Instanciating a Player","body":"The first step is to instanciate a new RxPlayer. Each RxPlayer instance is attached to a single video (or audio) HTML element, and is able to play a single content at once. To instanciate it with a linked video element you can just do something along the lines of: import RxPlayer from \"rx-player\";  const videoElement = document.querySelector(\"video\"); const player = new RxPlayer({ videoElement });  videoElement is an RxPlayer option and will be the HTMLElement the RxPlayer will load your media on. Despite its name, you can also give it an <audio> element. It will still be able to play an audio content without issue. When you are ready to make use of more advanced features, you can look at the other possible options in the Player Options page.","anchorH1":"quick_start","anchorH2":"instanciating_a_player"},{"h1":"Quick Start","h2":"Loading a content","body":"The next logical step is to load a content (audio, video or both). Loading a new content is done through the loadVideo method. loadVideo takes an object as arguments. There is here also a lot of possible options, but to simplify we will start with just three:   transport: String describing the transport protocol (can be \"dash\", \"smooth\" or \"directfile\" for now).   url: URL to the content (to the Manifest for Smooth contents, to the MPD for DASH contents or to the whole file for DirectFile contents).   autoPlay: Boolean indicating if you want the content to automatically begin to play once loaded. false by default (which means, the player will not begin to play on its own).   Here is a quick example which will load and play a DASH content: player.loadVideo({   url:     \"http://vm2.dashif.org/livesim-dev/segtimeline_1/testpic_6s/Manifest.mpd\",   transport: \"dash\",   autoPlay: true, }); ","anchorH1":"quick_start","anchorH2":"loading_a_content"},{"h1":"Quick Start","h2":"Reacting to basic events","body":"Now that we are loading a content, we might want to know:  if it succeed if it failed when we are able to interact with the content  To do all three of those things, you will need to listen to player events. This is done through the addEventListener method. This method works the same way than the native one you might already use on HTML elements. For example, to know if a fatal error happened (this is an error which interrupted the playback of the current content), you will just have to do: player.addEventListener(\"error\", (err) => {   console.log(\"the content stopped with the following error\", err); });  And to know if the player successfully loaded a content and if you can now interact with it, you can just do: player.addEventListener(\"playerStateChange\", (state) => {   if (state === \"LOADED\") {     console.log(\"the content is loaded\");     // interact with the content...   } });  There is multiple other events, all documented in the events documentation. As the state is a central focus of our API, we also heavily documented states in the player states documentation.","anchorH1":"quick_start","anchorH2":"reacting_to_basic_events"},{"h1":"Quick Start","h2":"Interacting with the player","body":"We’re now ready to interact with the current content. There is a huge list of APIs you can use. Some are useful only when a content is currently loaded (like play, pause, seekTo or setAudioTrack) and others can be used in any case (like setVolume, getVideoElement or loadVideo). Here is a complete example where I:  Instanciate an RxPlayer load a content with it with autoPlay toggle between play and pause once the content is loaded and the user click on the video element.  import RxPlayer from \"rx-player\";  // take the first video element on the page const videoElement = document.querySelector(\"video\");  const player = new RxPlayer({ videoElement });  player.addEventListener(\"error\", (err) => {   console.log(\"the content stopped with the following error\", err); });  player.addEventListener(\"playerStateChange\", (state) => {   if (state === \"LOADED\") {     console.log(\"the content is loaded\");      // toggle between play and pause when the user clicks on the video     videoElement.onclick = function () {       if (player.getPlayerState() === \"PLAYING\") {         player.pause();       } else {         player.play();       }     };   } });  player.loadVideo({   url:     \"http://vm2.dashif.org/livesim-dev/segtimeline_1/testpic_6s/Manifest.mpd\",   transport: \"dash\",   autoPlay: true, }); ","anchorH1":"quick_start","anchorH2":"interacting_with_the_player"},{"h1":"Quick Start","h2":"And now?","body":"Now that you know the basic RxPlayer APIs, you might want to dive deep into the whole API documentation. You can also read our next tutorial, on how to play contents with DRM, here.","anchorH1":"quick_start","anchorH2":"and_now?"}]},{"file":"./Getting_Started/Tutorials/Content_with_DRM.html","index":[{"h1":"Tutorial: Playing contents with DRMs","body":"Because different applications and different devices can work completely differently when it comes to DRM, and because it is a complex feature, we have a large API allowing to manage it. This tutorial page is specifically there to help you navigate through this API. We will begin from the simplest of use cases to dive into the more complex ones. We recommend you to read the quick start tutorial first if you haven’t, to have a general grasp on how to basically run a content.","anchorH1":"tutorial:_playing_contents_with_drms"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Playing a simple encrypted content","body":"To be able to play a simple encrypted content, we will need at least two parameters:  type: the name of the “key system” you want to use. getLicense: the license-fetching logic  This chapter will explain both and provide examples on how to load a video with both of these properties.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"playing_a_simple_encrypted_content"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Playing a simple encrypted content","h3":"The key system","body":"The key system, also known as “DRM name”, will designate which Content Decryption Module (or CDM) to use. You might have heard of “Widevine”, “PlayReady” or “FairPlay”, that’s the name what we want to know: which system you want to use. Which of them you want to use depend on several factors, among which:  what the content allows what the content right holder wants what you/your company wants what the browser can do  In the RxPlayer’s API, we more especially expect the whole “reverse domain name” for that key systems (e.g. com.widevine.alpha or com.microsoft.playready). We also have shortcuts for Widevine or PlayReady, where you can just tell us respectively widevine or playready as the key system and we will try several corresponding reverse domain names. In any case, you can ask for several key systems, even including ones that are not available in the current browser. Those will be detected and automatically filtered out. rxPlayer.loadVideo({   // ...   keySystems: [     {       type: \"com.widevine.alpha\",       // ...     },     {       type: \"com.microsoft.playready\",       // ...     },   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"playing_a_simple_encrypted_content","anchorH3":"the_key_system"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Playing a simple encrypted content","h3":"The license-fetching logic","body":"The second needed argument is a callback allowing to fetch the content license. An encrypted content will need one or several keys to be able to decrypt a content. Those keys are contained in one or several license files. Those files usually need to be downloaded from a license server. As that logic sometimes depends on your application (i.e. you might want to add authentification to that request to know which user made that request), the RxPlayer team made the choice to let you write your logic entirely. This logic takes the form of a callback named getLicense. This function is in fact triggered everytime a message is sent by the Content Decryption Module (what is sometimes known as “Widevine” or “PlayReady”), which is usually a request to fetch or renew the license. It gets two arguments when called:  message (Uint8Array): The “message” messageType (string): String describing the type of message received. There is only 4 possible message types, all defined in the w3c specification.  In most cases, this function is triggered for license requests. You’re encouraged to read what the messageType can be, but don’t be scared by it, you’ll most likely never need to check it. What you will most likely need to do, is simply sending the first argument, message, to the license server to fetch the license. That message generally contains information about the license you want to fetch. You will then need to return a Promise, which resolves with the license in an ArrayBuffer or Uint8Array form. If you don’t want to communicate a license based on this message, you can just return null or a Promise resolving with null. Here is an example of a valid and simple getLicense implementation: function getLicense(challenge) {   return new Promise((resolve, reject) => {     const xhr = new XMLHttpRequest();     xhr.open(\"POST\", LICENSE_SERVER_URL, true);     xhr.onerror = (err) => {       reject(err);     };     xhr.onload = (evt) => {       if (xhr.status >= 200 && xhr.status < 300) {         const license = evt.target.response;         resolve(license);       } else {         const error = new Error(           \"getLicense's request finished with a \" + `${xhr.status} HTTP error`         );         reject(error);       }     };     xhr.responseType = \"arraybuffer\";     xhr.send(challenge);   }); } ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"playing_a_simple_encrypted_content","anchorH3":"the_license-fetching_logic"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Playing a simple encrypted content","h3":"Example with both properties","body":"Now that all that has been explained here’s an example to play a simple encrypted DASH content with either PlayReady or Widevine. // We will use the same logic for both PlayReady and Widevine function getLicense(challenge) {   return new Promise((resolve, reject) => {     const xhr = new XMLHttpRequest();     xhr.open(\"POST\", LICENSE_SERVER_URL, true);     xhr.onerror = (err) => {       reject(err);     };     xhr.onload = (evt) => {       if (xhr.status >= 200 && xhr.status < 300) {         const license = evt.target.response;         resolve(license);       } else {         const error = new Error(           \"getLicense's request finished with a \" + `${xhr.status} HTTP error`         );         reject(error);       }     };     xhr.responseType = \"arraybuffer\";     xhr.send(challenge);   }); }  rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,     },     {       type: \"playready\",       getLicense,     },   ], });  This code is sufficient for a majority of encrypted contents.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"playing_a_simple_encrypted_content","anchorH3":"example_with_both_properties"},{"h1":"Tutorial: Playing contents with DRMs","h2":"More control over the license-fetching logic","body":"There’s a lot of things that can go wrong during the license request:  The user could be temporarly disconnected The license server might be down The license server might refuse to deliver a license based on your rights The license server might refuse to deliver a license based on your CDM capabilities And like any request a lot of other errors can happen  From this, you could want to have a different behavior based on what happened:  When a user is temporarly disconnected, you could chose to retry indefinitely (the RxPlayer retry after a delay to not overload the client or the server). When the license server is down, you might want to fail directly. When the license server refuse to deliver a license based on your rights, you might want to throw an explicit error message that you will be able to display. If there’s a problem with your CDM capabilities, you might want to just fallback to another media quality with a different license.  All of this is possible with more advanced APIs that we will see in this chapter.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"more_control_over_the_license-fetching_logic"},{"h1":"Tutorial: Playing contents with DRMs","h2":"More control over the license-fetching logic","h3":"getLicenseConfig","body":"getLicenseConfig is an object allowing to configure two parameters:   retry, which will set the maximum number of retry. When setting 1, for example, we will try two times the request: A first original time and one retry. You can decide to by default retry indefinitely by setting it to Infinity (yes, that’s a valid number in JS and some other languages). Don’t worry, you will still be able to retry less time on some other events (explained in the getLicense error configuration chapter).   timeout, which is the maximum time in milliseconds the RxPlayer will wait until it considers a getLicense call to have failed. By default it is set to 10000 (10 seconds). You can set it to -1 to disable any timeout.   For example, for infinite retry and no timeout, you can set: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       getLicenseConfig: {         retry: Infinity,         timeout: -1,       },     },     // ...   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"more_control_over_the_license-fetching_logic","anchorH3":"getlicenseconfig"},{"h1":"Tutorial: Playing contents with DRMs","h2":"More control over the license-fetching logic","h3":"getLicense error configuration","body":"getLicenseConfig handle general configurations about every getLicense calls, but you can also have more specific configuration when a specific license request fails. This is done thanks to the rejected Promise returned by getLicense. You can reject an error (or just an object), with the following properties:   noRetry: when set to true, the getLicense call will not be retried.   message: a custom message string we will communicate through a warning or error event (depending if we will retry or not the call)   fallbackOnLastTry: When set to true and if we are doing or last try or retry (to be sure you can set noRetry to true), we will try to fallback to another quality, which might have a different license. This is only useful for contents which have a different license depending on the quality (for example having different rights for 4k video content than for 480p video content). It is also only useful if the license server can refuse to deliver a license for a particular quality but accept for another quality.   Here is an example showcasing all of those properties: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense(challenge) {         return new Promise((resolve, reject) => {           const xhr = new XMLHttpRequest();           xhr.open(\"POST\", LICENSE_SERVER_URL, true);           xhr.onerror = (err) => {             // Keep retrying on XHR errors.             // Instanciating an Error like that automatically set the             // message attribute to this Error's message. That way, the             // linked \"error\" or \"warning\" event sent by the RxPlayer             // will have the same message.             const error = new Error(\"Request error: \" + err.toString());             reject(err);           };           xhr.onload = (evt) => {             if (xhr.status >= 200 && xhr.status < 300) {               const license = evt.target.response;               resolve(license);             } else if (xhr.status >= 500 && xhr.status < 600) {               // Directly fails + fallbacks on a server error               const error = new Error(                 \"The license server had a problem and\" +                   ` responded with ${xhr.status} HTTP ` +                   \"error. We will now fallback to another\" +                   \"quality.\"               );               error.noRetry = true;               error.fallbackOnLastTry = true;               reject(error);             } else {               // else continue to retry               const error = new Error(                 \"getLicense's request finished with a \" +                   `${xhr.status} HTTP error`               );               reject(error);             }           };           xhr.responseType = \"arraybuffer\";           xhr.send(challenge);         });       },       getLicenseConfig: {         retry: Infinity,         timeout: -1,       },     },     // ...   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"more_control_over_the_license-fetching_logic","anchorH3":"getlicense_error_configuration"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","body":"","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"Why and how","body":"One of the issues arising with DRM is that not all devices, Operating systems or web browsers can provide a high level of guarantee that a content will be protected against unauthorized usages (such as illegal copy). In other words, some devices, OS or browsers might provide more guarantees than other. That’s the main reason why there’s sometime a compromise to have between accessibility of a content (the number of the people able to view it) and this guarantee. To be able to provide the best of both worlds, a content right holder might ask for a higher protection guarantee for higher video qualities. For example, it might ask that a 4k video content of a given film should be much harder to “pirate” than the 240p version of the same film. In return, the 240p version can be watched by a lot more people on a lot of different devices. To achieve that, one of the solution on the content-side is to have different decryption keys depending on the quality chosen. There’s then two main strategies:   Every keys are in the same license. A player will thus do only one license request for the whole content and the keys inside will be individually refused or accepted.   There is one or several keys per licenses, in several licenses. That way, a player might ask a different license when switching the current quality.   There’s pros and cons to both, but let’s not go too far into that! Let’s start from the principle that our content is under one of those two cases here and let’s find out what we have to do to handle it.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"why_and_how"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"The strategy adopted by the RxPlayer","body":"When playing a content, the RxPlayer by default stops and throws an error as soon as either a key is refused or as the license fetching logic (the getLicense function) fails (after enough retries). When playing a content with multiple keys, you might instead not care that much if a key is refused or if the license-fetching logic fails. What you can just do is to remove the quality for which we could not obtain a key and to instead fallback on another, decipherable, quality. That’s exactly what the RxPlayer does, when the right options are set:   it automatically removes from the current media buffer the data linked to the un-decipherable quality and put it in a black list: we will not load this quality for the current content anymore.   it switches to another, hopefully decipherable, quality.   Let’s now talk about the API.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"the_strategy_adopted_by_the_rxplayer"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"fallbackOnLastTry","body":"This option was already explained in a previous chapter. Basically, it is a boolean you can set to true when rejecting an error from the getLicense callback. When set and if it was the last getLicense try or retry, the RxPlayer will stop to play every quality sharing the same “protection initialization data”. What that last part really means is a little complex, but it generally means that every qualities sharing the same license file will be considered as un-decipherable. For more information and an example on how to use it, you can go back on the concerned previous part of this tutorial. Please note that this option does not concern every errors linked to a refused key. It only concerns issues when the license server refuse to deliver a license. On most cases you will also need the API documented in the next part.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"fallbackonlasttry"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Contents with multiple keys","h3":"onKeyInternalError, onKeyOutputRestricted and onKeyExpiration","body":"Where fallbackOnLastTry really is about the failure of a license request, those options is about the refused keys themselves. As an example, the Content Decryption Module in the browser might decide that your current device cannot provide a high enough guarantee that the content cannot be copied. It might thus refuse to use one of the decryption key found in a license, especially the one needed for the higher content qualities. Those options then allows to fallback when this happens.   onKeyInternalError: Behavior to set when the corresponding key has the status \"internal-error\". We found that most widevine implementation use this error when a key is refused. You can set it to \"fallback\" so the RxPlayer switch to other, decipherable, Representations when this status is received.   onKeyOutputRestricted: Behavior to set when the corresponding key has the status \"output-restricted\". This is the proper status for a key refused due to output restrictions. You can set it to \"fallback\" so the RxPlayer switch to other, decipherable, Representations when this status is received.   onKeyOutputRestricted: Behavior to set when the corresponding key has the status \"expired\". You can set it to \"fallback\" so the RxPlayer switch to other, decipherable, Representations when this status is received.   For people on embedded devices with specific key systems, you can look a little more into what MediaKeyStatus is set when a key is refused. Here is an example which would be adapted to most cases: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       onKeyOutputRestricted: \"fallback\",       onKeyInternalError: \"fallback\",     },   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"contents_with_multiple_keys","anchorH3":"%60onkeyinternalerror%60,_%60onkeyoutputrestricted%60_and_%60onkeyexpiration%60"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Server certificate","body":"The “server Certificate” is a certificate allowing to encrypt messages coming from the Content Decryption module to the license server. They can be required by some key system as a supplementary security mechanism. Thankfully, an application is not obligated to set one, even if one is needed. If not set, the Content Decryption Module will download it itself by using the same route than a license request (the getLicense callback will be called). This means however, that we have to perform two round-trips to the license server instead of one:  one to fetch the “server certificate”. the other to fetch the license.  To avoid the first round-trip, it is possible for an application to directly indicate what the serverCertificate is when calling loadVideo. This is done through the serverCertificate property, in keySystems: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       serverCertificate,     },   ], });  The serverCertificate has to either be in an ArrayBuffer form or a TypedArray (i.e. Uint8Array, Uint16Array etc.)","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"server_certificate"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Persistent licenses","body":"A persistent license allows to store a license for it to be available even when a user quits the current page or restarts its computer. It can be used even if the user is offline. After loading a persistent license, it is automatically stored on the browser’s side, but the RxPlayer still has to store an ID to be able to retrieve the right session when reloading the same content later. Because of that, you’ll have to provide a storage mechanism and set it as a persistentLicenseConfig property of loadVideo’s keySystems option: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       persistentLicenseConfig,     },   ], }); ","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"persistent_licenses"},{"h1":"Tutorial: Playing contents with DRMs","h2":"Persistent licenses","h3":"persistentLicenseConfig property","body":"The persistentLicenseConfig property is an object allowing the RxPlayer to load and saved stored session identifiers, to be able to retrieve them later. It needs to contain two functions:  save: Which sould store the argument given. The argument will be an array of Objects. load: Called without any argument, it has to return what was given to the last save call. Any return value which is not an Array will be ignored (example: when save has never been called).  If the ability to retrieve persistent-licenses from older RxPlayer version is not important to you, you can also add a disableRetroCompatibility property set to true, this will unlock supplementary optimizations on contents. This API can very simply be implemented with the localStorage browser API: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       persistentLicenseConfig: {         save(data) {           localStorage.setItem(\"RxPlayer-persistent-storage\", JSON.stringify(data));         },         load() {           const item = localStorage.getItem(\"RxPlayer-persistent-storage\");           return item === null ? [] : JSON.parse(item);         },       },     },   ], });  Do not be scared about security implications, the data saved is not secret and does not help to identify a user. You can also use every storage API at your disposition (some embedded devices might have their own). As a nice bonus, you can note that the data given is perfectly “serializable” through the JSON.stringify browser API. This means that, as the example shown above, you can call JSON.stringify on that data and retrieve it through a JSON.parse call. This is very useful for storage APIs which cannot store JavaScript objects.","anchorH1":"tutorial:_playing_contents_with_drms","anchorH2":"persistent_licenses","anchorH3":"persistentlicenseconfig_property"}]},{"file":"./Getting_Started/Tutorials/Selecting_a_Track.html","index":[{"h1":"Tutorial: Selecting a track","body":"","anchorH1":"tutorial:_selecting_a_track"},{"h1":"Tutorial: Selecting a track","h2":"The goal of this tutorial","body":"The RxPlayer has an advanced API when it comes to track selection: You can list, change, enable or disable video audio and text tracks for either what is currently being played or any other Period in the current content. Because the RxPlayer’s track API tries to be complete and flexible, it can feel intimidating at first. This tutorial will help you understand what your options are, why you would use an API instead of another and how to use them.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"the_goal_of_this_tutorial"},{"h1":"Tutorial: Selecting a track","h2":"What is a “track”?","body":"We should first agree on what is a track, as a concept. Let’s take for example an italian film presented to an english-speaking audience. For that film, let’s imagine those multiple “audio tracks”:  one being the original audio track, in italian one being a dub in the english language another in english with accessibility features such as an audio description of what visually happens in the film (for example, to give cues of what is happening to the visually-impaired).  There also could be multiple “text tracks”:  subtitles in english closed-captions in english (for example, for the hearing impaired)  And we could even imagine multiple video tracks:  one displaying the “regular” film another displaying either the same film from a different camera angle (seems far-fetched here but let’s just pretend we’re talking about some kind of experimental film!)  All those will provide to the user a different way to offer the same film. In most cases, audiom video and text tracks are currently independent and can such be switched in a large number of combination to give a large number of different experience for what is effectively the same content.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"what_is_a_%22track%22?"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","body":"","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","h3":"Nominal case: currently played content","body":"Using methods Once the RxPlayer has loaded a content (meaning the RxPlayer is not in the STOPPED, LOADING or RELOADING player state) you can begin to ask it what is the current list of available tracks. This can be done through three RxPlayer methods:  getAvailableAudioTracks() to list audio tracks getAvailableVideoTracks() to list video tracks getAvailableTextTracks() to list text tracks  Those methods will all return arrays of objects, each object containing information about a single track. It should be noted that the information for an audio track won’t be the same than for a video or a text track. For example, you might be interested by the height and width available in a video track. Those notions make absolutely no sense for an audio track. For more information about the structure of the data returned by those methods, you can refer to their API documentation (a shortcut is available by clicking on the method name). Note that you can still ask for the current tracks when the RxPlayer does not have loaded any content (is in the STOPPED, LOADING or RELOADING player state), but you will most likely only get an empty array in those cases. Examples Those methods are straightforward, here are some examples of how they can be used: // Array of all available audio languages const availableLanguages = rxPlayer   .getAvailableAudioTracks()   .map((track) => track.language);  // List of audio tracks containing an audio description of what is visually // happening const audioDescriptionTracks = rxPlayer   .getAvailableAudioTracks()   .filter((track) => track.audioDescription);  // List of video tracks for which a profile with a 1080p resolution is available const highResVideoTracks = rxPlayer   .getAvailableVideoTracks()   .filter((track) => {     return track.representations.some(       (representation) =>         representation.height !== undefined && representation.height >= 1080     );   });  // List of text tracks available in french const frenchTextTracks = rxPlayer   .getAvailableTextTracks()   .filter((track) => track.normalized === \"fra\");  Using events If you want to be alerted when the list of currently available tracks is set or change, it might be a good idea to rely on events. Here are the three events you will need to know:   \"availableAudioTracksChange\": the list of available audio tracks for what is currently being played was just updated.   \"availableVideoTracksChange\": idem for video tracks   \"availableTextTracksChange\": idem for text tracks   All of those events will have the corresponding available tracks as a payload, which will be the exact same data that what you would get when calling the corresponding getAvailable...Tracks method at this point. Note that no available...TracksChange event will be sent when the RxPlayer stops the content or temporarly goes through the RELOADING player state with an empty array as a payload - as there is no current content in those cases. Examples Like any RxPlayer event, you will need to add an event listener for those: let currentAudioTracks = []; let currentVideoTracks = []; let currentTextTracks = [];  rxPlayer.addEventListener(\"availableAudioTracksChange\", (audioTracks) => {   console.log(\"New audio tracks:\", audioTracks);   currentAudioTracks = audioTracks; });  rxPlayer.addEventListener(\"availableVideoTracksChange\", (videoTracks) => {   console.log(\"New video tracks:\", videoTracks);   currentVideoTracks = videoTracks; });  rxPlayer.addEventListener(\"availableTextTracksChange\", (textTracks) => {   console.log(\"New text tracks:\", textTracks);   currentTextTracks = textTracks; }); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks","anchorH3":"nominal_case:_currently_played_content"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","h3":"Advanced case: Any part of multi-Period contents","body":"For contents with multiple Periods and/or when in the LOADING or RELOADING state, you may want to list the tracks for a part of the content that the RxPlayer is not yet playing. This can be for example for a future/previous live program, or even for the current one when the RxPlayer did not yet begin to play it. In those conditions, the three methods presented here (getAvailableVideoTracks, getAvailableTextTracks and getAvailableAudioTracks) can all take an argument: the id property of the wanted period: // Getting the audio track list for the Period with the \"foo\" id. rxPlayer.getAvailableAudioTracks(\"foo\");  That id can be known in several ways:   the getAvailablePeriods method can list the different Periods and their respective id property: const periods = rxPlayer.getAvailablePeriods(); for (const period of periods) {   console.log(`Tracks for Period ${period.id}:`,               rxPlayer.getAvailableAudioTracks(period.id)); }    the newAvailablePeriods event triggered each time new Periods are known (either when the content is first loaded, or when the it is updated) with their respective id property: rxPlayer.addEventListener(\"newAvailablePeriods, (periods) => {   for (const period of periods) {     console.log(`Tracks for Period ${period.id}:`,                 rxPlayer.getAvailableAudioTracks(period.id));   } });    the periodChange event triggered when the current Period being played changes, with the corresponding id property: rxPlayer.addEventListener(\"periodChange, (period) => {   console.log(`Tracks for the current Period ${period.id}:`,               rxPlayer.getAvailableAudioTracks(period.id)); });   ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks","anchorH3":"advanced_case:_any_part_of_multi-period_contents"},{"h1":"Tutorial: Selecting a track","h2":"Listing the available tracks","h3":"Obtaining those lists as soon as possible","body":"The RxPlayer does not “guess” the tracks available for a given content, it usually finds every information about them in the Manifest file which is loaded at the beginning. Thus, the list of available tracks will only be available once the RxPlayer has loaded and parsed that Manifest. Moreover, a Manifest can have several lists of available tracks depending on the player’s position (for example, a live channel with multiple programs might have different audio languages available for different programs). This means both that the available tracks won’t generally be known just after a loadVideo call and that it can then change at any time. The first instant when the list of available audio, video and text tracks is available after loading the content through loadVideo is on the newAvailablePeriods event: rxPlayer.loadVideo({ url: \"foo/bar\", transport: \"dash\" /* ... */ }); rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   for (const period of periods) {     const periodId = period.id;     const videoTracks = rxPlayer.getAvailableVideoTracks(periodId);     const audioTracks = rxPlayer.getAvailableVideoTracks(periodId);     const textTracks = rxPlayer.getAvailableTextTracks(periodId);     console.log(`Video tracks for Period \"${periodId}\":`${videoTracks}`);     console.log(`Audio tracks for Period \"${periodId}\":`${audioTracks}`);     console.log(`Text tracks for Period \"${periodId}\":`${textTracks}`);   } });  This newAvailablePeriods event is also the right one for setting the initial track (we will see how to below), as it’s guaranteed that at the point this event is sent, no media data has been loaded yet for the corresponding Period(s): rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   for (const period of periods) {     // Theoretical logic for initial track selections (presumably through the     // `getAvailable...Tracks` and `set...Track` families of API)     setInitialVideoTrack(period);     setInitialAudioTrack(period);     setInitialTextTrack(period);   } }); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"listing_the_available_tracks","anchorH3":"obtaining_those_lists_as_soon_as_possible"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","body":"","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Nominal case: currently played content","body":"Using methods You might also want to know which track is the one currently selected. There are several ways to do that.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"nominal_case:_currently_played_content_(1)"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Through methods","body":"The RxPlayer has a set of methods that just return the currently active tracks:   getAudioTrack: return information on the current audio track   getVideoTrack: return information on the current video track   getTextTrack: return information on the current text track   Those methods will return an object describing the attributes of the current tracks. They can also return null if no track has been enabled (for example, the user could have wanted to disable all text tracks) and undefined if the track is either unknown (which is a very rare occurence) or if no content is currently playing. Like the getAvailable...Tracks methods, the format of the objects returned will entirely depend on which method you call. You can refer to the API documentation to get more information on this. Also like the getAvailable...Tracks methods, the current text track will usually only be known once the RxPlayer has loaded a content (which means we are not in the STOPPED, LOADING or RELOADING player state). If no content is loaded, those APIs will just return undefined. Examples Here is an example on how you could use them: const currentTextTrack = rxPlayer.getTextTrack(); if (currentTextTrack === null) {   console.log(\"No text track is enabled\"); } else if (currentTextTrack === undefined) {   console.log(     \"We don't know the current text track. \" +       \"Are you sure a content is loaded?\"   ); } else {   const language = currentTextTrack.language;   console.log(\"We have a current text track in the \" + language + \"language\"); } ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"through_methods"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Through events","body":"Exactly like you would obtain the list of available tracks through the available...TracksChange events, you can know when the current track change as soon as possible through the following events:   \"audioTrackChange\": the currently-active audio track changed   \"videoTrackChange\": the currently-active video track changed   \"textTrackChange\": the currently-active text track changed   Those events just emit the current track information as soon as it changes, in the same format that the get...Track methods. Unlike for the get...Track methods however, its payload cannot be set to undefined: you won’t receive any ...TracksChange event if the track is unknown or if there is no content. This also means that you won’t have any event when the RxPlayer stops or re-load the current content, despite the fact that you don’t have any current track in that case. Calling the get...Track method in those cases will return undefined, as it should. This has to be considered. Example Like for any events, you will have to register an event listener: rxPlayer.addEventListener(\"textTrackChange\", (track) => {   if (track === null) {     console.log(\"No text track is active\");   } else {     console.log(       \"new active text track in the following language: \" + track.language     );   } }); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"through_events"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Through the list of available tracks","body":"As written earlier the available...TracksChange events and the getAvailable...Tracks methods both return arrays of objects, each object defining a single track. In each of those object, you will find an active boolean property, which will be set to true if the track is the currently chosen one and false otherwise. Note that it’s possible that none of the available tracks are active. This is for example the case when the track has been disabled (for example when the user wants no text tracks at all). // get the active audio track through `getAvailableAudioTracks` const activeAudioTrack1 = rxPlayer   .getAvailableAudioTracks()   .find((track) => track.active);  // get the active audio track through `availableAudioTracksChange` let activeAudioTrack2; rxPlayer.addEventListener(\"availableAudioTracksChange\", (tracks) => {   activeAudioTrack2 = tracks.find((track) => track.active); }); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"through_the_list_of_available_tracks"},{"h1":"Tutorial: Selecting a track","h2":"Knowing the current track","h3":"Which one to use?","body":"As usual here, this is highly dependant on your application. All of those APIs give the same information through different means. Accessing with the get...Track method is simple to use, the events allow to know at the earliest possible time and relying on the list of available tracks can simplify your code if you want both of them.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"knowing_the_current_track","anchorH3":"which_one_to_use?"},{"h1":"Tutorial: Selecting a track","h2":"Selecting a track","body":"Now that we have the list of available tracks and the current one, we might want to choose another one, or let the final user choose another one. To do that, you will have to use one of those three RxPlayer methods:  setAudioTrack(): change the current audio track setVideoTrack(): change the current video track setTextTrack(): change the current text track  Each of those methods take a single string as argument. That string should be the value of the id property of the chosen track. For example, to choose the first audio track with an audio description, you can do: const firstAudioTrackWithAD = rxPlayer   .getAvailableAudioTracks()   .find((track) => track.audioDescription);  if (firstAudioTrackWithAD !== undefined) {   rxPlayer.setAudioTrack(firstAudioTrackWithAD.id); }  It’s important to consider that those APIs only allow to change the current track and will have no impact on the other contents you will encounter in the future. After manually setting a track through the set...Track methods, you will receive the corresponding ...TrackChange event when the change is applied. Note that on some contents, changing a track from a given type might automatically also change the current track for another types. For example, switching to another audio language might also automatically turn on the subtitles. This is because some streaming protocols might “force” some combination. To detect those cases, you can either listen to every ...TrackChange events or call the corresponding get...Track method everytime you want to use them.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"selecting_a_track"},{"h1":"Tutorial: Selecting a track","h2":"Disabling a track","body":"Now what if you want no track at all? This is for example a frequent need for text tracks, where you might prefer to have no subtitles or closed captions appearing on the screen. You could also want to disable the video track, which is a trick often used to reduce the network bandwidth used by a content. You can disable respectively the current text track and the current video track by calling those methods:  disableTextTrack disableVideoTrack  However, like for selecting a track, this only concerns the current content being played. When playing a new content or even when just switching to another part of the content with a different track list, you might need to re-do the same method call.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"disabling_a_track"},{"h1":"Tutorial: Selecting a track","h2":"Tracks now missing from the Manifest","body":"There is a very unlikely event that could theoretically arise on some contents: the select track disappearing after a Manifest update. For example, after refreshing the Manifest files, it turns out that the previously-selected audio track has been completely removed from the Manifest, for the same Period. Here, the RxPlayer will by itself select another track instead and immediately emit a \"trackUpdate\" event a reason property set to \"missing\": rxPlayer.addEventListener(\"trackUpdate\", (data) => {   if (data.reason === \"missing\") {     console.warn(       `The previously-chosen ${data.trackType} track for the Period ` +       `\"${data.period.id}\" disappeared. A new track has been selected instead.`     );   } }); ","anchorH1":"tutorial:_selecting_a_track","anchorH2":"tracks_now_missing_from_the_manifest"},{"h1":"Tutorial: Selecting a track","h2":"Notes about the “textTrackMode” option","body":"This tutorial was focused on track selection but there’s still a last point I want to approach, which is how subtitles will be displayed to the user. By default, text tracks will be displayed through <tracks> elements which will be contained in the media element where the content plays. This allows to display subtitles but may not be sufficient when wanting to display richer subtitles (such as closed-captions). This is why the RxPlayer has a textTrackMode concept. By setting the textTrackMode to \"html\" in a loadVideo call, you will be able to profit from much richer subtitles than what you could have by default. If you do that, you also need to set the textTrackElement property to an HTML element, that the RxPlayer will use to display subtitles into. More information on those options can be found in the RxPlayer API.","anchorH1":"tutorial:_selecting_a_track","anchorH2":"notes_about_the_%22texttrackmode%22_option"}]},{"file":"./Getting_Started/Tutorials/EventStream_Handling.html","index":[{"h1":"Tutorial: Listening to stream events","body":"Some contents contain events a player will need to send at a particular point in time. We call those in the RxPlayer “stream events”. For example, stream events are often used jointly with ad-insertion, to allow a player to notify when an user begin to see a particular ad. Stream events are not only restrained to ad-related usages though. Any event you want to synchronize with the played content can be inserted.","anchorH1":"tutorial:_listening_to_stream_events"},{"h1":"Tutorial: Listening to stream events","h2":"Event Formats understood by the RxPlayer","body":"","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"event_formats_understood_by_the_rxplayer"},{"h1":"Tutorial: Listening to stream events","h2":"Event Formats understood by the RxPlayer","h3":"DASH EventStream elements","body":"For now, the RxPlayer only make use of DASH’ EventStream elements. Such elements are defined in a DASH MPD in the concerned Period. Here is an example of such element in an MPD: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <MPD   xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"   xmlns=\"urn:mpeg:dash:schema:mpd:2011\"   xsi:schemaLocation=\"urn:mpeg:dash:schema:mpd:2011 DASH-MPD.xsd\"   type=\"dynamic\"   minimumUpdatePeriod=\"PT2S\"   timeShiftBufferDepth=\"PT30M\"   availabilityStartTime=\"2011-12-25T12:30:00\"   minBufferTime=\"PT4S\"   profiles=\"urn:mpeg:dash:profile:isoff-live:2011\">      <Period id=\"1\">       <EventStream schemeIdUri=\"urn:uuid:XYZY\" timescale=\"1000\" value=\"call\">         <Event presentationTime=\"0\" duration=\"10000\" id=\"0\">           1 800 10101010         </Event>         <Event presentationTime=\"20000\" duration=\"10000\" id=\"1\">           1 800 10101011         </Event>         <Event presentationTime=\"40000\" duration=\"10000\" id=\"2\">           1 800 10101012         </Event>         <Event presentationTime=\"60000\" duration=\"10000\" id=\"3\">           1 800 10101013         </Event>       </EventStream>       <!-- ... -->     </Period>  </MPD>  Here the <EventStream /> elements and its <Event /> children elements will be parsed by the RxPlayer. Each <Event /> element can then be sent through a single RxPlayer events.","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"event_formats_understood_by_the_rxplayer","anchorH3":"dash_eventstream_elements"},{"h1":"Tutorial: Listening to stream events","h2":"How to listen to stream events","body":"The RxPlayer notify of such events through the usual RxPlayer events. As a reminder (or if you didn’t know), the RxPlayer can send a multitude of events that can be listened to by the usage of the addEventListener method. The events related to stream events are:   \"streamEvent\": an event has just been reached.   \"streamEventSkip\": an event has been skipped over. This usually means that a player seek operation resulted in the corresponds event being “missed”.   In any case, the corresponding event will be attached as a payload. Example: // listen to \"streamEvent\" events rxPlayer.addEventListener(\"streamEvent\", (evt) => {   console.log(\"An event has been reached:\", evt); });  // listen to \"streamEventSkip\" events rxPlayer.addEventListener(\"streamEventSkip\", (evt) => {   console.log(\"We just 'skipped' an event:\", evt); }); ","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"how_to_listen_to_stream_events"},{"h1":"Tutorial: Listening to stream events","h2":"The event format","body":"Whether you’re listening to the \"streamEvent\" or the \"streamEventSkip\" event, you will receive an object containing the corresponding event information. Here is an example of such events: {   start: 10, // start time of the event, in seconds.              //              // It is always defined, as a number.              //              // A start at `10` here means that the event began when the player              // reached the position at 10 seconds.    end: 25, // Optional end time of the event, in seconds.            //            // It can be undefined or unset for events without any duration.            // A end at `25` here indicates that this event only last from the            // position at 10 seconds (the `start`) to the position at 25            // seconds, or an event with a duration of 15 seconds.            //            // If `end` is defined, you can be notified when the end of this            // event is reached by adding an `onExit` callback to that event            // (continue reading this tutorial for more information).    data: { // The event's data itself.      type: EVENT_TYPE, // String describing the source of the event.      value: EVENT_VALUE, // This property's format and content depends on the                         // `type` property. For example, when the type property                         // is set to \"dash-event-stream\", this value will be the                         // <Event /> element corresponding to that DASH event.   } }  As written in this example, the underlying format of the event itself will depend on the source of the event. For example, an event generated from a DASH’s <EventStream /> won’t be in the same format that an event generated from a MP4’s emsg box. You can know which current format is used by checking the value of the data.type property. For now, we only have one format: DASH EventStream elements, which will have a data.type property equal to \"dash-event-stream\".","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"the_event_format"},{"h1":"Tutorial: Listening to stream events","h2":"The event format","h3":"DASH EventStream elements","body":"A DASH EventStream’s event will be parsed under the following format: {   start: 10, // As usual, the event start time in seconds    end: 15, // optional end position of the event, in seconds.            // Can be not set or set to `undefined` for events without a duration    data: {      type: \"dash-event-stream\", // Type corresponding to a DASH's EventStream's                                // Event element      value: {       schemeIdUri: SCHEME_ID_URI,       element: EVENT_ELEMENT,       timescale: EVENT_TIMESCALE,     }   } }  Where:   SCHEME_ID_URI will be the value of the corresponding EventStream’s schemeIdUri attribute   EVENT_ELEMENT will be the corresponding <Event /> element in the MPD.   EVENT_TIMESCALE will be the value of the corresponding EventStream’s timescale attribute. This indicates a way to convert some time information on an EVENT_ELEMENT into seconds (by dividing the value by timescale), though it can usually safely be ignored.   For example for the following EventStream: <EventStream schemeIdUri=\"urn:uuid:XYZY\" timescale=\"1000\" value=\"call\">   <Event presentationTime=\"0\" duration=\"10000\" id=\"0\">1 800 10101010</Event>   <Event presentationTime=\"40000\" duration=\"10000\" id=\"1\">1 800 10101012</Event>   <Event presentationTime=\"60000\" duration=\"10000\" id=\"2\">1 800 10101013</Event> </EventStream>  The RxPlayer will define those three events (note: I used custom syntax here to include a readable document format): // The first event: {   start: 0,   end: 10,   data: {     type: \"dash-event-stream\",     value: {       schemeIdUri: \"urn::uuid::XYZY\",       element: <Event presentationTime=\"0\" duration=\"10000\" id=\"0\">                  1 800 10101010                </Event>,       timescale: 1000,     }   } }  // The second event: {   start: 40,   end: 50,   data: {     type: \"dash-event-stream\",     value: {       schemeIdUri: \"urn::uuid::XYZY\",       element: <Event presentationTime=\"40000\" duration=\"10000\" id=\"1\">                  1 800 10101012                </Event>,       timescale: 1000,     }   } }  // The third event: {   start: 60,   end: 70,   data: {     type: \"dash-event-stream\",     value: {       schemeIdUri: \"urn::uuid::XYZY\",       element: <Event presentationTime=\"60000\" duration=\"10000\" id=\"2\">                  1 800 10101013                </Event>,       timescale: 1000,     }   } } ","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"the_event_format","anchorH3":"dash_eventstream_elements_(1)"},{"h1":"Tutorial: Listening to stream events","h2":"Listening when an event has ended","body":"Some stream events have a end property, you could thus need to know when an event that the RxPlayer reached is now ended. Thankfully, we planned this need in the API of the RxPlayer. Any event with a set end can be added an onExit callback. This callback will be called once the event has ended. So for example you can write: rxPlayer.addEventListener(\"streamEvent\", (evt) => {   console.log(\"An event has been reached:\", evt);   if (evt.end !== undefined) {     evt.onExit = () => {       console.log(\"An event has been exited:\", evt);     };   } });  When defined, that onExit callback will be called once the RxPlayer either reaches the end position of the event or seek outside of the scope of this event. Please note however that even if an event has an end property, it is possible that the onExit callback will never be called. For example, the user could stop the content while an event was “active” (we do not trigger onExit callbacks in that case) or the corresponding <Event /> could “disappear” from the MPD once it has been refreshed.","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"listening_when_an_event_has_ended"},{"h1":"Tutorial: Listening to stream events","h2":"Example","body":"To end this tutorial, lets define a complete example: rxPlayer.addEventListener(\"streamEvent\", (evt) => {   console.log(\"An event has been reached:\", evt);    console.log(\"This is an event of type:\", evt.data.type);   if (evt.data.type === \"dash-event-stream\") {     console.log(\"This is a DASH EventStream's Event element.\");      console.log(\"schemeIdUri:\", evt.data.schemeIdUri);     console.log(\"<Event /> element:\", evt.data.element);   }    if (evt.end !== undefined) {     evt.onExit = () => {       console.log(\"An event has been exited:\", evt);     };   } });  rxPlayer.addEventListener(\"streamEventSkip\", (evt) => {   console.log(\"We just 'skipped' an event:\", evt);    console.log(\"This was an event of type:\", evt.data.type);   // ... }); ","anchorH1":"tutorial:_listening_to_stream_events","anchorH2":"example"}]},{"file":"./Getting_Started/Migration_From_v3/Overview.html","index":[{"h1":"Migration guide: from v3.x.x to v4.0.0","body":"","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Overview","body":"The v4.0.0 release is a major RxPlayer release. It deeply changes some aspects of the RxPlayer API, particularly relative to tracks and quality selection. Though we succeeded to maintain API compatibility for more than 5 years despite huge changes in the OTT media streaming domain, we considered that an API overhaul was now necessary to better handle the features of the current streaming landscape (normalization of multi-Period contents, multiplication of potential video, audio and text characteristics, low-latency streaming, Content Steering, MSE-in-worker etc.) as well as to improve the RxPlayer maintainance by removing old deprecated but burdensome API. Still, we understand that porting to a new major version of the RxPlayer might not be a small task, and thus decided to continue maintaining the v3.x.x for some time, while pre-releasing the beta version of the v4.0.0 with this complete migration guide.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"overview"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Organization of this documentation","body":"The goal of this documentation is not to advertise about new RxPlayer features, it is only to list all breaking changes and indicate how to replace the corresponding options, methods and events. If you want to know what was brought into a v4.x.x release instead, you can obtain more information by looking at release notes, the changelog, the API documentation and tutorials.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"organization_of_this_documentation"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Important changes","body":"","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"important_changes"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Important changes","h3":"New player state: \"FREEZING\"","body":"The \"FREEZING\" state A new player state, \"FREEZING\", has been added. This state is switched to when playback is not advancing despite not being paused and despite the player having some buffered media data to play. Generally a brief and transitory state, there may even be valid and un-worrying reasons behind this state: for example it may be caused by some minor performance issue after heavy operations like seeking, or triggered when the player is waiting for the license to be loaded. Though a \"FREEZING\" state may also be linked to a real content or device issue. The RxPlayer will use tricks to try to come out of a \"FREEZING\" state if it locks playback for too long,  but if it happens often and/or for long periods of time, it might be a sign that there some other issues to look for either on the content, on the environment (device, browser, hardware etc.) or both. Previously such \"FREEZING\" state was either reported as a \"BUFFERING\" state or not reported at all (i.e. we would for example be in a \"PLAYING\" state) depending on the case. As such this new state does not correspond to any new behavior, it just gives more precision about something that was previously not specifically described. How to handle it Player states in general are still communicated through the playerStateChange event and getPlayerState methods, which you may now want to update to handle the new \"FREEZING\" case. For most cases, showing a waiting indicator on top of the video like a spinner, like you probably already do for the \"BUFFERING\" case, should be sufficient. rxPlayer.addEventListener(\"playerStateChange\", (state) => {   switch (state) {     case \"BUFFERING\":     case \"FREEZING\":       displaySpinner();       break;     // ...   } });  Some applications might however prefer to report differently such \"FREEZING\" cases, for example to detect playback issues on some devices.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"important_changes","anchorH3":"new_player_state:_%60%22freezing%22%60"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Important changes","h3":"RxPlayer behavior when reaching the content’s end","body":"The RxPlayer previously automatically stopped the content when its end was reached unless the (now removed) stopAtEnd constructor option was set to false. As a saner default, the RxPlayer now won’t stop the content when reaching its end anymore, if you want to reproduce this behavior, you can simply stop the content when the \"ENDED\" player state is reached: rxPlayer.addEventListener(\"playerStateChange\", (state) => {   if (state === \"ENDED\") {     rxPlayer.stop();   } }); ","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"important_changes","anchorH3":"rxplayer_behavior_when_reaching_the_content's_end"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Important changes","h3":"The \"RELOADING\" state now has to be handled","body":"Brought in the v3.6.0 (2018), the \"RELOADING\" player state was switched to when the RxPlayer needed to reset buffers in specific situations. Because just adding a player state is a breaking change, we were careful to only allow it when specific options were set. The RxPlayer may now switch to the \"RELOADING\" state in any situation where it could fix playback issues, allowing us to more effectively work-around specific bugs. This means that you now have to make sure that state is considered. You can see more information on the \"RELOADING\" state in the player state page. Thankfully, it is now possible to perform more operations under that state, such as switching tracks and qualities.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"important_changes","anchorH3":"the_%60%22reloading%22%60_state_now_has_to_be_handled"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Important changes","h3":"Removal of track preferences API","body":"All methods related to track preferences:  setPreferredAudioTracks setPreferredTextTracks setPreferedVideoTracks getPreferredAudioTracks getPreferredTextTracks getPreferredVideoTracks  As well as the following constructor options:  preferredAudioTracks preferredTextTracks preferredVideoTracks  Have been removed because their behaviors and more can be replaced by the new track API. For more information on how to replace them, you can go to the preferences pages of the migration guide.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"important_changes","anchorH3":"removal_of_track_preferences_api"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Important changes","h3":"Removal of bitrate control API","body":"All methods related to controlling the current audio and video bitrate:  setMinVideoBitrate setMinAudioBitrate getMinVideoBitrate getMinAudioBitrate setMaxVideoBitrate setMaxAudioBitrate getMaxVideoBitrate getMaxAudioBitrate setVideoBitrate setAudioBitrate getManualVideoBitrate getManualAudioBitrate  As well as the following constructor options:  minVideoBitrate minAudioBitrate maxVideoBitrate maxAudioBitrate  Have been removed. To replace them, we created the much more powerful “Representations locking” family of methods and options. Documentation on how to do the switch from the old API to the new is documented in the Bitrate Selection page of the migration guide","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"important_changes","anchorH3":"removal_of_bitrate_control_api"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Other modifications","body":"","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"other_modifications"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Other modifications","h3":"Constructor options","body":"Constructor options are options given when instantiating a new RxPlayer. Several of these options have been removed, they are all listed in the Constructor Options page.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"other_modifications","anchorH3":"constructor_options"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Other modifications","h3":"loadVideo options","body":"Several options of the central loadVideo method have been updated and removed. They are all listed in the loadVideo Options page.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"other_modifications","anchorH3":"%60loadvideo%60_options"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Other modifications","h3":"Player events","body":"All updated and removed events are listed in the Player Events page.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"other_modifications","anchorH3":"player_events"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Other modifications","h3":"Player Errors","body":"All updated and removed player errors and warnings are listed in the Player Error page.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"other_modifications","anchorH3":"player_errors"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Other modifications","h3":"Methods","body":"Several RxPlayer methods were removed, replaced or had their arguments changed. This is all documented in the Player Methods page.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"other_modifications","anchorH3":"methods"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Other modifications","h3":"Types","body":"Several RxPlayer types have been removed and updated. This is all documented in the Player Types page.","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"other_modifications","anchorH3":"types"},{"h1":"Migration guide: from v3.x.x to v4.0.0","h2":"Other modifications","h3":"Miscellaneous","body":"Other minor changes on which you might have relied are present in the v4.x.x:   From now, you should not expect Internet Explorer 11 to keep being supported as we won’t be testing this browser nor officially providing support for it anymore. You may however be able contribute if its support is important to you, as long as those modifications have a low influence on the code’s health.   It is not possible anymore to use environment variables (like RXP_DASH) to bundle a personalized build yourself. If you want to have a personalized build, you now have to rely on the mininal RxPlayer.   “Forced” text tracks are now not switched according to audio track preferences because the preference API has been removed. Instead, the forced text track linked to the default audio track is by default chosen and an application can change it at any time.  ","anchorH1":"migration_guide:_from_v3.x.x_to_v4.0.0","anchorH2":"other_modifications","anchorH3":"miscellaneous"}]},{"file":"./Getting_Started/Migration_From_v3/Preferences.html","index":[{"h1":"Removal of track preferences API","body":"","anchorH1":"removal_of_track_preferences_api"},{"h1":"Removal of track preferences API","h2":"Methods and options removed","body":"All track preferences API have been removed in profit of a now more flexible track switching API which should allow to perform the same logic and more. This means that the following methods are all removed:  setPreferredAudioTracks setPreferredTextTracks setPreferredVideoTracks getPreferredAudioTracks getPreferredTextTracks getPreferredVideoTracks  As well as the following constructor options:  preferredAudioTracks preferredTextTracks preferredVideoTracks ","anchorH1":"removal_of_track_preferences_api","anchorH2":"methods_and_options_removed"},{"h1":"Removal of track preferences API","h2":"Why was those removed?","body":"Those methods and options have been removed because the new track switching API now allows an application to handle the full preference functionalities with even more customizability. Keeping both the preferences API and the new enhanced track switching API could have brought confusion in how they would interact, we have thus taken the choice of removing the preferences API altogether.","anchorH1":"removal_of_track_preferences_api","anchorH2":"why_was_those_removed?"},{"h1":"Removal of track preferences API","h2":"How to replace them","body":"","anchorH1":"removal_of_track_preferences_api","anchorH2":"how_to_replace_them"},{"h1":"Removal of track preferences API","h2":"How to replace them","h3":"The notion of a “Period”","body":"The preferences API basically allowed to automatically set a default track each time a new track choice was available. Thus, the RxPlayer relied on them each time a new content was played, and more generally each time a new Period was encountered. This “Period” notion allows for example to handle several track choices on DASH contents with multiple <Period> elements, each with its own list of tracks. For example you could consider a multi-period live channel with a weather report in a single audio language followed by a multi-lingual film, here we would have two periods, each with its own selected track. To know the list of periods currently considered by the RxPlayer, you can now call the getAvailablePeriods RxPlayer method: const periods = rxPlayer.getAvailablePeriods();  To be notified when new Periods are being considered by the RxPlayer, you can react to the new newAvailablePeriods RxPlayer event: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   // Do things with those periods }); ","anchorH1":"removal_of_track_preferences_api","anchorH2":"how_to_replace_them","anchorH3":"the_notion_of_a_%22period%22"},{"h1":"Removal of track preferences API","h2":"How to replace them","h3":"Enhanced track methods","body":"Moreover, to let an application change the track of any of those Period elements linked to the current content, whether that Period already have been played, are playing or will be played, the following track setting methods can now receive the concerned period’s id property as argument.   getAudioTrack: For example, to get the audio track currently set for some period Period, object returned by either getAvailablePeriods or the newAvailablePeriods event, you can do: const audioTrackForPeriod = rxPlayer.getAudioTrack(period.id);    getTextTrack: const textTrackForPeriod = rxPlayer.getTextTrack(period.id);    getVideoTrack: const videoTrackForPeriod = rxPlayer.getVideoTrack(period.id);    getAvailableAudioTracks: For example, to get the list of available audio tracks for a Period period: const allAudioTracksForPeriod = rxPlayer.getAvailableAudioTracks(period.id);    getAvailableTextTracks: const allTextTracksForPeriod = rxPlayer.getAvailableTextTracks(period.id);    getAvailableVideoTracks: const allVideoTracksForPeriod = rxPlayer.getAvailableVideoTracks(period.id);    setAudioTrack: For example, to set the audio track of some period element returned by either getAvailablePeriods or the newAvailablePeriods event, you can do: rxPlayer.setAudioTrack({   trackId: wantedAudioTrack.id,   periodId: period.id, });    setTextTrack: rxPlayer.setTextTrack({   trackId: wantedTextTrack.id,   periodId: period.id, });    setVideoTrack: rxPlayer.setVideoTrack({   trackId: wantedVideoTrack.id,   periodId: period.id, });   ","anchorH1":"removal_of_track_preferences_api","anchorH2":"how_to_replace_them","anchorH3":"enhanced_track_methods"},{"h1":"Removal of track preferences API","h2":"How to replace them","h3":"Simple example","body":"Thus, you can replicate most of the preferences API by simply manually listing the current tracks on new Periods as they start being considered by the RxPlayer, setting the more adapted one each time. This can be done by reacting to the newAvailablePeriods event, like this: // Example: selecting the english audio track by default for all future contents  rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   for (const period of periods) {     applyAudioTrackPreferences(period);   } });  /**  * Choose regular (not audio description) english audio track if one, else  * the default one.  * @param {Object} period - Period Object as returned by the RxPlayer  */ function applyAudioTrackPreferences(period) {   // Getting the tracks available in that Period, through its id   const audioTracks = rxPlayer.getAvailableAudioTracks(period.id);   for (const audioTrack of audioTracks) {     if (       audioTrack.normalized === \"eng\" &&       audioTrack.audioDescription !== true     ) {       // Setting the audio track for that Period       rxPlayer.setAudioTrack({         trackId: audioTrack.id,         periodId: period.id,       });       return;     }   } }  This logic will only apply for future encountered periods, even though you may also want to apply the preference retroactively to the currently loaded Periods. If that is the case, you can also get the list of currently-considered Periods through the getAvailablePeriods method and also select a track for those:   const currentPeriods = rxPlayer.getAvailablePeriods();   for (const period of currentPeriods) {     applyAudioTrackPreferences(period);   }  If you want to be thorough, you may also want to re-apply preferences in the extremely rare case where the chosen track would simply disappear for the corresponding Period (for example after a Manifest refresh). This almost never happens, but the RxPlayer now send a trackUpdate event in that case with a reason property set to \"missing\". Here is how you could handle this: rxPlayer.addEventListener(\"trackUpdate\", (evt) => {   if (evt.reason === \"missing\" && evt.trackType === \"audio\") {     // The last chosen audio track just disappeared from the content.     // Re-apply preferences     applyAudioTrackPreferences(evt.period);   } }); ","anchorH1":"removal_of_track_preferences_api","anchorH2":"how_to_replace_them","anchorH3":"simple_example"},{"h1":"Removal of track preferences API","h2":"Full example for audio preferences replacement","body":"As you’ve seen, applications now have all the elements to implement the same audio track preferences API than before, though now all that preference logic has to be written on the application-side. Because we understand that just translating the preferences API to the newer more explicit one might take some time, we’ve written in this chapter code allowing to rely on the same preferences array as before while profiting from the more powerful API. Here’s how a complete applyAudioTrackPreferences function, applying the audio preferences array from the v3.x.x on a specific Period, would be implemented: /**  * For the given Period (or the current one if `period` is not indicated),  * apply the currently-preferred audio track according to the given  * preferences.  *  * @param {Object|undefined} period - The Period object for the wanted Period.  * If undefined, the current Period will be considered instead.  * @param {Array.<Object>} preferencesArray - The audio preferences, in the  * format of the RxPlayer v3 API  */ function applyAudioTrackPreferences(period, preferencesArray) {   const availableAudioTracks = rxPlayer.getAvailableAudioTracks(     period?.id,   );   const optimalTrack = findFirstOptimalAudioTrack(     availableAudioTracks,     preferencesArray   );   if (optimalTrack === null) {     console.warn(       \"It's not possible for now to disable the audio track. \" +       \"Keeping the default one instead.\"       );   } else {     rxPlayer.setAudioTrack({       trackId: optimalTrack.id,       periodId: period?.id,     });   } }  /**  * Find the optimal audio track given their list and the array of preferred  * audio tracks sorted from the most preferred to the least preferred.  *  * `null` if the most optimal audio track is no audio track.  * @param {Array.<Object>} audioTracks - Available audio tracks  * @param {Array.<Object>} preferredAudioTrack - The audio preferences, in the  * format of the RxPlayer v3 API  * @returns {Object|null}  */ function findFirstOptimalAudioTrack(   audioTracks,   preferredAudioTracks ) {   if (audioTracks.length === 0) {     return null;   }    for (let i = 0; i < preferredAudioTracks.length; i += 1) {     const preferredAudioTrack = preferredAudioTracks[i];     if (preferredAudioTrack === null) {       return null;     }      const matchPreferredAudio =       createAudioPreferenceMatcher(preferredAudioTrack);     const foundTrack = audioTracks.find(matchPreferredAudio);      if (foundTrack !== undefined) {       return foundTrack;     }   }    // no optimal track, just return the first one   return audioTracks[0]; }  /**  * Create a function allowing to compare an audio track with a given  * `preferredAudioTrack` preference to see if they match.  *  * This function is curried to be easily and optimally used in a loop context.  *  * @param {Object} preferredAudioTrack - The audio track preference you want to  * compare audio tracks to.  * @returns {Function} - Function taking in argument an audio track and  * returning `true` if it matches the `preferredAudioTrack` preference (and  * `false` otherwise.  */ function createAudioPreferenceMatcher(preferredAudioTrack) {   /**    * Compares an audio track to the given `preferredAudioTrack` preference.    * Returns `true` if it matches, false otherwise.    * @param {Object} audioTrack    * @returns {boolean}    */   return function matchAudioPreference(audioTrack) {     if (preferredAudioTrack.language !== undefined) {       const language = audioTrack.language ?? '';       if (language !== preferredAudioTrack.language) {         return false;       }     }     if (preferredAudioTrack.audioDescription !== undefined) {       if (preferredAudioTrack.audioDescription) {         if (audioTrack.audioDescription !== true) {           return false;         }       } else if (audioTrack.audioDescription === true) {         return false;       }     }     if (preferredAudioTrack.codec === undefined) {       return true;     }     const regxp = preferredAudioTrack.codec.test;     const codecTestingFn = (rep) =>       rep.codec !== undefined && regxp.test(rep.codec);      if (preferredAudioTrack.codec.all) {       return audioTrack.representations.every(codecTestingFn);     }     return audioTrack.representations.some(codecTestingFn);   }; }  Like seen in the How to replace then chapter, you can trigger that logic for all futures track choices by listening to newAvailablePeriods and to trackUpdate events: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   // Apply preferences each time a new Period is available   for (const period of periods) {     applyAudioTrackPreferences(period);   } });  rxPlayer.addEventListener(\"trackUpdate\", (evt) => {   if (evt.reason === \"missing\" && evt.trackType === \"audio\") {     // The last chosen audio track just disappeared from the content.     // Re-apply preferences     applyAudioTrackPreferences(evt.period);   } });  And if you also want to apply it to the Periods currently considered by the RxPlayer:   const currentPeriods = rxPlayer.getAvailablePeriods();   for (const period of currentPeriods) {     applyAudioTrackPreferences(period);   } ","anchorH1":"removal_of_track_preferences_api","anchorH2":"full_example_for_audio_preferences_replacement"},{"h1":"Removal of track preferences API","h2":"Full example for text preferences replacement","body":"Likewise, here’s how a complete applyTextTrackPreferences function, applying the text preferences array from the v3.x.x on a specific Period, would be implemented: /**  * For the given Period (or the current one if `period` is not indicated),  * apply the currently-preferred text track according to the given  * preferences.  *  * @param {Object|undefined} period - The Period object for the wanted Period.  * If undefined, the current Period will be considered instead.  * @param {Array.<Object>} preferencesArray - The audio preferences, in the  * format of the RxPlayer v3 API  */ function applyTextTrackPreferences(period, preferencesArray) {   const availableTextTracks = rxPlayer.getAvailableTextTracks(     period?.id,   );   const optimalTrack = findFirstOptimalTextTrack(     availableTextTracks,     preferencesArray   );   if (optimalTrack === null) {     rxPlayer.disableTextTrack(period?.id);   } else {     rxPlayer.setTextTrack({       trackId: optimalTrack.id,       periodId: period?.id,     });   } }  /**  * Find an optimal text adaptation given their list and the array of preferred  * text tracks sorted from the most preferred to the least preferred.  *  * `null` if the most optimal text adaptation is no text adaptation.  * @param {Array.<Object>} textTracks  * @param {Array.<Object|null>} preferredTextTracks  * @returns {Object|null}  */ function findFirstOptimalTextTrack(   textTracks,   preferredTextTracks ) {   if (textTracks.length === 0) {     return null;   }    for (let i = 0; i < preferredTextTracks.length; i += 1) {     const preferredTextTrack = preferredTextTracks[i];      if (preferredTextTrack === null) {       return null;     }      const matchPreferredText = createTextPreferenceMatcher(preferredTextTrack);     const foundTrack = textTracks.find(matchPreferredText);      if (foundTrack !== undefined) {       return foundTrack;     }   }    // no optimal adaptation   return null; }  /**  * Create a function allowing to compare text tracks with a given  * `preferredTextTrack` preference to see if they match.  *  * This function is curried to be easily and optimally used in a loop context.  *  * @param {Object} preferredTextTrack - The text track preference you want to  * compare text tracks to.  * @returns {Function} - Function taking in argument a text track and  * returning `true` if it matches the `preferredTextTrack` preference (and  * `false` otherwise.  */ function createTextPreferenceMatcher(preferredTextTrack) {   /**    * Compares a text track to the given `preferredTextTrack` preference.    * Returns `true` if it matches, false otherwise.    * @param {Object} textTrack    * @returns {boolean}    */   return function matchTextPreference(textTrack) {     return (       textTrack.language === preferredTextTrack.language &&       (preferredTextTrack.closedCaption         ? textTrack.closedCaption === true         : textTrack.closedCaption !== true) &&       (preferredTextTrack.forced         ? textTrack.forced === true         : textTrack.forced !== true)     );   }; }  Like seen in the How to replace then chapter, you can trigger that logic for all futures track choices by listening to newAvailablePeriods and to trackUpdate events: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   // Apply preferences each time a new Period is available   for (const period of periods) {     applyTextTrackPreferences(period);   } });  rxPlayer.addEventListener(\"trackUpdate\", (evt) => {   if (evt.reason === \"missing\" && evt.trackType === \"audio\") {     // The last chosen audio track just disappeared from the content.     // Re-apply preferences     applyTextTrackPreferences(evt.period);   } });  And if you also want to apply it to the Periods currently considered by the RxPlayer:   const currentPeriods = rxPlayer.getAvailablePeriods();   for (const period of currentPeriods) {     applyTextTrackPreferences(period);   } ","anchorH1":"removal_of_track_preferences_api","anchorH2":"full_example_for_text_preferences_replacement"},{"h1":"Removal of track preferences API","h2":"Full example for video preferences replacement","body":"As for video tracks, an applyVideoTrackPreferences function, applying the video preferences array from the v3.x.x on a specific Period, could be implemented this way: /**  * For the given Period (or the current one if `period` is not indicated),  * apply the currently-preferred video track according to the given  * preferences.  *  * @param {Object|undefined} period - The Period object for the wanted Period.  * If undefined, the current Period will be considered instead.  * @param {Array.<Object>} preferencesArray - The video preferences, in the  * format of the RxPlayer v3 API  */ function applyVideoTrackPreferences(period, preferencesArray) {   const availableVideoTracks = rxPlayer.getAvailableVideoTracks(     period?.id,   );   const optimalTrack = findFirstOptimalVideoTrack(     availableVideoTracks,     preferencesArray   );   if (optimalTrack === null) {     rxPlayer.disableVideoTrack(period?.id);   } else {     rxPlayer.setVideoTrack({       trackId: optimalTrack.id,       periodId: period?.id,     });   } }  /**  * Find the optimal video track given their list and the array of preferred  * video tracks sorted from the most preferred to the least preferred.  *  * `null` if the most optimal video track is no video track.  * @param {Array.<Object>} videoTracks - Available video tracks  * @param {Array.<Object>} preferredVideoTrack - The video preferences, in the  * format of the RxPlayer v3 API  * @returns {Object|null}  */ function findFirstOptimalVideoTrack(   videoTracks,   preferredVideoTracks ) {   if (videoTracks.length === 0) {     return null;   }    for (let i = 0; i < preferredVideoTracks.length; i += 1) {     const preferredVideoTrack = preferredVideoTracks[i];     if (preferredVideoTrack === null) {       return null;     }      const matchPreferredVideo =       createVideoPreferenceMatcher(preferredVideoTrack);     const foundTrack = videoTracks.find(matchPreferredVideo);      if (foundTrack !== undefined) {       return foundTrack;     }   }    // no optimal track, just return the first one   return videoTracks[0]; }  /**  * Create a function allowing to compare an video track with a given  * `preferredVideoTrack` preference to see if they match.  *  * This function is curried to be easily and optimally used in a loop context.  *  * @param {Object} preferredVideoTrack - The video track preference you want to  * compare video tracks to.  * @returns {Function} - Function taking in argument an video track and  * returning `true` if it matches the `preferredVideoTrack` preference (and  * `false` otherwise.  */ function createVideoPreferenceMatcher(preferredVideoTrack) {   /**    * Compares a video track to the given `preferredVideoTrack` preference.    * Returns `true` if it matches, false otherwise.    * @param {Object} videoTrack    * @returns {boolean}    */   return function matchVideoPreference(videoTrack) {     if (preferredVideoTrack.signInterpreted !== undefined &&         preferredVideoTrack.signInterpreted !== videoTrack.isSignInterpreted)     {       return false;     }     if (preferredVideoTrack.codec === undefined) {       return true;     }     const regxp = preferredVideoTrack.codec.test;     const codecTestingFn = (rep) =>       rep.codec !== undefined && regxp.test(rep.codec);      if (preferredVideoTrack.codec.all) {       return videoTrack.representations.every(codecTestingFn);     }     return videoTrack.representations.some(codecTestingFn);   }; }  Like seen in the How to replace then chapter, you can trigger that logic for all futures track choices by listening to newAvailablePeriods and to trackUpdate events: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   // Apply preferences each time a new Period is available   for (const period of periods) {     applyVideoTrackPreferences(period);   } });  rxPlayer.addEventListener(\"trackUpdate\", (evt) => {   if (evt.reason === \"missing\" && evt.trackType === \"video\") {     // The last chosen video track just disappeared from the content.     // Re-apply preferences     applyVideoTrackPreferences(evt.period);   } });  And if you also want to apply it to the Periods currently considered by the RxPlayer:   const currentPeriods = rxPlayer.getAvailablePeriods();   for (const period of currentPeriods) {     applyVideoTrackPreferences(period);   } ","anchorH1":"removal_of_track_preferences_api","anchorH2":"full_example_for_video_preferences_replacement"}]},{"file":"./Getting_Started/Migration_From_v3/Bitrate_Selection.html","index":[{"h1":"Bitrate Selection","body":"","anchorH1":"bitrate_selection"},{"h1":"Bitrate Selection","h2":"Methods and options removed","body":"The v4.0.0 release totally changes how Representations (a.k.a. qualities or profiles) selection works. Previously, this selection was only based on bitrate settings. It is now more explicit by directly allowing an application to select which Representation(s) it wants to be able to play. Due to this, v3.x.x methods related to controlling the current audio and video bitrate:  setMinVideoBitrate setMinAudioBitrate getMinVideoBitrate getMinAudioBitrate setMaxVideoBitrate setMaxAudioBitrate getMaxVideoBitrate getMaxAudioBitrate setVideoBitrate setAudioBitrate getManualVideoBitrate getManualAudioBitrate  As well as the following constructor options:  minVideoBitrate minAudioBitrate maxVideoBitrate maxAudioBitrate  Have all been removed.","anchorH1":"bitrate_selection","anchorH2":"methods_and_options_removed"},{"h1":"Bitrate Selection","h2":"Why was those removed?","body":"When drafting a better API for Representation selection than what we had before, we finally reached a point where we were constructing an API that would allow to replicate all those methods and options. Even better, they could now be based on any criteria (e.g. on the video quality’s height, framerate, codecs, decipherability status etc.), and not just its bitrate. This, and the fact that the specific audio or video quality’s bitrate might not always be known depending on the streaming technology, led us to remove the previous bitrate-specific API to the more general and powerful “Representations locking” API that will be shown in this page.","anchorH1":"bitrate_selection","anchorH2":"why_was_those_removed?"},{"h1":"Bitrate Selection","h2":"How to replace them","body":"","anchorH1":"bitrate_selection","anchorH2":"how_to_replace_them"},{"h1":"Bitrate Selection","h2":"How to replace them","h3":"Semantic of the previous API","body":"What the bitrate methods and options were doing was basically to restrain the pool of Representation the RxPlayer would chose from based on each of those object’s bitrate property. Basically, calling setMaxVideoBitrate(1000) / maxVideoBitrate: 1000 would filter out all video Representation whose bitrate was higher than 1000 (with an exception if no Representation passed that test, in which case it would take the Representation(s) with the lowest bitrate instead). Likewise setMinVideoBitrate(1000) / minVideoBitrate: 1000 would the other way around filter out all video Representation was lower than 1000 (with again the same exception than the maxVideoBitrate one, only the highest bitrate now). At last setVideoBitrate(1000) would select the Representation with a bitrate set exactly to 1000, immediately lower if not found, or the closest if no Representation has a bitrate lower or equal to 1000.","anchorH1":"bitrate_selection","anchorH2":"how_to_replace_them","anchorH3":"semantic_of_the_previous_api"},{"h1":"Bitrate Selection","h2":"How to replace them","h3":"Now: Locking Representations explicitly","body":"Now, there’s a new set of methods and options allowing to explicitly filter Representation based on any criteria you want and for any choosen track:   the lockVideoRepresentations and lockAudioRepresentations methods, only authorize respectively some video and some audio Representation from being played by the RxPlayer. For example to only allows some video Representations called “repA” and “repB”, for the current Period (that is: the content being played right now), you could write: rxPlayer.lockVideoRepresentations([repA.id, repB.id]);    setAudioTrack and setVideoTrack now also allows to only authorize some audio and video Representation from being played in the chosen track by setting a lockedRepresentations property. For example to only allow the Representations “rep1” and “rep2” in a new audio track “aTrack”, you could write: rxPlayer.setAudioTrack({   trackId: aTrack.id,   lockedRepresentations: [rep1.id, rep2.id], });    the getLockedVideoRepresentations and getLockedAudioRepresentations), methods allows to get the list of respectively the currently locked video and audio Representations, or null if none are locked for that type: const lockedVideoRepresentations = rxPlayer.getLockedVideoRepresentations(); if (lockedVideoRepresentations === null) {   console.log(\"There's no video Representation locked for the current content\"); } else {   console.log(     \"`id` property of the video Representations locked for the current content:\",     lockedVideoRepresentations   ); }    the unlockVideoRepresentations and unlockAudioRepresentations methods, allows to unlock previously respectively “locked” video and audio Representations. // Re-enable all video Representations (which previously have been // restrained for example by a `lockVideoRepresentations` call: rxPlayer.unlockVideoRepresentations();   ","anchorH1":"bitrate_selection","anchorH2":"how_to_replace_them","anchorH3":"now:_locking_representations_explicitly"},{"h1":"Bitrate Selection","h2":"How to replace them","h3":"Obtaining the Representation objects","body":"As for the Representation objects themselves, they can for example be obtained by using:   getVideoTrack for a currently-chosen video track, through its representations property, whose content is an array of elements each describing a Representation linked to that video track. const currentVideoTrack = rxPlayer.getVideoTrack(); console.log(   \"This video track has \" +   currentVideoTrack.representations.length +   \" different video Representation(s)\" ); for (let i = 0; i < currentVideoTrack.representations.length; i++) {   console.log(     \"The Representation number \" + i + \" has a bitrate set to: \" +     currentVideoTrack.representations[i].bitrate   ); }    getAudioTrack for a currently-chosen audio track, again through its representations property. const currentAudioTrack = rxPlayer.getAudioTrack(); console.log(   \"This audio track has \" +   currentAudioTrack.representations.length +   \" different audio Representation(s)\" );    getAvailableVideoTracks for all available video tracks linked to a Period, here the representations property is still present on each “track object” returned by that method. const trackList = rxPlayer.getAvailableVideoTracks(); console.log(`There are currently ${trackList.length} video track(s) available`); for (let i = 0; i < trackList.representations.length; i++) {   console.log(\"Data for video track number \" + i + \":\");   const videoTrack = trackList[i];   for (let j = 0; j < videoTrack.representations.length; j++) {     console.log(       \"Its Representation number \" + j + \" has an height set to: \" +       videoTrack.representations[j].height     );   } }    getAvailableAudioTracks for all available audio tracks linked to a Period, also through a representations property. const trackList = rxPlayer.getAvailableAudioTracks(); console.log(`There are currently ${trackList.length} audio track(s) available`);    The videoTrackChange, audioTrackChange, availableVideoTracksChange and availableAudioTracksChange player events which respectively emit data similar to the getVideoTrack, getAudioTrack, getAvailableVideoTracks and getAvailableAudioTracks methods.  ","anchorH1":"bitrate_selection","anchorH2":"how_to_replace_them","anchorH3":"obtaining_the_%60representation%60_objects"},{"h1":"Bitrate Selection","h2":"How to replace them","h3":"Global idea to replace the previous API","body":"Thus the idea would be now to, for each set video track, to explicitly select the Representation(s) you want, based on the criteria you want. For example, to only play the video Representation(s) which have a bitrate set to 500 for the current content, you could write: const currentVideoTrack = rxPlayer.getVideoTrack(); const representations500 = currentVideoTrack.representations.filter(r => {   return r.bitrate === 500; }); if (representations500.length > 0) {   // Note: It's only the `id` property that is wanted here   const representationsId = representations500.map(r => r.id);   rxPlayer.lockVideoRepresentations(representationsId); } ","anchorH1":"bitrate_selection","anchorH2":"how_to_replace_them","anchorH3":"global_idea_to_replace_the_previous_api"},{"h1":"Bitrate Selection","h2":"How to replace them","h3":"Reacting to the lock “breaking”","body":"In rare and very specific situations, locked Representation may all become unplayable during playback. This can for example happen when all the locked Representations appear to be undecipherable once their licence have been fetched. Instead of stopping on error when this happens, the RxPlayer choose to “break the lock”, which means it goes back to play all Representation from the chosen track. Just before doing that, it emits the \"brokenRepresentationsLock\" event, allowing you to react to this. In the context of replacing bitrate API, you may want to profit from this event to re-apply the bitrate limitation you had - or to stop the content if you want to. For example, only play the lowest video bitrate after the lock is broken, you can write: player.addEventListener(\"brokenRepresentationsLock\", (data) => {   const videoTrack = rxPlayer.getVideoTrack(data.period.id);   const lowestBitrate = videoTrack.representations.reduce((acc, r) => {     if (acc === undefined || acc.bitrate === undefined) {       return r;     }     if (r.bitrate !== undefined && r.bitrate < acc.bitrate) {       return r;     }     return acc;   }, undefined);   if (lowestBitrate !== undefined) {     rxPlayer.lockVideoRepresentations({       representations: [lowestBitrate.id],       periodId: data.period.id,     });   } } ","anchorH1":"bitrate_selection","anchorH2":"how_to_replace_them","anchorH3":"reacting_to_the_lock_%22breaking%22"},{"h1":"Bitrate Selection","h2":"How to replace them","h3":"Switching at new “Periods”","body":"The “Period” notion allows for example to handle several Representation choices on DASH contents with multiple <Period> elements, each with its own list of tracks and thus, Representation linked to it. For example you could consider an old film only available with video Representations up to 720p followed by a football match with video Representations ranging up to UHD. Here we would have two periods, each with its own tracks and Representations. To know the list of periods currently considered by the RxPlayer, you can now call the getAvailablePeriods RxPlayer method: const periods = rxPlayer.getAvailablePeriods();  To be notified when new Periods are being considered by the RxPlayer, you can react to the new newAvailablePeriods RxPlayer event: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   // Do things with those periods });  Most methods exposed in this page, whether they are for Representations locking or the tracks API, allow to precize which Period you’re talking about (if it’s not communicated, the RxPlayer will assume that you’re talking about the currently-playing one). For example, to only lock the first video Representation of the first considered Period you can do: const periods = rxPlayer.getAvailablePeriods(); if (periods.length > 0) {   const firstPeriodVideoTrack = rxPlayer.getVideoTrack(periods[0].id);   if (firstPeriodVideoTrack.representations.length > 0) {     rxPlayer.lockVideoRepresentations({       representations: [firstPeriodVideoTrack.representations[0].id],       periodId: periods[0].id,     });   } } ","anchorH1":"bitrate_selection","anchorH2":"how_to_replace_them","anchorH3":"switching_at_new_%22periods%22"},{"h1":"Bitrate Selection","h2":"How to replace them","h3":"Locking each time a track is chosen","body":"The choice of Representation has to be performed basically at each new chosen track, whether it is for a new Period or an already-known one whose track has been changed. The former (new periods) can be reacted to via the \"newAvailablePeriods\" events we wrote about in previous chapters. The latter (track change, for any Period) now also has its own event \"trackUpdate\". For example to only play the video Representations whose bitrate is inferior or equal to 1000000, you can write: player.addEventListener(\"trackUpdate\", (data) => {   const videoTrack = rxPlayer.getVideoTrack(data.period.id);   const filtered = videoTrack.representations.filter((r) => {     return r.bitrate !== undefined && r.bitrate <= 1000000;   });   if (filtered.length > 0) {     rxPlayer.lockVideoRepresentations({       representations: filtered,       periodId: data.period.id,     });   } else {     // To be defined on your side what you want to do here   } } ","anchorH1":"bitrate_selection","anchorH2":"how_to_replace_them","anchorH3":"locking_each_time_a_track_is_chosen"},{"h1":"Bitrate Selection","h2":"Full examples of bitrate selection replacements","body":"","anchorH1":"bitrate_selection","anchorH2":"full_examples_of_bitrate_selection_replacements"},{"h1":"Bitrate Selection","h2":"Full examples of bitrate selection replacements","h3":"setMaxVideoBitrate / maxVideoBitrate / setMaxAudioBitrate / maxAudioBitrate","body":"The following examples only talk about the video variants of these API to simplify, but it can be applied to the audio variant. To replace the setMaxVideoBitrate method or the maxVideoBitrate option, we will first declare a function replicating its behavior for a given bitrate and Period: function lockMaxBitrateForPeriod(maxBitrate, period) {   if (maxBitrate === Infinity) {     // /!\\ If you also have other bitrate restrictions, you may not want to     // unlock here     rxPlayer.unlockVideoRepresentations(period.id);   } else {     const videoTrack = rxPlayer.getVideoTrack(period.id);     const representationIds = videoTrack.representations.reduce(       (acc, representation) => {         if (           representation.bitrate !== undefined &&           representation.bitrate <= maxBitrate         ) {           acc.push(representation.id);         }         return acc;       },       [],     );      if (representationIds.length > 0) {       rxPlayer.lockVideoRepresentations({         periodId: period.id,         representations: representationIds,       });     } else {       // Special case for when no Representation respects the maximum bitrate:       // Lock Representation(s) with the lowest bitrate       const lowestBitrate = videoTrack.representations         .map((representation) => representation.bitrate)         .filter((representation) => representation !== undefined)         .sort((a, b) => a - b)[0];       if (lowestBitrate === undefined) {         rxPlayer.unlockVideoRepresentations(period.id);       } else {         rxPlayer.lockVideoRepresentations({           periodId: period.id,           representations: videoTrack.representations.filter(             (representation) => representation.bitrate <= lowestBitrate,           ),         });       }     }   } }  Then we want to apply it each times a new Period is available and each time the track for any Period is changed: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   for (let i = 0; i < periods.length; i += 1) {     lockMaxBitrateForPeriod(       maxBitrate, // To set to the bitrate wanted       periods[i],     );   } });  rxPlayer.addEventListener(\"trackUpdate\", (data) => {   lockMaxBitrateForPeriod(     maxBitrate, // To set to the bitrate wanted     data.period,   ); });  Because we might want to still re-apply the same logic when/if the lock is broken, we can also add: rxPlayer.addEventListener(\"brokenRepresentationsLock\", (data) => {   lockMaxBitrateForPeriod(     maxBitrate, // To set to the bitrate wanted     data.period,   ); });  And finally, if you want to apply the maximum bitrate while the content is already playing, you can write: const periods = rxPlayer.getAvailablePeriods(); for (let i = 0; i < periods.length; i += 1) {   const period = periods[i];   lockMaxBitrateForPeriod(     maxBitrate, // To set to the bitrate wanted     period,   ); } ","anchorH1":"bitrate_selection","anchorH2":"full_examples_of_bitrate_selection_replacements","anchorH3":"%60setmaxvideobitrate%60_/_%60maxvideobitrate%60_/_%60setmaxaudiobitrate%60_/_%60maxaudiobitrate%60"},{"h1":"Bitrate Selection","h2":"Full examples of bitrate selection replacements","h3":"setMinVideoBitrate / minVideoBitrate / setMinAudioBitrate / minAudioBitrate","body":"The following examples only talk about the video variants of these API to simplify, but it can be applied to the audio variant. Replacing the setMinVideoBitrate method or the minVideoBitrate option is very close than what has to be done to replace the setMaxVideoBitrate method and / or the maxVideoBitrate option. Because of these we will only here describe a lockMinBitrateForPeriod function, which is supposed to be the lockMaxBitrateForPeriod function equivalent for minimum bitrates: function lockMinBitrateForPeriod(minBitrate, period) {   if (minBitrate === 0) {     // /!\\ If you also have other bitrate restrictions, you may not want to     // unlock here     rxPlayer.unlockVideoRepresentations(period.id);   } else {     const videoTrack = rxPlayer.getVideoTrack(period.id);     const representationIds = videoTrack.representations.reduce(       (acc, representation) => {         if (           representation.bitrate !== undefined &&           representation.bitrate >= minBitrate         ) {           acc.push(representation.id);         }         return acc;       },       [],     );      if (representationIds.length > 0) {       rxPlayer.lockVideoRepresentations({         periodId: period.id,         representations: representationIds,       });     } else {       // Special case for when no Representation respects the minimum bitrate:       // Lock Representation(s) with the highest bitrate       const highestBitrate = videoTrack.representations         .map((representation) => representation.bitrate)         .filter((representation) => representation !== undefined)         .sort((a, b) => b - a)[0];       if (highestBitrate === undefined) {         rxPlayer.unlockVideoRepresentations(period.id);       } else {         rxPlayer.lockVideoRepresentations({           periodId: period.id,           representations: videoTrack.representations.filter(             (representation) => representation.bitrate >= highestBitrate,           ),         });       }     }   } } ","anchorH1":"bitrate_selection","anchorH2":"full_examples_of_bitrate_selection_replacements","anchorH3":"%60setminvideobitrate%60_/_%60minvideobitrate%60_/_%60setminaudiobitrate%60_/_%60minaudiobitrate%60"},{"h1":"Bitrate Selection","h2":"setAudioBitrate / setVideoBitrate","body":"The following examples only talk about the video variants of these API to simplify, but it can be applied to the audio variant. Replacing the setVideoBitrate method is very close than what has to be done to replace the setMaxVideoBitrate method or the maxVideoBitrate option. Because of these we will only here describe a lockBitrateForPeriod function, which is supposed to be the lockMaxBitrateForPeriod function equivalent for a chosen bitrates: function lockBitrateForPeriod(bitrate, period) {   if (bitrate === 0) {     // /!\\ If you also have other bitrate restrictions, you may not want to     // unlock here     rxPlayer.unlockVideoRepresentations(period.id);   } else {     const videoTrack = rxPlayer.getVideoTrack(period.id);     const filteredReps = videoTrack.representations       .filter((representation) => {         return (           representation.bitrate !== undefined &&           representation.bitrate <= bitrate         );       });      if (filteredReps.length > 0) {       const highestBitrateId = filteredReps         .sort((a, b) => b.bitrate - a.bitrate)[0];       rxPlayer.lockVideoRepresentations({         periodId: period.id,         representations: [highestBitrateId],       });     } else {       // Special case for when no Representation respects the given bitrate:       // Lock Representation(s) with the lowest bitrate       const lowestBitrate = videoTrack.representations         .map((representation) => representation.bitrate)         .filter((representation) => representation !== undefined)         .sort((a, b) => a - b)[0];       if (lowestBitrate === undefined) {         rxPlayer.unlockVideoRepresentations(period.id);       } else {         rxPlayer.lockVideoRepresentations({           periodId: period.id,           representations: videoTrack.representations.filter(             (representation) => representation.bitrate <= lowestBitrate,           ),         });       }     }   } } ","anchorH1":"bitrate_selection","anchorH2":"%60setaudiobitrate%60_/_%60setvideobitrate%60"}]},{"file":"./Getting_Started/Migration_From_v3/Constructor_Options.html","index":[{"h1":"Constructor Options","body":"Constructor options are options given when instantiating a new RxPlayer. Several have been removed, they will all be listed in this page.","anchorH1":"constructor_options"},{"h1":"Constructor Options","h2":"Removed options","body":"","anchorH1":"constructor_options","anchorH2":"removed_options"},{"h1":"Constructor Options","h2":"Removed options","h3":"limitVideoWidth","body":"The limitVideoWidth option has been removed. Instead, a more complete videoResolutionLimit constructor option exists, allowing either to limit the width to the media element - so roughly similar to limitVideoWidth - or even to the screen resolution, if you want to be ready with a higher resolution in case the user enables fullscreen mode. To replace limitVideoWidth, you can write: const rxPlayer = new RxPlayer({   // ...   videoResolutionLimit: \"videoElement\", }); ","anchorH1":"constructor_options","anchorH2":"removed_options","anchorH3":"%60limitvideowidth%60"},{"h1":"Constructor Options","h2":"Removed options","h3":"initialAudioBitrate / initialVideoBitrate","body":"Both the initialAudioBitrate and initialVideoBitrate constructor options were replaced by a now single baseBandwidth option which apply to both.","anchorH1":"constructor_options","anchorH2":"removed_options","anchorH3":"%60initialaudiobitrate%60_/_%60initialvideobitrate%60"},{"h1":"Constructor Options","h2":"Removed options","h3":"stopAtEnd","body":"The stopAtEnd constructor option has been removed and the RxPlayer now doesn’t stop at the end of the content by default. If you relied on this property, it was probably to set it to false which is now the default behavior - thus it doesn’t need to be replaced by anything. If you previously set this property to true or didn’t set this property however, you might want to explicitly stop the content when the \"ENDED\" player state is reached: rxPlayer.addEventListener(\"playerStateChange\", (state) => {   if (state === \"ENDED\") {     rxPlayer.stop();   } }); ","anchorH1":"constructor_options","anchorH2":"removed_options","anchorH3":"%60stopatend%60"},{"h1":"Constructor Options","h2":"Removed options","h3":"preferredAudioTrack / preferredTextTracks / preferredVideoTracks","body":"All preferences options and methods have been removed in profit of the more powerful track API. The migration for those has its own documentation page: Track Preferences.","anchorH1":"constructor_options","anchorH2":"removed_options","anchorH3":"%60preferredaudiotrack%60_/_%60preferredtexttracks%60_/_%60preferredvideotracks%60"},{"h1":"Constructor Options","h2":"Removed options","h3":"minAudioBitrate / minVideoBitrate / maxAudioBitrate / maxVideoBitrate","body":"All bitrate selection options and methods have been removed in profit of the new locked Representations API. The migration for those has its own documentation page: Bitrate Selection.","anchorH1":"constructor_options","anchorH2":"removed_options","anchorH3":"%60minaudiobitrate%60_/_%60minvideobitrate%60_/_%60maxaudiobitrate%60_/_%60maxvideobitrate%60"},{"h1":"Constructor Options","h2":"Removed options","h3":"throttleWhenHidden","body":"The deprecated throttleWhenHidden option has been removed. It can probably be completely replaced by the throttleVideoBitrateWhenHidden loadVideo option, the only difference is that the latter will not decrease the video bitrate if the video is still visible through a picture in picture element.","anchorH1":"constructor_options","anchorH2":"removed_options","anchorH3":"%60throttlewhenhidden%60"}]},{"file":"./Getting_Started/Migration_From_v3/loadVideo_Options.html","index":[{"h1":"loadVideo Options","body":"Multiple options of the loadVideo have been changed or removed. They will all be listed in this page.","anchorH1":"%60loadvideo%60_options"},{"h1":"loadVideo Options","h2":"Removed options","body":"","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options"},{"h1":"loadVideo Options","h2":"Removed options","h3":"manualBitrateSwitchingMode","body":"The manualBitrateSwitchingMode option has been removed. It is now possible to indicate the wanted switching mode directly on the lockVideoRepresentations or lockAudioRepresentations call through its switchingMode property instead.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60manualbitrateswitchingmode%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"defaultAudioTrack / defaultTextTrack","body":"The deprecated default tracks options have now been removed. Those can be replaced by the now more powerful track API, documented in the Track Preferences page of the migration documentation.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60defaultaudiotrack%60_/_%60defaulttexttrack%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"hideNativeSubtitles","body":"The deprecated hideNativeSubtitles option has been removed without replacement. It had been added a long time ago, for knownj use cases that were since completely replaced by using the \"html\" textTrackMode. If you still need that option for a valid use case, you are welcomed to open an issue.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60hidenativesubtitles%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"transportOptions.aggressiveMode","body":"The aggressiveMode option has been removed without replacement. It was previously mostly used as a work-around to optimize the time at which new segments were requested, but was always too risky and experimental for our taste.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60transportoptions.aggressivemode%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"transportOptions.supplementaryTextTracks","body":"The deprecated supplementaryTextTracks option has been completely removed in profit of using the more flexiple TextTrackRenderer tool.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60transportoptions.supplementarytexttracks%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"transportOptions.supplementaryImageTracks","body":"The deprecated supplementaryImageTracks option has been completely removed. If you want to display image thumbnails, you now have to load and display them in your application. You can still use the parseBifThumbnails tool to parse thumbnails in the “BIF” format.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60transportoptions.supplementaryimagetracks%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"keySystems[].persistentLicense","body":"The persistentLicense option has now been removed because it is, and already was, unnecessary. The simple presence of the keySystems[].persistentLicenseConfig option - which is the renaming of the old keySystems[].licenseStorage option (see below) - now suffice by itself to indicate that you want to use persistent license. The persistentLicense property can thus be safely removed.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60keysystems%5B%5D.persistentlicense%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"keySystems[].fallbackOn","body":"The fallbackOn object has been removed, and its content has been completely replaced by the more powerful keySystems[].onKeyOutputRestricted option (replacing keySystems[].fallbackOn.keyOutputRestricted) and keySystems[].onKeyInternalError option (replacing keySystems[].fallbackOn.keyInternalError). As such what was previously written: rxPlayer.loadVideo({   keySystems: [{     fallbackOn: {       keyOutputRestricted: true,       keyInternalError: true,     }     // ...   }],   // ... });  Can now be written: rxPlayer.loadVideo({   keySystems: [{     onKeyOutputRestricted: \"fallback\",     onKeyInternalError: \"fallback\",     // ...   }],   // ... }); ","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60keysystems%5B%5D.fallbackon%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"keySystems[].onKeyStatusesChange","body":"The onKeyStatusesChange callback has been removed with no replacement as no known usage was done of this callback. If you want it back, please open an issue.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60keysystems%5B%5D.onkeystatuseschange%60"},{"h1":"loadVideo Options","h2":"Removed options","h3":"keySystems[].throwOnLicenseExpiration","body":"The deprecated throwOnLicenseExpiration option has been removed because it can be fully replaced by the keySystems[].onKeyExpiration option option.","anchorH1":"%60loadvideo%60_options","anchorH2":"removed_options","anchorH3":"%60keysystems%5B%5D.throwonlicenseexpiration%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","body":"","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"url","body":"A very minor update to the url option of loadVideo is that it is now required to set it directly to the url of the Manifest for contents of the \"smooth\" transport. An undocumented feature of that option was that, for legacy reasons, it was previously possible to set it to a JSON or XML document that would contain the Manifest URL. You’re most probably not impacted by this change as as far as we know, the feature was only used internally at Canal+ and was not documented.","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60url%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"networkConfig","body":"The networkConfig loadVideo option has been entirely renamed, both the option itself, renamed to requestConfig, and its inner properties. Moreover, the offlineRetry option has been removed because it was too unreliable for real offline detection. If you miss this feature and wish for a replacement, please open an issue! Basically what was written previously as: rxPlayer.loadVideo({   networkConfig: {     segmentRetry: 2,     segmentRequestTimeout: 15000,     manifestRetry: 3,     manifestRequestTimeout : 7000,   },   // ... });  Can now be written as: rxPlayer.loadVideo({   requestConfig: {     segment: {       maxRetry: 2,       timeout: 15000,     },     manifest: {       maxRetry: 3,       timeout: 7000,     },   },   // ... }); ","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60networkconfig%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"audioTrackSwitchingMode","body":"The audioTrackSwitchingMode option can now be indicated directly on the corresponding setAudioTrack call through its switchingMode property. However it is still possible to declare a default value when switching an audio track through the new defaultAudioTrackSwitchingMode loadVideo option. This means that: rxPlayer.loadVideo({   audioTrackSwitchingMode: \"reload\",   // ... });  Can be replaced by: rxPlayer.loadVideo({   defaultAudioTrackSwitchingMode: \"reload\",   // ... }); ","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60audiotrackswitchingmode%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"keySystems[].licenseStorage","body":"The licenseStorage option has been renamed to persistentLicenseConfig. This means that what was previously: rxPlayer.loadVideo({   keySystems: [{     licenseStorage: {       save(data) {         localStorage.setItem(\"RxPlayer-persistent-storage\", JSON.stringify(data));       },       load() {         const item = localStorage.getItem(\"RxPlayer-persistent-storage\");         return item === null ? [] : JSON.parse(item);       },     },     // ...   }],   // ... });  Now becomes: rxPlayer.loadVideo({   keySystems: [{     persistentLicenseConfig: {       save(data) {         localStorage.setItem(\"RxPlayer-persistent-storage\", JSON.stringify(data));       },       load() {         const item = localStorage.getItem(\"RxPlayer-persistent-storage\");         return item === null ? [] : JSON.parse(item);       },     },     // ...   }],   // ... }); ","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60keysystems%5B%5D.licensestorage%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"keySystems[].persistentStateRequired","body":"The persistentStateRequired boolean property of the keySystems option has been updated to a persistentState property accepting instead the MediaKeysRequirement the RxPlayer should set the persistentState property of the wanted MediaKeySystemConfiguration. This means that what was previously written as: rxPlayer.loadVideo({   keySystems: [{     persistentStateRequired: true,     // ...   }],   // ... });  Now becomes: rxPlayer.loadVideo({   keySystems: [{     persistentState: \"required\",     // ...   }],   // ... }); ","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60keysystems%5B%5D.persistentstaterequired%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"keySystems[].distinctiveIdentifierRequired","body":"The distinctiveIdentifierRequired boolean property of the keySystems option has been updated to a distinctiveIdentifier property accepting instead the MediaKeysRequirement the RxPlayer should set the distinctiveIdentifier property of the wanted MediaKeySystemConfiguration. This means that what was previously written as: rxPlayer.loadVideo({   keySystems: [{     distinctiveIdentifierRequired: true,     // ...   }],   // ... });  Now becomes: rxPlayer.loadVideo({   keySystems: [{     distinctiveIdentifier: \"required\",     // ...   }],   // ... }); ","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60keysystems%5B%5D.distinctiveidentifierrequired%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"keySystems[].audioRobustnesses / keySystems[].videoRobustnesses","body":"Both undocumented, the audioRobustnesses and videoRobustnesses properties of the keySystems loadVideo options allowed to configure the wanted robustnes levels of encrypted content. They have now been replaced by the much more powerful audioCapabilitiesConfig and videoCapabilitiesConfig respectively. What was previously written: rxPlayer.loadVideo({   keySystems: [{     audioRobustnesses: [\"2000\"],     videoRobustnesses: [\"3000\", \"2000\"],     // ...   }],   // ... });  Can now be written as: rxPlayer.loadVideo({   keySystems: [{     audioCapabilitiesConfig: {       type: \"robustness\",       value: [\"2000\"],     },     videoCapabilitiesConfig: {       type: \"robustness\",       value: [\"3000\", \"2000\"],     },     // ...   }],   // ... }); ","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60keysystems%5B%5D.audiorobustnesses%60_/_%60keysystems%5B%5D.videorobustnesses%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"transportOptions","body":"The transportOptions option of loadVideo has been removed. Instead, you should now put what it contained directly on the loadVideo call. For example: rxPlayer.loadVideo({   transportOptions: {     segmentLoader: (args, callbacks) => {       // ...     },     minimumManifestUpdateInterval: 5000,   },   // ... });  Should now become: rxPlayer.loadVideo({   segmentLoader: (args, callbacks) => {     // ...   },   minimumManifestUpdateInterval: 5000,   // ... });  Note however that multiple properties previously found inside the transportOptions option has now been removed and updated (they are all documented here). The removed options are:  aggressiveMode supplementaryTextTracks supplementaryImageTracks  Updated options are:  manifestLoader segmentLoader  Change will be documented below.","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60transportoptions%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"transportOptions.manifestLoader","body":"The transportOptions.manifestLoader option, which is now just manifestLoader (at the root of loadVideo options) now only received two arguments:   The first argument - which was previously just the Manifest’s URL - is now an object with two properties:   url (string|undefined): The same URL that was previously communicated directly.   timeout (number|undefined): Timeout in milliseconds after which a request should preferably be aborted, according to current configuration. This property is mainly indicative, you may or may not want to exploit this information depending on your use cases. Previously, this property was communicated through a third argument.     The second argument didn’t change, it is still its callbacks   The third argument has been removed and integrated in the first one.   The manifestLoader documentation has been updated if you wish to have an example and more documentation.","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60transportoptions.manifestloader%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"transportOptions.segmentLoader","body":"The transportOptions.segmentLoader option, which is now just segmentLoader (at the root of loadVideo options) has seen its first argument updated:   Its url property, before always a string, can now be set to undefined if unknown.   The manifest, period, adaptation, representation and segment properties have been removed as it exposed the RxPlayer’s internals too much.   An isInit boolean (or set to undefined) property has been added to indicate whether this is an initialization segment.   a trackType string has been added to signal which track’s type this segment is part of.   A byteRanges array (or set to undefined) property has been added to announce the byte-range(s) for which the resource should be requested. More information on its format in the segmentLoader documentation.   The segmentLoader documentation has been updated if you wish to have an example and more documentation.","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60transportoptions.segmentloader%60"},{"h1":"loadVideo Options","h2":"Renamed and updated options","h3":"transportOptions.representationFilter","body":"The transportOptions.representationFilter option, which is now just representationFilter (at the root of loadVideo options) has seen its first argument updated:  frameRate is now either a number - in terms of frame per seconds - or undefined, instead of a string. bitrate can now be undefined or just not be defined as a property at all. The decipherable property has been removed. The index property has been removed. A new contentProtections property has been added, describing protections associated to the corresponding Representation.  The bufferType property of its second argument also has been renamed trackType to align with other APIs. The representationFilter documentation has been updated if you wish to have an example and more documentation.","anchorH1":"%60loadvideo%60_options","anchorH2":"renamed_and_updated_options","anchorH3":"%60transportoptions.representationfilter%60"}]},{"file":"./Getting_Started/Migration_From_v3/Player_Events.html","index":[{"h1":"RxPlayer events","body":"RxPlayer events can be listened to thanks to the addEventListener method of the RxPlayer. Many of them have changed in the v4.0.0. They are all listed here.","anchorH1":"rxplayer_events"},{"h1":"RxPlayer events","h2":"playerStateChange","body":"Two player states have been updated:   The \"FREEZING\" state has been added to the possible states sent through the playerStateChange event. This new state, which is sent when playback does not advance despite the fact that the right conditions for it are there, is described in the overview. In many case, you might want to handle it like a \"BUFFERING\" state.   The RELOADING player state can now happen at any time if it allows to unlock playback. Previously, it could only be sent if specific options have been used.  ","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"audioBitrateChange / videoBitrateChange","body":"Both the audioBitrateChange and videoBitrateChange events have been removed. They can however completely be replaced by respectively the more powerful audioRepresentationChange and videoRepresentationChange events. Both new events do not communicate directly the bitrate, but the Representation which each may contain a bitrate property: // What was previously written rxPlayer.addEventListener(\"videoBitrateChange\", (bitrate) => {   if (bitrate === -1) {     console.log(\"video bitrate unknown or no video Representation playing\");   } else {     console.log(\"new video bitrate:\", bitrate);   } });  // Can now be written as rxPlayer.addEventListener(\"videoRepresentationChange\", (representation) => {   if (representation === null) {     console.log(\"no video Representation playing\");   } else if (representation.bitrate === undefined) {     console.log(\"video bitrate unknown\");   } else {     console.log(\"new video bitrate:\", representation.bitrate);   } }); ","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60audiobitratechange%60_/_%60videobitratechange%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"availableAudioBitratesChange / availableVideoBitratesChange","body":"The availableAudioBitratesChange and  availableVideoBitratesChange API have been removed like most bitrate-oriented API. If you want to know when the list of audio and video bitrates for the current Period changes, you can listen to respectively when the current audio track changes through the audioTrackChange event and when the current video track changes through the videoTrackChange event. There’s a last potential situation for the bitrates changing, which is when the track doesn’t change but the list of bitrate does. For example this may happen when some qualities in the current video or audio track are found to be undecipherable. Sadly, there’s no way for now to be notified when this last event happens. If you need this, please open an issue.","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60availableaudiobitrateschange%60_/_%60availablevideobitrateschange%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"decipherabilityUpdate","body":"The decipherabilityUpdate event has been removed with no replacement. Indeed, it was unused as far as we know and exposed too much of the RxPlayer internals. If you need this, please open an issue.","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60decipherabilityupdate%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"positionUpdate","body":"The maximumBufferTime property from positionUpdate events has been renamed maximumPosition, to align with the other APIs.","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60positionupdate%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"periodChange","body":"The periodChange is still present but its payload has been reduced to its core properties. See its documentation for more information.","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60periodchange%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"fullscreenChange","body":"The deprecated fullscreenChange event has been removed. Fullscreen functionalities now have to be completely handled by the applications, which most likely already did just that anyway.","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60fullscreenchange%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"nativeTextTracksChange","body":"The deprecated nativeTextTracksChange event has been removed. This event was initially added for legacy reasons and should not be relied on anymore.","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60nativetexttrackschange%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"bitrateEstimationChange","body":"The bitrateEstimationChange event has been removed. It has been removed because it was poorly understood (it’s not always close to the expected bandwidth), because it actually has a very complex relationship with the chosen quality and because its structure prevented us to make some evolutions to the RxPlayer internals.","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60bitrateestimationchange%60"},{"h1":"RxPlayer events","h2":"playerStateChange","h3":"imageTrackUpdate","body":"All image related API, like the imageTrackUpdate event, have been removed. If you need to parse BIF file, you can use the parseBifThumbnails tool instead.","anchorH1":"rxplayer_events","anchorH2":"%60playerstatechange%60","anchorH3":"%60imagetrackupdate%60"}]},{"file":"./Getting_Started/Migration_From_v3/Player_Errors.html","index":[{"h1":"RxPlayer errors","body":"Errors are what are sent through the \"error\" event, the \"warning\" event and optionally returned by the getPlayerError method. A few of them have changed in the v4.0.0. They are all listed here.","anchorH1":"rxplayer_errors"},{"h1":"RxPlayer errors","h2":"MediaError","body":"Previously, if no compatible audio and/or video codec was found in the Manifest, a MediaError with the code MANIFEST_PARSE_ERROR would be sent through a \"error\" event (and returned by the getPlayerError method) after several MediaError with MANIFEST_INCOMPATIBLE_CODECS_ERROR \"warning\" events for each Adaptation with no supported codec found. Now this final fatal error is also a MediaError with the code MANIFEST_INCOMPATIBLE_CODECS_ERROR, as it’s more precize.","anchorH1":"rxplayer_errors","anchorH2":"%60mediaerror%60"},{"h1":"RxPlayer errors","h2":"NetworkError","body":"We removed the xhr property from NetworkError objects as it prevented us from relying on the fetch API for requests.","anchorH1":"rxplayer_errors","anchorH2":"%60networkerror%60"}]},{"file":"./Getting_Started/Migration_From_v3/Player_Methods.html","index":[{"h1":"RxPlayer methods","body":"Several RxPlayer methods have been removed, renamed or updated. They are all listed here.","anchorH1":"rxplayer_methods"},{"h1":"RxPlayer methods","h2":"Removed methods","body":"","anchorH1":"rxplayer_methods","anchorH2":"removed_methods"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getAvailableAudioBitrates / getAvailableVideoBitrates","body":"Both the getAvailableAudioBitrates and getAvailableVideoBitrates methods have been removed, like most bitrate-oriented API. Its behavior is however easy to replace, just by using respectively the getAudioTrack and getVideoTrack methods: // instead of getAvailableVideoBitrates you can do const videoTrack = rxPlayer.getVideoTrack(); if (videoTrack !== null && videoTrack !== undefined) {   const availableVideoBitrates = video.representation     .map(r => r.bitrate)     .filter(bitrate => bitrate !== undefined); }  Note however that one of the main reason for calling one of those method was to change the currently playing bitrate and that such way of controlling the quality has been removed in profit of the new representation lock API. You can read the Bitrate Selection part of the migration guide for more information on this.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getavailableaudiobitrates%60_/_%60getavailablevideobitrates%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getVideoBitrate / getAudioBitrate","body":"Both the getAudioBitrate and getVideoBitrate methods have been removed, like most bitrate-oriented API. Its behavior is however easy to replace, just by using respectively the getAudioRepresentation and and getVideoRepresentation methods: // instead of getVideoBitrate you can do const videoRepresentation = rxPlayer.getVideoRepresentation(); if (videoRepresentation !== null && videoRepresentation !== undefined) {   console.log(\"Current video bitrate:\", videoRepresentation.bitrate); } ","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getvideobitrate%60_/_%60getaudiobitrate%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"setAudioBitrate / setVideoBitrate / getManualAudioBitrate / getManualAudioBitrate","body":"The setAudioBitrate, setVideoBitrate, getManualAudioBitrate and getManualAudioBitrate methods have all been removed, as documented in the Bitrate Selection part of the migration guide.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60setaudiobitrate%60_/_%60setvideobitrate%60_/_%60getmanualaudiobitrate%60_/_%60getmanualaudiobitrate%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"setMinAudioBitrate / setMinVideoBitrate / getMinAudioBitrate / setMinAudioBitrate","body":"The setMinAudioBitrate, setMinVideoBitrate, getMinAudioBitrate and setMinAudioBitrate methods have all been removed, as documented in the Bitrate Selection part of the migration guide.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60setminaudiobitrate%60_/_%60setminvideobitrate%60_/_%60getminaudiobitrate%60_/_%60setminaudiobitrate%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"setMaxAudioBitrate / setMaxVideoBitrate / getMaxAudioBitrate / setMaxAudioBitrate","body":"The setMaxAudioBitrate, setMaxVideoBitrate, getMaxAudioBitrate and setMaxAudioBitrate methods have all been removed, as documented in the Bitrate Selection part of the migration guide.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60setmaxaudiobitrate%60_/_%60setmaxvideobitrate%60_/_%60getmaxaudiobitrate%60_/_%60setmaxaudiobitrate%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getPreferredAudioTracks / getPreferredVideoTracks / getPreferredTextTracks","body":"The getPreferredAudioTracks, getPreferredVideoTracks and getPreferredTextTracks methods have been removed. Track preferences API does not exist anymore as documented in the Preferences part of the migration guide.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getpreferredaudiotracks%60_/_%60getpreferredvideotracks%60_/_%60getpreferredtexttracks%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"setPreferredAudioTracks / setPreferredVideoTracks / setPreferredTextTracks","body":"The setPreferredAudioTracks, setPreferredVideoTracks and setPreferredTextTracks methods have been removed. Track preferences API does not exist anymore as documented in the Preferences part of the migration guide.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60setpreferredaudiotracks%60_/_%60setpreferredvideotracks%60_/_%60setpreferredtexttracks%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getVideoPlayedTime","body":"The getVideoPlayedTime method has been removed because it was poorly named, poorly understood, and it is easy to replace. To replace it, you can write: function getVideoPlayedTime() {   const position = rxPlayer.getPosition();   const mediaElement = rxPlayer.getVideoElement();   if (mediaElement === null) {     console.error(\"The RxPlayer is disposed\");   } else {     const range = getRange(mediaElement.buffered, currentTime);     return range !== null ? currentTime - range.start :   } }  /**  * Get range object of a specific time in a TimeRanges object.  * @param {TimeRanges} timeRanges  * @returns {Object}  */ function getRange(timeRanges, time) {   for (let i = timeRanges.length - 1; i >= 0; i--) {     const start = timeRanges.start(i);     if (time >= start) {       const end = timeRanges.end(i);       if (time < end) {         return { start, end };       }     }   }   return null; } ","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getvideoplayedtime%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getVideoLoadedTime","body":"The getVideoLoadedTime method has been removed because it was poorly named, poorly understood, and it is easy to replace. To replace it, you can write: function getVideoLoadedTime() {   const position = rxPlayer.getPosition();   const mediaElement = rxPlayer.getVideoElement();   if (mediaElement === null) {     console.error(\"The RxPlayer is disposed\");   } else {     const range = getRange(mediaElement.buffered, currentTime);     return range !== null ? range.end - range.start :                             0;   } }  /**  * Get range object of a specific time in a TimeRanges object.  * @param {TimeRanges} timeRanges  * @returns {Object}  */ function getRange(timeRanges, time) {   for (let i = timeRanges.length - 1; i >= 0; i--) {     const start = timeRanges.start(i);     if (time >= start) {       const end = timeRanges.end(i);       if (time < end) {         return { start, end };       }     }   }   return null; } ","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getvideoloadedtime%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getManifest","body":"The getManifest method has been removed with no replacement because it exposed the RxPlayer’s internals too much. If you needed it for something, please open an issue explaining which property you needed.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getmanifest%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getCurrentAdaptations","body":"The getCurrentAdaptations method has been removed with no replacement because it exposed the RxPlayer’s internals too much. If you needed it for something, please open an issue explaining which property you needed.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getcurrentadaptations%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getCurrentRepresentations","body":"The getCurrentRepresentations method has been removed with no replacement because it exposed the RxPlayer’s internals too much. If you needed it for something, please open an issue explaining which property you needed.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getcurrentrepresentations%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"isFullscreen / setFullscreen / exitFullscreen","body":"The isFullscreen, setFullscreen and exitFullscreen methods have been removed. Fullscreen functionalities now have to be completely handled by the applications, which most likely already did just that anyway.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60isfullscreen%60_/_%60setfullscreen%60_/_%60exitfullscreen%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getNativeTextTrack","body":"The getNativeTextTrack methods has been removed. This method was initially added for legacy reasons and should not be relied on anymore.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getnativetexttrack%60"},{"h1":"RxPlayer methods","h2":"Removed methods","h3":"getImageTrackData","body":"All image-related API, like the getImageTrackData method, have been removed. If you need to parse BIF file, you can use the parseBifThumbnails tool instead.","anchorH1":"rxplayer_methods","anchorH2":"removed_methods","anchorH3":"%60getimagetrackdata%60"},{"h1":"RxPlayer methods","h2":"Renamed","body":"","anchorH1":"rxplayer_methods","anchorH2":"renamed"},{"h1":"RxPlayer methods","h2":"Renamed","h3":"getUrl","body":"The getUrl has both be updated and renamed, into the getContentUrls method. However getContentUrls returns an optional array of URL (all URLs at which the content can be reached) whereas getUrl only provided a single one. If you want to replicate getUrl’s behavior, you may want to only use the first string optionally returned by getContentUrls.","anchorH1":"rxplayer_methods","anchorH2":"renamed","anchorH3":"%60geturl%60"},{"h1":"RxPlayer methods","h2":"Renamed","h3":"getVideoDuration","body":"The getVideoDuration method has been renamed getMediaDuration to prevent confusion with the duration of the video track.","anchorH1":"rxplayer_methods","anchorH2":"renamed","anchorH3":"%60getvideoduration%60"},{"h1":"RxPlayer methods","h2":"Renamed","h3":"getVideoBufferGap","body":"The getVideoDuration method has been renamed getCurrentBufferGap to prevent confusion with the buffer gap specific to the video buffer.","anchorH1":"rxplayer_methods","anchorH2":"renamed","anchorH3":"%60getvideobuffergap%60"},{"h1":"RxPlayer methods","h2":"Updated","body":"","anchorH1":"rxplayer_methods","anchorH2":"updated"},{"h1":"RxPlayer methods","h2":"getPlayerState","body":"Two player states have been updated:   The \"FREEZING\" state has been added to the possible states sent through the playerStateChange event. This new state, which is sent when playback does not advance despite the fact that the right conditions for it are there, is described in the overview. In many case, you might want to handle it like a \"BUFFERING\" state.   The RELOADING player state can now happen at any time if it allows to unlock playback. Previously, it could only be sent if specific options have been used.  ","anchorH1":"rxplayer_methods","anchorH2":"%60getplayerstate%60"},{"h1":"RxPlayer methods","h2":"getPlayerState","h3":"getAvailableVideoTracks / getVideoTrack","body":"Several properties that can be received in a getAvailableVideoTracks or getVideoTrack call, to describe a video Representation (in the representations property of tracks returned by both methods), have been updated:   A Representation’s frameRate property is now either a number - in terms of frame per seconds - or undefined, instead of a string.   A Representation’s bitrate property can now be undefined if unknown.  ","anchorH1":"rxplayer_methods","anchorH2":"%60getplayerstate%60","anchorH3":"%60getavailablevideotracks%60_/_%60getvideotrack%60"},{"h1":"RxPlayer methods","h2":"getPlayerState","h3":"getAvailableAudioTracks / getAudioTrack","body":"The bitrate property that can be retrieved as a child property of the representations property, itself found in tracks returned by the getAvailableAudioTracks and getAudioTrack methods, can now be undefined if unknown.","anchorH1":"rxplayer_methods","anchorH2":"%60getplayerstate%60","anchorH3":"%60getavailableaudiotracks%60_/_%60getaudiotrack%60"}]},{"file":"./Getting_Started/Migration_From_v3/Player_Types.html","index":[{"h1":"RxPlayer types","body":"Several of RxPlayer TypeScript types  have been removed, renamed or updated. They are all listed here.","anchorH1":"rxplayer_types"},{"h1":"RxPlayer types","h2":"IPersistentSessionStorage","body":"IPersistentSessionStorage has been renamed IPersistentLicenseConfig to replicate the renaming of the licenseStorage option into the persistentLicenseConfig option.","anchorH1":"rxplayer_types","anchorH2":"%60ipersistentsessionstorage%60"},{"h1":"RxPlayer types","h2":"ISupplementaryTextTrackOption","body":"The ISupplementaryTextTrackOption type has been removed because the corresponding supplementaryTextTracks option has been removed.","anchorH1":"rxplayer_types","anchorH2":"%60isupplementarytexttrackoption%60"},{"h1":"RxPlayer types","h2":"ISupplementaryImageTrackOption","body":"The ISupplementaryImageTrackOption type has been removed because the corresponding supplementaryImageTracks option has been removed.","anchorH1":"rxplayer_types","anchorH2":"%60isupplementaryimagetrackoption%60"},{"h1":"RxPlayer types","h2":"IBitrateEstimate","body":"The IBitrateEstimate type has been removed as the corresponding bitrateEstimationChange event has been removed.","anchorH1":"rxplayer_types","anchorH2":"%60ibitrateestimate%60"},{"h1":"RxPlayer types","h2":"IManifest / IPeriod / IAdaptation / IRepresentation","body":"All those types have been removed because corresponding API now return more specialized types.","anchorH1":"rxplayer_types","anchorH2":"%60imanifest%60_/_%60iperiod%60_/_%60iadaptation%60_/_%60irepresentation%60"},{"h1":"RxPlayer types","h2":"IRepresentationInfos","body":"The IRepresentationInfos type has been renamed IRepresentationContext (the second argument for the representationFilter API).","anchorH1":"rxplayer_types","anchorH2":"%60irepresentationinfos%60"},{"h1":"RxPlayer types","h2":"IBifThumbnail / IBifObject","body":"Both types have now to be imported from the parseBifThumbnails tool’s path instead.","anchorH1":"rxplayer_types","anchorH2":"%60ibifthumbnail%60_/_%60ibifobject%60"},{"h1":"RxPlayer types","h2":"IExposedSegment","body":"The IExposedSegment type has been removed as no API depends on it anymore.","anchorH1":"rxplayer_types","anchorH2":"%60iexposedsegment%60"},{"h1":"RxPlayer types","h2":"IAudioTrackPreference / ITextTrackPreference / IVideoTrackPreference","body":"The IAudioTrackPreference, ITextTrackPreference and IVideoTrackPreference public types have been removed as the corresponding API do not exist anymore.","anchorH1":"rxplayer_types","anchorH2":"%60iaudiotrackpreference%60_/_%60itexttrackpreference%60_/_%60ivideotrackpreference%60"},{"h1":"RxPlayer types","h2":"IDefaultAudioTrackOption / IDefaultTextTrackOption","body":"Both types have been removed because the corresponding defaultAudioTrack and defaultTextTrack options also have been removed.","anchorH1":"rxplayer_types","anchorH2":"%60idefaultaudiotrackoption%60_/_%60idefaulttexttrackoption%60"}]},{"file":"./Getting_Started/Minimal_Player.html","index":[{"h1":"Importing a minimal player with feature selection","body":"","anchorH1":"importing_a_minimal_player_with_feature_selection"},{"h1":"Importing a minimal player with feature selection","h2":"Overview","body":"The RxPlayer comes with many features, even some you might never need. For example, you may only care for DASH with TTML subtitles and not about Smooth streaming, VTT or SRT parsing. Because each implementation has its need, we permit multiple ways to import the player with limited features. This customization can be done by importing the minimal version of the RxPlayer and then adding only the features your want. This allows to greatly reduce the final bundle size, if your bundler (esbuild, webpack, rollup, vite…) support tree-shaking, like most do.","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"overview"},{"h1":"Importing a minimal player with feature selection","h2":"How it works","body":"If you imported the RxPlayer library through the npm package (like via the npm install rx-player command), you can import a minimal version of the player by importing it from \"rx-player/minimal\": import MinimalRxPlayer from \"rx-player/minimal\";  // This player has the same API than the RxPlayer, but with no feature // (e.g. no DASH, Smooth or Directfile playback) const player = new MinimalRxPlayer();  // use the regular APIs... player.setVolume(0.5);  You then will need to add the features you want on it. Those can be accessed through the path \"rx-player/features\": // import the DASH and Smooth features, which will be added to the RxPlayer import { DASH, SMOOTH } from \"rx-player/features\";  At last you can add those features to the imported RxPlayer class by calling the special addFeatures static method, which is only present on the minimal version of the Player: // addFeatures takes an array of features as argument MinimalRxPlayer.addFeatures([DASH, SMOOTH]);  Here is the complete example: import MinimalRxPlayer from \"rx-player/minimal\"; import { DASH, SMOOTH } from \"rx-player/features\";  MinimalRxPlayer.addFeatures([DASH, SMOOTH]);  There is also “experimental” features. Such features can completely change from one version to the next - unlike regular features which just follows semantic versioning. This means that you may have to keep the concerned code up-to-date each time you depend on a new RxPlayer version. Such features are imported from \"rx-player/experimental/features\" instead: import MinimalRxPlayer from \"rx-player/minimal\"; import { DASH_WASM } from \"rx-player/experimental/features\";  MinimalRxPlayer.addFeatures([DASH_WASM]);  You can of course depend on both experimental and regular features: import MinimalRxPlayer from \"rx-player/minimal\"; import { DASH, SMOOTH } from \"rx-player/features\"; import { DASH_WASM } from \"rx-player/experimental/features\";  MinimalRxPlayer.addFeatures([DASH, SMOOTH, DASH_WASM]);  By using the minimal version, you will reduce the final bundle file if tree-shaking is performed on the final code (like in webpack’s production mode). The key is just to know which feature does what. The next chapter will list and explain the role of every one of them.","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"how_it_works"},{"h1":"Importing a minimal player with feature selection","h2":"List of features","body":"Features, which are variables imported from the \"rx-player/features\" path, are all objects declared in upper-case. Here is the anotated exhaustive list (notes are at the bottom of the table):    Feature Description of the feature     SMOOTH Enable Smooth streaming (HSS) playback   DASH Enable DASH playback using a JavaScript-based MPD parser   DIRECTFILE Enable playback of “directfile” contents   EME Enable playback of encrypted contents   NATIVE_TEXT_BUFFER [1] Allow to display text tracks through <tracks> elements   HTML_TEXT_BUFFER [1] Allow to display richer text tracks through HTML elements   NATIVE_SRT_PARSER [2] Parse SRT text tracks for the native text buffer   NATIVE_VTT_PARSER [2] Parse VTT text tracks for the native text buffer   NATIVE_TTML_PARSER [2] Parse TTML text tracks for the native text buffer   NATIVE_SAMI_PARSER [2] Parse SAMI text tracks for the native text buffer   HTML_SRT_PARSER [3] Parse SRT text tracks for the HTML text buffer   HTML_VTT_PARSER [3] Parse VTT text tracks for the HTML text buffer   HTML_TTML_PARSER [3] Parse TTML text tracks for the HTML text buffer   HTML_SAMI_PARSER [3] Parse SAMI text tracks for the HTML text buffer   DASH_WASM [4] [5] Enable DASH playback using a WebAssembly-based MPD parser   LOCAL_MANIFEST [4] Enable playback of “local” contents   METAPLAYLIST [4] Enable playback of “metaplaylist” contents    Notes: [1]: You will need to also add at least one parser for this type of buffer for those features to be useful. (example: NATIVE_SRT_PARSER will parse srt subtitles for the NATIVE_TEXT_BUFFER) [2]: Those features will only be used if NATIVE_TEXT_BUFFER is an added feature. [3]: Those features will only be used if HTML_TEXT_BUFFER is an added feature. [4]: Those type of contents are experimental. They should be imported from rx-player/experimental/features. [5]: In cases where both the DASH and DASH_WASM features are added (which are both parsers for DASH contents), the RxPlayer will default using the WebAssembly parser (provided by DASH_WASM) and fallback on the JavaScript parser (provided by DASH) when it cannot do so.","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"list_of_features"},{"h1":"Importing a minimal player with feature selection","h2":"Examples","body":"To help you choose your features, are some examples that represents common usecases.","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"examples"},{"h1":"Importing a minimal player with feature selection","h2":"Examples","h3":"unencrypted DASH contents with native webVTT subtitles","body":"import RxPlayer from \"rx-player/minimal\"; import {   DASH,   NATIVE_TEXT_BUFFER,   NATIVE_VTT_PARSER, } from \"rx-player/features\";  RxPlayer.addFeatures([DASH, NATIVE_TEXT_BUFFER, NATIVE_VTT_PARSER]); ","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"examples","anchorH3":"unencrypted_dash_contents_with_native_webvtt_subtitles"},{"h1":"Importing a minimal player with feature selection","h2":"possibly-encrypted DASH contents with HMTL webVTT and TTML subtitles","body":"import RxPlayer from \"rx-player/minimal\"; import {   DASH,   EME,   HTML_TEXT_BUFFER,   HTML_VTT_PARSER,   HTML_HTML_PARSER, } from \"rx-player/features\";  RxPlayer.addFeatures([   DASH,   EME,   HTML_TEXT_BUFFER,   HTML_VTT_PARSER,   HTML_TTML_PARSER, ]); ","anchorH1":"importing_a_minimal_player_with_feature_selection","anchorH2":"possibly-encrypted_dash_contents_with_hmtl_webvtt_and_ttml_subtitles"}]},{"file":"./Getting_Started/Glossary.html","index":[{"h1":"Glossary","body":"","anchorH1":"glossary"},{"h1":"Glossary","h2":"Overview","body":"As the RxPlayer manages multiple type of streaming technologies, which can use their own definition and terminology, we had to find a compromise and use our own terminology, which try to take the best from these. We here define various terms used in the documentation which might not be obvious right along.","anchorH1":"glossary","anchorH2":"overview"},{"h1":"Glossary","h2":"Definitions","body":"","anchorH1":"glossary","anchorH2":"definitions"},{"h1":"Glossary","h2":"Definitions","h3":"Adaptation","body":"Simply put, what we call an “Adaptation” is just an audio, video or text track. More technically, it is an element of a Period (and by extension of the Manifest) which represents a single type of media. An adaptation can be for example any of those things:  A video track A french audio track An italian text track A thumbnail track …  Many Streaming Technology have this concept even though their name can change, an Adaptation is equivalent to:  DASH’s AdaptationSet Microsoft Smooth Streaming’s StreamIndex  Note: There is minor differences between the RxPlayer’s Adaptation and DASH’ AdaptationSet. Namely multiple AdaptationSets can be merged into a single Adaptation in very specific cases. You can find more infos on it here.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"adaptation"},{"h1":"Glossary","h2":"Definitions","h3":"Buffer","body":"When we talk about the “buffer” in the RxPlayer, we most likely refer to the structures in the browser holding media data, waiting to be decoded. Several layers of buffers can be defined in the browser-side to allow to have a smooth playback, fast seeking etc.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"buffer"},{"h1":"Glossary","h2":"Definitions","h3":"Buffer type","body":"RxPlayer’s buffer types describe a single “type” of media. Example of such types are:  “video”: which represents only the video content “audio”: the audio content without the video “text”: the subtitles, for example ","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"buffer_type"},{"h1":"Glossary","h2":"Definitions","h3":"Chunk","body":"Depending on the context, a chunk can be either a sub-part of a Media Segment or the Media segment itself.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"chunk"},{"h1":"Glossary","h2":"Definitions","h3":"Initialization segment","body":"An initialization segment is a specific type of media segment, which includes metadata necessary to initialize the browser’s internal decoder. Those are sometimes needed before we can actually begin to push any “real” media segment from the corresponding Representation. As such, when one is needed, the initialization segment is the first segment downloaded for a given Representation.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"initialization_segment"},{"h1":"Glossary","h2":"Definitions","h3":"Manifest","body":"The Manifest is the generic name for the document which describes the content you want to play. This is equivalent to the DASH’s Media Presentation Description (or MPD), the Microsoft Smooth Streaming’s Manifest and the HLS’ Master Playlist. Such document can describe for example:  multiple qualities for the same video or audio tracks multiple audio tracks in different languages presence of subtitles  Note that this concept is only used in Streaming technologies. You won’t interact with a Manifest if you’re directly playing a MP4 or webM file.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"manifest"},{"h1":"Glossary","h2":"Definitions","h3":"Media segment","body":"A media segment (or simply segment), is a small chunk of media data. In many streaming technologies, a content is separated into multiple chunks of small duration (usually between 2 and 10 seconds). This allows, for reasons to long to detail here, to easily implements many features:  live streaming, language switching adaptive streaming  When you play a content with the RxPlayer, it will most of the time download media segments of different types (audio, video, text…) progressively rather than the whole content at a single time.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"media_segment"},{"h1":"Glossary","h2":"Definitions","h3":"Period","body":"A Period is a sub-element of the the Manifest which defines what the content will be from a starting time to an ending time. It contains its own Adaptations and Representations. Having multiple Periods in the same Manifest allows for example to define multiple programs on the same content, each with its own tracks and quality characteristics. Depending on the transport used, they correspond to different concepts:  for DASH contents, it is more or less the same thing than an MPD’s <Period> element for “local” contents, it corresponds to a single object from the periods array. for “MetaPlaylist” contents, it corresponds to all the Period elements we retrieved after parsing the corresponding Manifest from the elements of the contents array. any other transport will have a single Period, describing the whole content.  – As an example, let’s take a manifest describing a live content with chronologically:  an english TV Show an old italian film with subtitles an American blockbuster with closed captions.  Let’s say that those sub-contents are drastically different:  they are all in different languages the american blockbuster has more available video bitrates than the old italian one  Because the available tracks and available qualities are different from sub-content to sub-content, we cannot just give a single list of Adaptations valid for all of them. They have to be in some way separated in the Manifest object. That’s a case where Periods will be used. Here is a visual representation of how the Periods would be divided here:         Period 1                Period 2                Period 3 08h05              09h00                       10h30                 now   |==================|===========================|====================|         TV Show               Italian Film        American Blockbuster  Each of these Periods will be linked to different audio, video and text Adaptations, themselves linked to different Representations.","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"period"},{"h1":"Glossary","h2":"Definitions","h3":"Representation","body":"A Representation is an element of an Adaptation, and by extension of the Manifest) that describes an interchangeable way to represent the parent Adaptation. For example, a video Adaptation can have several Representations, each having its own resolution (width and height) or its own bitrate (amount of bytes per seconds of content). The idea behind a Representation is that it can be changed by any other one in the same Adaptation as the content plays. This is most often implemented to allow multiple bitrates for the same Adaptation, to be more flexible to poor network (low bandwidth) or computing (slow computer) conditions. A Representation has its equivalent in multiple Streaming technologies. It is roughly the same as:  DASH’s Representation Microsoft Smooth Streaming’s QualityIndex HLS’ variant (the notion of variant is actually a little more complex, so here it’s not an exact comparison) ","anchorH1":"glossary","anchorH2":"definitions","anchorH3":"representation"}]},{"file":"./Getting_Started/Troubleshooting.html","index":[{"h1":"Troubleshooting","body":"This page regroups multiple frequent problems that have been encountered with the RxPlayer associated to the found solution. If that solution does not work for you, do not hesitate to create an issue.","anchorH1":"troubleshooting"},{"h1":"Troubleshooting","h2":"autoPlay doesn’t work","body":"  If the media plays automatically despite not setting the autoPlay loadVideo option or setting it to false, check that the media element does not already have an autoplay attribute. If it has, you should remove it so the autoPlay loadVideo option work as intended. We hesitated doing it ourselves but finally chose not to, to not break other applications putting it there for a reason   If the media does not play despite setting the autoPlay loadVideo option to true, it is probably due to the browser blocking it (and in that case, you should also have received a MEDIA_ERROR warning event, with the code MEDIA_ERR_BLOCKED_AUTOPLAY). In that scenario, the content will only be able to play after a user interaction is done on the page (e.g. user clicking on a “play” button). This is a behavior forced by multiple browsers to prevent annoying autoplaying video, generally those who have sound enabled (on that matter, muting the media element might also work).  ","anchorH1":"troubleshooting","anchorH2":"%60autoplay%60_doesn't_work"},{"h1":"Troubleshooting","h2":"Text tracks does not respect the format’s style","body":"  Check that you’re not in the default \"native\" textTrackMode (when either the textTrackMode loadVideo option is not set or is set to native, or when the textTrackElement loadVideo option is not set). If you’re in that case, style-enriched subtitles are only available in the \"html\" textTrackMode. Please set both textTrackMode to \"html\" and a textTrackElement to display text tracks into.  ","anchorH1":"troubleshooting","anchorH2":"text_tracks_does_not_respect_the_format's_style"},{"h1":"Troubleshooting","h2":"Issues when switching the audio track","body":"  If audio tracks take a LOT of time on some devices to change, it may be due to how often low-level audio buffers are updated (from higher-level browser audio buffers) on that device. To fix that solution, you might want to set either the defaultAudioTrackSwitchingMode loadVideo option or the switchingMode property on calls to setAudioTrack to \"direct\", or \"reload\" if you have issues with the former value.   If you lose sound after switching the audio track and you’re in the \"direct\" switchingMode, this is a known issue on some browser versions. Please change the switchingMode to any other value (the closest to \"direct\" being \"reload\".  ","anchorH1":"troubleshooting","anchorH2":"issues_when_switching_the_audio_track"},{"h1":"Troubleshooting","h2":"Parts of a content are automatically skipped/seeked over","body":"The RxPlayer has two complex inner mechanisms that may lead to subparts of a content being seemingly automatically skipped:   A buffer discontinuity detection mechanism that tend to prioritize uninterrupted content playback over content completeness   A browser’s garbage collection detection mechanism that also prioritize the same aspect   When some media data appears to be skipped, it generally means to the RxPlayer that either:  no media data was available at that position media data was available, but the browser stalled trying to play it media data was available at that position, but was immediately garbage collected by the browser, potentially multiple times in a row.  You can investigate in which scenario you are by looking at the RxPlayer’s logs. If you see logs about “GC” (garbage collector) before those skip happen, you might be in the last scenario. If it appears to be insistent, you may want to check the remaining available memory on the device when it happens. If it looks very low, you might want to configure the RxPlayer so less media data is buffered in advance, through either:   the maxVideoBufferSize constructor option, or   the setMaxVideoBufferSize method  ","anchorH1":"troubleshooting","anchorH2":"parts_of_a_content_are_automatically_skipped/seeked_over"},{"h1":"Troubleshooting","h2":"Codec switching does not work","body":"By default, codec switching is performed seamlessly but that does not work on all devices. Please check the onCodecSwitch loadVideo option, and set it to \"reload\" - if that’s not already the case - to see if it fixes the issue.","anchorH1":"troubleshooting","anchorH2":"codec_switching_does_not_work"},{"h1":"Troubleshooting","h2":"The RxPlayer uses a lot of memory","body":"By default the RxPlayer uses the most memory it can to provide the best experience. It may not always what you might want however. To let you configure how much media data is kept at maximum behind and ahead of the current position, you can set respectively a “maximum buffer behind” or a “maximum buffer ahead” in seconds through either:   the maxBufferBehind and maxBufferAhead constructor options.   the setMaxBufferBehind and the setMaxBufferAhead methods   If you’re setting a “maximum buffer ahead”, please keep in mind that it should always be higher than the set “wanted buffer ahead” option wantedBufferAhead constructor option or setWantedBufferAhead method). If you want even a more precize control over memory usage of media data, you can set the “maximum video buffer size” setting through either:   the maxVideoBufferSize constructor option, or   the setMaxVideoBufferSize method  ","anchorH1":"troubleshooting","anchorH2":"the_rxplayer_uses_a_lot_of_memory"},{"h1":"Troubleshooting","h2":"Playback issues related to DRMs","body":"There is a lot of compatibility issues that may be linked to DRMs. Here is some of them.","anchorH1":"troubleshooting","anchorH2":"playback_issues_related_to_drms"},{"h1":"Troubleshooting","h2":"Playback issues related to DRMs","h3":"Issues with fallbacking with the Edge browser and PlayReady","body":"We sometimes encountered a bug which makes the player loads indefinitely when fallbacking from an undecipherable quality, if done through the fallbackOnLastTry option. This was only constated on the Edge browser and appears to be a browser or CDM bug. Sadly, no work-around has been found for now for this issue. We’re currently trying to create a reproducible scenario and document that issue so it can hopefully be fixed in the future. In the meantime, you’re encouraged either to use Widevine (only on Chromium-based Edge) or to not make use of the fallBackOnLastTry option on that browser.","anchorH1":"troubleshooting","anchorH2":"playback_issues_related_to_drms","anchorH3":"issues_with_fallbacking_with_the_edge_browser_and_playready"},{"h1":"Troubleshooting","h2":"Playback issues related to DRMs","h3":"The Player do not download any segment when playing encrypted contents","body":"This is probably due to an issue we encountered several time on embedded devices. Basically, this behavior is due to a deadlock, where the RxPlayer is waiting for the CDM logic to be initialized to download segments but the CDM logic wait for the opposite: it will only initialize itself once segments have been downloaded. The RxPlayer is waiting for the CDM initialization for a very specific usage: playing a mix of unencrypted and encrypted data. We detected that on some Chrome versions we could not play encrypted data if we first played unencrypted data without the CDM logic in place. Fortunately, this usage is for very specific cases and you most likely won’t need it (or even if you will, you most likely will not encounter that problem). You can completely remove that deadlock with a property called disableMediaKeysAttachmentLock. Like other properties introduced here, you should put it in the keySystems object of loadVideo, like such: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       disableMediaKeysAttachmentLock: true,     },     {       type: \"playready\",       getLicense,       disableMediaKeysAttachmentLock: true,     },   ], }); ","anchorH1":"troubleshooting","anchorH2":"playback_issues_related_to_drms","anchorH3":"the_player_do_not_download_any_segment_when_playing_encrypted_contents"},{"h1":"Troubleshooting","h2":"Playback issues related to DRMs","h3":"After two or several loadVideo calls the RxPlayer refuses to play","body":"There’s a chance that you’re encountering another issue we found on embedded devices. By default, the RxPlayer maintains a cache containing the last loaded licenses. This allows to quickly switch to already-played contents, an important improvement when playing live contents for example. Rest assured, our cache size is not infinite, and as such it should work on most devices. However, we found that on some devices, this logic can be problematic, and it will just refuse to add a license at a given point. You can add a property which will flush that cache anytime the content changes, called closeSessionsOnStop. Like other properties introduced here, you should put it in the keySystems object of loadVideo, like such: rxPlayer.loadVideo({   url: MANIFEST_URL,   transport: \"dash\",   keySystems: [     {       type: \"widevine\",       getLicense,       closeSessionsOnStop: true,     },     {       type: \"playready\",       getLicense,       closeSessionsOnStop: true,     },   ], }); ","anchorH1":"troubleshooting","anchorH2":"playback_issues_related_to_drms","anchorH3":"after_two_or_several_loadvideo_calls_the_rxplayer_refuses_to_play"}]},{"file":"./api/Overview.html","index":[{"h1":"RxPlayer API","body":"The API documentation is a thorough guide through every feature exposed by the RxPlayer, in a logical order. If you are already familiar with the API, you might prefer the conciseness of the API reference instead. Conversely, If you are very new to the RxPlayer and don’t want to dive deep in the API for the moment, you might want to check the Getting Started pages instead.  Only variables and methods defined here are considered as part of the API. Any other property or method you might find in any other way are not considered as part of the API and can thus change without notice.   As some terms used here might be too foreign or slightly different than the one you’re used to, we also wrote a list of terms and definitions used by the RxPlayer in a \"Glossary\" page. ","anchorH1":"rxplayer_api"}]},{"file":"./api/Creating_a_Player.html","index":[{"h1":"Creating a RxPlayer","body":"","anchorH1":"creating_a_rxplayer"},{"h1":"Creating a RxPlayer","h2":"Instantiation","body":"Instantiating a new RxPlayer is necessary before being able to load a content. Doing so is straightforward: import RxPlayer from \"rx-player\"; const player = new RxPlayer(options); ","anchorH1":"creating_a_rxplayer","anchorH2":"instantiation"},{"h1":"Creating a RxPlayer","h2":"Player options","body":"Player options are options given to the player on instantiation. It’s an object with multiple properties. None of them are mandatory. For most usecase though, you might want to set at least the associated media element via the videoElement property.","anchorH1":"creating_a_rxplayer","anchorH2":"player_options"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"videoElement","body":"type: HTMLMediaElement|undefined The media element the player will use. Note that despite what its name suggests, this can be a <video> or an <audio> element. // Instantiate the player with the first video element in the DOM const player = new Player({   videoElement: document.getElementsByTagName(\"VIDEO\")[0], });  If not defined, a <video> element will be created without being inserted in the document. You will have to do it yourself through the getVideoElement method to add it yourself: const player = new Player();  const videoElement = player.getVideoElement(); document.body.appendChild(videoElement); ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"videoelement"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"baseBandwidth","body":"type: Number|undefined defaults: 0 The initial value used for bandwidth calculations, in bits per seconds. The RxPlayer will base itself on this value initially before estimating it itself. You can set this value either if you have a rough-enough idea of the user’s current bandwidth and/or if you prefer to start loading specific media qualities initially. For example, to set an initial bandwidth of 700 kilobits per seconds, you can set: const player = new Player({   baseBandwidth: 700000, });   This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"basebandwidth"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"wantedBufferAhead","body":"type: Number|undefined defaults: 30 Set the default buffering goal, as a duration ahead of the current position, in seconds. Once this size of buffer is reached, the player won’t try to download new segments anymore.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"wantedbufferahead"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"maxVideoBufferSize","body":"type: Number|undefined defaults: Infinity Set the maximum size the video buffer can take in the memory, in kilobytes (kb). Once this value is reached, the player won’t try to download new video segments anymore. The limit is approximative as it’s based on internal estimation.  The internal checks of the RxPlayer is based on an estimation of what the RxPlayer think is currently buffered and an estimation of the size of the next segments.   In DirectFile mode (see loadVideo options), this method has no effect.   This option will have no effects if we didn't buffer at least MIN_BUFFER_LENGTH ( defaults at 5sec )   This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"maxvideobuffersize"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"maxBufferAhead","body":"type: Number|undefined defaults: Infinity Set the maximum kept buffer ahead of the current position, in seconds. Everything superior to that limit (currentPosition + maxBufferAhead) will be automatically garbage collected. This feature is not necessary as the browser should by default correctly remove old segments from memory if/when the memory is scarce. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. Its default value, Infinity, will remove this limit and just let the browser do this job instead. The minimum value between this one and the one returned by getWantedBufferAhead will be considered when downloading new segments.  Bear in mind that a too-low configuration there (e.g. inferior to `10`) might prevent the browser to play the content at all.  You can update that limit at any time through the setMaxBufferAhead method.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"maxbufferahead"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"maxBufferBehind","body":"type: Number|undefined defaults: Infinity Set the maximum kept buffer before the current position, in seconds. Everything before that limit (currentPosition - maxBufferBehind) will be automatically garbage collected. This feature is not necessary as the browser should by default correctly remove old segments from memory if/when the memory is scarce. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. Its default value, Infinity, will remove this limit and just let the browser do this job instead. You can update that limit at any time through the setMaxBufferBehind method.  This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"maxbufferbehind"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"videoResolutionLimit","body":"type: string defaults: \"none\" This option allows to throttle the played video resolution according to either the videoElement’s resolution or to the screen resolution, thus preventing to unnecessarily waste bandwidth to load a video quality that won’t be able to be properly displayed anyway. This option can have the following values:   \"videoElement\": The loaded video Representation will be throttled according to the given videoElement’s dimensions. Meaning that the RxPlayer won’t be trying to play higher qualities whose resolutions should not be discernible, with an exception when the picture-in-picture mode is enabled in which case the resolution limit is compared to the picture-in-picture window instead.   \"screen\": The loaded video Representation will be throttled according to the screen’s dimensions. Simply written, the RxPlayer won’t try to play Representation with a resolution higher than the screen resolution with the exception of the immediately superior resolution if no Representation has the same resolution than the screen. You might prefer this value over \"videoElement\" to stay ready when and if the user decides to enter a “fullscreen mode”.   \"none\": No such limit on the video Representation’s resolution will be automatically applied.    This option will have no effect for contents loaded in Directfile mode (see loadVideo options). ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"videoresolutionlimit"},{"h1":"Creating a RxPlayer","h2":"Player options","h3":"throttleVideoBitrateWhenHidden","body":"type: Boolean defaults: false The player has a specific feature which throttle the video to the minimum bitrate when the current video element is considered hidden (e.g. the containing page is hidden and the Picture-In-Picture mode is disabled) for more than a minute. To activate this feature, set it to true. const player = Player({   throttleVideoBitrateWhenHidden: true, });   This option will have no effect for contents loaded :  In DirectFile mode (see loadVideo options). On Firefox browsers (version >= 67) : We can’t know if the Picture-In-Picture feature or window is enabled. Thus we can’t rely on document hiddenness attributes, as the video may be visible, through the PIP window.  ","anchorH1":"creating_a_rxplayer","anchorH2":"player_options","anchorH3":"throttlevideobitratewhenhidden"}]},{"file":"./api/Loading_a_Content.html","index":[{"h1":"Loading a Content","body":"","anchorH1":"loading_a_content"},{"h1":"Loading a Content","h2":"The loadVideo method","body":"The loadVideo method of the RxPlayer loads the content described in the argument. This is the central method to use when you want to play a new content. Options available are described in the next chapters. Despite its name, this method can also load audio-only content.","anchorH1":"loading_a_content","anchorH2":"the_%60loadvideo%60_method"},{"h1":"Loading a Content","h2":"The loadVideo method","h3":"Example","body":"player.loadVideo({   url: \"http://vm2.dashif.org/livesim-dev/segtimeline_1/testpic_6s/Manifest.mpd\",   transport: \"dash\",   autoPlay: true, }); ","anchorH1":"loading_a_content","anchorH2":"the_%60loadvideo%60_method","anchorH3":"example"},{"h1":"Loading a Content","h2":"loadVideo options","body":"loadVideo receives a single object in argument which can take several properties all defined here.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"transport","body":"type: string|undefined The transport protocol used for this content. This property is mandatory. Can be either:   \"dash\" - for DASH contents. If you’re using the minimal build of the player, you will need to add at least either one of the following features to be able to play DASH contents:   the DASH feature (rely on a generally-sufficient JavaScript parser)   the DASH_WASM experimental feature (backed by a WebAssembly parser, more efficient when handling very large MPDs). More information in the DASH_WASM experimental feature documentation.   or both (which will use the latter only when available)     \"smooth\" - for Microsoft Smooth Streaming contents If you’re using the minimal build of the player, you will need to add at least the SMOOTH feature to be able to play Smooth contents.   \"directfile\" - for loading a video in DirectFile mode, which allows to directly play media files (example: .mp4 or .webm files) without using a transport protocol. With that option, you can even play HLS contents on multiple browsers (mainly safari and iOS browsers). If you’re using the minimal build of the player, you will need to add at least the DIRECTFILE feature to be able to play those contents.      In that mode, multiple APIs won't have any effect.   This is documented in the documentation of each concerned method, option or   event in the API.    \"metaplaylist\" for MetaPlaylist streams, which are a concatenation of multiple smooth and DASH contents If you’re using the minimal build of the player, you will need to add at least the METAPLAYLIST experimental feature to be able to play those contents.   \"local\" for local manifests, which allows to play downloaded DASH, Smooth or MetaPlaylist contents (when offline for example). If you’re using the minimal build of the player, you will need to add at least the LOCAL_MANIFEST experimental feature to be able to play those contents.   Example: // play some dash content rxPlayer.loadVideo({   transport: \"dash\",   url: \"https://www.example.com/dash.mpd\", }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"transport"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"url","body":"type: string|undefined For Smooth, DASH or MetaPlaylist contents, the URL to the Manifest (or equivalent) For DirectFile mode contents, the URL of the content (the supported contents depends on the current browser). This property is mandatory unless either:   a manifestLoader option is defined, in which case that callback will be called instead any time we want to load the Manifest.   an initialManifest option is defined, in which case it as the first version of the Manifest. Note however that if the Manifest needs to be refreshed and no url nor manifestLoader has been set, the RxPlayer will most likely fail and stop playback.   Example: // play some dash content rxPlayer.loadVideo({   url: \"https://www.example.com/dash.mpd\",   transport: \"dash\", }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"url"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"keySystems","body":"type: Array.<Object>|undefined keySystems allows to define every options relative to the encryption of the wanted content. This property is mandatory if the content relies on DRM and needs to be decrypted but unnecessary if the content is not encrypted. As keySystems options are numerous, they are described in its own documentation page, Decryption Options.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"keysystems"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"autoPlay","body":"type: Boolean|undefined defaults: false If set to true, the video will play immediately after being loaded.  On some browsers, auto-playing a media without user interaction is blocked due to the browser's policy.   In that case, the player won't be able to play (it will stay in a `LOADED` state) and you will receive a warning event containing a `MEDIA_ERROR` with the code: `MEDIA_ERR_BLOCKED_AUTOPLAY`.   A solution in that case would be to propose to your users an UI element to trigger the play with an interaction. ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"autoplay"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"startAt","body":"type: Object|undefined startAt allows to define a starting position in the played content whether it is a live content or not. This option is only defining the starting position, not the beginning of the content. The user will then be able to navigate anywhere in the content through the seekTo API. If defined, this property must be an object containing a single key. This key can be either:   position (Number): The starting position, in seconds.   wallClockTime (Number|Date): The starting wall-clock time (re-scaled position from Manifest information to obtain a timestamp on live contents), in seconds. Useful to use the type of time returned by the getWallClockTime API for live contents. If a Date object is given, it will automatically be converted into seconds.   fromFirstPosition (Number): relative position from the minimum possible one, in seconds. That is:  for dynamic (live) contents, from the beginning of the buffer depth (as defined by the Manifest). for non-dynamic (vod) contents, from the position 0 (this option should be equivalent to position)    fromLastPosition (Number): relative position from the maximum possible one, in seconds. Should be a negative number:  for dynamic (e.g. live) contents, it is the difference between the starting position and the currently last possible position, as defined by the manifest. for VoD contents, it is the difference between the starting position and the end position of the content.    percentage (Number): percentage of the wanted position. 0 being the minimum position possible (0 for static content, buffer depth for dynamic contents) and 100 being the maximum position possible (duration for VoD content, last currently possible position for dynamic contents).    Only one of those properties will be considered, in the same order of priority they are written here.  If the value set is inferior to the minimum possible position, the minimum possible position will be used instead. If it is superior to the maximum possible position, the maximum will be used instead as well. More information on how the initial position is chosen can be found in the specific documentation page on this subject. Notes for dynamic contents For dynamic contents, startAt could work not as expected:   Depending on the type of Manifest, it will be more or less precize to guess the current last position of the content. This will mostly affect the fromLastPosition option.   If the Manifest does not allow to go far enough in the past (not enough buffer, server-side) to respect the position wanted, the maximum buffer depth will be used as a starting time instead.   If the Manifest does not allow to go far enough in the future to respect the position wanted, the current last available position will be used to define the starting time instead.   If startAt is not set on live contents, the time suggested by the Manifest will be considered. If it is also not set, the initial position will be based on the real live edge. Example // using position player.loadVideo({   // ...   startAt: {     position: 10, // start at position == 10 (in seconds)   }, });  // using wall-clock time player.loadVideo({   // ...   startAt: {     wallClockTime: Date.now() / 1000 - 60, // 1 minute before what's broadcasted     // now   }, });  // using fromFirstPosition player.loadVideo({   // ...   startAt: {     fromFirstPosition: 30, // 30 seconds after the beginning of the buffer   }, });  // using fromLastPosition player.loadVideo({   // ...   startAt: {     fromLastPosition: -60, // 1 minute before the end   }, }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"startat"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"requestConfig","body":"type: Object defaults: {}  This option has no effect in DirectFile mode (see  transport option)  Configuration linked to Manifest and segment requests. This object can take the following properties (all are optional):   segment (object|undefined): If set, segment-specific request configuration. That object can contain any of the following properties:   maxRetry (number|undefined): Maximum number of times a segment request will be retried when an error happen - only on some condition [1]. Those retry will be done with a progressive delay, to avoid overloading a CDN. When this count is reached, the player will stop and throw a fatal error. Defaults to 4.   timeout (number|undefined): Timeout, in milliseconds, after which segment requests are aborted and, depending on other options, retried. To set to -1 for no timeout. undefined (the default) will lead to a default, large, timeout being used.     manifest (object|undefined): If set, manifest-specific request configuration. That object can contain any of the following properties:   maxRetry (number|undefined): Maximum number of times a Manifest request will be retried when a request error happen - only on some condition [1]. Defaults to 4. Those retry will be done with a progressive delay, to avoid overloading a CDN. When this count is reached, the player will stop and throw a fatal error. Defaults to 4.   timeout (number|undefined): Timeout, in milliseconds, after which manifest requests are aborted and, depending on other options, retried. To set to -1 for no timeout. undefined (the default) will lead to a default, large, timeout being used.     [1] To retry a request, one of the following condition should be met:   The request failed because of a 404 HTTP code   The request failed because of an HTTP code in the 500 family   The request failed because of a timeout   the request failed because of an unknown request error (might be a parsing/interface error)  ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"requestconfig"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"textTrackMode","body":"type: string|undefined defaults: \"native\"  This option has no effect in DirectFile mode (see  transport option)  This option allows to specify how the text tracks should be displayed. There is two possible values:  \"native\" \"html\"  In the default \"native\" mode, a <track> element will be created on the video and the subtitles will be displayed by it, with a minimal style. There is no action on your side, the subtitles will be correctly displayed at the right time. In \"html\" mode, the text tracks will be displayed on a specific HTML element. This mode allows us to do much more stylisation, such as the one defined by TTML styling attributes or SAMI’s CSS. It is particularly useful to correctly manage complex closed captions (with multiple colors, positionning etc.). With this mode, you will need to provide a wrapper HTML element with the textTrackElement option. All text track formats supported in \"native\" mode also work in \"html\" mode. More infos on supported text tracks can be found in the text track documentation.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"texttrackmode"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"textTrackElement","body":"type: HTMLElement|undefined  This option has no effect in DirectFile mode (see  transport option)  textTrackElement is only required and used if you provided a \"html\" textTrackMode. This property will be the element on which text tracks will be set, as child elements, at the right time. We expect that this element is the exact same size than the media element it applies to (this allows us to properly place the subtitles position without polling where the video is in your UI). You can however re-size or update the style of it as you wish, to better suit your UI needs.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"texttrackelement"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"minimumManifestUpdateInterval","body":"type: number|undefined  This option has no effect in DirectFile mode (see  transport option)  Set the minimum time, in milliseconds, we have to wait between Manifest updates. A Manifest may need to be updated in regular intervals (e.g. many DASH dynamic contents depend on that behavior). The frequency at which we normally update a Manifest depends on multiple factors: the information taken from the Manifest, the transport chosen or the current playback conditions. You might want to use minimumManifestUpdateInterval to limit that frequency to a minimum. This option is principally useful on some embedded devices where resources are scarce. The request and data decompression done at each Manifest update might be too heavy for some and reducing the interval at which they are done might help. Please note however than reducing that frequency can raise the chance of rebuffering, as we might be aware of newly generated segments later than we would be without that option. Example: rxPlayer.loadVideo({   // ...   minimumManifestUpdateInterval: 5000, // Perform Manifest updates at most                                        // every 5 seconds   }, }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"minimummanifestupdateinterval"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"initialManifest","body":"type: number|undefined  This option has no effect in DirectFile mode (see  transport option)  Manifest that will be initially used (before any potential Manifest refresh). Some applications pre-load the Manifest to parse some information from it before calling loadVideo. As in that case the Manifest has already been loaded, an application can optimize content loading time by giving to the RxPlayer that already-loaded Manifest so the latter can avoid doing another request for it. The format accepted for that option depends on the current chosen transport:   for \"dash\" and \"smooth\" contents either a string (of the whole Manifest’s xml data) or a corresponding Document format is accepted.   for \"metaplaylist\", either a string (for the whole JSON) or the corresponding JS Object is accepted.   for \"local\", only the corresponding local Manifest as a JS object is accepted.   Note that using this option could have implications for live contents. Depending on the content, the initial playing position and maximum position could be calculated based on that option’s value. In a case where the corresponding Manifest request was performed long before the loadVideo call, the RxPlayer could be for example initially playing far from the real live edge. Because of that, it is recommended to only set that options for live/dynamic contents if its request was done immediately before the loadVideo call.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"initialmanifest"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"manifestUpdateUrl","body":"type: string|undefined  This option has no effect in DirectFile mode (see  transport option)  Set a custom Manifest URL for Manifest updates. This URL can point to another version of the Manifest with a shorter timeshift window, to lighten the CPU, memory and bandwidth impact of Manifest updates. Example: rxPlayer.loadVideo({   transport: \"dash\",   url: \"https://example.com/full-content.mpd\",   manifestUpdateUrl: \"https://example.com/content-with-shorter-window.mpd\", });  When the RxPlayer plays a live content, it may have to refresh frequently the Manifest to be aware of where to find new media segments. It generally uses the regular Manifest URL when doing so, meaning that the information about the whole content is downloaded again. This is generally not a problem though: The Manifest is generally short enough meaning that this process won’t waste much bandwidth memory or parsing time. However, we found that for huge Manifests (multiple MB uncompressed), this behavior could be a problem on some low-end devices (some set-top-boxes, chromecasts) where slowdowns can be observed when Manifest refresh are taking place. The manifestUpdateUrl will thus allow an application to provide a second URL, specifically used for Manifest updates, which can represent the same content with a shorter timeshift window (e.g. using only 5 minutes of timeshift window instead of 10 hours for the full Manifest). The content will keep its original timeshift window and the RxPlayer will be able to get information about new segments at a lower cost.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"manifestupdateurl"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"representationFilter","body":"type: Function|undefined  This option has no effect in DirectFile mode (see  transport option)  Allows to filter out Representations (i.e. media qualities) from the Manifest to avoid playing them. rxPlayer.loadVideo({   // ...   representationFilter(representation, infos) {     // Filter function   }, }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"representationfilter"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"segmentLoader","body":"type: Function|undefined  This option has no effect in DirectFile mode (see  transport option)  Defines a custom segment loader for when you want to perform the requests yourself. rxPlayer.loadVideo({   // ...   segmentLoader(infos, callbacks) {     // logic to download a segment   }, });  More info on it can be found here.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"segmentloader"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"manifestLoader","body":"type: Function|undefined  This option has no effect in DirectFile mode (see  transport option)  Defines a custom Manifest loader (allows to set a custom logic for the Manifest request). rxPlayer.loadVideo({   // ...   manifestLoader(url, callbacks) {     // logic to fetch the Manifest   }, });  More info on it can be found here.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"manifestloader"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"onCodecSwitch","body":"type: string|undefined defaults: \"continue\"  This option has no effect in DirectFile mode (see  transport option)  Behavior taken by the player when switching to either an audio or video track which has a codec “incompatible” with the previous one (for example going from avc, a.k.a h264 to hevc, a.k.a. h265). This switch can either after the user switches from one track to another or after encountering a new Period in some transport technologies (concept existing for DASH, “local” and MetaPlaylist contents). Can be set to one of those two values:   \"continue\": try to have a seamless transition between both codecs. This behavior works on most modern browsers but might lead to problems like infinite buffering and decoding errors on older browsers and peculiar platforms. This is the default behavior.   \"reload\": When switching from one codec to another - incompatible - one, the RxPlayer will “reload” the content: the player will go into the \"RELOADING\" state for a small amount of time, during which the video will disappear and many APIs will become unavailable, before playing the track with the new codec. That behavior has the advantage of working on any platform but disadvantage of having a visible transition when those type of codec switches happen. Use it if you have issues with codec switching on some platforms. More information about the \"RELOADING\" state can be found in the player states documentation.  ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"oncodecswitch"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"defaultAudioTrackSwitchingMode","body":"type: string|undefined defaults: \"seamless\"  This option has no effect in DirectFile mode (see  transport option)  Behavior taken by the player by default when switching to a different audio track, for example through the setAudioTrack method. Note that this is only a default value which can be changed at any setAudioTrack call, through its switchingMode optional property. Those are the possible values for that option:   \"seamless\": The transition between the old audio track and the new one happens seamlessly, without interruption. This is the default behavior. As an inconvenient, you might have at worst a few seconds in the previous audio track before the new one can be heard.   \"direct\": The player will try to switch to the new audio track as soon as possible, which might lead to a brief interruption and rebuffering period (where the RxPlayer is in the BUFFERING state) while it is doing so.   \"reload\" The player will directly switch to the new audio track (like direct) but may reload the media to do so. During this reloading step, there might be a black screen instead of the video and the RxPlayer might go into the RELOADING state temporarily. Although it provides a more aggressive transition than the \"direct\" mode (because it goes through a reloading step with a black screen), the \"reload\" mode might be preferable in specific situations where \"direct\" is seen to have compatibility issues. We observed such issues with some contents and devices combinations, if you observe issues such as losing the audio or video glitches just after changing the audio track while the \"direct\" mode is used, you may want to use the \"reload\" mode instead. More information about the \"RELOADING\" state can be found in the player states documentation.  ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"defaultaudiotrackswitchingmode"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"lowLatencyMode","body":"type: Boolean|undefined defaults: false Allow to play DASH low-latency contents (with Chunk-encoded and chunk-transferred CMAF segments) with a low latency efficiently. In the some rare browsers who do not support the fetch API (like IE11 or the BlackBerry browser), we might be more prone to rebuffering in that mode the first few seconds. If you want to have a better experience on those browsers, you might want to begin to play further from the live edge in those cases through the startAt option. More information on playing low-latency DASH contents can be found in the corresponding documentation page.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"lowlatencymode"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"enableFastSwitching","body":"type: boolean|undefined defaults: true  This option has no effect in DirectFile mode (see  transport option)  Enable (when set to true and by default) or disable (when set to false) the “fast-switching” feature. “Fast-switching” is an optimization which allows the RxPlayer to replace low-quality segments (i.e. with a low bitrate) with higher-quality segments (higher bitrate) in the buffer in some situations. This is used for example to obtain a faster quality transition when the user’s network bandwidth raise up: instead of pushing the new high-quality segments at the end of the current buffer, we push them much sooner - “on top” of already pushed low-quality segments - so the user can quickly see the better quality. In most cases, this is a feature you want. On some rare devices however, replacing segments is poorly supported. We’ve for example seen on a few devices that old replaced segments were still decoded (and not the new better-quality segments that should have replaced them). On other devices, replacing segments resulted in visible small decoding issues. Setting enableFastSwitching to false thus allows to disable the fast-switching behavior. Note that it is - sadly - difficult to know when you need to disable it. In the great majority of cases, enabling fast-switching (the default behavior) won’t lead to any problem. So we advise to only disable it when you suspect that segment replacement when the quality raises is at the source of some issues you’re having (in which case it will help to see if that’s really the case). It is also warning to add that setting enableFastSwitching to false only disable the fast-switching feature and not all the logic where the RxPlayer is replacing segments it already pushed to the buffer. Forbiding the RxPlayer to replace segments altogether is today not possible and would even break playback in some situations: when multi-Period DASH contents have overlapping segments, when the browser garbage-collect partially a segment…","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"enablefastswitching"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"checkMediaSegmentIntegrity","body":"type: Function|undefined  This option has no effect in DirectFile mode (see  transport option)  If set to true, the RxPlayer will retry a media segment request if that segment seems corrupted. If not set or set to false, the RxPlayer might interrupt playback in the same situation. You can set this option if you suspect the CDN providing your contents to sometimes send you incomplete/corrupted segments. Example: rxPlayer.loadVideo({   // ...   checkMediaSegmentIntegrity: true, }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"checkmediasegmentintegrity"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"serverSyncInfos","body":"type: Function|undefined  This option has no effect in DirectFile mode (see  transport option)  Allows to provide a time synchronization mechanism between the client and the server. This value is mainly useful for live DASH contents based on a SegmentTemplate scheme without SegmentTimeline elements as those rely on having a synchronized clock on the client side. The serverSyncInfos object contains two keys:   serverTimestamp (number): Unix timestamp of the server at a given point in time, in milliseconds.   clientTime (number): Value of the performance.now() API at the time the serverTimestamp value was true. Please note that if your page contains multiple worker, the performance.now() call should be done on the same worker than the one in which loadVideo is called.  The `performance.now()` API is used here because it is the main API to obtain a monotically increasing clock on the client-side.    Example: const timeResponse = await fetch(timeServerURL); const clientTime = performance.now(); const serverTimestamp = await timeResponse.text(); const serverSyncInfos = { serverTimestamp, clientTime }; rxPlayer.loadVideo({   // ...   serverSyncInfos, });  If indicated, we will ignore any time indication on the MPD and only consider serverSyncInfos to calculate the time on the server side. This value is also very useful for low-latency contents, as some of them do not indicate any server’s time, relying on the client one instead. Note that there is a risk of us losing synchronization when leap seconds are added/substracted to unix time. However we consider those situations rare enough (and the effect should be relatively weak) to let this as is for the moment. For a complete explanation, you can look at the corresponding chapter of the low-latency documentation.","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"serversyncinfos"},{"h1":"Loading a Content","h2":"loadVideo options","h3":"referenceDateTime","body":"type: Function|undefined  This option has no effect in DirectFile mode (see  transport option)  Only useful for live contents. This is the default amount of time, in seconds, to add as an offset to a given media content’s time, to obtain the real live time. For example, if the media has it’s 0 time corresponding to the 30th of January 2010 at midnight, you can set the referenceDateTime to new Date(2010-01-30) / 1000. This value is useful to communicate back to you the “live time”, for example through the getWallClockTime method. This will only be taken into account for live contents, and if the Manifest / MPD does not already contain an offset (example: an “availabilityStartTime” attribute in a DASH MPD). Example: rxPlayer.loadVideo({   // ...   referenceDateTime: new Date(2015 - 05 - 29) / 1000, }); ","anchorH1":"loading_a_content","anchorH2":"%60loadvideo%60_options","anchorH3":"referencedatetime"}]},{"file":"./api/Decryption_Options.html","index":[{"h1":"Decryption Options","body":"","anchorH1":"decryption_options"},{"h1":"Decryption Options","h2":"Overview","body":"The RxPlayer has a lot of decryption-related options that you can give when calling the loadVideo method, itself described in the previous documentation page. This page will desribe most of them. In the case you find this documentation hard to grasp, we’ve written a tutorial on DRM configuration here.","anchorH1":"decryption_options","anchorH2":"overview"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","body":"keySystems is a loadVideo option allowing to communicate your decryption-related preferences. It takes the form of an array of objects, themselves potentially containing any of the properties described here. Each object in the keySystems array will describe decryption configuration, from the most preferred (the one you wish to be apply) to the least preferred (the fallback configurations). That way, the RxPlayer will first try to apply the configuration linked to the first object. If it fails, it will try the second and so on. If all configurations fail, the RxPlayer will stop playback with an ENCRYPTED_MEDIA_ERROR with the INCOMPATIBLE_KEYSYSTEMS code (see error documentation). Mostly, the type and getLicense properties are usually mandatory for encrypted contents. Depending on your situation you might also want to set other options.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"type","body":"type: string Name of the DRM system used. Can be either one of:  \"widevine\" \"playready\" \"clearkey\"  For more specific (or just different ones), the full reverse domain name of the key system can be used instead, for example:  \"com.widevine.alpha\", \"com.microsoft.playready.hardware\" \"com.apple.fps.1_0\" etc.  Example rxPlayer.loadVideo({   // ...   keySystems: [     {       type: \"com.microsoft.playready.recommendation\",       // ...     }     // ...   ] }); ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"type"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"getLicense","body":"type: Function Callback which will be triggered everytime a message is sent by the Content Decryption Module (CDM), usually to fetch/renew the license. Gets two arguments when called:  the message (Uint8Array): The message, formatted to an Array of bytes. the messageType (string): String describing the type of message received. There is only 4 possible message types, all defined in the w3c specification.  This function should return either synchronously the license, null to not set a license for this message event or a Promise which should either:  resolve if the license was fetched, with the licence in argument resolve with null if you do not want to set a license for this message event reject if an error was encountered.  Note: We set a 10 seconds timeout by default on this request (configurable through the keySystems[].getLicenseConfig object). If the returned Promise do not resolve or reject under this limit, the RxPlayer will stop with an error. In any case, if a license is provided by this function it should be under a BufferSource type (example: an Uint8Array or an ArrayBuffer). If this callback throws or rejects, the RxPlayer will either:   retry if new retry attempts can be done according to the parameters given as getLicenseConfig and if the noRetry property of the last rejected/throwed value was not set to true. In that case an error with the KEY_LOAD_ERROR code will still be emitted through a warning event to indicate that this attempt as failed.   stop playback, emitting an error event with the KEY_LOAD_ERROR code, if no attempt is left to be done (or if the noRetry property of the last throwed/rejected error was set to true) AND if the fallbackOnLastTry property on the last throwed/rejected error was not set to true.   try to fallback to a different Representation (a.k.a. media profile) if no attempt is left to be done (or if the noRetry property of the last throwed/rejected error was set to true) AND if the fallbackOnLastTry property on the last throwed/rejected error WAS set to true. In that case an error with the KEY_LOAD_ERROR code will still be emitted through a warning event to indicate that this attempt as failed. If we have no Representation to fallback to anymore, we will throw a MediaError with a NO_PLAYABLE_REPRESENTATION code, as documented in the errors documentation.   If the getLicense call throws/rejects, you can add any of the following properties (none are mandatory) to configure the behavior of the RxPlayer relative to that failure:   noRetry (Boolean): If set to true, we won’t make another attempt to call getLicense for this particular message. This will result in:  if the fallbackOnLastTry boolean has been set to true, it will trigger a fallback to another Representations (and a KEY_LOAD_ERROR warning being sent) if possible (and throw a NO_PLAYABLE_REPRESENTATION error code if there’s no Representation left to fallback to, as documented in the fallbackOnLastTry property documentation). If not, a KEY_LOAD_ERROR error code will be directly thrown and playback will be stopped.  If set to false or not set, the current retry parameters will be applied (see getLicenseConfig)   message (string): If the message property is set as a “string”, this message will be set as the message property of the corresponding EncryptedMediaError (either communicated through an \"error\" event if we’re not retrying or through a \"warning\" event if we’re retrying). As every other getLicense-related errors, this error will have the KEY_LOAD_ERROR code property.   fallbackOnLastTry (boolean): If this getLicense is the last retry (if the noRetry property is set to true, this is always true), we will not throw immediately but rather try to fallback on other Representations (e.g. qualities) which might have a different decryption key. If no Representation is left, we will throw a MediaError with a NO_PLAYABLE_REPRESENTATION code, as documented in the errors documentation. This option is thus only useful for contents depending on multiple licenses. When fallbacking, we might need to reload the current MediaSource, leading to a black screen during a brief instant. When reloading, the RxPlayer will have the \"RELOADING\" player state. on most situations, we will however not reload the media source but only perform a very little seek (of some milliseconds). you might see the stream stutter for a very brief instant at that point. On the Edge browser, we found an issue that can arise when this option is set if PlayReady is used. This issue can make the player loads the content indefinitely. Sadly, no work-around has been found for now for this issue. We’re currently trying to create a reproducible scenario and document that issue so it can hopefully be fixed in the future. In the meantime, you’re encouraged either to use Widevine (only on Chromium-based Edge) or to not make use of the fallBackOnLastTry option on that browser.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"getlicense"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"getLicenseConfig","body":"type: Object | undefined Optional configuration for the keySystems[].getLicense callback. Can contain the following properties:   retry (Number|undefined) (default: 2): number of time getLicense is retried on error or on timeout before we fail on a KEY_LOAD_ERROR   timeout (Number|undefined) (default: 10000): timeout, in milliseconds after which we consider the getLicense callback to have failed. Set it to -1 to disable any timeout.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"getlicenseconfig"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"serverCertificate","body":"type: BufferSource | undefined Eventual certificate used to encrypt messages to the license server. If set, we will try to set this certificate on the CDM. If it fails, we will still continue to try deciphering the content (albeit a warning will be emitted in that case with the code \"LICENSE_SERVER_CERTIFICATE_ERROR\").","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"servercertificate"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"persistentLicenseConfig","body":"type: Object | undefined Set it only if you want to load persistent-license(s) for later retrieval. Note that not all licenses can be persisted, this is dependent both on the loaded licenses and on the Content Decryption Module used in the browser. This is an object containing the following properties:   save (Function): function which takes into argument an Array.<Object> which will contain information on all the DRM sessions the RxPlayer currently needs to save. No return value is needed.   load (Function): Function which takes no argument and returns the last stored Array.<Object> (the last one given to save).   disableRetroCompatibility (boolean): If set to true the RxPlayer might not be able to load licenses persisted through an older RxPlayer version. This will allow to unlock some optimizations, for example to allow a faster loading of the current content. We recommend setting that option to true if retrieving persisted licenses through older versions are not that warning to you.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"persistentlicenseconfig"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"maxSessionCacheSize","body":"type: number | undefined The RxPlayer maintains a cache of recently opened MediaKeySession (and consequently of recently fetched licenses) as an optimization measure. That way, loading a content whose license had already been fetched won’t necessitate a new license request, leading to shorter loading times and less requests. The size of this cache is usually kept relatively low (in the 10s) by the player. We found out however that some devices have an even lower limit for the number of MediaKeySession that can be created at the same time. The maxSessionCacheSize option allows to configure the maximum number of MediaKeySession that should be kept “alive” at the same time. Any supplementary older MediaKeySession will be closed, at least when the time comes to create a new one.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"maxsessioncachesize"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"closeSessionsOnStop","body":"type: Boolean | undefined If set to true, the MediaKeySession created for a content will be immediately closed when the content stops its playback. This might be required by your key system implementation (most often, it is not). If set to false or not set, the MediaKeySession can be reused if the same content needs to be re-decrypted. If you want to set this property because the current device has a limited number of MediaKeySession that can be created at the same time, prefer using maxSessionCacheSize instead.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"closesessionsonstop"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"singleLicensePer","body":"type: string | undefined Allows to use optimally a single license for multiple decryption keys. Can be set to the following values:   \"init-data\": This is the default value. Under that behavior, the RxPlayer will try to fetch a new license any time it encounters an unknown encryption initialization data in the current content. This usually means that a license will be fetched any time a new decryption key is encountered, which is the most sensible thing to do in most cases.   \"content\": Only fetch a single license for the whole content, even if the content has multiple keys. Under that behavior, only a single license will be fetched, with a “challenge” generated from the first encryption initialization data encountered. Not only that, all Representations (qualities) whose key was not present in the license will be fallbacked from[1], meaning that they won’t be played anymore.   \"periods\": Each license fetched will be assumed to be for a group of Periods. That is, the RxPlayer will assume that any license fetched:   will contain all the compatible keys for the Period of the Representation for which the license request was done. That is, if the license request was done for a Representation in the second Period, the license fetched will be assumed to contain all compatible keys linked to the second Period. This means that all expected keys which are absent will be considered as not compatible - thus their corresponding Representation will be fallbacked from[1]).   may contain all compatible keys for some other Periods (or all other Periods). The rule here is that as long as the license contain at least one decryption key linked to a Representation of any other Period, the RxPlayer will assume that the license server returned all compatible keys for that Period. Any other key linked to that Period but absent from the license will considered as not compatible - and thus their corresponding Representation will be fallbacked from[1].   This option allows to avoid doing too much license requests (compared to the default “init-data” mode) for contents encrypted with multiple keys, but also may be preferable to the “content” mode in any of the following situations:   You don’t know all upcoming keys in advance. Here you can just communicate them by groups of Periods   The devices on which the RxPlayer will play are not able to store all keys needed for a single content at once Here you can just provide a limited number of keys, linked to a limited number of Periods.     [1] Note that while fallbacking, it is possible that the player goes into the \"RELOADING\" state (during which the video will disappear and many APIs will become unavailable). More information about the \"RELOADING\" state can be found in the player states documentation. You can set this option as an optimization (to only perform a single license requests instead of many while playing contents encrypted with multiple keys) but only if the corresponding optimizations have also been performed on the side of the license server (to return a license for every keys even if one for a single key was asked for).","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"singlelicenseper"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"disableMediaKeysAttachmentLock","body":"type: Boolean | undefined In regular conditions, we might want to wait for the media element to have decryption capabilities (what we call here “MediaKeys attachment”) before beginning to load the actual content. Waiting for that capability validation first allows for example to play a content which contains both encrypted and unencrypted data on Chrome and Chromium-derived browsers. However, we found that on some peculiar devices (like some set-top boxes) this can create a deadlock: the browser might wait for some content to be loaded before validating the media element’s decryption capabilities. Because we didn’t find a good enough compromise for now, we added the disableMediaKeysAttachmentLock boolean. By setting it to true, we won’t wait for “MediaKeys attachment” before pushing the first content. The downside being that content of mixed unencrypted/encrypted data might not be playable with that configuration. You can try that property if your encrypted contents seems to be loading indefinitely on some peculiar targets.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"disablemediakeysattachmentlock"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"distinctiveIdentifier","body":"type: String | undefined Whether the use of Distinctive Indentifier(s) or Distinctive Permanent Identifier(s) will be required, optional or not-allowed. It can be set to any value of the MediaKeysRequirement enumeration, as declared here in the EME specification. This is not needed for most use cases.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"distinctiveidentifier"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"persistentState","body":"type: String | undefined Whether the decryption module’s ability to persist state will be required, optional or not-allowed. This includes session data and any other type of state, but does not include distinctive identifiers, for which there’s another keySystems option, distinctiveIdentifier. If the persistentLicenseConfig keySystems option has been set to true, setting this value to \"required\" is redundant and therefore unnecessary (as exploiting persistent licenses already necessitate the ability to persist session state). It can be set to any value of the MediaKeysRequirement enumeration, as declared here in the EME specification. This is not needed for most use cases.","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"persistentstate"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"onKeyOutputRestricted","body":"type: string | undefined \"error\" by default. Behavior the RxPlayer should have when a key has the status \"output-restricted\". This is the proper status for a key refused due to output restrictions. onKeyOutputRestricted can be set to a string, each describing a different behavior, the default one if not is defined being \"error\":   \"error\": The RxPlayer will stop on an error when any key has the \"output-restricted\" status. This is the default behavior. The error emitted in that case should be an EncryptedMediaError with a KEY_STATUS_CHANGE_ERROR code property with a set keyStatuses property containing at least one string set to \"output-restricted\".   \"continue\": The RxPlayer will not do anything when a key has the \"output-restricted\" status. This may lead in many cases to infinite rebuffering.   \"fallback\": The Representation(s) linked to the problematic key(s) will be fallbacked from, meaning the RxPlayer will switch to other representation without keys with a problematic status. If no Representation remains, an error with the NO_PLAYABLE_REPRESENTATION code will be thrown. Note that when the “fallbacking” action is taken, the RxPlayer might temporarily switch to the \"RELOADING\" state - which should thus be properly handled.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"onkeyoutputrestricted"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"onKeyInternalError","body":"type: string | undefined \"error\" by default. Behavior the RxPlayer should have when a key has the status \"internal-error\". onKeyInternalError can be set to a string, each describing a different behavior, the default one if not is defined being \"error\":   \"error\": The RxPlayer will stop on an error when any key has the \"internal-error\" status. This is the default behavior. The error emitted in that case should be an EncryptedMediaError with a KEY_STATUS_CHANGE_ERROR code property with a set keyStatuses property containing at least one string set to \"internal-error\".   \"continue\": The RxPlayer will not do anything when a key has the \"internal-error\" status. This may lead in many cases to infinite rebuffering.   \"fallback\": The Representation(s) linked to the problematic key(s) will be fallbacked from, meaning the RxPlayer will switch to other representation without keys with a problematic status. If no Representation remains, an error with the NO_PLAYABLE_REPRESENTATION code will be thrown. Note that when the “fallbacking” action is taken, the RxPlayer might temporarily switch to the \"RELOADING\" state - which should thus be properly handled.   \"close-session\": The RxPlayer will close and re-create a DRM session (and thus re-download the corresponding license) if any of the key associated to this session has the \"internal-error\" status. It will try to do so in an efficient manner, only reloading the license when the corresponding content plays. The RxPlayer might go through the \"RELOADING\" and/or light decoding glitches can arise while doing so, depending on the platform, for some seconds, under that mode.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"onkeyinternalerror"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"onKeyExpiration","body":"type: string | undefined \"error\" by default. Behavior the RxPlayer should have when one of the key is known to be expired. onKeyExpiration can be set to a string, each describing a different behavior, the default one if not is defined being \"error\":   \"error\": The RxPlayer will stop on an error when any key is expired. This is the default behavior. The error emitted in that case should be an EncryptedMediaError with a KEY_STATUS_CHANGE_ERROR code property with a set keyStatuses property containing at least one string set to \"expired\".   \"continue\": The RxPlayer will not do anything when a key expires. This may lead in many cases to infinite rebuffering.   \"fallback\": The Representation(s) linked to the expired key(s) will be fallbacked from, meaning the RxPlayer will switch to other representation without expired keys. If no Representation remains, an error with the NO_PLAYABLE_REPRESENTATION code will be thrown. Note that when the “fallbacking” action is taken, the RxPlayer might temporarily switch to the \"RELOADING\" state - which should thus be properly handled.   \"close-session\": The RxPlayer will close and re-create a DRM session (and thus re-download the corresponding license) if any of the key associated to this session expired. It will try to do so in an efficient manner, only reloading the license when the corresponding content plays. The RxPlayer might go through the \"RELOADING\" state after an expired key and/or light decoding glitches can arise, depending on the platform, for some seconds, under that mode.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"onkeyexpiration"},{"h1":"Decryption Options","h2":"loadVideo keySystems options","h3":"videoCapabilitiesConfig / audioCapabilitiesConfig","body":"type: Object | undefined videoCapabilitiesConfig and audioCapabilitiesConfig allow to configure respectively the videoCapabilities and audioCapabilities of the wanted key system. Setting one of these options (or both) allows for example to signal that some robustness level (SL3000, Widevine L1…) are explicitely wanted when decrypting respectively video and audio and/or that the key system should also be compatible to specific video/audio codecs and containers. Those options are relatively advanced, thus it is preferable to let them to undefined unless you understand what you’re doing. The values videoCapabilitiesConfig and audioCapabilitiesConfig can be set to have a similar format They can both be set to an object with two properties: type and value. The content of the value property totally depends on the set type property. The type property can be set to one of the three following values:   \"robustness\": When type is set to \"robustness\", value should be set to an array of strings, each defining a wanted key system robustness by order of preference. For example: { type: \"robustness\", value: [\"3000\", \"2000\"] }  Mean that you want first a \"3000\" robustness and - if not available - a \"2000\" one. Note that when type is set to \"robustness\", default mime-types - defined by the RxPlayer - will be considered in the resulting sequence of MediaKeySystemMediaCapability objects. Those should be compatible with most usages.   \"contentType\": When type is set to \"contentType\", value should be set to an array of strings, each defining by order of preference mimeTypes of the video content to decrypt (if you’re setting videoCapabilitiesConfig) or of the audio contents to decrypt (if you’re setting audioCapabilitiesConfig.). Note that when type is set to \"contentType\", chosen robustnesses in the corresponding sequence of MediaKeySystemMediaCapability objects will have a default value chosen by the RxPlayer. Those should be compatible with most usages.   \"full\": When type is set to \"full\", value should be set to an array of object, each being, a MediaKeySystemMediaCapability object. This value will then be taken as is, either as the wanted videoCapabilities (if you’re setting the videoCapabilitiesConfig property) or as the wanted audioCapabilities (if you’re setting the audioCapabilitiesConfig property) of the resulting MediaKeySystemConfiguration wanted by the RxPlayer.  ","anchorH1":"decryption_options","anchorH2":"loadvideo_%60keysystems%60_options","anchorH3":"videocapabilitiesconfig_/_audiocapabilitiesconfig"}]},{"file":"./api/Basic_Methods/getPlayerState.html","index":[{"h1":"getPlayerState","body":"","anchorH1":"getplayerstate"},{"h1":"getPlayerState","h2":"Description","body":"Returns the “state” the player is currently in. Can be either one of those strings:   \"STOPPED\": The player is idle. No content is loading nor is loaded.   \"LOADING\": The player is loading a new content. Most APIs related to the current content are not yet available while the content is loading.   \"LOADED\": The player has loaded the new content, it is now ready to play. From this point onward you can use APIs interacting with the current content such as seekTo or setAudioTrack.   \"PLAYING\": The player is currently playing the content.   \"PAUSED\": The player has paused.   \"ENDED\": The player has reached the end of the current content.   \"BUFFERING\": the player has reached the end of the buffer and is waiting for data to be appended.   \"FREEZING\": The player cannot play the content despite having enough data, due to an unknown reason. In most of those cases, the RxPlayer will be able to continue playback by itself, after some time. As such, most FREEZING cases can be treated exactly like a BUFFERING state.   \"SEEKING\": The player has reached the end of the buffer because a seek has been performed, new segments are being loaded.   \"RELOADING\": The player needs to reload its current (for example, when switching the current video track). While this state is active, most API related to the currently playing content are not available. This state should be treated like the LOADING state.   As it is a central part of our API and can be difficult concept to understand, we have a special page of documentation on player states.","anchorH1":"getplayerstate","anchorH2":"description"},{"h1":"getPlayerState","h2":"Syntax","body":"const state = player.getPlayerState();   return value string:  The current state of the player. ","anchorH1":"getplayerstate","anchorH2":"syntax"},{"h1":"getPlayerState","h2":"Example","body":"switch (player.getPlayerState()) {   case \"STOPPED\":     console.log(\"No content is/will be playing\");     break;   case \"LOADING\":     console.log(\"A new content is currently loading\");     break;   case \"LOADED\":     console.log(\"The new content is loaded and ready to be played\");     break;   case \"PLAYING\":     console.log(\"The player is currently playing\");     break;   case \"PAUSED\":     console.log(\"The player is currently paused\");     break;   case \"BUFFERING\":     console.log(\"The player is paused while buffering new data\");     break;   case \"FREEZING\":     console.log(\"The player is frozen\");     break;   case \"SEEKING\":     console.log(\"The player is still seeking, waiting for new data\");     break;   case \"ENDED\":     console.log(\"The player has reached the end of the content.\");     break;   case \"RELOADING\":     console.log(\"The player is currently reloading the content\");     break;   default:     console.log(\"This is impossible!\");     break; } ","anchorH1":"getplayerstate","anchorH2":"example"}]},{"file":"./api/Basic_Methods/addEventListener.html","index":[{"h1":"addEventListener","body":"","anchorH1":"addeventlistener"},{"h1":"addEventListener","h2":"Description","body":"Add an event listener to trigger a callback as it happens. The callback will have the event payload as a single argument. The RxPlayer API is heavily event-based. As an example: to know when a content is loaded, the most straightforward way is to add an event listener for the \"playerStateChange\" event. This can be done only through this method. To have the complete list of player events, consult the Player events page.","anchorH1":"addeventlistener","anchorH2":"description"},{"h1":"addEventListener","h2":"Syntax","body":"player.addEventListener(event, callback);    arguments:   event string: The wanted event’s name.   callback Function: The callback for the event. The same callback may be used again when calling removeEventListener.    ","anchorH1":"addeventlistener","anchorH2":"syntax"},{"h1":"addEventListener","h2":"Example","body":"player.addEventListener(\"error\", function (err) {   console.log(`The player stopped with an error: ${err.message}`); }); ","anchorH1":"addeventlistener","anchorH2":"example"}]},{"file":"./api/Basic_Methods/removeEventListener.html","index":[{"h1":"removeEventListener","body":"","anchorH1":"removeeventlistener"},{"h1":"removeEventListener","h2":"Description","body":"Remove an event listener. That is, remove a callback previously registered with addEventListener from being triggered on the corresponding event. This also free-up the corresponding ressources. The callback given is optional: if not given, every registered callback to that event will be removed.","anchorH1":"removeeventlistener","anchorH2":"description"},{"h1":"removeEventListener","h2":"Syntax","body":"// Remove all callbacks linked to event player.removeEventListener(event);  // Remove specific listener player.removeEventListener(event, callback);    arguments:   event string: The event name.   callback (optional) Function|undefined: The callback given when calling the corresponding addEventListener API.    ","anchorH1":"removeeventlistener","anchorH2":"syntax"},{"h1":"removeEventListener","h2":"Example","body":"player.removeEventListener(\"playerStateChange\", listenerCallback); ","anchorH1":"removeeventlistener","anchorH2":"example"}]},{"file":"./api/Basic_Methods/play.html","index":[{"h1":"play","body":"","anchorH1":"play"},{"h1":"play","h2":"Description","body":"Play/resume the current loaded video. Equivalent to a video element’s play method. You might want to call that method either to start playing (when the content is in the \"LOADED\" state and auto-play has not been enabled in the last loadVideo call) or to resume when the content has been paused. The returned Promise informs you on the result:   if playback succeeds, the Promise is fulfilled   if playback fails, the Promise is rejected along with an error message explaining the failure - coming directly from the browser. Such failure can for example be due to your browser’s policy, which may forbid to call play on a media element without any user interaction. Please note that in that case, you will also receive a warning event containing a MEDIA_ERROR with the code: MEDIA_ERR_PLAY_NOT_ALLOWED.    On browsers which do not support Promises natively (such as Internet Explorer 11), a JavaScript implementation is provided instead. This implementation has the exact same implementation than ES2015 Promises.  You might want for a content to be loaded before being able to play (the current state has to be different than LOADING, RELOADING or STOPPED).","anchorH1":"play","anchorH2":"description"},{"h1":"play","h2":"Syntax","body":"player.play();   return value Promise.<void>: Resolves when the play operation succeeded or reject when it failed. ","anchorH1":"play","anchorH2":"syntax"},{"h1":"play","h2":"Example","body":"const resumeContent = () => {   player.play(); }; ","anchorH1":"play","anchorH2":"example"}]},{"file":"./api/Basic_Methods/pause.html","index":[{"h1":"pause","body":"","anchorH1":"pause"},{"h1":"pause","h2":"Description","body":"Pause the current loaded video. Equivalent to a video element’s pause method. Note that a content can be paused even if its current state is BUFFERING, SEEKING or FREEZING. You might want for a content to be loaded before being able to pause (the current state has to be different than LOADING, RELOADING or STOPPED).","anchorH1":"pause","anchorH2":"description"},{"h1":"pause","h2":"Syntax","body":"player.pause(); ","anchorH1":"pause","anchorH2":"syntax"},{"h1":"pause","h2":"Example","body":"const pauseContent = () => {   player.pause(); }; ","anchorH1":"pause","anchorH2":"example"}]},{"file":"./api/Basic_Methods/stop.html","index":[{"h1":"stop","body":"","anchorH1":"stop"},{"h1":"stop","h2":"Description","body":"Stop playback of the current content if one. This will totaly un-load the current content. To re-start playing the same content, you can either call the reload method or just call loadVideo again.","anchorH1":"stop","anchorH2":"description"},{"h1":"stop","h2":"Syntax","body":"player.stop(); ","anchorH1":"stop","anchorH2":"syntax"},{"h1":"stop","h2":"Example","body":"const stopVideo = () => {   player.stop(); }; ","anchorH1":"stop","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getPosition.html","index":[{"h1":"getPosition","body":"","anchorH1":"getposition"},{"h1":"getPosition","h2":"Description","body":"Returns the current media element’s playing position, in seconds. For live contents, the returned position will not be re-scaled to correspond to a live timestamp. If you want that behavior, you can call getWallClockTime instead. This is the only difference between the two. Generally, you can follow the following rule:   if you want to use that current position to use it with the other APIs (like seekTo, getMinimumPosition, getMaximumPosition etc.) use getPosition - as this is the real position in the media.   if you want to display the current position to the viewer/listener, use getWallClockTime instead - as it will be set in the proper scale for live contents to display the right live time.  ","anchorH1":"getposition","anchorH2":"description"},{"h1":"getPosition","h2":"Syntax","body":"const position = player.getPosition();   return value number: The current media element’s position. ","anchorH1":"getposition","anchorH2":"syntax"},{"h1":"getPosition","h2":"Example","body":"const pos = player.getPosition(); console.log(`The video element's current position is: ${pos} second(s)`); ","anchorH1":"getposition","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getWallClockTime.html","index":[{"h1":"getWallClockTime","body":"","anchorH1":"getwallclocktime"},{"h1":"getWallClockTime","h2":"Description","body":"Returns the current “wall-clock” playing position in seconds. That is:   for live contents, this is the current position scaled to correspond to a live timestamp, in seconds.   for non-live contents, returns the position from the absolute beginning time of the content, also in seconds. In the absolute majority of cases this will be equal to the value returned by getPosition.   Use this method to display the current position to the user.","anchorH1":"getwallclocktime","anchorH2":"description"},{"h1":"getWallClockTime","h2":"Syntax","body":"const wallClockTime = player.getWallClockTime();   return value number: Current “wall-clock” position. ","anchorH1":"getwallclocktime","anchorH2":"syntax"},{"h1":"getWallClockTime","h2":"Example","body":"const wallClockTime = player.getWallClockTime(); const nowInSeconds = Date.now() / 1000; const delta = nowInSeconds - wallClockTime;  if (delta < 5) {   // (5 seconds of margin)   console.log(\"You're playing live\"); } else {   console.log(`You're playing ${delta} seconds behind the live content`); } ","anchorH1":"getwallclocktime","anchorH2":"example"}]},{"file":"./api/Basic_Methods/seekTo.html","index":[{"h1":"seekTo","body":"","anchorH1":"seekto"},{"h1":"seekTo","h2":"Description","body":"Seek in the current content (i.e. change the current position). The argument can be an object with a single Number property, either:   relative: seek relatively to the current position   position: seek to the given absolute position (equivalent to player.getVideoElement().currentTime = newPosition)   wallClockTime: seek to the given wallClock position, as returned by getWallClockTime.   The argument can also just be a Number property, which will have the same effect than the position property (absolute position). Seeking should only be done when a content is loaded (i.e. the player isn’t in the STOPPED, LOADING or RELOADING state). The seek operation will start as soon as possible, in almost every cases directly after this method is called. You will know when the seek is being performed and has been performed respectively by listening to the seeking and seeked player events (see the player events page). While seeking, the RxPlayer might also switch to the SEEKING state.","anchorH1":"seekto","anchorH2":"description"},{"h1":"seekTo","h2":"Syntax","body":"player.seekTo(position);    arguments:  position Object|number: The position you want to seek to.   ","anchorH1":"seekto","anchorH2":"syntax"},{"h1":"seekTo","h2":"Examples","body":"// seeking to 54 seconds from the start of the content player.seekTo({ position: 54 });  // equivalent to just: player.seekTo(54);  // seeking 5 seconds after the current position player.seekTo({ relative: 5 });  // seeking 5 seconds before the current position player.seekTo({ relative: -5 });  // seeking to live content player.seekTo({ wallClockTime: Date.now() / 1000 }); ","anchorH1":"seekto","anchorH2":"examples"}]},{"file":"./api/Basic_Methods/getMinimumPosition.html","index":[{"h1":"getMinimumPosition","body":"","anchorH1":"getminimumposition"},{"h1":"getMinimumPosition","h2":"Description","body":"Returns the minimum seekable player position. Returns null if no content is loaded. This is useful for live contents, where the earliest time at which it is possible to seek usually evolves over time. This method allows to know the earliest possible time a seek can be performed at any point in time. As the given position is the absolute minimum position, you might add a security margin (like a few seconds) when seeking to this position in a live content. Not doing so could led to the player being behind the minimum position after some time (e.g. because of buffering or decoding issues), and thus unable to continue playing. You will be alerted if the player’s position fell behind the minimum possible position by receiving a warning event (see the player events page) with an error having a MEDIA_TIME_BEFORE_MANIFEST code property (see the player errors page). Note that you can also have those warnings without any seek operation, e.g. due to buffering for too long. For VoD contents, as the minimum position normally doesn’t change, seeking at the minimum position should not cause any issue.","anchorH1":"getminimumposition","anchorH2":"description"},{"h1":"getMinimumPosition","h2":"Syntax","body":"const minimumPosition = player.getMinimumPosition();   return value number|null: Minimum seekable position. null if no content is currently loaded. ","anchorH1":"getminimumposition","anchorH2":"syntax"},{"h1":"getMinimumPosition","h2":"Example","body":"// Seeking close to the minimum position (with a 5 seconds security margin) player.seekTo({ position: player.getMinimumPosition() + 5 }); ","anchorH1":"getminimumposition","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getMaximumPosition.html","index":[{"h1":"getMaximumPosition","body":"","anchorH1":"getmaximumposition"},{"h1":"getMaximumPosition","h2":"Description","body":"Returns the maximum seekable player position. Returns null if no content is currently loaded. This is useful for live contents, where this position might be updated continously as new content is generated. This method allows thus to seek directly at the live edge of the content. Please bear in mind that seeking exactly at the maximum position is rarely a good idea:  for VoD contents, the playback will end for live contents, the player will then need to wait until it can build enough buffer.  As such, we advise to remove a few seconds from that position when seeking.","anchorH1":"getmaximumposition","anchorH2":"description"},{"h1":"getMaximumPosition","h2":"Syntax","body":"const maximumPosition = player.getMaximumPosition();   return value number|null: Maximum seekable position. null if no content is currently loaded. ","anchorH1":"getmaximumposition","anchorH2":"syntax"},{"h1":"getMaximumPosition","h2":"Example","body":"// seeking 5 seconds before the end (or the live edge for live contents) player.seekTo({   position: player.getMaximumPosition() - 5, }); ","anchorH1":"getmaximumposition","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getMediaDuration.html","index":[{"h1":"getMediaDuration","body":"","anchorH1":"getmediaduration"},{"h1":"getMediaDuration","h2":"Description","body":"Returns the duration of the current content as taken from the media element.  This duration is in fact the maximum position possible for the content. As such, for contents not starting at the position 0, this value will not be equal to the difference between the maximum and minimum possible position, as would normally be expected from a property named \"duration\". ","anchorH1":"getmediaduration","anchorH2":"description"},{"h1":"getMediaDuration","h2":"Syntax","body":"const duration = player.getMediaDuration();   return value number: Current content duration, as taken from the media element. ","anchorH1":"getmediaduration","anchorH2":"syntax"},{"h1":"getMediaDuration","h2":"Example","body":"const pos = player.getPosition(); const dur = player.getMediaDuration();  console.log(`current position: ${pos} / ${dur}`); ","anchorH1":"getmediaduration","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getError.html","index":[{"h1":"getError","body":"","anchorH1":"geterror"},{"h1":"getError","h2":"Description","body":"Returns the current “fatal error” if one happenned for the last loaded content. Returns null otherwise. A “fatal error” is an error which led the current loading/loaded content to completely stop. Such errors are usually also sent through the \"error\" event when they happen. See the Player Error documentation for more information.","anchorH1":"geterror","anchorH2":"description"},{"h1":"getError","h2":"Syntax","body":"const currentError = player.getError();   return value Error|null: The current fatal Error or null if no fatal error happened yet. ","anchorH1":"geterror","anchorH2":"syntax"},{"h1":"getError","h2":"Example","body":"const error = player.getError();  if (!error) {   console.log(\"The player did not crash\"); } else if (error.code === \"PIPELINE_LOAD_ERROR\") {   console.error(\"The player crashed due to a failing request\"); } else {   console.error(`The player crashed: ${error.code}`); } ","anchorH1":"geterror","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getVideoElement.html","index":[{"h1":"getVideoElement","body":"","anchorH1":"getvideoelement"},{"h1":"getVideoElement","h2":"Description","body":"Returns the media element used by the RxPlayer. You’re not encouraged to use its APIs as they can enter in conflict with the RxPlayer’s API. Despite its name, this method can also return an audio element if the RxPlayer was instantiated with one.","anchorH1":"getvideoelement","anchorH2":"description"},{"h1":"getVideoElement","h2":"Syntax","body":"const elt = player.getVideoElement();   return value HTMLMediaElement: The media element attached to the RxPlayer. ","anchorH1":"getvideoelement","anchorH2":"syntax"},{"h1":"getVideoElement","h2":"Example","body":"const videoElement = player.getVideoElement(); videoElement.className = \"my-video-element\"; ","anchorH1":"getvideoelement","anchorH2":"example"}]},{"file":"./api/Basic_Methods/getAvailablePeriods.html","index":[{"h1":"getAvailablePeriods","body":"","anchorH1":"getavailableperiods"},{"h1":"getAvailablePeriods","h2":"Description","body":"Returns information on all Periods currently considered by the RxPlayer in the current content. This method mainly allows to obtain information on its audio, video or text tracks as well as on audio and video Representations - and to change any of them - by using the corresponding Period’s id property returned here. The value returned by this method is an array of object, each describing a single Period in chronological order. Those objects all contain the following properties:   start (number): The starting position at which the Period starts, in seconds.   end (number|undefined): The position at which the Period ends, in seconds. undefined either if not known or if the Period has no end yet (e.g. for live contents, the end might not be known for now).   id (string): id for this Period, allowing to call track and Representation selection APIs (such as setAudioTrack and lockVideoRepresentations for example) even if that Period is not currently playing.    In DirectFile mode (see loadVideo options), this method might just return an empty array. ","anchorH1":"getavailableperiods","anchorH2":"description"},{"h1":"getAvailablePeriods","h2":"Syntax","body":"const periods = rxPlayer.getAvailablePeriods();   return value Array.<Object>: Information on all Periods currently available in the content. ","anchorH1":"getavailableperiods","anchorH2":"syntax"}]},{"file":"./api/Basic_Methods/getCurrentPeriod.html","index":[{"h1":"getCurrentPeriod","body":"","anchorH1":"getcurrentperiod"},{"h1":"getCurrentPeriod","h2":"Description","body":"Returns information on the currentPeriods being played. The value returned by this method is either null, for when no content is currently being played or when it is unknown, or an object with the following properties:   start (number): The starting position at which the Period starts, in seconds.   end (number|undefined): The position at which the Period ends, in seconds. undefined either if not known or if the Period has no end yet (e.g. for live contents, the end might not be known for now).   id (string): id for this Period, allowing to call track and Representation selection APIs (such as setAudioTrack and lockVideoRepresentations for example) even if that Period is not currently playing.    In DirectFile mode (see loadVideo options), this method might just return an empty array. ","anchorH1":"getcurrentperiod","anchorH2":"description"},{"h1":"getCurrentPeriod","h2":"Syntax","body":"const currentPeriod = rxPlayer.getCurrentPeriod();    return value Object|null: Information on the current Period being played. null either if no content is currently playing or if the current Period is unknown.  ","anchorH1":"getcurrentperiod","anchorH2":"syntax"}]},{"file":"./api/Basic_Methods/dispose.html","index":[{"h1":"dispose","body":"","anchorH1":"dispose"},{"h1":"dispose","h2":"Description","body":"Free the ressources used by the player. You can call this method if you know you won’t need the RxPlayer anymore.  The player won't work correctly after calling this method. ","anchorH1":"dispose","anchorH2":"description"},{"h1":"dispose","h2":"Syntax","body":"player.dispose(); ","anchorH1":"dispose","anchorH2":"syntax"}]},{"file":"./api/Basic_Methods/reload.html","index":[{"h1":"reload","body":"","anchorH1":"reload"},{"h1":"reload","h2":"Description","body":"Re-load the last loaded content as fast as possible. This API can be called at any time after a content has been loaded (the LOADED state has been reached), even if the player has been stopped since and even if it was due to a fatal error. The user may need to call this API in several cases. For example, it may be used in case of an error that will not reproduce or inversely when the error is consistent at a certain playback time (e.g. due to a specific chunk defect). The options argument is an object containing :   reloadAt (Object | undefined): The object contain directives about the starting playback position :  relative (string | undefined) : start playback relatively from the last playback position (last played position before entering into STOPPED or ENDED state). position (string|undefined) : absolute position at which we should start playback  If no reload position is defined, start playback at the last playback position.   autoPlay (boolean | undefined): If set to true, the reloaded content will automatically play after being \"LOADED\". If set to false, it will stay in the \"LOADED\" state (and paused) once loaded, without automatically played. If unset or set to undefined, the content will automatically play if the content was playing the last time it was played and stay in the \"LOADED\" state (and paused) if it was paused last time it was played.   Note that despite this method’s name, the player will not go through the RELOADING state while reloading the content but through the regular LOADING state - as if loadVideo was called on that same content again.  On some browsers, auto-playing a media without user interaction is blocked due to the browser's policy.   In that case, the player won't be able to play (it will stay in a `LOADED` state) and you will receive a warning event containing a `MEDIA_ERROR` with the code: `MEDIA_ERR_BLOCKED_AUTOPLAY`.   A solution in that case would be to propose to your users an UI element to trigger the play with an interaction. ","anchorH1":"reload","anchorH2":"description"},{"h1":"reload","h2":"Syntax","body":"// without options player.reload();  // or with options player.reload(options)`    arguments:  options (optional) Object | undefined: Optional requirements, e.g. at which position the player should reload.   ","anchorH1":"reload","anchorH2":"syntax"},{"h1":"reload","h2":"Example","body":"player.addEventListener(\"error\", (error) => {   if (error.code === \"BUFFER_APPEND_ERROR\") {     // Try to reload after the last playback position, in case of defectuous     // media content at current time.     player.reload({ reloadAt: { relative: +5 } });   } else {     // Try to reload at the last playback position     player.reload();   } }); ","anchorH1":"reload","anchorH2":"example"}]},{"file":"./api/Player_States.html","index":[{"h1":"Player states","body":"The player state, that you can obtain either with the getPlayerState method or through the playerStateChange player event, is a central part of our API: it is from this value that you will know:  when a new content finished loading when the content is paused to build buffer when the content is ended as a generality, in what “state” is the player currently  As such, it is important this concept is understood when developping with the rx-player, which is exactly the point of this page.","anchorH1":"player_states"},{"h1":"Player states","h2":"List of possible states","body":"Today the player can have one of these 10 possible states:  STOPPED LOADING LOADED PLAYING PAUSED BUFFERING FREEZING SEEKING ENDED RELOADING ","anchorH1":"player_states","anchorH2":"list_of_possible_states"},{"h1":"Player states","h2":"List of possible states","h3":"The STOPPED state","body":"STOPPED is the default state of the player. It indicates that no content is playing. To simplify state exploitation, STOPPED is also emitted as a transition state when loading a new content while another one was currently loaded (or loading). That way, you can just listen to the STOPPED state to know when the current content is not loaded anymore. When the player encounters an error, it will also stop and switch to the STOPPED state.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_stopped_state"},{"h1":"Player states","h2":"List of possible states","h3":"The LOADING state","body":"The LOADING state indicates that a new content is currently loading. It appears only after the STOPPED state. That means that the player is currently downloading enough of the content to be able to play it. While this state is active, most of the content-related APIs (like setAudioTrack) are not available. You have to wait for the LOADED state for that.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_loading_state"},{"h1":"Player states","h2":"List of possible states","h3":"The LOADED state","body":"LOADED appears only after a LOADING state, and indicates that the current content can now be played. From this point onward, most of the content-related APIs (like setAudioTrack) are now available. If the autoPlay loadVideo option has been set to true, the state will then switch to PLAYING directly. Else, the player will usually be paused and stay in the LOADED state (there is some edge cases, see the “Possible state transitions” chapter for more information).","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_loaded_state"},{"h1":"Player states","h2":"List of possible states","h3":"The PLAYING state","body":"Indicates that the player is currently playing the content.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_playing_state"},{"h1":"Player states","h2":"List of possible states","h3":"The PAUSED state","body":"Indicates that the player is currently paused in the content.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_paused_state"},{"h1":"Player states","h2":"List of possible states","h3":"The BUFFERING state","body":"The player is paused because it needs to build buffer. TThe player cannot play the content despite having enough data, due to an unknown reason. The player will not play until it gets out of this state.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_buffering_state"},{"h1":"Player states","h2":"List of possible states","h3":"The FREEZING state","body":"TThe player cannot play the content despite having enough data, due to an unknown reason. This state might be due to either:  poor performance an issue with the current device the key of an encrypted content not being loaded soon enough  The player will not play until it gets out of this state. In most of those cases, the RxPlayer will be able to continue playback by itself, after some time. As such, most FREEZING cases can be treated exactly like a BUFFERING state.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_freezing_state"},{"h1":"Player states","h2":"List of possible states","h3":"The SEEKING state","body":"The content is paused because it needs to build buffer after seeking in the content (this can be seen as a special BUFFERING case). The player will not play until it gets out of this state.","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_seeking_state"},{"h1":"Player states","h2":"List of possible states","h3":"The ENDED state","body":"The player reached the end of the content. It should now be paused at the last frame if a video content is available at this time and this state acts like what you can expect from HTML5 playback:   when seeking when the content is ended, you will be paused (even if you were playing before)   after calling play, you will play back from the beginning  ","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_ended_state"},{"h1":"Player states","h2":"List of possible states","h3":"The RELOADING state","body":"This state indicates that the player needs to “re-load” then content. In those cases, we need to stop and reload the content on the browser-side, due to browser limitation. While this state is active, multiple player API are unavailable:  you cannot play or pause you cannot seek you cannot obtain the last playing position or the content duration  This is why we sometime recommend to manage this state as if it was the LOADING state (where those APIs - and other - are also not available). However, the player won’t go to the LOADED state after RELOADING, you will instead know that it had finished reloading simply when it goes out of this state (see the “Possible state transitions” chapter for more information).","anchorH1":"player_states","anchorH2":"list_of_possible_states","anchorH3":"the_reloading_state"}]},{"file":"./api/Player_Events.html","index":[{"h1":"Player events","body":"","anchorH1":"player_events"},{"h1":"Player events","h2":"Overview","body":"To communicate about events (like an error or the update of the current video bitrate) the player use the event listener pattern. As documented in the API, you can call addEventListener to register a callback for a particular event, like: player.addEventListener(\"playerStateChange\", (newState) => {   console.log(\"the RxPlayer's state changed to:\", newState); });  You can unregister a callback through the removeEventListener API, documented here.","anchorH1":"player_events","anchorH2":"overview"},{"h1":"Player events","h2":"Basic events","body":"This chapter describes the most important events sent by the player.","anchorH1":"player_events","anchorH2":"basic_events"},{"h1":"Player events","h2":"Basic events","h3":"playerStateChange","body":"payload type: string Emit the current state of the player, every time it changes. This is the event to catch if you want to know when the player is playing, is paused, is rebuffering, is ended or is stopped. As it is a central part of our API and can be difficult concept to understand, we have a special page of documentation on player states.","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"playerstatechange"},{"h1":"Player events","h2":"Basic events","h3":"error","body":"payload type: Error Triggered when a fatal error happened. A fatal error is an error that led the player to stop playing the current content. The payload is the corresponding error. See the Player Error documentation for more information.","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"error"},{"h1":"Player events","h2":"Basic events","h3":"warning","body":"payload type: Error Triggered each time a minor error happened. This error won’t lead the RxPlayer to stop the content. It can for example be an HTTP request error, some minor error detected in the content or the current position being to far below the minimum playable position. The payload is the corresponding error. See the Player Error documentation for more information.","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"warning"},{"h1":"Player events","h2":"Basic events","h3":"positionUpdate","body":"payload type: Object Emit information about the current position at most every seconds (also emits every time various player events are received). The object emitted as the following properties:   position (Number): The current position in the video, in seconds.   duration (Number): The duration of the content.   bufferGap (Number): The gap, in seconds, between the current position and the end of the current buffered range.   playbackRate (Number): The current playback rate the content is on.   liveGap (Number|undefined): Only for live contents. The gap between the current position and the “live edge”. Might not be set for directfile contents.   maximumPosition (Number|undefined): The maximum time until which the buffer can currently be filled. That is:   for static contents (like VoD), the duration.   for dynamic contents (like live contents), the current maximum available position (live edge for live contents) minus a security margin we added to avoid buffering ahead of it.     wallClockTime (Number|undefined): Only for live contents. The current time converted to wall-clock time in seconds. That is the real live position (and not the position as announced by the video element).  ","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"positionupdate"},{"h1":"Player events","h2":"Basic events","h3":"seeking","body":"Emitted when a “seek” operation (to “move”/“skip” to another position) begins on the currently loaded content.","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"seeking"},{"h1":"Player events","h2":"Basic events","h3":"seeked","body":"Emitted when a “seek” operation (to “move”/“skip” to another position) on the currently loaded content has finished","anchorH1":"player_events","anchorH2":"basic_events","anchorH3":"seeked"},{"h1":"Player events","h2":"Track selection events","body":"This chapter describes events linked to the current audio, video or text track.","anchorH1":"player_events","anchorH2":"track_selection_events"},{"h1":"Player events","h2":"Track selection events","h3":"availableAudioTracksChange","body":"payload type: Array.<Object> Triggered when the currently available audio tracks might have changed (e.g.: at the beginning of the content, when period changes…) for the currently-playing Period. The event might also rarely be emitted even if the list of available audio tracks did not really change - as the RxPlayer might send it in situations where there’s a chance it had without thoroughly checking it. The array emitted contains object describing each available audio track:   active (Boolean): Whether the track is the one currently active or not.   id (string): The id used to identify the track. Use it for setting the track via setAudioTrack.   language (string): The language the audio track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   audioDescription (Boolean): Whether the track is an audio description of what is happening at the screen.   dub (Boolean|undefined): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between audio tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Array listing the available audio Representations linked to this audio track. Each object describing a single Representation, with the following properties:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds.   codec (string|undefined): The codec of the representation     This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"availableaudiotrackschange"},{"h1":"Player events","h2":"Track selection events","h3":"availableVideoTracksChange","body":"payload type: Array.<Object> Triggered when the currently available video tracks might change (e.g.: at the beginning of the content, when period changes…) for the currently-playing Period. The event might also rarely be emitted even if the list of available video tracks did not really change - as the RxPlayer might send it in situations where there’s a chance it had without thoroughly checking it. The array emitted contains object describing each available video track:   id (string): The id used to identify the track. Use it for setting the track via setVideoTrack.   active (Boolean): Whether this track is the one currently active or not.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between video tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   width (Number|undefined): The width of video, in pixels.   height (Number|undefined): The height of video, in pixels.   codec (string|undefined): The codec given in standard MIME type format.   frameRate (number|undefined): The video framerate.     signInterpreted (Boolean): Whether the track contains sign interpretation.   This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"availablevideotrackschange"},{"h1":"Player events","h2":"Track selection events","h3":"availableTextTracksChange","body":"payload type: Array.<Object> Triggered when the currently available text tracks might change (e.g.: at the beginning of the content, when period changes…) for the currently-playing Period. The event might also rarely be emitted even if the list of available text tracks did not really change - as the RxPlayer might send it in situations where there’s a chance it had without thoroughly checking it. The array emitted contains object describing each available text track:   id (string): The id used to identify the track. Use it for setting the track via setTextTrack.   language (string): The language the text track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between text tracks. This information is usually set only if the current Manifest contains one.   closedCaption (Boolean): Whether the track is specially adapted for the hard of hearing or not.   forced (Boolean): If true this text track is meant to be displayed by default if no other text track is selected. It is often used to clarify dialogue, alternate languages, texted graphics or location and person identification.   active (Boolean): Whether the track is the one currently active or not.   This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"availabletexttrackschange"},{"h1":"Player events","h2":"Track selection events","h3":"audioTrackChange","body":"payload type: Object|null Information about the current audio track, each time it changes for the currently-playing Period. The payload is an object describing the new track, with the following properties:   id (string): The id used to identify the track.   language (string): The language the audio track is in.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   audioDescription (Boolean): Whether the track is an audio description of what is happening at the screen.   dub (Boolean|undefined): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between audio tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Array listing the available audio Representations linked to this audio track. Each object describing a single Representation, with the following properties:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds.   codec (string|undefined): The codec of the representation     This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"audiotrackchange"},{"h1":"Player events","h2":"Track selection events","h3":"textTrackChange","body":"payload type: Object|null Information about the current audio track, each time it changes for the currently-playing Period. The payload is an object describing the new track, with the following properties:   id (string): The id used to identify the track.   language (string): The language the text track is in.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   closedCaption (Boolean): Whether the track is specially adapted for the hard of hearing or not.   forced (Boolean): If true this text track is meant to be displayed by default if no other text track is selected. It is often used to clarify dialogue, alternate languages, texted graphics or location and person identification.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between text tracks. This information is usually set only if the current Manifest contains one.   This event only concerns the currently-playing Period.","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"texttrackchange"},{"h1":"Player events","h2":"Track selection events","h3":"videoTrackChange","body":"payload type: Object|null Information about the current audio track, each time it changes for the currently-playing Period. Information about the current video track, each time it changes (the last received segment got a new one). The payload is an object describing the new track, with the following properties:   id (string): The id used to identify the track. Use it for setting the track via setVideoTrack.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between video tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   width (Number|undefined): The width of video, in pixels.   height (Number|undefined): The height of video, in pixels.   codec (string|undefined): The codec given in standard MIME type format.   frameRate (number|undefined): The video framerate.     isTrickModeTrack (Boolean|undefined): If set to true, this track is a trick mode track. This type of tracks proposes video content that is often encoded with a very low framerate with the purpose to be played more efficiently at a much higher speed. To enter or exit a mode where trickmode tracks are used instead of regular non-trickmode ones, you can use the setPlaybackRate function.   trickModeTracks (Object | undefined): Trick mode video tracks attached to this video track. Each of those objects contain the same properties that a regular video track (same properties than what is documented here). It this property is either undefined or not set, then this track has no linked trickmode video track.   signInterpreted (Boolean): Whether the track contains sign interpretation.   A null payload means that video track has been disabled. This event only concerns the currently-playing Period.  In DirectFile mode (see transport option), a `null` payload may be received even if the video track is still visually active. This seems due to difficult-to-detect browser bugs. We recommend not disabling video track when in directfile mode to avoid that case (this is documented in the corresponding APIs). ","anchorH1":"player_events","anchorH2":"track_selection_events","anchorH3":"videotrackchange"},{"h1":"Player events","h2":"Representation selection events","body":"This chapter describes events linked to the current audio, video or Representation / quality.","anchorH1":"player_events","anchorH2":"representation_selection_events"},{"h1":"Player events","h2":"Representation selection events","h3":"videoRepresentationChange","body":"payload type: Object|null Emitted when the current video Representation being considered by the RxPlayer changes. The payload is an object describing this new Representation, with the following properties:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   width (Number|undefined): The width of video, in pixels.   height (Number|undefined): The height of video, in pixels.   codec (string|undefined): The codec of the Representation.   frameRate (number|undefined): The video framerate.   A null payload means that no video track is available now. This event only concerns the currently-playing Period.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"representation_selection_events","anchorH3":"videorepresentationchange"},{"h1":"Player events","h2":"Representation selection events","h3":"audioRepresentationChange","body":"payload type: Object|null Emitted when the current audio Representation being considered by the RxPlayer changes. The payload is an object describing the new Representation, with the following properties:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds.   codec (string|undefined): The codec of the representation   This event only concerns the currently-playing Period.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"representation_selection_events","anchorH3":"audiorepresentationchange"},{"h1":"Player events","h2":"Playback information","body":"This chapter describes events describing miscellaneous information about the current content.","anchorH1":"player_events","anchorH2":"playback_information"},{"h1":"Player events","h2":"Playback information","h3":"periodChange","body":"payload type: Object Triggered when the current Period being seen changes. The payload of this event is an object containing the following properties:   start (number): The starting position at which the Period starts, in seconds.   end (number|undefined): The position at which the Period ends, in seconds. undefined either if not known or if the Period has no end yet (e.g. for live contents, the end might not be known for now).   id (string): id of the Period, allowing to call track and Representation selection APIs (such as setAudioTrack and lockVideoRepresentations for example) even when the Period changes.    This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"playback_information","anchorH3":"periodchange"},{"h1":"Player events","h2":"Playback information","h3":"newAvailablePeriods","body":"payload type: Array.<Object> This event is triggered when one or multiple new Periods start to be considered by the RxPlayer in the current content. This event mainly allows to choose the text, audio and/or video tracks as well as the audio and/or video Representations to select for those Period(s). This event is first sent once the content is first loaded and then may be triggered gain everytime the RxPlayer is considering another Period of the content. The payload of this event is an array of object, each describing a single Period in chronological order. Those objects all contain the following properties:   start (number): The starting position at which the Period starts, in seconds.   end (number|undefined): The position at which the Period ends, in seconds. undefined either if not known or if the Period has no end yet (e.g. for live contents, the end might not be known for now).   id (string): id for this Period, allowing to call track and Representation selection APIs (such as setAudioTrack and lockVideoRepresentations for example) even if that Period is not currently playing.    This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"playback_information","anchorH3":"newavailableperiods"},{"h1":"Player events","h2":"Playback information","h3":"trackUpdate","body":"payload type: Object Event triggered if a video, audio or text track chosen for any Period is changed by the RxPlayer. This event is triggered just after the track is updated but before any of the corresponding data is actually loaded, thus allowing you to edit track or Representations settings before the RxPlayer can continue. However keep in mind that this event is not triggered for the initial default track choice made by the RxPlayer. If you want to react to this event instead, you can rely on the newAvailablePeriods event. Cases where the track changes include:   when the application updates a track manually (for example through a setAudioTrack call)   when it had to be done as a side-effect of another API (for example after enabling trickmode video tracks through a setPlaybackRate call)   or in the extremely rare situation where the RxPlayer had to do it by itself automatically (one situation would be when a refreshed content’s Manifest removes the previously-chosen track. There, the RxPlayer will send the trackUpdate event and - if no new track is chosen since - will automatically switch to that track so playback can continue).   The payload for this event is an object with the following properties:   trackType (string): The type of track concerned. Can for example be audio for an audio track, video for a video track or text for a text track.   period (Object): Information about the concerned Period. This object contains as properties:   start (number): The starting position at which the Period starts, in seconds.   end (number|undefined): The position at which the Period ends, in seconds. undefined either if not known or if the Period has no end yet (e.g. for live contents, the end might not be known for now).   id (string): id of the Period, allowing to call track and Representation selection APIs (such as setAudioTrack and lockVideoRepresentations for example) even when the Period changes.     reason (string): The reason for the track update. For now, it can be set to:   \"manual\": the track was updated because the application called a method to directly update it. This event is the direct consequence of calling setAudioTrack, setTextTrack, setVideoTrack, disableTextTrack or disableVideoTrack, so it corresponds to track updates you should already be aware of.   \"trickmode-enabled\": The track is being updated because the application wanted to enable video trickmode tracks (usually by setting the preferTrickModeTracks option of the setPlaybackRate method to true).   \"trickmode-disabled\": The track is being updated because the application wanted to disable video trickmode tracks (usually by setting the preferTrickModeTracks option of the setPlaybackRate method to false).   \"missing\" the previously-chosen track was missing from the content’s refreshed Manifest.   Though other reasons may be added in the future (for future reasons not covered by those values), so you should expect this possibility in your application’s logic.    This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"playback_information","anchorH3":"trackupdate"},{"h1":"Player events","h2":"Playback information","h3":"brokenRepresentationsLock","body":"payload type: Object Fairly rare event triggered if representations locked through Representations selection API such as lockVideoRepresentations or lockAudioRepresentations all became unplayable (most likely linked to encryption reasons), in which case, the RxPlayer “broke” that lock, i.e. it decided to remove that lock and play all Representations instead. This event is sent strictly before the RxPlayer had the chance to actually load those other Representations. You can thus profit from this event by synchronously locking Representations you wish to play and thus avoid playing the others. The payload for this event is an object with the following properties:   period (Object): Information about the concerned Period. This object contains as properties:   start (number): The starting position at which the Period starts, in seconds.   end (number|undefined): The position at which the Period ends, in seconds. undefined either if not known or if the Period has no end yet (e.g. for live contents, the end might not be known for now).   id (string): id of the Period, allowing to call track and Representation selection APIs (such as setAudioTrack and lockVideoRepresentations for example) even when the Period changes.     trackType (string): The type of track concerned. Can for example be audio for audio Representations or video for video Representations.    This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"playback_information","anchorH3":"brokenrepresentationslock"},{"h1":"Player events","h2":"inbandEvents","body":"payload type: Object Event triggered when the player encounters inband events in the stream. These events are included in the loaded and parsed chunks, and are often used to carry content metadata. Each event contains :  type (type: String) : defines the type of the event, specific to an inband event from a streaming protocol. value (type: Object) : the actual parsed content of the event.  The supported inband event types are :   “emsg” : The emsg (Event message box) provides inband signaling for generic or MPEG-DASH specific events. One ISOBMFF media segment may contain one or several boxes. The parsed event contains :  schemeIdUri (String) value (String) timescale (Number) presentationTimeDelta (Number) eventDuration (Number) id (Number) messageData (Uint8Array)  These attributes are documented in the ISOBMFF specification.    This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"inbandevents"},{"h1":"Player events","h2":"inbandEvents","h3":"streamEvent","body":"payload type: Object Event triggered when the player enters the time boundaries of a “stream event”. “Stream events” are metadata that can be defined in various streaming protocols, which indicates that an application should trigger some action when a specific time is reached in the content. Those events can either have only a start time or both a start time and an end time:   in the case where an event only has a start time, the RxPlayer will trigger a streamEvent right when the user reaches that time. If we return multiple time at that position (for example, when a user seeks back to it), you will receive a streamEvent as many times for that same event.   in the case where an event has both a start and end time, the RxPlayer will trigger a streamEvent when the current position goes inside these time boundaries (between the start and end time). This can happen while reaching the start during regular playback but also when seeking at a position contained between the start and end time. The streamEvent event will not be re-sent until the current position “exits” those time boundaries. If the current position goes out of the boundaries of that event and then goes into it again (most likely due to the user seeking back into it), you will again receive a streamEvent for that same event.   The payload of a streamEvent depends on the source of the event. For example, it will not have the same format when it comes from a Manifest than when it comes from the media container. All possible formats are described in the stream event tutorial. Note: When an event has both a start and an end time, you can define a onExit callback on the payload. That callback will automatically be triggered when the current position goes after the end time or before the start time of that event. The onExit callback will only be called a single time at most and will only concern this iteration of the event (and not possible subsequent ones).  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"inbandevents","anchorH3":"streamevent"},{"h1":"Player events","h2":"inbandEvents","h3":"streamEventSkip","body":"payload type: Object Event triggered when the player skipped the time boundaries of a “stream event” (you can refer to the streamEvent event for a definition of what a “stream event” is). This means that the current position the player plays at, immediately changed from a time before the start time of a “stream event” to after its end time (or just after its end time for “stream event” without an end time). This is most likely due to the user seeking in the content. A “regular” content playback which continuously plays the content without seeking shouldn’t trigger any streamEventSkip event. The payload of a streamEventSkip is the same than for a streamEvent and as such depends on the source of the event. All possible formats are described in the stream event tutorial. Note that unlike streamEvent events, there’s no point to define an onExit callback on the payload of a streamEventSkip event. This is because this event was not entered, and will thus not be exited.  This event is not sent in DirectFile mode (see transport option) ","anchorH1":"player_events","anchorH2":"inbandevents","anchorH3":"streameventskip"}]},{"file":"./api/Player_Errors.html","index":[{"h1":"Player errors and warnings","body":"","anchorH1":"player_errors_and_warnings"},{"h1":"Player errors and warnings","h2":"Overview","body":"Various errors can be triggered when playing a media content. Those can happen when:  The network is unreachable The codecs are not supported We have no mean to decrypt the data …  Some errors can be fatal to content playback in which case they will stop the player, others act more as warnings and are more along the line of a minor problem notification. You can know if a fatal error interrupted your playback by:   adding an event listener to the \"error\" event (see the player events documentation). This event listener will take the error directly in argument.   calling the getError API if the current state is STOPPED. If different from null, it means that a fatal error happened (see the documentation for getError).   You can also be warned of any non-fatal error by:  adding an event listener to the \"warning\" event (see the player events documentation). The event listener will take the non-fatal error directly in argument.  All of those are in essence Error instances with added information. Those supplementary information are described in this page.","anchorH1":"player_errors_and_warnings","anchorH2":"overview"},{"h1":"Player errors and warnings","h2":"Structure of an Error","body":"Each of RxPlayer’s error objects have at least those properties:   type (string): A large category for the error (e.g. NETWORK_ERROR, ENCRYPTED_MEDIA_ERROR …)   code (string): A set identification “code” for the error encountered   message (string): A displayable, human-readable, summary of the error.   fatal (boolean): If true, the error was fatal. Meaning that the playback was interrupted by it  ","anchorH1":"player_errors_and_warnings","anchorH2":"structure_of_an_error"},{"h1":"Player errors and warnings","h2":"Types","body":"The types are the different strings you can have as the type property of an error. This chapter provides an exhaustive list of the possible type of error encountered.","anchorH1":"player_errors_and_warnings","anchorH2":"types"},{"h1":"Player errors and warnings","h2":"Types","h3":"NETWORK_ERROR","body":"A NetworkError is any Network-related error (HTTP 404, request timeout…), they all have a type property equal to \"NETWORK_ERROR\". codes A NetworkError can only have the following code (code property):  \"PIPELINE_LOAD_ERROR\": the Manifest or segment request failed.  more information A NetworkError provide much more infos than this code. Among its properties, you have:   url (string): The url the request has been on   status (Number): Status code of the HTTP request.   errorType (string): Further precision about what went wrong. This string can either be:  \"TIMEOUT\": The request timeouted. \"ERROR_EVENT\": The XMLHttpRequest has sent an error event \"PARSE_ERROR\": No data could have been extracted from this request \"ERROR_HTTP_CODE\": The request finished with a status code not in the 2xx range.   ","anchorH1":"player_errors_and_warnings","anchorH2":"types","anchorH3":"network_error"},{"h1":"Player errors and warnings","h2":"Types","h3":"MEDIA_ERROR","body":"Error related to the media itself. It can both come from the player itself (Manifest parsing) or from the browser itself (content playback). They all have a type property equal to \"MEDIA_ERROR\". codes A MediaError can have the following codes (code property):   \"BUFFER_APPEND_ERROR\": A media segment could not have been added to the corresponding media buffer. This often happens with malformed segments.   \"BUFFER_FULL_ERROR\": The needed segment could not have been added because the corresponding media buffer was full.   \"BUFFER_TYPE_UNKNOWN\": The type of buffer considered (e.g. “audio” / “video” / “text”) has no media buffer implementation in your build.   \"MANIFEST_INCOMPATIBLE_CODECS_ERROR\": An Adaptation (or track) has none of its Representations (read quality) in a supported codec.   \"MANIFEST_PARSE_ERROR\": Generic error to signal than the Manifest could not be parsed.   \"MANIFEST_UNSUPPORTED_ADAPTATION_TYPE\": One of the Adaptation has a type (e.g. “audio”, “text” or “video” which is not managed by the RxPlayer).   \"MEDIA_ERR_ABORTED\": A crucial browser-side fetching operation was aborted.   \"MEDIA_ERR_BLOCKED_AUTOPLAY\": The current browser has a policy which forbids us to autoPlay the content. As a consequence, the rx-player stays in a \"LOADED\" state. This code is always a warning and it never causes playback interruption.   \"MEDIA_ERR_PLAY_NOT_ALLOWED\": A play call on our API (coming from you) failed because the current browser does not allow it. The content should still be in a paused state. This is in almost any case due a browser policy which prevents a content to play without any user interaction. In those cases, we recommend to display a UI element on your page inviting the final user to manually play the content.   \"MEDIA_ERR_NOT_LOADED_METADATA\": The current browser falsely announce having loaded the content’s metadata. In that case, we cannot switch to the LOADED state directly (we will be blocked in either a LOADING or a RELOADING state) and you’re encouraged to call play manually when you want to play the content. This is a case only encountered in the Samsung browser (as found in Android) when loading a content in “directfile” mode.   \"MEDIA_ERR_DECODE\": A pushed segment/media could not be decoded by the browser. This happens most-of-all with malformed segments.   \"MEDIA_ERR_NETWORK\": A browser-side request failed.   \"MEDIA_ERR_SRC_NOT_SUPPORTED\": The media associated to the video element is not valid.   \"MEDIA_ERR_UNKNOWN\": Media error impossible to characterize.   \"MEDIA_KEYS_NOT_SUPPORTED\": The current browser has no MediaKeys implementation and the content is encrypted.   \"MEDIA_SOURCE_NOT_SUPPORTED\": No known MediaSource API is supported by your browser and we need to create one.   \"MEDIA_STARTING_TIME_NOT_FOUND\": The provided or calculated starting time was not found in the corresponding media.   \"MEDIA_TIME_BEFORE_MANIFEST\": The current time in the media is behind what is currently declared in the Manifest. This can lead to stalling indefinitely as the player won’t be able to download new segments arround the current time.   \"MEDIA_TIME_AFTER_MANIFEST\": The current time in the media is after what is currently declared in the Manifest. This can lead to stalling indefinitely as the player won’t be able to download new segments arround the current time.   \"DISCONTINUITY_ENCOUNTERED\": A discontinuity (i.e. a hole in the media buffer) has been encontered and seeked over. This is rarely a problem and may be encountered at a very start of a content when the initial segment’s start is much later than expected.   \"NO_PLAYABLE_REPRESENTATION\": The currently chosen Adaptation does not contain any playable Representation. This usually happens when every Representation has been blacklisted due to encryption limitations.   \"MANIFEST_UPDATE_ERROR\": This error should never be emitted as it is handled internally by the RxPlayer. Please open an issue if you encounter it. This error is triggered when an incoherent version of the Manifest was received during a partial update. The RxPlayer should catch the error and trigger a full update instead when that happens.   \"MEDIA_TIME_NOT_FOUND\": This error should never be emitted by the RxPlayer. Please open an issue if you encounter it. It is triggered when a time we initially thought to be in the bounds of the Manifest actually does not link to any “Period” of the Manifest.  ","anchorH1":"player_errors_and_warnings","anchorH2":"types","anchorH3":"media_error"},{"h1":"Player errors and warnings","h2":"Types","h3":"ENCRYPTED_MEDIA_ERROR","body":"Those errors are linked to the Encrypted Media Extensions. They concern various DRM-related problems. They all have a type property equal to \"ENCRYPTED_MEDIA_ERROR\". codes An EncryptedMediaError can have the following codes (code property):   \"INCOMPATIBLE_KEYSYSTEMS\": None of the provided key systems was compatible with the current browser.   \"INVALID_ENCRYPTED_EVENT\": An encountered encrypted event was not valid.   \"INVALID_KEY_SYSTEM\": One of the given key system was not accepted by the RxPlayer.   \"KEY_ERROR\": The MediaKeySession emitted an error.   \"KEY_GENERATE_REQUEST_ERROR\": An error happened when calling the generateRequest API to generate a challenge.   \"KEY_LOAD_ERROR\": An error was returned by the code fetching the license.   \"KEY_LOAD_TIMEOUT\": The request for fetching the license had a duration of more than 10 seconds.   \"KEY_STATUS_CHANGE_ERROR\": An error was detected when the MediaKeySession emitted a keyStatuseschange event (e.g. a key became \"expired\"). EncryptedMediaError having the KEY_STATUS_CHANGE_ERROR code will also have a keyStatuses property, which is an array of objects - each describing a problematic key status with the following properties:  keyId (ArrayBuffer): The key id concerned by the status change indicated by keyStatus keyStatus (MediaKeyStatus): The problematic key status encountered linked to the keyId of the same object.  If multiple objects are found in the keyStatuses property, it means that multiple keys changed to a problematic status roughly around the same time.   \"KEY_UPDATE_ERROR\": An error was detected after a message (like a license was given to the CDM).   \"LICENSE_SERVER_CERTIFICATE_ERROR\": The server certificate of a MediaKeys could not be set.   \"MEDIA_IS_ENCRYPTED_ERROR\": The media is encrypted and no key system was given to the RxPlayer’s APIs.   CREATE_MEDIA_KEYS_ERROR: An unknown error happened when creating a CDM instance (to decrypt the content). More specifically, this error happens when the EME createMediaKeys API throws or rejects. This is a relatively rare situation generally linked to an issue in the CDM. It has been encountered mainly on some faulty Android devices and Electron applications. If this happens repeatedly, try reinstalling the CDM module on your device.   \"MULTIPLE_SESSIONS_SAME_INIT_DATA\": This error should never be emitted by the RxPlayer. Please open an issue if you encounter it. It is emitted when the RxPlayer try to open multiple MediaKeySession for the same initialization data (instead of using the exact same MediaKeySession).  ","anchorH1":"player_errors_and_warnings","anchorH2":"types","anchorH3":"encrypted_media_error"},{"h1":"Player errors and warnings","h2":"Types","h3":"OTHER_ERROR","body":"Those errors are various other errors which does not belong to other types. They all have a type property equal to \"OTHER_ERROR\". codes An OtherError can have the following codes (code property):   \"PIPELINE_LOAD_ERROR\": The Manifest or segment request failed and the request has been done through a given callback (i.e. not the RxPlayer’s XMLHttpRequest implementation).   \"PIPELINE_PARSE_ERROR\": The RxPlayer’s Manifest or segment parsing logic failed. This is most likely due to a malformed Manifest or segment.   \"INTEGRITY_ERROR\": An integrity-checking mechanism in the RxPlayer detected that there was an error with some loaded data. Such mechanism can be triggered for example when the checkMediaSegmentIntegrity option is set on the loadVideo call.   \"NONE\": The error cannot be characterized.  ","anchorH1":"player_errors_and_warnings","anchorH2":"types","anchorH3":"other_error"}]},{"file":"./api/Track_Selection/getAudioTrack.html","index":[{"h1":"getAudioTrack","body":"","anchorH1":"getaudiotrack"},{"h1":"getAudioTrack","h2":"Description","body":"Get information about the audio track currently set. null if no audio track is enabled right now. If an audio track is set and information about it is known, this method will return an object with the following properties:   id (Number|string): The id used to identify this track. No other audio track for the same Period will have the same id. This can be useful when setting the track through the setAudioTrack method.   language (string): The language the audio track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-3 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   audioDescription (Boolean): Whether the track is an audio description of what is happening at the screen.   dub (Boolean|undefined): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between audio tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation. No other Representation from this track will have the same id.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   codec (string|undefined): The audio codec the Representation is in, as announced in the corresponding Manifest.     undefined if no audio content has been loaded yet or if its information is unknown. You can also get the information on the chosen audio track for another Period by calling getAudioTrack with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: getting track information for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getAudioTrack(periods[0].id);   In DirectFile mode (see loadVideo options), if there is no audio tracks API in the browser, this method returns \"undefined\". ","anchorH1":"getaudiotrack","anchorH2":"description"},{"h1":"getAudioTrack","h2":"Syntax","body":"// Get information about the currently-playing audio track const audioTrack = player.getAudioTrack();  // Get information about the audio track for a specific Period const audioTrack = player.getAudioTrack(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get information about its current audio track. If not defined, the information associated to the currently-playing Period will be returned.    return value Object|null|undefined  ","anchorH1":"getaudiotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getTextTrack.html","index":[{"h1":"getTextTrack","body":"","anchorH1":"gettexttrack"},{"h1":"getTextTrack","h2":"Description","body":"Get information about the text track currently set. null if no text track is enabled right now. If a text track is set and information about it is known, this method will return an object with the following properties:   id (Number|string): The id used to identify this track. No other text track for the same Period will have the same id. This can be useful when setting the track through the setTextTrack method.   language (string): The language the text trac./…/Basic_Methods/loadVideo.md#transport set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-3 language codes). If the translation attempt fails (no corresponding ISO./…/Basic_Methods/loadVideo.md#transport found), it will equal the value of language   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between text tracks. This information is usually set only if the current Manifest contains one.   closedCaption (Boolean): Whether the track is specially adapted for the hard of hearing or not.   forced (Boolean): If true this text track is meant to be displayed by default if no other text track is selected. It is often used to clarify dialogue, alternate languages, texted graphics or location and person identification.   undefined if no text content has been loaded yet or if its information is unknown. You can also get the information on the chosen text track for another Period by calling getTextTrack with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: getting track information for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getTextTrack(periods[0].id);   In DirectFile mode (see loadVideo options), if there is no text tracks API in the browser, this method returns \"undefined\". ","anchorH1":"gettexttrack","anchorH2":"description"},{"h1":"getTextTrack","h2":"Syntax","body":"// Get information about the currently-playing text track const textTrack = player.getTextTrack();  // Get information about the text track for a specific Period const textTrack = player.getTextTrack(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get information about its current text track. If not defined, the information associated to the currently-playing Period will be returned.    return value Object|null|undefined  ","anchorH1":"gettexttrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getVideoTrack.html","index":[{"h1":"getVideoTrack","body":"","anchorH1":"getvideotrack"},{"h1":"getVideoTrack","h2":"Description","body":"Get information about the video track currently set.  null if no video track is enabled right now. undefined if no video content has been loaded yet or if its information is unknown.  If a video track is set and information about it is known, this method will return an object with the following properties:   id (string): The id used to identify this track. No other video track for the same Period will have the same id. This can be useful when setting the track through the setVideoTrack method.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between video tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation. No other Representation from this track will have the same id.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   width (Number|undefined): The width of this video Representation, in pixels.   height (Number|undefined): The height of this video Representation, in pixels.   codec (string|undefined): The video codec the Representation is in, as announced in the corresponding Manifest.   frameRate (number|undefined): The video frame rate, in frames per second.   hdrInfo (Object|undefined) Information about the hdr characteristics of the track. (see HDR support documentation)     signInterpreted (Boolean|undefined): If set to true, this track is known to contain an interpretation in sign language. If set to false, the track is known to not contain that type of content. If not set or set to undefined we don’t know whether that video track contains an interpretation in sign language.   isTrickModeTrack (Boolean|undefined): If set to true, this track is a trick mode track. This type of tracks proposes video content that is often encoded with a very low framerate with the purpose to be played more efficiently at a much higher speed. To enter or exit a mode where trickmode tracks are used instead of regular non-trickmode ones, you can use the setPlaybackRate function.   trickModeTracks (Array.<Object> | undefined): Trick mode video tracks attached to this video track. Each of those objects contain the same properties that a regular video track (same properties than what is documented here). It this property is either undefined or not set, then this track has no linked trickmode video track.   You can also get the information on the chosen video track for another Period by calling getVideoTrack with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: getting track information for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getVideoTrack(periods[0].id);   In DirectFile mode (see loadVideo options), if there is no video tracks API in the browser, this method returns \"undefined\". ","anchorH1":"getvideotrack","anchorH2":"description"},{"h1":"getVideoTrack","h2":"Syntax","body":"// Get information about the currently-playing video track const videoTrack = player.getVideoTrack();  // Get information about the video track for a specific Period const videoTrack = player.getVideoTrack(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get information about its current video track. If not defined, the information associated to the currently-playing Period will be returned.    return value Object|null|undefined  ","anchorH1":"getvideotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getAvailableAudioTracks.html","index":[{"h1":"getAvailableAudioTracks","body":"","anchorH1":"getavailableaudiotracks"},{"h1":"getAvailableAudioTracks","h2":"Description","body":"Returns the list of available audio tracks for the current content. Each of the objects in the returned array have the following properties:   active (Boolean): Whether the track is the one currently active or not. Only maximum one audio track can be active at a time.   id (string): The id used to identify the track. Use it for setting the track via setAudioTrack.   language (string): The language the audio track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   audioDescription (Boolean): Whether the track is an audio description of what is happening at the screen.   dub (Boolean|undefined): If set to true, this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between audio tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   codec (string|undefined): The audio codec the Representation is in, as announced in the corresponding Manifest.     You can also get the list of available audio tracks for a specific Period by calling getAvailableAudioTracks with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: getting the audio track list for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getAvailableAudioTracks(periods[0].id);   In DirectFile mode (see loadVideo options), if there is no supported tracks in the file or no track management API in the browser this method will return an empty Array. ","anchorH1":"getavailableaudiotracks","anchorH2":"description"},{"h1":"getAvailableAudioTracks","h2":"Syntax","body":"// Get list of available audio tracks for the currently-playing Period const audioTracks = player.getAvailableAudioTracks();  // Get list of available audio tracks for a specific Period const audioTrack = player.getAvailableAudioTracks(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get the list of available audio tracks. If not defined, this method will return the list of audio tracks for the currently-playing Period.    return value Array.<Object>  ","anchorH1":"getavailableaudiotracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getAvailableTextTracks.html","index":[{"h1":"getAvailableTextTracks","body":"","anchorH1":"getavailabletexttracks"},{"h1":"getAvailableTextTracks","h2":"Description","body":"Returns the list of available text tracks (subtitles) for the current content. Each of the objects in the returned array have the following properties:   id (string): The id used to identify the track. Use it for setting the track via setTextTrack.   language (string): The language the text track is in, as set in the Manifest.   normalized (string): An attempt to translate the language property into an ISO 639-3 language code (for now only support translations from ISO 639-1 and ISO 639-2 language codes). If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   closedCaption (Boolean): Whether the track is specially adapted for the hard of hearing or not.   forced (Boolean): If true this text track is meant to be displayed by default if no other text track is selected. It is often used to clarify dialogue, alternate languages, texted graphics or location and person identification.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between text tracks. This information is usually set only if the current Manifest contains one.   active (Boolean): Whether the track is the one currently active or not.   You can also get the list of available text tracks for a specific Period by calling getAvailableTextTracks with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: getting the text track list for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getAvailableTextTracks(periods[0].id);   In DirectFile mode (see loadVideo options), if there is no supported tracks in the file or no track management API in the browser this method will return an empty Array. ","anchorH1":"getavailabletexttracks","anchorH2":"description"},{"h1":"getAvailableTextTracks","h2":"Syntax","body":"// Get list of available text tracks for the currently-playing Period const textTracks = player.getAvailableTextTracks();  // Get list of available text tracks for a specific Period const textTrack = player.getAvailableTextTracks(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get the list of available text tracks. If not defined, this method will return the list of text tracks for the currently-playing Period.    return value Array.<Object>  ","anchorH1":"getavailabletexttracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/getAvailableVideoTracks.html","index":[{"h1":"getAvailableVideoTracks","body":"","anchorH1":"getavailablevideotracks"},{"h1":"getAvailableVideoTracks","h2":"Description","body":"Returns the list of available video tracks for the current content. Each of the objects in the returned array have the following properties:   id (string): The id used to identify the track. Use it for setting the track via setVideoTrack.   active (Boolean): Whether this track is the one currently active or not.   label (string|undefined): A human readable label that may be displayed in the user interface providing a choice between video tracks. This information is usually set only if the current Manifest contains one.   representations (Array.<Object>): Representations of this video track, with attributes:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   width (Number|undefined): The width of video, in pixels.   height (Number|undefined): The height of video, in pixels.   codec (string|undefined): The video codec the Representation is in, as announced in the corresponding Manifest.   frameRate (number|undefined): The video framerate.   hdrInfo (Object|undefined) Information about the hdr characteristics of the track. (see HDR support documentation)     signInterpreted (Boolean|undefined): If set to true, the track is known to contain an interpretation in sign language. If set to false, the track is known to not contain that type of content. If not set or set to undefined we don’t know whether that video track contains an interpretation in sign language.   trickModeTracks (Array.<Object> | undefined): Trick mode video tracks attached to this video track. Each of those objects contain the same properties that a regular video track (same properties than what is documented here). It this property is either undefined or not set, then this track has no linked trickmode video track.   You can also get the list of available video tracks for a specific Period by calling getAvailableVideoTracks with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: getting the video track list for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getAvailableVideoTracks(periods[0].id);   In DirectFile mode (see loadVideo options), if there is no supported tracks in the file or no track management API in the browser this method will return an empty Array. ","anchorH1":"getavailablevideotracks","anchorH2":"description"},{"h1":"getAvailableVideoTracks","h2":"Syntax","body":"// Get list of available video tracks for the currently-playing Period const videoTracks = player.getAvailableVideoTracks();  // Get list of available video tracks for a specific Period const videoTrack = player.getAvailableVideoTracks(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get the list of available video tracks. If not defined, this method will return the list of video tracks for the currently-playing Period.    return value Array.<Object>  ","anchorH1":"getavailablevideotracks","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setAudioTrack.html","index":[{"h1":"setAudioTrack","body":"","anchorH1":"setaudiotrack"},{"h1":"setAudioTrack","h2":"Description","body":"Change the audio track. This method can take a string corresponding to the wanted track’s id property. This id can for example be obtained on the corresponding track object returned by the getAvailableAudioTracks method. // Setting the first audio track const audioTracks = rxPlayer.getAvailableAudioTracks(); rxPlayer.setAudioTrack(audioTracks[0].id);  setAudioTrack can also accept an object argument allowing more precize settings, described below. In the case an object is given, the audio track’s id should be set as in a trackId property. // Setting the first audio track const audioTracks = rxPlayer.getAvailableAudioTracks(); rxPlayer.setAudioTrack({   trackId: audioTracks[0].id, });   If used on Safari, in _DirectFile_ mode, the track change may change the track on other track type (e.g. changing video track may change subtitle track too). This has two potential reasons :    The HLS defines variants, groups of tracks that may be read together   Safari may decide to enable a track for accessibility or user language   convenience (e.g. Safari may switch subtitle to your OS language if you pick   another audio language)   You can know if another track has changed by listening to the corresponding   events that the tracks have changed.  ","anchorH1":"setaudiotrack","anchorH2":"description"},{"h1":"setAudioTrack","h2":"Description","h3":"Changing the audio track for any Period","body":"You can change the audio track for any Period (and not just the one being played) by indicating its id property in a periodId property of the Object given to setAudioTrack. Periods’ id properties can be retrieved from several means such as the getAvailablePeriods method or the newAvailablePeriods and periodChange events. // Example: // Changing the audio track for the second Period in the current Manifest  // Recuperating all Periods currently in the Manifest const periods = rxPlayer.getAvailablePeriods();  // Getting the audio track for this second Period (and not the current one): const audioTracks = rxPlayer.getAvailableAudioTracks(periods[1].id);  // Updating the audio track of the second Period rxPlayer.setAudioTrack({   trackId: audioTracks[0].id,   periodId: periods[1].id, });  ","anchorH1":"setaudiotrack","anchorH2":"description","anchorH3":"changing_the_audio_track_for_any_period"},{"h1":"setAudioTrack","h2":"Description","h3":"Changing the way the audio track transition is done","body":"When switching the audio track, media data from the previous audio track might still be present and playable in the buffer. Because you might prefer a direct transition - which may lead to a little rebuffering (or even reloading) short moment over a seamless transition where the previous audio track might be still audible for a few seconds, the RxPlayer let you define a “switching mode” by setting the switchingMode property given to setAudioTrack. The available “switching modes” are:   \"seamless\": Clean the previous audio track from the buffer, yet keep some of its data around the current position to ensure the transition stay seamless (i.e. playback still continue). This is the default mode. The advantage is that the switch will not be abrupt (playback will not be interrupted) but you might still have a few seconds playing in the previous audio track.   \"direct\": Directly audibly switch to the new tracks. Here you will ensure that the now unwanted tracks won’t be played in the future but you might be left with a playback interruption and some rebuffering time while the new audio track is loaded.   \"reload\": Directly audibly switch to the new tracks through a “reloading” step if necessary. This mode might have better results than \"direct\" on devices with poor compatibility, but the RxPlayer might temporarily go through a \"RELOADING\" state, during which a black screen is shown and multiple APIs are unavailable.   // example: switching audio tracks in \"direct\" mode rxPlayer.setAudioTrack({   // we will just lock the first one here   trackId: [audioTrackId],   switchingMode: \"direct\", }); ","anchorH1":"setaudiotrack","anchorH2":"description","anchorH3":"changing_the_way_the_audio_track_transition_is_done"},{"h1":"setAudioTrack","h2":"Description","h3":"Selecting only some Representations in the new audio track","body":"You can also start “locking” only a given set of Representations in the new track (so that only those Representations will be played) as soon as you switch the audio track. This can be done by adding a lockedRepresentations property to the setAudioTrack call, which should contain an array of the wanted Representations’ id property: const audioTracks = rxPlayer.getAvailableAudioTracks(); const wantedAudioTrack = audioTracks[1]; rxPlayer.setAudioTrack({   trackId: wantedAudioTrack.id,    // \"Locking\" only the first audio Representation   // (it will be the only Representation being played)   lockedRepresentations: [wantedAudioTrack.representations[0]], });  Doing this is equivalent to locking the audio Representations through a lockAudioVideoRepresentations call, you can read its documentation page for more information on its behavior.","anchorH1":"setaudiotrack","anchorH2":"description","anchorH3":"selecting_only_some_representations_in_the_new_audio_track"},{"h1":"setAudioTrack","h2":"Description","h3":"Setting the audio track as soon as possible","body":"If you want to set an audio track as soon as possible, for example to choose an initial audio track before any other one had time to be loaded, you can perform the setAudioTrack call on the newAvailablePeriods event: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   for (const period of periods) {     const periodId = period.id;     const firstAudioTrack = rxPlayer.getAvailableAudioTracks(periodId)[0];     if (firstAudioTrack !== undefined) {       rxPlayer.setAudioTrack({         trackId: firstAudioTrack.id,         periodId,       });     }   } });  This will set the audio track for any future Period being loaded, including in future and not-yet-loaded contents. If you want to also update the audio track of already-loaded Periods, you can also call the getAvailablePeriods method to obtain their id property and update their audio tracks right away: const periods = rxPlayer.getAvailablePeriods(); for (const period of periods) {   const periodId = period.id;   const firstAudioTrack = rxPlayer.getAvailableAudioTracks(periodId)[0];   if (firstAudioTrack !== undefined) {     rxPlayer.setAudioTrack({       trackId: firstAudioTrack.id,       periodId,     });   } } ","anchorH1":"setaudiotrack","anchorH2":"description","anchorH3":"setting_the_audio_track_as_soon_as_possible"},{"h1":"setAudioTrack","h2":"Syntax","body":"player.setAudioTrack(audioTrackId);    arguments:  audioTrackId string: The id of the track you want to set    // Setting the current audio track player.setAudioTrack(audioTrackId);  // More complex settings player.setAudioTrack({   // required   trackId: audioTrackId,    // all optional   periodId,   switchingMode,   lockedRepresentations, });    arguments:   arg string|Object: Either the audio track’s id property of the track you want to set for current Period, or an object with the following properties (only trackId is required):   trackId (string): The id property of the track you want to lock.   periodId (string|undefined): If defined, the id of the concerned Period. If not defined, it will be applied for the current Period.   switchingMode (string|undefined): Behavior of the RxPlayer if there is a need to perform a transition between a previous audio track and the new one. The list of modes available are described in this page.   lockedRepresentations (Array.<string>|undefined): The list of Representations’ id you wish to “lock” when switching to the new track. More information in the corresponding documentation page.      ","anchorH1":"setaudiotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setTextTrack.html","index":[{"h1":"setTextTrack","body":"","anchorH1":"settexttrack"},{"h1":"setTextTrack","h2":"Description","body":"Change the text (subtitles) track. This method can take a string corresponding to the wanted track’s id property. This id can for example be obtained on the corresponding track object returned by the getAvailableTextTracks method. // Setting the first text track const textTracks = rxPlayer.getAvailableTextTracks(); rxPlayer.setTextTrack(textTracks[0].id);  setTextTrack can also accept an object argument allowing more precize settings, described below. In the case an object is given, the text track’s id should be set as in a trackId property. // Setting the first text track const textTracks = rxPlayer.getAvailableTextTracks(); rxPlayer.setTextTrack({   trackId: textTracks[0].id, });   If used on Safari, in _DirectFile_ mode, the track change may change the track on other track type (e.g. changing video track may change the subtitles track too). This has two potential reasons :    The HLS defines variants, groups of tracks that may be read together   Safari may decide to enable a track for accessibility or user language   convenience (e.g. Safari may switch subtitle to your OS language if you pick   another audio language)   You can know if another track has changed by listening to the corresponding   events that the tracks have changed.  ","anchorH1":"settexttrack","anchorH2":"description"},{"h1":"setTextTrack","h2":"Description","h3":"Changing the text track for any Period","body":"You can change the text track for any Period (and not just the one being played) by indicating its id property in a periodId property of the Object given to setTextTrack. Periods’ id properties can be retrieved from several means such as the getAvailablePeriods method or the newAvailablePeriods and periodChange events. // Example: // Changing the text track for the second Period in the current Manifest  // Recuperating all Periods currently in the Manifest const periods = rxPlayer.getAvailablePeriods();  // Getting the text track for this second Period (and not the current one): const textTracks = rxPlayer.getAvailableTextTracks(periods[1].id);  // Updating the text track of the second Period rxPlayer.setTextTrack({   trackId: textTracks[0].id,   periodId: periods[1].id, });  ","anchorH1":"settexttrack","anchorH2":"description","anchorH3":"changing_the_text_track_for_any_period"},{"h1":"setTextTrack","h2":"Description","h3":"Setting the text track as soon as possible","body":"If you want to set an text track as soon as possible, for example to choose an initial text track before any other one had time to be loaded, you can perform the setTextTrack call on the newAvailablePeriods event: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   for (const period of periods) {     const periodId = period.id;     const firstTextTrack = rxPlayer.getAvailableTextTracks(periodId)[0];     if (firstTextTrack !== undefined) {       rxPlayer.setTextTrack({         trackId: firstTextTrack.id,         periodId,       });     }   } });  This will set the text track for any future Period being loaded, including in future and not-yet-loaded contents. If you want to also update the text track of already-loaded Periods, you can also call the getAvailablePeriods method to obtain their id property and update their text tracks right away: const periods = rxPlayer.getAvailablePeriods(); for (const period of periods) {   const periodId = period.id;   const firstTextTrack = rxPlayer.getAvailableTextTracks(periodId)[0];   if (firstTextTrack !== undefined) {     rxPlayer.setTextTrack({       trackId: firstTextTrack.id,       periodId,     });   } } ","anchorH1":"settexttrack","anchorH2":"description","anchorH3":"setting_the_text_track_as_soon_as_possible"},{"h1":"setTextTrack","h2":"Syntax","body":"player.setTextTrack(textTrackId);    arguments:  textTrackId string: The id of the track you want to set    // Setting the current text track player.setTextTrack(textTrackId);  // More complex settings player.setTextTrack({   // required   trackId: textTrackId,    // optional   periodId, });    arguments:   arg string|Object: Either the text track’s id property of the track you want to set for current Period, or an object with the following properties (only trackId is required):   trackId (string): The id property of the track you want to lock.   periodId (string|undefined): If defined, the id of the concerned Period. If not defined, it will be applied for the current Period.      ","anchorH1":"settexttrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/setVideoTrack.html","index":[{"h1":"setVideoTrack","body":"","anchorH1":"setvideotrack"},{"h1":"setVideoTrack","h2":"Description","body":"Change the video track. This method can take a string corresponding to the wanted track’s id property. This id can for example be obtained on the corresponding track object returned by the getAvailableVideoTracks method. // Setting the first video track const video = rxPlayer.getAvailableVideoTracks(); rxPlayer.setVideoTrack(video[0].id);  setVideoTrack can also accept an object argument allowing more precize settings, described below. In the case an object is given, the video track’s id should be set as in a trackId property. // Setting the first video track const videoTracks = rxPlayer.getAvailableVideoTracks(); rxPlayer.setVideoTrack({   trackId: videoTracks[0].id, });  If trickmode tracks are enabled (usually through the corresponding setPlaybackRate method option) and if that new video track is linked to trickmode tracks, one of the trickmode tracks will be loaded instead. Note that trickmode tracks cannot be forced through the setVideoTrack method by giving directly the trickmode tracks’ id. If you want to enable or disable trickmode tracks, you should use setPlaybackRate instead. Setting a new video track when a previous one was already playing can lead by default to a RELOADING player state, during which playback might go into a transitory black screen and while multiple API will not be available. You can forbid this from happening (with some disadvantages, by explicitely setting  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setvideotrack","anchorH2":"description"},{"h1":"setVideoTrack","h2":"Description","h3":"Changing the video track for any Period","body":"You can change the video track for any Period (and not just the one being played) by indicating its id property in a periodId property of the Object given to setVideoTrack. Periods’ id properties can be retrieved from several means such as the getAvailablePeriods method or the newAvailablePeriods and periodChange events. // Example: // Changing the video track for the second Period in the current Manifest  // Recuperating all Periods currently in the Manifest const periods = rxPlayer.getAvailablePeriods();  // Getting the video track for this second Period (and not the current one): const videoTracks = rxPlayer.getAvailableVideoTracks(periods[1].id);  // Updating the video track of the second Period rxPlayer.setVideoTrack({   trackId: videoTracks[0].id,   periodId: periods[1].id, });  ","anchorH1":"setvideotrack","anchorH2":"description","anchorH3":"changing_the_video_track_for_any_period"},{"h1":"setVideoTrack","h2":"Description","h3":"Changing the way the video track transition is done","body":"When switching the video track, media data from the previous video track might still be present and playable in the buffer. Because you might prefer a direct transition - which may lead to a little rebuffering or even reloading short moment over a seamless transition where the previous video track might be still visible for a few seconds, the RxPlayer let you define a “switching mode” by setting the switchingMode property given to setVideoTrack. The available “switching modes” are:   \"seamless\": Clean the previous video track from the buffer, yet keep some of its data around the current position to ensure the transition stay seamless (i.e. playback still continue). The advantage is that the switch will not be abrupt (playback will not be interrupted) but you might still have a few seconds playing in the previous video track.   \"direct\": Directly and visibly switch to the new tracks. Here you will ensure that the now unwanted tracks won’t be played in the future but you might be left with a playback interruption and some rebuffering time while the new video track is loaded.   \"reload\": Directly and visibly switch to the new tracks, maybe going through the \"RELOADING\" state if necessary, during which a black screen is shown and multiple APIs are unavailable. This mode might be preferable to the \"direct\" mode for several reasons:   the \"direct\" mode might trigger some rebuffering time during which the last video frame from the previous video track is still shown. By comparison, \"reload\" whould show a black screen here instead.   This mode might have better results than \"direct\" on devices with poor compatibility     // example: switching video tracks in \"direct\" mode rxPlayer.setVideoTrack({   // we will just lock the first one here   trackId: [videoTrackId],   switchingMode: \"direct\", }); ","anchorH1":"setvideotrack","anchorH2":"description","anchorH3":"changing_the_way_the_video_track_transition_is_done"},{"h1":"setVideoTrack","h2":"Description","h3":"Selecting only some Representations in the new video track","body":"You can also start “locking” only a given set of Representations in the new track (so that only those Representations will be played) as soon as you switch the video track. This can be done by adding a lockedRepresentations property to the setVideoTrack call, which should contain an array of the wanted Representations’ id property: const videoTracks = rxPlayer.getAvailableVideoTracks(); const wantedVideoTrack = videoTracks[1]; rxPlayer.setVideoTrack({   trackId: wantedVideoTrack.id,   lockedRepresentations: [wantedVideoTrack.representations[0]], });  Doing this is equivalent to locking the video Representations through a lockAudioVideoRepresentations call, you can read its documentation page for more information on its behavior.","anchorH1":"setvideotrack","anchorH2":"description","anchorH3":"selecting_only_some_representations_in_the_new_video_track"},{"h1":"setVideoTrack","h2":"Description","h3":"Setting the video track as soon as possible","body":"If you want to set an video track as soon as possible, for example to choose an initial video track before any other one had time to be loaded, you can perform the setVideoTrack call on the newAvailablePeriods event: rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   for (const period of periods) {     const periodId = period.id;     const firstVideoTrack = rxPlayer.getAvailableVideoTracks(periodId)[0];     if (firstVideoTrack !== undefined) {       rxPlayer.setVideoTrack({         trackId: firstVideoTrack.id,         periodId,       });     }   } });  This will set the video track for any future Period being loaded, including in future and not-yet-loaded contents. If you want to also update the video track of already-loaded Periods, you can also call the getAvailablePeriods method to obtain their id property and update their video tracks right away: const periods = rxPlayer.getAvailablePeriods(); for (const period of periods) {   const periodId = period.id;   const firstVideoTrack = rxPlayer.getAvailableVideoTracks(periodId)[0];   if (firstVideoTrack !== undefined) {     rxPlayer.setVideoTrack({       trackId: firstVideoTrack.id,       periodId,     });   } } ","anchorH1":"setvideotrack","anchorH2":"description","anchorH3":"setting_the_video_track_as_soon_as_possible"},{"h1":"setVideoTrack","h2":"Syntax","body":"player.setVideoTrack(videoTrackId);    arguments:  videoTrackId string: The id of the track you want to set    // Setting the current video track player.setVideoTrack(videoTrackId);  // More complex settings player.setVideoTrack({   // required   trackId: videoTrackId,    // all optional   periodId,   switchingMode,   lockedRepresentations, });    arguments:   arg string|Object: Either the video track’s id property of the track you want to set for current Period, or an object with the following properties (only trackId is required):   trackId (string): The id property of the track you want to lock.   periodId (string|undefined): If defined, the id of the concerned Period. If not defined, it will be applied for the current Period.   switchingMode (string|undefined): Behavior of the RxPlayer if there is a need to perform a transition between a previous video track and the new one. The list of modes available are described in this page.   lockedRepresentations (Array.<string>|undefined): The list of Representations’ id you wish to “lock” when switching to the new track. More information in the corresponding documentation page.      ","anchorH1":"setvideotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/disableTextTrack.html","index":[{"h1":"disableTextTrack","body":"","anchorH1":"disabletexttrack"},{"h1":"disableTextTrack","h2":"Description","body":"Disable the current text track, if one. After calling that method, no subtitles track will be displayed for the current Period until setTextTrack is called. You can also disable the text track for another Period by calling disableTextTrack with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: disabling the text track for all Periods const periods = rxPlayer.getAvailablePeriods(); for (const period of periods) {   rxPlayer.disableTextTrack(period.id); } ","anchorH1":"disabletexttrack","anchorH2":"description"},{"h1":"disableTextTrack","h2":"Syntax","body":"// Disable the current text track player.disableTextTrack();  // Disable the text track for a specific Period player.disableTextTrack(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to disable the text track. If not defined, the text track of the currently-playing Period will be disabled.   ","anchorH1":"disabletexttrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/disableVideoTrack.html","index":[{"h1":"disableVideoTrack","body":"","anchorH1":"disablevideotrack"},{"h1":"disableVideoTrack","h2":"Description","body":"Disable the current video track, if one. Might enter in RELOADING state for a short period after calling this API. You can also disable the video track for another Period by calling disableVideoTrack with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: disabling the video track for all Periods const periods = rxPlayer.getAvailablePeriods(); for (const period of periods) {   rxPlayer.disableVideoTrack(period.id); }   This option may have no effect in DirectFile mode (see loadVideo options).   The directfile mode is a special case here because when in it, the RxPlayer depends for track selection on the  corresponding HTML standard as implemented by the different browsers.  Though this standard says nothing about not being able to disable the video track (or to stay more in line with their terms: to not select any video track), no browser implementation actually seem to be able to do it, even when the corresponding browser APIs show that no video track is currently selected. This might be a bug on their parts.   Due to this fact, we do not recommend using this API in directfile mode for now. You might even receive a reassuring `videoTrackChange` event (with a `null` payload) while the video track is still actually active. ","anchorH1":"disablevideotrack","anchorH2":"description"},{"h1":"disableVideoTrack","h2":"Syntax","body":"// Disable the current video track player.disableVideoTrack();  // Disable the video track for a specific Period player.disableVideoTrack(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to disable the video track. If not defined, the video track of the currently-playing Period will be disabled.   ","anchorH1":"disablevideotrack","anchorH2":"syntax"}]},{"file":"./api/Track_Selection/isTrickModeEnabled.html","index":[{"h1":"isTrickModeEnabled","body":"","anchorH1":"istrickmodeenabled"},{"h1":"isTrickModeEnabled","h2":"Description","body":"Tells if trick mode tracks are currently enabled if available. Trick mode tracks are video tracks with a generally lower frame rate, allowing for example to play content fast-forward in an efficient way. Note that isTrickModeEnabled returning true does not always mean that a video trick mode track is currently displayed, as it depends on whether it is actually available on the current content. You can know if a trick mode video track is currently playing by checking if the track returned by the getVideoTrack method has its isTrickModeTrack property set to true.","anchorH1":"istrickmodeenabled","anchorH2":"description"},{"h1":"isTrickModeEnabled","h2":"Syntax","body":"const isTrickModeEnabled = player.isTrickModeEnabled();   return value boolean ","anchorH1":"istrickmodeenabled","anchorH2":"syntax"}]},{"file":"./api/Representation_Selection/getVideoRepresentation.html","index":[{"h1":"getVideoRepresentation","body":"","anchorH1":"getvideorepresentation"},{"h1":"getVideoRepresentation","h2":"Description","body":"Get information about the video Representation currently loaded. Note that this only returns the video Representation that is loaded which may be different to the one that is played. The returned value can either be an object or:  null if no video track is enabled right now. undefined if no video content has been loaded yet or if its information is unknown.  In case it a video track is set and its properties is known, the getVideoRepresentation method will return an object with the following properties:   id (string): The id used to identify this Representation. No other video Representation for the same Period will have the same id. This can be useful when locking the Representation through the lockVideoRepresentations method.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   width (Number|undefined): The width of this video Representation, in pixels.   height (Number|undefined): The height of this video Representation, in pixels.   codec (string|undefined): The video codec the Representation is in, as announced in the corresponding Manifest.   frameRate (number|undefined): The video frame rate, in frames per second.   hdrInfo (Object|undefined) Information about the hdr characteristics of the Representation. (see HDR support documentation)   You can also get the information on the loaded video Representation for another Period by calling getVideoRepresentation with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: getting Representation information for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getVideoRepresentation(periods[0].id);   In DirectFile mode (see loadVideo options), this method returns \"undefined\". ","anchorH1":"getvideorepresentation","anchorH2":"description"},{"h1":"getVideoRepresentation","h2":"Syntax","body":"// Get information about the currently-loaded video Representation const videoRepresentation = player.getVideoRepresentation();  // Get information about the loaded video Representation for a specific Period const videoRepresentation = player.getVideoRepresentation(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get information about its currently loaded video Representation. If not defined, the information associated to the currently-playing Period will be returned.    return value Object|null|undefined  ","anchorH1":"getvideorepresentation","anchorH2":"syntax"}]},{"file":"./api/Representation_Selection/getAudioRepresentation.html","index":[{"h1":"getAudioRepresentation","body":"","anchorH1":"getaudiorepresentation"},{"h1":"getAudioRepresentation","h2":"Description","body":"Get information about the audio Representation currently loaded. Note that this only returns the audio Representation that is loaded which may be different to the one that is played. The returned value can either be an object or:  null if no audio track is enabled right now. undefined if no audio content has been loaded yet or if its information is unknown.  In case it a audio track is set and its properties is known, the getAudioRepresentation method will return an object with the following properties:   id (string): The id used to identify this Representation. No other audio Representation for the same Period will have the same id. This can be useful when locking the Representation through the lockAudioRepresentations method.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   codec (string|undefined): The audio codec the Representation is in, as announced in the corresponding Manifest.   You can also get the information on the loaded audio Representation for another Period by calling getAudioRepresentation with the corresponding Period’s id in argument. Such id can be obtained through the getAvailablePeriods method, the newAvailablePeriods event or the periodChange event. // example: getting Representation information for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getAudioRepresentation(periods[0].id);   In DirectFile mode (see loadVideo options), this method returns \"undefined\". ","anchorH1":"getaudiorepresentation","anchorH2":"description"},{"h1":"getAudioRepresentation","h2":"Syntax","body":"// Get information about the currently-loaded audio Representation const audioRepresentation = player.getAudioRepresentation();  // Get information about the loaded audio Representation for a specific Period const audioRepresentation = player.getAudioRepresentation(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get information about its currently loaded audio Representation. If not defined, the information associated to the currently-playing Period will be returned.    return value Object|null|undefined  ","anchorH1":"getaudiorepresentation","anchorH2":"syntax"}]},{"file":"./api/Representation_Selection/lockAudioVideoRepresentations.html","index":[{"h1":"lockVideoRepresentations / lockAudioRepresentations","body":"","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations"},{"h1":"lockVideoRepresentations / lockAudioRepresentations","h2":"Description","body":"Allows to specify respectively which video or audio Representations (a.k.a. qualities) can be played in the current audio or video track, by specifying those Representations’s id property. The RxPlayer will then choose which Representation to play between them through its usual adaptive logic. You can also force a single Representation by setting only one id in the corresponding array. The list and characteristics of each video or audio Representation as well as their id property can be found in the representations array returned respectively by the getVideoTrack() or getAudioTrack() method: // example: locking 1080p video Representations or more  const videoTrack = rxPlayer.getVideoTrack(); if (videoTrack === null) {   throw new Error(\"No video track currently\"); } const repIds = videoTrack.representations  .filter(rep => rep.height !== undefined && rep.height >= 1080)  .map(rep => rep.id); rxPlayer.lockVideoRepresentations(repIds);  This function can be used in a much more advanced way by giving it an object as argument (instead of just an array of the wanted Representations’ id), where the Representations’ id are set as a representations property. More information on this below.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations","anchorH2":"description"},{"h1":"lockVideoRepresentations / lockAudioRepresentations","h2":"Description","h3":"About “locking” and “unlocking”","body":"This mechanism of only enabling some Representations for a given track is called “locking Representations”. Calling this method allows to start locking Representations until either:   they are unlocked (through respectively the unlockVideoRepresentations or unlockAudioRepresentations method)   the corresponding track is changed: the lock is removed after switching the track for that Period. If you choose to come back to the original track in the future, it won’t be locked anymore either.   the RxPlayer “break” the lock. This is a very rare occurence happening when locked Representations all become unavailable. More details on this below.   You can know if video or audio Representations are locked for the current track (or even for the track of any Period in the content) by calling respectively the getLockedVideoRepresentations or getLockedAudioRepresentations method. It will either return null if no lock is active or the list of locked Representations’s id if a lock is currently active.","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations","anchorH2":"description","anchorH3":"about_%22locking%22_and_%22unlocking%22"},{"h1":"lockVideoRepresentations / lockAudioRepresentations","h2":"Description","h3":"Locking the Representations for another Period","body":"lockVideoRepresentations / lockAudioRepresentations can also be used to lock video and audio Representations for a Period that is not yet being played. In those more advanced usages, those methods can take an object, where the representations to lock can be set as a representations property, and the wanted period can be indicated by setting its id as a periodId property. You can list all Periods in the current content and their id by calling the getAvailablePeriods API. // example: locking an audio Representation for the second Period.  const periods = rxPlayer.getAvailablePeriods(); const secondPeriod = periods[1]; const audioTrack = rxPlayer.getAudioTrack(secondPeriod.id);  rxPlayer.lockAudioRepresentations({   // we will just lock the first one here   representations: [audioTrack.representations[0].id],   periodId: secondPeriod.id, }); ","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations","anchorH2":"description","anchorH3":"locking_the_representations_for_another_period"},{"h1":"lockVideoRepresentations / lockAudioRepresentations","h2":"Description","h3":"Configuring the “switching mode”","body":"The RxPlayer might already have buffered data before you lock Representations, meaning that some Representations which are from now unwanted may already be in the buffer and thus might still be played. Because you might want an abrupt but direct transition between old Representations and the new ones, or a more seamless transition, you can configure the way with which the RxPlayer may switch from the previous Representations to the new locked ones. This is called the “switching mode” and it is configurable through the switchingMode property that can be passed to lockAudioRepresentations and lockVideoRepresentations. If you do not care that the old Representations in the buffer might still be played, you can set this mode to \"seamless\"(will clean the buffer but without cleaning the data around the current position to keep a smooth playback) or to \"lazy\" (keep the buffer as is, without cleaning what was there before). If however you want to perform a strict and directly visible/audible switch, you might prefer to set it to \"direct\" (which might trigger a brief rebuffering) or to \"reload\" (which might trigger a temporary black screen). Here is the description of all possible modes:   \"seamless\": Clean the buffer from buffered media content from now unwanted Representations, yet keep some of that data around the current position to ensure the transition stay seamless (i.e. playback still continue). This is the default mode when locking Representations. The advantage is that the switch will not be abrupt (playback will not be interrupted) but you might still have a few seconds playing in the previous quality.   \"lazy\": Keep all other Representations in the buffer. This is the default RxPlayer’s behavior when changing the quality through regular adaptive streaming. The advantage here is that this is the most efficient in terms of network resources, though you might still play now unwanted Representations in the future. This option is particularly useful if the lock is for example used to ensure a networking bandwidth cap: here you might want that new segments only be from low quality Representations but you would not care about already-loaded segments.   \"direct\": Directly visibly/audibly switch to the new Representations. Here you will ensure that the now unwanted Representations won’t be played in the future but you might be left with a playback interruption and some rebuffering time while the new quality is loaded.   \"reload\": Directly visibly/audibly switch to the new Representations through a “reloading” step if necessary. Under that mode, you will ensure that the previous frame won’t be visible anymore and you might also have better results than \"direct\" on devices with poor compatibility, but the RxPlayer might temporarily go through a \"RELOADING\" state, during which a black screen is shown and multiple APIs are unavailable.   // example: switching video qualities in \"direct\" mode  const videoTrack = rxPlayer.getVideoTrack(); rxPlayer.lockVideoRepresentations({   // we will just lock the first one here   representations: [videoTrack.representations[0].id],   switchingMode: \"direct\", }); ","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations","anchorH2":"description","anchorH3":"configuring_the_%22switching_mode%22"},{"h1":"lockVideoRepresentations / lockAudioRepresentations","h2":"Description","h3":"“Breaking” the lock","body":"There is an edge case that should be noted, especially for encrypted contents relying on multiple decryption keys: Some rare events can make some previously-available Representations become unavailable. The main (and as of v4.0.0, only) reason would be encrypted Representations whose decryption key cannot either be used or obtained. In the event where all locked Representations become unavailable, the RxPlayer will automatically unlock Representations for that track so it can continue to play the content, a mechanism we call here “breaking the lock”. You can be notified when this happens and react accordingly (e.g. to lock other Representations or stop playback) by listening and reacting to the brokenRepresentationsLock RxPlayer event. // example: stopping playback when the lock is broken rxPlayer.addEventListener(\"brokenRepresentationsLock\", () => {   rxPlayer.stop(); }); ","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations","anchorH2":"description","anchorH3":"%22breaking%22_the_lock"},{"h1":"lockVideoRepresentations / lockAudioRepresentations","h2":"Description","h3":"Locking Representations as soon as possible","body":"You can choose to lock video and audio Representations from any Period before any media content from that Period is being loaded and buffered by reacting to the newAvailablePeriods event: // example: locking the first video Representation for each future Period rxPlayer.addEventListener(\"newAvailablePeriods\", (periods) => {   for (const period of periods) {     const videoTrack = rxPlayer.getVideoTrack(period.id);     if (videoTrack.representations.length > 0) {       rxPlayer.lockVideoRepresentations([videoTrack.representations[0].id]);     }   } });  If the content has already loaded, you can also retrieve the list of already-loaded Periods (and lock their Representations) thanks to the getAvailablePeriods method: // example: locking the first video Representation for each current Period const periods = rxPlayer.getAvailablePeriods(); for (const period of periods) {   const videoTrack = rxPlayer.getVideoTrack(period.id);   if (videoTrack.representations.length > 0) {     rxPlayer.lockVideoRepresentations([videoTrack.representations[0].id]);   } } ","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations","anchorH2":"description","anchorH3":"locking_representations_as_soon_as_possible"},{"h1":"lockVideoRepresentations / lockAudioRepresentations","h2":"Description","h3":"Locking Representations when switching to a new track","body":"You can also choose to lock video and audio Representations as soon as you switch respectively the video or audio track by calling setVideoTrack or setAudioTrack with a lockedRepresentations property, which will contain the ids of the Representations to lock. // example: locking video Representations when switching the video track const videoTracks = rxPlayer.getAvailableVideoTracks(); const wantedVideoTrack = videoTracks[1]; rxPlayer.setVideoTrack({   trackId: wantedVideoTrack.id,   lockedRepresentations: [wantedVideoTrack.representations[0]], });  Or more generally, you can apply that locking logic anytime the video or audio track switches, whether it is done explicitly (for example through a setVideoTrack call) or implicitly (for example because the previously-chosen track is not available anymore), by reacting to the trackUpdate event: rxPlayer.addEventListener(\"trackUpdate\", (evt) => {     if (evt.trackType === \"video\") {       const videoTrack = rxPlayer.getVideoTrack(evt.period.id);       if (videoTrack.representations.length > 0) {         rxPlayer.lockVideoRepresentations({           representations: [videoTrack.representations[0].id],           periodId: evt.period.id,         });       }     } else if (evt.trackType === \"audio\") {       const audioTrack = rxPlayer.getAudioTrack(evt.period.id);       if (audioTrack.representations.length > 0) {         rxPlayer.lockAudioRepresentations({           representations: [audioTrack.representations[0].id],           periodId: evt.period.id,         });       }     }   } }); ","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations","anchorH2":"description","anchorH3":"locking_representations_when_switching_to_a_new_track"},{"h1":"lockVideoRepresentations / lockAudioRepresentations","h2":"Syntax","body":"// Locking the current video Representations player.lockVideoRepresentations(lockedRepresentationsId);  // More complex configurations player.lockVideoRepresentations({   // required   representations: lockedRepresentationsId,    // all optional   periodId,   switchingMode, });  // Locking the current audio Representations player.lockAudioRepresentations(lockedRepresentationsId);  // More complex configurations player.lockAudioRepresentations({   // required   representations: lockedRepresentationsId,    // all optional   periodId,   switchingMode, });    arguments:   arg Array.<string>|Object: Either a list of the Representations’ id to lock for the current Period, or an object with the following properties (only representations is required):   representations (Array.<string>): The list of Representations’id to lock.   periodId (string|undefined): If defined, the id of the concerned Period. If not defined, it will be applied for the current Period.   switchingMode (string|undefined): Behavior of the RxPlayer if there is a need to perform a transition between previous Representation(s) to the new locked ones. The list of modes available are described in this page.      ","anchorH1":"lockvideorepresentations_/_lockaudiorepresentations","anchorH2":"syntax"}]},{"file":"./api/Representation_Selection/getLockedVideoRepresentations.html","index":[{"h1":"getLockedVideoRepresentations","body":"","anchorH1":"getlockedvideorepresentations"},{"h1":"getLockedVideoRepresentations","h2":"Description","body":"Get the last video Representations manually locked through the lockVideoRepresentations method. Returns null when no video Representation is locked. Without arguments, it returns the list of locked video Representation for the current Period. You can also get the list for any Period by providing its id property as argument. // example: getting Representations locked for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getLockedVideoRepresentations(periods[0].id); ","anchorH1":"getlockedvideorepresentations","anchorH2":"description"},{"h1":"getLockedVideoRepresentations","h2":"Syntax","body":"// Get information about the locked video Representation for the current Period const lockedVideoRepresentations = player.getLockedVideoRepresentations();  // Get information about the locked video Representation for a specific Period const lockedVideoRepresentations = player.getLockedVideoRepresentations(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get its locked video Representation. If not defined, the information associated to the currently-playing Period will be returned.    return value: Array.<string>|null: Last locked video Representation for the corresponding Period null if no video Representation is locked.  ","anchorH1":"getlockedvideorepresentations","anchorH2":"syntax"}]},{"file":"./api/Representation_Selection/getLockedAudioRepresentations.html","index":[{"h1":"getLockedAudioRepresentations","body":"","anchorH1":"getlockedaudiorepresentations"},{"h1":"getLockedAudioRepresentations","h2":"Description","body":"Get the last audio Representations manually locked through the lockAudioRepresentations method. Returns null when no audio Representation is locked. Without arguments, it returns the list of locked audio Representation for the current Period. You can also get the list for any Period by providing its id property as argument. // example: getting Representations locked for the first Period const periods = rxPlayer.getAvailablePeriods(); console.log(rxPlayer.getLockedAudioRepresentations(periods[0].id); ","anchorH1":"getlockedaudiorepresentations","anchorH2":"description"},{"h1":"getLockedAudioRepresentations","h2":"Syntax","body":"// Get information about the locked audio Representation for the current Period const lockedAudioRepresentations = player.getLockedAudioRepresentations();  // Get information about the locked audio Representation for a specific Period const lockedAudioRepresentations = player.getLockedAudioRepresentations(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get its locked audio Representation. If not defined, the information associated to the currently-playing Period will be returned.    return value: Array.<string>|null: Last locked audio Representation for the corresponding Period null if no audio Representation is locked.  ","anchorH1":"getlockedaudiorepresentations","anchorH2":"syntax"}]},{"file":"./api/Representation_Selection/unlockAudioVideoRepresentations.html","index":[{"h1":"unlockVideoRepresentations / unlockAudioRepresentations","body":"","anchorH1":"unlockvideorepresentations_/_unlockaudiorepresentations"},{"h1":"unlockVideoRepresentations / unlockAudioRepresentations","h2":"Description","body":"Disable a lock previously set respectively with the lockVideoRepresentations or the lockAudioRepresentations methods. Without arguments, it unlocks locked Representation for the current Period. You can also unlock Representations for any Period by providing its id property as argument. // Example: unlocking video Representations for the first Period const periods = rxPlayer.getAvailablePeriods(); rxPlayer.unlockVideoRepresentations(periods[0].id); ","anchorH1":"unlockvideorepresentations_/_unlockaudiorepresentations","anchorH2":"description"},{"h1":"unlockVideoRepresentations / unlockAudioRepresentations","h2":"Syntax","body":"// Unlock video Representations for the current Period player.unlockVideoRepresentations();  // Unlock audio Representations for the current Period player.unlockAudioRepresentations();  // Unlock video Representations for a specific Period player.unlockVideoRepresentations(periodId);  // Unlock audio Representations for a specific Period player.unlockAudioRepresentations(periodId);    arguments:  periodId string|undefined: The id of the Period for which you want to get its video or audio Representations unlock. If not defined, it will apply to the currently-playing Period.   ","anchorH1":"unlockvideorepresentations_/_unlockaudiorepresentations","anchorH2":"syntax"}]},{"file":"./api/Speed_Control/setPlaybackRate.html","index":[{"h1":"setPlaybackRate","body":"","anchorH1":"setplaybackrate"},{"h1":"setPlaybackRate","h2":"Description","body":"Updates the current playback rate, i.e. the speed at which contents are played. As its name hints at, the value indicates the rate at which contents play:   Setting it to 2 allows to play at a speed multiplied by 2 relatively to regular playback.   Setting that value to 1 reset the playback rate to its “normal” rythm.   Setting it to 0.5 allows to play at half the speed relatively to regular playback.   etc.   This method’s effect is persisted from content to content, and can be called even when no content is playing (it will still have an effect for the next contents). If you want to reverse effects provoked by setPlaybackRate before playing another content, you will have to call setPlaybackRate first with the default settings you want to set. As an example, to reset the speed to “normal” (x1) speed and to disable trickMode video tracks (which may have been enabled by a previous setPlaybackRate call), you can call: player.setPlaybackRate(1, { preferTrickModeTracks: false });  – This method can be used to switch to or exit from “trickMode” video tracks, which are tracks specifically defined to mimic the visual aspect of a VCR’s fast forward/rewind feature, by only displaying a few video frames during playback. This behavior is configurable through the second argument, by adding a property named preferTrickModeTracks to that object. You can set that value to true to switch to trickMode video tracks when available, and set it to false when you want to disable that logic. Note that like any configuration given to setPlaybackRate, this setting is persisted through all future contents played by the player. If you want to stop enabling trickMode tracks, you will have to call setPlaybackRate again with preferTrickModeTracks set to false. You can know at any moment whether this behavior is enabled by calling the areTrickModeTracksEnabled method. This will only means that the RxPlayer will select in priority trickmode video tracks, not that the currently chosen video tracks is a trickmode track (for example, some contents may have no trickmode tracks available). If you want to know about the latter instead, you can call getVideoTrack and/or listen to videoTrackChange events. The track returned may have an isTrickModeTrack property set to true, indicating that it is a trickmode track. Note that switching to or getting out of a trickmode video track may lead to the player being a brief instant in a \"RELOADING\" state (notified through playerStateChange events and the getPlayerState method). When in that state, a black screen may be displayed and multiple RxPlayer APIs will not be usable. This method can be called at any time, even when no content is loaded and is persisted from content to content. You can set it to 1 to reset its value to the “regular” default. It is possible to try to enable the trick mode track by setting the second argument to true (and disable it when setting false). If available, the RxPlayer will switch the current video track to the trick mode one. The trick mode track proposes video content that is often encoded with a very low framerate because the content is not intended to be played at regular framerate and because the chunks must be faster to load for the client. Examples // plays three times faster than normal player.setPlaybackRate(3);  // plays five times faster than normal, and enable trickmode tracks if they exist player.setPlaybackRate(5, { preferTrickModeTracks: true });  // reset the speed to \"normal\" (x1) speed and to disable trickMode video tracks player.setPlaybackRate(1, { preferTrickModeTracks: false }); ","anchorH1":"setplaybackrate","anchorH2":"description"},{"h1":"setPlaybackRate","h2":"Syntax","body":"player.setPlaybackRate(speed);  // or, with trickmode settings player.setPlaybackRate(speed, { preferTrickModeTracks });    arguments:  speed number: The speed / playback rate you want to set. options (optional) Object|undefined: Options related to the speed update.   ","anchorH1":"setplaybackrate","anchorH2":"syntax"}]},{"file":"./api/Speed_Control/getPlaybackRate.html","index":[{"h1":"getPlaybackRate","body":"","anchorH1":"getplaybackrate"},{"h1":"getPlaybackRate","h2":"Description","body":"Returns the current playback rate. 1 for normal playback, 2 when playing at double the speed, etc. Example const currentPlaybackRate = player.getPlaybackRate(); console.log(`Playing at a x${currentPlaybackRate}} speed`); ","anchorH1":"getplaybackrate","anchorH2":"description"},{"h1":"getPlaybackRate","h2":"Syntax","body":"const rate = player.getPlaybackRate();   return value number ","anchorH1":"getplaybackrate","anchorH2":"syntax"}]},{"file":"./api/Speed_Control/areTrickModeTracksEnabled.html","index":[{"h1":"areTrickModeTracksEnabled","body":"","anchorH1":"aretrickmodetracksenabled"},{"h1":"areTrickModeTracksEnabled","h2":"Description","body":"Returns true if trickmode playback is active (it is usually enabled through the setPlaybackRate method), which means that the RxPlayer selects “trickmode” video tracks in priority. Returns false in other cases. Note that this doesn’t mean that the player is currently playing a trickmode track nor that it is even playing a content, only that it selects trickmode tracks in priority. To switch on or off this mode, you can use the setPlaybackRate method.","anchorH1":"aretrickmodetracksenabled","anchorH2":"description"},{"h1":"areTrickModeTracksEnabled","h2":"Syntax","body":"const areEnabled = player.areTrickModeTracksEnabled();   return value boolean ","anchorH1":"aretrickmodetracksenabled","anchorH2":"syntax"}]},{"file":"./api/Volume_Control/setVolume.html","index":[{"h1":"setVolume","body":"","anchorH1":"setvolume"},{"h1":"setVolume","h2":"Description","body":"Set the current volume, from 0 (no sound) to 1 (the maximum sound level). Note that the volume set here is persisted even when loading another content. As such, this method can also be called when no content is currently playing.","anchorH1":"setvolume","anchorH2":"description"},{"h1":"setVolume","h2":"Syntax","body":"player.setVolume(volume);    arguments:  volume number: Volume from 0 to 1.   ","anchorH1":"setvolume","anchorH2":"syntax"},{"h1":"setVolume","h2":"Example","body":"// set the full volume player.setVolume(1); ","anchorH1":"setvolume","anchorH2":"example"}]},{"file":"./api/Volume_Control/getVolume.html","index":[{"h1":"getVolume","body":"","anchorH1":"getvolume"},{"h1":"getVolume","h2":"Description","body":"Current volume of the player, from 0 (no sound) to 1 (maximum sound). 0 if muted through the mute API. As the volume is not dependent on a single content (it is persistent), this method can also be called when no content is playing.","anchorH1":"getvolume","anchorH2":"description"},{"h1":"getVolume","h2":"Syntax","body":"const volume = player.getVolume();   return value number ","anchorH1":"getvolume","anchorH2":"syntax"},{"h1":"getVolume","h2":"Example","body":"const volume = player.getVolume();  if (volume === 1) {   console.log(\"You're playing at maximum volume\"); } else if (volume === 0) {   console.log(\"You're playing at no volume\"); } else if (volume > 0.5) {   console.log(\"You're playing at a high volume\"); } else {   console.log(\"You're playing at a low volume\"); } ","anchorH1":"getvolume","anchorH2":"example"}]},{"file":"./api/Volume_Control/mute.html","index":[{"h1":"mute","body":"","anchorH1":"mute"},{"h1":"mute","h2":"Description","body":"Mute the volume. Basically set the volume to 0 while keeping in memory the previous volume to reset it at the next unMute call. As the volume is not dependent on a single content (it is persistent), this method can also be called when no content is playing.","anchorH1":"mute","anchorH2":"description"},{"h1":"mute","h2":"Syntax","body":"player.mute(); ","anchorH1":"mute","anchorH2":"syntax"},{"h1":"mute","h2":"Example","body":"// mute the current volume player.mute(); ","anchorH1":"mute","anchorH2":"example"}]},{"file":"./api/Volume_Control/isMute.html","index":[{"h1":"isMute","body":"","anchorH1":"ismute"},{"h1":"isMute","h2":"Description","body":"Returns true if the volume is set to 0.","anchorH1":"ismute","anchorH2":"description"},{"h1":"isMute","h2":"Syntax","body":"const isMute = player.isMute();   return value boolean ","anchorH1":"ismute","anchorH2":"syntax"},{"h1":"isMute","h2":"Example","body":"if (player.isMute()) {   console.log(\"The content plays with no sound.\"); } ","anchorH1":"ismute","anchorH2":"example"}]},{"file":"./api/Volume_Control/unMute.html","index":[{"h1":"unMute","body":"","anchorH1":"unmute"},{"h1":"unMute","h2":"Description","body":"When muted, restore the volume to the one previous to the last mute call. When the volume is already superior to 0, this call won’t do anything. As the volume is not dependent on a single content (it is persistent), this method can also be called when no content is playing.","anchorH1":"unmute","anchorH2":"description"},{"h1":"unMute","h2":"Syntax","body":"player.unMute(); ","anchorH1":"unmute","anchorH2":"syntax"},{"h1":"unMute","h2":"Example","body":"// mute the current volume player.mute();  // unmute and restore the previous volume player.unMute(); ","anchorH1":"unmute","anchorH2":"example"}]},{"file":"./api/Buffer_Control/setWantedBufferAhead.html","index":[{"h1":"setWantedBufferAhead","body":"","anchorH1":"setwantedbufferahead"},{"h1":"setWantedBufferAhead","h2":"Description","body":"Set the buffering goal, as a duration ahead of the current position, in seconds. Once this size of buffer reached, the player won’t try to download new segments anymore. By default, this value is set to 30.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setwantedbufferahead","anchorH2":"description"},{"h1":"setWantedBufferAhead","h2":"Syntax","body":"player.setWantedBufferAhead(bufferGoal);    arguments:  bufferGoal number: Ideal amount of buffer that should be pre-loaded, in seconds.   ","anchorH1":"setwantedbufferahead","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/getWantedBufferAhead.html","index":[{"h1":"getWantedBufferAhead","body":"","anchorH1":"getwantedbufferahead"},{"h1":"getWantedBufferAhead","h2":"Description","body":"returns the buffering goal, as a duration ahead of the current position, in seconds. This is the amount of seconds after the current position that the RxPlayer will try to preload in the buffer. Once that value is reached, the RxPlayer won’t normally request new media data until the value comes down again (due e.g. to the current position evolving or to a seeking operation). By default, this value is set to 30.","anchorH1":"getwantedbufferahead","anchorH2":"description"},{"h1":"getWantedBufferAhead","h2":"Syntax","body":"const bufferGoal = player.getWantedBufferAhead();   return value number: current “buffering goal”, in seconds. ","anchorH1":"getwantedbufferahead","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/setMaxBufferBehind.html","index":[{"h1":"setMaxBufferBehind","body":"","anchorH1":"setmaxbufferbehind"},{"h1":"setMaxBufferBehind","h2":"Description","body":"Set the maximum kept buffer before the current position, in seconds. Everything before that limit (currentPosition - maxBufferBehind) will be automatically garbage collected. This feature is not necessary as the browser should by default correctly remove old segments from memory if/when the memory is scarce. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. You can set it to Infinity to remove this limit and just let the browser do this job instead.  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setmaxbufferbehind","anchorH2":"description"},{"h1":"setMaxBufferBehind","h2":"Syntax","body":"player.setMaxBufferBehind(bufferSize);    arguments:  bufferSize number: Maximum amount of buffer behind the current position, in seconds.   ","anchorH1":"setmaxbufferbehind","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/getMaxBufferBehind.html","index":[{"h1":"getMaxBufferBehind","body":"","anchorH1":"getmaxbufferbehind"},{"h1":"getMaxBufferBehind","h2":"Description","body":"Returns the maximum kept buffer before the current position, in seconds. This setting can be updated either by:  calling the setMaxBufferBehind method. instanciating an RxPlayer with a maxBufferBehind property set. ","anchorH1":"getmaxbufferbehind","anchorH2":"description"},{"h1":"getMaxBufferBehind","h2":"Syntax","body":"const bufferSize = player.getMaxBufferBehind();   return value number: Maximum kept buffer before the  current position, in seconds. ","anchorH1":"getmaxbufferbehind","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/setMaxBufferAhead.html","index":[{"h1":"setMaxBufferAhead","body":"","anchorH1":"setmaxbufferahead"},{"h1":"setMaxBufferAhead","h2":"Description","body":"Set the maximum kept buffer ahead of the current position, in seconds. Everything superior to that limit (currentPosition + maxBufferAhead) will be automatically garbage collected. This feature is not necessary as the browser should by default correctly remove old segments from memory if/when the memory is scarce. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. You can set it to Infinity to remove any limit and just let the browser do this job instead. The minimum value between this one and the one returned by getWantedBufferAhead will be considered when downloading new segments.  Bear in mind that a too-low configuration there (e.g. inferior to 10) might prevent the browser to play the content at all.   In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setmaxbufferahead","anchorH2":"description"},{"h1":"setMaxBufferAhead","h2":"Syntax","body":"player.setMaxBufferAhead(bufferSize);    arguments:  bufferSize number: Maximum amount of buffer ahead of the current position, in seconds.   ","anchorH1":"setmaxbufferahead","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/getMaxBufferAhead.html","index":[{"h1":"getMaxBufferAhead","body":"","anchorH1":"getmaxbufferahead"},{"h1":"getMaxBufferAhead","h2":"Description","body":"Returns the maximum kept buffer ahead of the current position, in seconds. This setting can be updated either by:  calling the setMaxBufferAhead method. instanciating an RxPlayer with a maxBufferAhead property set. ","anchorH1":"getmaxbufferahead","anchorH2":"description"},{"h1":"getMaxBufferAhead","h2":"Syntax","body":"const bufferSize = player.getMaxBufferAhead();   return value number: Maximum kept buffer in front of the  current position, in seconds. ","anchorH1":"getmaxbufferahead","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/setMaxVideoBufferSize.html","index":[{"h1":"setMaxVideoBufferSize","body":"","anchorH1":"setmaxvideobuffersize"},{"h1":"setMaxVideoBufferSize","h2":"Description","body":"Set the maximum memory the video buffer can take up in the memory, in kilobytes Defaults at Infinity Once this value is reached, the player won’t try to download new video segments anymore. This feature was designed with devices that have limited memory and trying to play very high bitrates representations in minds. However on some custom targets, or just to better control the memory footprint of the player, you might want to set this limit. You can set it to Infinity to remove this limit and just let the browser do this job instead.  The limit set by `setMaxVideoBufferSize` is approximative, and bypassed in edge case scenarios if we dont have enough buffer because of this limitation.   In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"setmaxvideobuffersize","anchorH2":"description"},{"h1":"setMaxVideoBufferSize","h2":"Syntax","body":"player.setMaxVideoBufferSize(bufferSize);    arguments:  bufferSize number: Maximum amount of memory the buffer can download, in kilobytes   ","anchorH1":"setmaxvideobuffersize","anchorH2":"syntax"}]},{"file":"./api/Buffer_Control/getMaxVideoBufferSize.html","index":[{"h1":"getMaxBufferSize","body":"","anchorH1":"getmaxbuffersize"},{"h1":"getMaxBufferSize","h2":"Description","body":"Returns the maximum video buffer memory size limit , in kilobytes. This setting can be updated either by:  calling the setMaxVideoBufferSize method. instanciating an RxPlayer with a maxVideoBufferSize property set. ","anchorH1":"getmaxbuffersize","anchorH2":"description"},{"h1":"getMaxBufferSize","h2":"Syntax","body":"const bufferSize = player.getMaxBufferSize();   return value number: Maximum buffer memory size limit, in kilobytes. ","anchorH1":"getmaxbuffersize","anchorH2":"syntax"}]},{"file":"./api/Buffer_Information/getCurrentBufferGap.html","index":[{"h1":"getCurrentBufferGap","body":"","anchorH1":"getcurrentbuffergap"},{"h1":"getCurrentBufferGap","h2":"Description","body":"Returns in seconds the difference between:  the current time. the end of the current contiguous loaded range.  In other words, this is the amount of seconds left in the buffer before the end of the current contiguous range of media data. If we’re currently playing at the position at 51 seconds, and there is media data from the second 40 to the second 60, then getCurrentBufferGap() will return 9 (60 - 51).","anchorH1":"getcurrentbuffergap","anchorH2":"description"},{"h1":"getCurrentBufferGap","h2":"Syntax","body":"const bufferGap = player.getCurrentBufferGap();   return value number ","anchorH1":"getcurrentbuffergap","anchorH2":"syntax"}]},{"file":"./api/Content_Information/getContentUrls.html","index":[{"h1":"getContentUrls","body":"","anchorH1":"getcontenturls"},{"h1":"getContentUrls","h2":"Description","body":"Returns URLs through which the Manifest being played can be reached, or in DirectFile mode, of the content being played. Returns undefined if no content is loaded yet or if no URL is known. Example const urls = player.getContentUrls(); if (urls !== undefined && urls.length > 0) {   console.log(     \"We are playing a content reachable through the following URLs:\",     urls   ); } ","anchorH1":"getcontenturls","anchorH2":"description"},{"h1":"getContentUrls","h2":"Syntax","body":"const urls = player.getContentUrls();   return value Array.<string>|undefined ","anchorH1":"getcontenturls","anchorH2":"syntax"}]},{"file":"./api/Content_Information/updateContentUrls.html","index":[{"h1":"updateContentUrls","body":"","anchorH1":"updatecontenturls"},{"h1":"updateContentUrls","h2":"Description","body":"Update URL of the content currently being played (e.g. of DASH’s MPD), optionally also allowing to request an immediate refresh of it. This method can for example be called when you would prefer that the content and its associated resources to be reached through another URL than what has been used until now. Note that if a request through one of the given URL lead to a HTTP redirect, the RxPlayer will generally prefer the redirected URL over the URL explicitely communicated (to prevent more HTTP redirect).  In DirectFile mode (see loadVideo options), this method has no effect. ","anchorH1":"updatecontenturls","anchorH2":"description"},{"h1":"updateContentUrls","h2":"Syntax","body":"player.updateContentUrls(urls); // or player.updateContentUrls(urls, params);    arguments:   urls Array.<string>|under: URLs to reach that content / Manifest from the most prioritized URL to the least prioritized URL.   params Object|undefined: Optional parameters linked to this URL change.   Can contain the following properties:  refresh boolean: If true the resource in question (e.g. DASH’s MPD) will be refreshed immediately.   ","anchorH1":"updatecontenturls","anchorH2":"syntax"},{"h1":"updateContentUrls","h2":"Examples","body":"// Update with only one URL player.updateContentUrls([\"http://my.new.url\"]);  // Update with multiple URLs player.updateContentUrls([   \"http://more.prioritized.url\",   \"http://less.prioritized.url\", ]);  // Set no URL (only is useful in some very specific situations, like for content // with no Manifest refresh or when a `manifestLoader` is set). player.updateContentUrls(undefined);  // Update and ask to refresh immediately player.updateContentUrls([\"http://my.new.url\"], { refresh: true }); ","anchorH1":"updatecontenturls","anchorH2":"examples"}]},{"file":"./api/Content_Information/isLive.html","index":[{"h1":"isLive","body":"","anchorH1":"islive"},{"h1":"isLive","h2":"Description","body":"Returns true if the content is a “live” content (e.g. a live TV Channel). false otherwise. Also false if no content is loaded yet. Example if (player.isLive()) {   console.log(\"We're playing a live content\"); } ","anchorH1":"islive","anchorH2":"description"},{"h1":"isLive","h2":"Syntax","body":"const isLive = player.isLive();   return value boolean ","anchorH1":"islive","anchorH2":"syntax"}]},{"file":"./api/Content_Information/getKeySystemConfiguration.html","index":[{"h1":"getKeySystemConfiguration","body":"","anchorH1":"getkeysystemconfiguration"},{"h1":"getKeySystemConfiguration","h2":"Description","body":"Returns information on the key system configuration currently associated to the HTMLMediaElement (e.g. <video> element) linked to the RxPlayer. The returned value might be null if no key system configuration is attached or if it is unknown, or, if a key system is attached and known, an object with the following properties:   keySystem (string): The actual key system string of the key system currently used. Note that it may be different than the key system name used as type property of the keySystems loadVideo option originally communicated. For example, calling the loadVideo like this: rxPlayer.loadVideo({   keySystems: [{     type: \"widevine\",     // ...   }],   // ... });  May lead to keySystem being set to \"com.widevine.alpha\" instead on most platforms where it is its proper denomination.   configuration (Object): The MediaKeySystemConfiguration actually used currently by the key system. You may parse that configuration to deduce for example the current robustness levels of the key system.  ","anchorH1":"getkeysystemconfiguration","anchorH2":"description"},{"h1":"getKeySystemConfiguration","h2":"Syntax","body":"const values = player.getKeySystemConfiguration();   return value Object|null ","anchorH1":"getkeysystemconfiguration","anchorH2":"syntax"}]},{"file":"./api/Static_Properties.html","index":[{"h1":"RxPlayer Static Properties","body":"The RxPlayer has multiple static properties allowing to read or modify global RxPlayer attributes.","anchorH1":"rxplayer_static_properties"},{"h1":"RxPlayer Static Properties","h2":"version","body":"The version static property returns a string corresponding to the current version of the RxPlayer:","anchorH1":"rxplayer_static_properties","anchorH2":"version"},{"h1":"RxPlayer Static Properties","h2":"version","h3":"example","body":"import RxPlayer from \"rx-player\";  console.log(\"Current RxPlayer version:\", RxPlayer.version); ","anchorH1":"rxplayer_static_properties","anchorH2":"version","anchorH3":"example"},{"h1":"RxPlayer Static Properties","h2":"LogLevel","body":"The current level of verbosity for the RxPlayer logs, as a string. Those logs all use the console. From the less verbose to the most:   \"NONE\": no log   \"ERROR\": unexpected errors (via console.error)   \"WARNING\": The previous level + minor problems encountered (via console.warn)   \"INFO\": The previous levels + noteworthy events (via console.info)   \"DEBUG\": The previous levels + normal events of the player (via console.log)   If the value set to this property is different than those, it will be automatically set to \"NONE\".","anchorH1":"rxplayer_static_properties","anchorH2":"loglevel"},{"h1":"RxPlayer Static Properties","h2":"LogLevel","h3":"Example","body":"import RxPlayer from \"rx-player\"; RxPlayer.LogLevel = \"WARNING\"; ","anchorH1":"rxplayer_static_properties","anchorH2":"loglevel","anchorH3":"example_(1)"},{"h1":"RxPlayer Static Properties","h2":"ErrorTypes","body":"The different “types” of Error you can get on playback error, See the Player Error documentation for more information.","anchorH1":"rxplayer_static_properties","anchorH2":"errortypes"},{"h1":"RxPlayer Static Properties","h2":"ErrorCodes","body":"The different Error “codes” you can get on playback error, See the Player Error documentation for more information.","anchorH1":"rxplayer_static_properties","anchorH2":"errorcodes"}]},{"file":"./api/Typescript_Types.html","index":[{"h1":"Exported TypeScript Types","body":"The RxPlayer being written in TypeScript, it has type definitions attached to its source code that can be helpful if you develop an application in TypeScript yourself.","anchorH1":"exported_typescript_types"},{"h1":"Exported TypeScript Types","h2":"“Using” types","body":"Because we follow the usual way of adding definition files (as d.ts file alongside our sources), those typings should be auto-exported when importing our library in your favorite editor (as long as it is linked to a TSServer of some sort).","anchorH1":"exported_typescript_types","anchorH2":"%22using%22_types"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","body":"As some APIs can have pretty complicated arguments, you might also want to import some of our internal type definitions into your code. To simplify this process, we export some type definitions which can be imported through the following line in your file: import { SOME_TYPE } from \"rx-player/types\"  Here are the list of exported types, per category.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"RxPlayer Constructor","body":"The type IConstructorOptions corresponds to the interface that the RxPlayer constructor accepts as an argument. Example: import RxPlayer from \"rx-player\"; import { IConstructorOptions } from \"rx-player/types\";  function generateConstructorOptions() : IConstructorOptions {   const videoElement = document.querySelector(\"video\");   return {     stopAtEnd: false,     videoElement,   }; }  const options = generateConstructorOptions(); const player = new RxPlayer(options);  export default player; ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"rxplayer_constructor"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"loadVideo","body":"The ILoadVideoOptions type corresponds to the argument to give to the RxPlayer’s method loadVideo. Example: // the type wanted import { ILoadVideoOptions } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  function generateLoadVideoOptions(url : string) : ILoadVideoOptions {   return {     url,     transport: \"dash\",     autoPlay: true,   }; }  const loadVideoOpts = generateLoadVideoOptions(config.DEFAULT_URL); rxPlayer.loadVideo(loadVideoOpts);  Speaking of loadVideo, some subparts of ILoadVideoOptions are also exported:   IKeySystemOption: type for an element of the keySystems array, which is an optional property given to loadVideo. To clarify, the keySystems property in a loadVideo call is an optional array of one or multiple IKeySystemOption.   IPersistentLicenseConfig: type of the persistentLicenseConfig property of the keySystems option given to loadVideo.   IPersistentSessionInfo: type used by an IPersistentSessionStorage’s storage.   IManifestLoader: type for the manifestLoader option of loadVideo.   IManifestLoaderInfo: type for the first argument of the manifestLoader function (defined by IManifestLoader.)   ILoadedManifestFormat: type for the accepted Manifest formats as returned by a IManifestLoader.   IRepresentationFilter: type for the representationFilter option of   loadVideo.   IRepresentationFilterRepresentation: type for the first argument of the representationFilter function (defined by IRepresentationFilter.)   IHDRInformation: optional type of the hdrInfo property from a IRepresentationFilterRepresentation object.   IRepresentationContext: type for the second argument of the representationFilter function (defined by IRepresentationFilter.)   IServerSyncInfos: type for the serverSyncInfos option of loadVideo.   IInitialManifest: type for the initialManifest option of loadVideo.   ISegmentLoader: type for the segmentLoader option of loadVideo.   ISegmentLoaderContext: type for the first argument of the segmentLoader function (defined by ISegmentLoader.)   ITrackType: type for the type property of a ISegmentLoaderContext object.   INetworkConfigOption: type for the networkConfig property optionally given to loadVideo.   IStartAtOption: type for the startAt property optionally given to loadVideo.   IAudioTrackSwitchingMode: The various values accepted on the defaultAudioTrackSwitchingMode property optionally given to loadVideo.  ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"loadvideo"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getPlayerState method / playerStateChange event","body":"The return type of the getPlayerState state method and of the playerStateChange events is a string describing the current state of the RxPlayer. All values possible are defined through the IPlayerState type: // the type(s) wanted import { IPlayerState } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function getPlayerState() : IPlayerState {   return rxPlayer.getPlayerState(); } ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getplayerstate_method_/_playerstatechange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getAvailableAudioTracks method / availableAudioTracksChange event","body":"The return type of the getAvailableAudioTracks method is an array of objects. Each of this objects corresponds to the IAvailableAudioTrack interface. Example: // the type(s) wanted import { IAvailableAudioTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function getAvailableAudioTracks() : IAvailableAudioTrack[] {   return rxPlayer.getAvailableAudioTracks(); }  The property of each track’s representations property corresponds to the IAudioRepresentation type.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getavailableaudiotracks_method_/_availableaudiotrackschange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getAvailableTextTracks method / availabletextTracksChange event","body":"The return type of the getAvailableTextTracks method is an array of objects. Each of this objects corresponds to the IAvailableTextTrack interface. Example: // the type(s) wanted import { IAvailableTextTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  function getAvailableTextTracks() : IAvailableTextTrack[] {   return rxPlayer.getAvailableTextTracks(); } ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getavailabletexttracks_method_/_availabletexttrackschange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getAvailableVideoTracks method / availableVideoTracksChange event","body":"The return type of the getAvailableVideoTracks method is an array of objects. Each of this objects corresponds to the IAvailableVideoTrack interface. Example: // the type(s) wanted import { IAvailableVideoTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  function getAvailableVideoTracks() : IAvailableVideoTrack[] {   return rxPlayer.getAvailableVideoTracks(); }  The property of each track’s representations property corresponds to the IVideoRepresentation type.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getavailablevideotracks_method_/_availablevideotrackschange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getAudioTrack method /audioTrackChange event","body":"The IAudioTrack corresponds to both the type returned by the getAudioTrack method and emitted as the payload of the audioTrackChange event. Example: // the type(s) wanted import { IAudioTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  rxPlayer.addEventListener(\"audioTrackChange\", (track : IAudioTrack) => {   console.log(\"current track:\", track); });  function getCurrentlyDownloadedAudioTrack() : IAudioTrack {   return rxPlayer.getAudioTrack(); }  The representations property also has an exported type: IAudioRepresentation.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getaudiotrack_method_/audiotrackchange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getTextTrack method / textTrackChange event","body":"The ITextTrack corresponds to both the type returned by the getTextTrack method and emitted as the payload of the textTrackChange event. Example: // the type(s) wanted import { ITextTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  rxPlayer.addEventListener(\"textTrackChange\", (track : ITextTrack) => {   console.log(\"current track:\", track); });  function getCurrentlyDownloadedTextTrack() : ITextTrack {   return rxPlayer.getTextTrack(); } ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"gettexttrack_method_/_texttrackchange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"getVideoTrack method / videoTrackChange event","body":"The IVideoTrack corresponds to both the type returned by the getVideoTrack method and emitted as the payload of the videoTrackChange event. Example: // the type(s) wanted import { IVideoTrack } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  // hypothetical file exporting a configuration object import config from \"./config\"; // define a global config  rxPlayer.addEventListener(\"videoTrackChange\", (track : IVideoTrack) => {   console.log(\"current track:\", track); });  function getCurrentlyDownloadedVideoTrack() : IVideoTrack {   return rxPlayer.getVideoTrack(); } ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"getvideotrack_method_/_videotrackchange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"setAudioTrack method","body":"The IAudioTrackSetting type corresponds to the object that may be given to the RxPlayer’s setAudioTrack method Example: // the type(s) wanted import { IAudioTrackSetting } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function setAudioTrack(track : IAudioTrackSetting) {   rxPlayer.setAudioTrack(track); }  The IAudioTrackSwitchingMode type list the various values accepted for the switchingMode property of the IAudioTrackSetting object.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"setaudiotrack_method"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"setVideoTrack method","body":"The IVideoTrackSetting type corresponds to the object that may be given to the RxPlayer’s setVideoTrack method Example: // the type(s) wanted import { IVideoTrackSetting } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function setVideoTrack(track : IVideoTrackSetting) {   rxPlayer.setVideoTrack(track); }  The IVideoTrackSwitchingMode type list the various values accepted for the switchingMode property of the IVideoTrackSetting object.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"setvideotrack_method"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"lockVideoRepresentations method","body":"The ILockedVideoRepresentationsSettings type corresponds to the object that may be given to the RxPlayer’s lockVideoRepresentations method. Example: // the type(s) wanted import { ILockedVideoRepresentationsSettings } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function lockVideoRepresentations(toLock : ILockedVideoRepresentationsSettings) {   rxPlayer.lockVideoRepresentations(toLock); }  The IVideoRepresentationsSwitchingMode type list the various values accepted for the switchingMode property of the ILockedVideoRepresentationsSettings object.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"lockvideorepresentations_method"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"lockAudioRepresentations method","body":"The ILockedAudioRepresentationsSettings type corresponds to the object that may be given to the RxPlayer’s lockAudioRepresentations method. Example: // the type(s) wanted import { ILockedAudioRepresentationsSettings } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function lockAudioRepresentations(toLock : ILockedAudioRepresentationsSettings) {   rxPlayer.lockAudioRepresentations(toLock); }  The IAudioRepresentationsSwitchingMode type list the various values accepted for the switchingMode property of the ILockedAudioRepresentationsSettings object.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"lockaudiorepresentations_method"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"positionUpdate event","body":"The type IPositionUpdate corresponds to the payload of a positionUpdate event. Example: // the type(s) wanted import { IPositionUpdate } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"positionUpdate\", (evt : IPositionUpdate) {   console.log(evt); }); ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"positionupdate_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"periodChange event","body":"The type IPeriodChangeEvent corresponds to the payload of a periodChange event. Example: // the type(s) wanted import { IPeriodChangeEvent } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"periodChange\", (evt : IPeriodChangeEvent) {   console.log(evt); }); ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"periodchange_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"streamEvent / streamEventSkip events","body":"The type IStreamEvent corresponds to the payload of either a streamEvent or a streamEventSkip event. The type IStreamEventData is the type of its data property. Example: // the type(s) wanted import { IStreamEvent, IStreamEventData } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  function processEventData(eventData : IStreamEventData) {   if (eventData.type === \"dash-event-stream\") {     console.log(\"DASH EventStream's event received!\");   } }  rxPlayer.addEventListener(\"streamEvent\", (evt : IStreamEvent) {   processEventData(evt.data); }); ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"streamevent_/_streameventskip_events"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"brokenRepresentationsLock event","body":"The type IBrokenRepresentationsLockContext corresponds to the payload of a brokenRepresentationsLock event. Example: // the type(s) wanted import { IBrokenRepresentationsLockContext } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(   \"brokenRepresentationsLock\",   (evt : IBrokenRepresentationsLockContext) {     console.log(evt);   });  The IPeriod type corresponds to the value of the period property from this IBrokenRepresentationsLockContext object. The ITrackType type corresponds to the value of the trackType property from this IBrokenRepresentationsLockContext object.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"brokenrepresentationslock_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"autoTrackSwitch event","body":"The type IAutoTrackSwitchEventPayload corresponds to the payload of a autoTrackSwitch event. Example: // the type(s) wanted import { IAutoTrackSwitchEventPayload } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"autoTrackSwitch\", (evt : IAutoTrackSwitchEventPayload) {   console.log(evt); });  The IPeriod type corresponds to the value of the period property from this IAutoTrackSwitchEventPayload object. The ITrackType type corresponds to the value of the trackType property from this IAutoTrackSwitchEventPayload object.","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"autotrackswitch_event"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"RxPlayer errors and warnings","body":"RxPlayer errors and warnings may for now be either a plain Error instance or a special RxPlayer-defined error (which extends the Error Object). All RxPlayer-defined error are compatible with the exported IPlayerError type. Which means that you could write the following: // the type wanted import { IPlayerError } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"error\", (err : Error | IPlayerError) => {   // ... });  rxPlayer.addEventListener(\"warning\", (err : Error | IPlayerError) => {   // ... });  ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"rxplayer_errors_and_warnings"},{"h1":"Exported TypeScript Types","h2":"Importing specific types","h3":"EncryptedMediaError’s keyStatuses property","body":"Some EncryptedMediaError error thrown by the RxPlayer, may have a keyStatuses property set. In that case, the type is described by the IEncryptedMediaErrorKeyStatusObject type: // the type wanted import { IEncryptedMediaErrorKeyStatusObject } from \"rx-player/types\";  // hypothetical file exporting an RxPlayer instance import rxPlayer from \"./player\";  rxPlayer.addEventListener(\"error\", (err : Error | IPlayerError) => {   if (err.type === \"ENCRYPTED_MEDIA_ERROR\" && err.keyStatuses !== undefined) {     logKeyStatuses(err.keyStatuses);   } });  function logKeyStatuses(keyStatuses: IEncryptedMediaErrorKeyStatusObject): void { console.log(keyStatuses); }  ","anchorH1":"exported_typescript_types","anchorH2":"importing_specific_types","anchorH3":"encryptedmediaerror's_%60keystatuses%60_property"}]},{"file":"./api/Tools/TextTrackRenderer.html","index":[{"h1":"TextTrackRenderer","body":"","anchorH1":"texttrackrenderer"},{"h1":"TextTrackRenderer","h2":"Overview","body":"The TextTrackRenderer is a tool allowing to render subtitles synchronized with a video element (or any HTMLMediaElement). For now it supports the following formats:  TTML webVTT srt sami  The video does not need to be played through the RxPlayer for the TextTrackRenderer to work. It is a completely independent tool which just rely on the video element for synchronization information.","anchorH1":"texttrackrenderer","anchorH2":"overview"},{"h1":"TextTrackRenderer","h2":"Brief summary","body":"If you don’t want to read all this documentation, here is a complete example of how it can be used: // import TextTrackRenderer and the parsers we want import TextTrackRenderer, {   TTML_PARSER,   VTT_PARSER,   SRT_PARSER,   SAMI_PARSER, } from \"rx-player/tools/TextTrackRenderer\";  // Add the needed parsers to the TextTrackRenderer TextTrackRenderer.addParsers([   TTML_PARSER,   VTT_PARSER,   SRT_PARSER,   SAMI_PARSER, ]);  // get video element the subtitles has to be synchronized to const videoElement = document.querySelector(\"video\");  // get HTML element in which the text track will be displayed // Should generally be on top of the video, with the same size than it (but can // also be in any shape, corresponding to your UI needs). const textTrackElement = document.querySelector(\".text-track-container\");  const textTrackRenderer = new TextTrackRenderer({   videoElement,   textTrackElement, });  // example: a \".srt\" track const exampleSRT = `1 00:00:01,600 --> 00:00:04,200 English (US)  2 00:00:05,900 --> 00:00:07,999 This is a subtitle in American English  3 00:00:10,000 --> 00:00:14,000 Adding subtitles is very easy to do `;  try {   textTrackRenderer.setTextTrack({     data: exampleSRT,     type: \"srt\", // or \"ttml\" / \"vtt\" / \"sami\"     // timeOffset: 2.3, // optional offset in seconds to add to the subtitles   }); } catch (e) {   console.error(`Could not parse the subtitles: ${e}`); } ","anchorH1":"texttrackrenderer","anchorH2":"brief_summary"},{"h1":"TextTrackRenderer","h2":"How to import it","body":"The TextTrackRenderer alone can be imported as such: import TextTrackRenderer from \"rx-player/tools/TextTrackRenderer\";  But just importing the TextTrackRenderer alone is pointless, you also have to import the text track parsers you want to use manually (this is a choice we made to avoid wasting space for subtitles formats you might not want). To import the parsers you want, you just have to do something along the line of: // Add two parsers to the TextTrackRenderer: one for TTML subtitles and one for // srt subtitles import TextTrackRenderer, {   TTML_PARSER,   SRT_PARSER, } from \"rx-player/tools/TextTrackRenderer\"; TextTrackRenderer.addParsers([TTML_PARSER, SRT_PARSER]);  Here are the different available parsers:    Import name Subtitles format parsed     TTML_PARSER TTML   VTT_PARSER WebVTT   SRT_PARSER SubRip (.srt)   SAMI_PARSER SAMI   ","anchorH1":"texttrackrenderer","anchorH2":"how_to_import_it"},{"h1":"TextTrackRenderer","h2":"How to use it","body":"","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Preamble","body":"Now that it is imported, we can begin to use it. We will need three items:   The video element our subtitles has to be synchronized to.   Another HTML element, in which the various subtitles will be rendered by the TextTrackRenderer. In general, you want that element to be on top of the video element, with the same dimensions. You might however set it in the shape and size you want. It can even be reduced dynamically at any time (for example, to reduce this element’s height when a UI element appear at the bottom of the screen, thus avoiding the subtitles from overlapping that new element).   The whole text track data, as a string (you will have to download the subtitles yourself).   To simplify, let’s give a name to all those 3 elements:  the videoElement the textTrackElement the textTrackData ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"preamble"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Creating a TextTrackRenderer","body":"We first have to create a new TextTrackRenderer with the first two items: const textTrackRenderer = new TextTrackRenderer({   videoElement,   textTrackElement, }); ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"creating_a_texttrackrenderer"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Setting a text track on it","body":"With textTrackRenderer, the TextTrackRenderer instance, we can now add at any time a text track through its setTextTrack method: try {   textTrackRenderer.setTextTrack({     data: textTrackData,     type: SUBTITLES_FORMAT,   }); } catch (e) {   console.error(`Could not parse the subtitles: ${e}`); }  Here, SUBTITLES_FORMAT is a string indicating in which format the subtitles are. It can be any of those strings:    type Corresponding subtitles format     \"ttml\" TTML   \"vtt\" WebVTT   \"srt\" SubRip (.srt)   \"sami\" SAMI    (Each format needs the corresponding parser to be imported. See the previous chapter for more information.) Note that the setTextTrack method can throw if the subtitles are found to be invalid. Any subsequent call to setTextTrack will remove the current text track and replace them with the new text track instead: // Add TTML subtitles textTrackRenderer.setTextTrack({   data: textTrackData1,   type: \"ttml\", });  // Completely removes the TTML subtitles and replace them by other subtitles, in // webVTT this time textTrackRenderer.setTextTrack({   data: textTrackData2,   type: \"vtt\", });  If your subtitles have a delay or are in advance relatively to the video, you can also set an offset in seconds through the timeOffset property. For example, this will display each subtitles 1.3 seconds later (for when subtitles appear and disappear too much in advance): textTrackRenderer.setTextTrack({   data: textTrackData,   type: \"srt\",   timeOffset: 1.3, });  And this will display each subtitles 1.3 seconds before they normally appear and disappear (for when subtitles are too late): textTrackRenderer.setTextTrack({   data: textTrackData,   type: \"srt\",   timeOffset: -1.3, }); ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"setting_a_text_track_on_it"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Removing the current text track","body":"If you just want to completely remove the current text track, you can call the removeTextTrack method: textTrackRenderer.removeTextTrack(); ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"removing_the_current_text_track"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Disposing of the TextTrackRenderer","body":"If you’re sure that you won’t need the TextTrackRenderer anymore, you can dispose of most ressources (which is not much) it took on your page by calling the dispose method: textTrackRenderer.dispose();  That TextTrackRenderer instance won’t be usable once you’ve call this method, so be sure you don’t need it anymore before calling it.","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"disposing_of_the_texttrackrenderer"},{"h1":"TextTrackRenderer","h2":"How to use it","h3":"Notes on the SAMI format","body":"The SAMI subtitles format might necessitate you to specify the language you want to parse. This can be done on the setTextTrack call like this: textTrackRenderer.setTextTrack({   data: textTrackData,   type: \"sami\",   language: \"en-US\", // or fr-FR... }); ","anchorH1":"texttrackrenderer","anchorH2":"how_to_use_it","anchorH3":"notes_on_the_sami_format"},{"h1":"TextTrackRenderer","h2":"About logs","body":"The TextTrackRenderer can display logs to the console. It relies on the exact same logger instance than the RxPlayer. This logger can be independently imported from \"rx-player/logger\": import logger from \"rx-player/logger\";  You can then set its verbosity through its setLevel method: logger.setLevel(LOGGER_LEVEL);  LOGGER_LEVEL can be any of those strings (from the less verbose to the most):   \"NONE\": no log   \"ERROR\": unexpected errors (via console.error)   \"WARNING\": The previous level + minor problems encountered (via console.warn)   \"INFO\": The previous levels + noteworthy events (via console.info)   \"DEBUG\": The previous levels + regular events (via console.log)    Updating the logger level will also update the RxPlayer's logger level as it is the exact same logger that is used there. ","anchorH1":"texttrackrenderer","anchorH2":"about_logs"}]},{"file":"./api/Tools/VideoThumbnailLoader.html","index":[{"h1":"VideoThumbnailLoader","body":"","anchorH1":"videothumbnailloader"},{"h1":"VideoThumbnailLoader","h2":"Overview","body":"The VideoThumbnailLoader is a tool that can help exploiting a trickmode video track to provide thumbnails for a video content. The goal is to make a thumbnail out of HTML5 video element, by :  Managing the loading / appending of resources from a given track (video segments). Exploiting the Media Source Extension API to make it invisible to user.  The tool will need the loaded manifest to contain trickmode tracks. These kind of track exists in MPEG-DASH and HLS, and contains lightweight video tracks, most of the time including one unique frame for each video segments. As video segments from trickmode tracks may be quicker to load and easier to decode, they are preferred over standard video tracks for creating thumbnails.","anchorH1":"videothumbnailloader","anchorH2":"overview"},{"h1":"VideoThumbnailLoader","h2":"How to use it","body":"As an experimental tool, the VideoThumbnailLoader won’t be included in a default RxPlayer build. Instead, it should be imported by adding the RxPlayer through a dependency trough the npm registry (e.g. by doing something like npm install rx-player) and then specifically importing this tool from \"rx-player/experimental/tools\": import VideoThumbnailLoader, {   DASH_LOADER, } from \"rx-player/experimental/tools/VideoThumbnailLoader\"; import RxPlayer from \"rx-player\";  const player = new RxPlayer({   /* some options */ });  // Link logic to handle DASH segments VideoThumbnailLoader.addLoader(DASH_LOADER);  // Video element used to display thumbnails. const thumbnailVideoElement = document.createElement(\"video\");  // Link VideoThumbnailLoader to the RxPlayer instance const videoThumbnailLoader = new VideoThumbnailLoader(   thumbnailVideoElement,   player );  player.loadVideo({   /* some options */ });  // Ask for the VideoThumbnailLoader to fetch a thumbnail for the current // content that should be displayed at presentation time = 200 seconds. videoThumbnailLoader.setTime(200); ","anchorH1":"videothumbnailloader","anchorH2":"how_to_use_it"},{"h1":"VideoThumbnailLoader","h2":"Static methods","body":"","anchorH1":"videothumbnailloader","anchorH2":"static_methods"},{"h1":"VideoThumbnailLoader","h2":"Static methods","h3":"addLoader","body":"arguments:  loader (Object): Imported loader from VideoThumbnailLoader package.  To be able to load and parse segments from a specific streaming format, you must import the corresponding loader and add it to the related instance : /!\\ Note that this is a static method, it has to be called on the VideoThumbnailLoader class and will add the corresponding logic to all VideoThumbnailLoader instances (even those already created). Example import VideoThumbnailLoader, {   DASH_LOADER,   MPL_LOADER, } from \"rx-player/experimental/tools/VideoThumbnailLoader\"; VideoThumbnailLoader.addLoader(DASH_LOADER); VideoThumbnailLoader.addLoader(MPL_LOADER); ","anchorH1":"videothumbnailloader","anchorH2":"static_methods","anchorH3":"addloader"},{"h1":"VideoThumbnailLoader","h2":"Instance methods","body":"","anchorH1":"videothumbnailloader","anchorH2":"instance_methods"},{"h1":"VideoThumbnailLoader","h2":"Instance methods","h3":"setTime","body":"arguments:  time (number): Time for which we want to display a thumbnail, in seconds.  return value: Promise Display thumbnail for the corresponding time (in seconds). Note: this tool rely on “trickmode” tracks to be present for the corresponding content at the corresponding time. Return value The return value is a Promise. It :  resolve when the thumbnail for given time has been loaded. reject in case of error : return an error.  The promise does not only rejects when setting thumbnail has failed. There are some cases where the thumbnail loader decides not to load. Here is a list of every failure code (error.code) :  NO_MANIFEST : No manifest available on current RxPlayer instance. NO_TRACK : In the player manifest, there are either no period or no representation to get video chunks. NO_THUMBNAIL : No segments are available for this time of the track. LOADING_ERROR : An error occured when loading a thumbnail into the video element. ABORTED : The loading has been aborted (probably because of another loading started) NO_LOADER : Trickmode track can’t be loaded as no loader was imported, or exists for this type of content (e.g. HSS content)  Example videoThumbnailLoader   .setTime(3000)   .then(() => {     console.log(\"Success :)\");   })   .catch((err) => {     console.log(\"Failure :(\", err);   }); ","anchorH1":"videothumbnailloader","anchorH2":"instance_methods","anchorH3":"settime"},{"h1":"VideoThumbnailLoader","h2":"Instance methods","h3":"dispose","body":"Dispose the tool resources. It has to be called when the tool is not used anymore. Example   onComponentUnmount() {     videoThumbnailLoader.dispose();   } ","anchorH1":"videothumbnailloader","anchorH2":"instance_methods","anchorH3":"dispose"}]},{"file":"./api/Tools/StringUtils.html","index":[{"h1":"StringUtils","body":"","anchorH1":"stringutils"},{"h1":"StringUtils","h2":"Overview","body":"Tools to convert strings into bytes and vice-versa. The RxPlayer internally has a lot of code dealing with strings to bytes conversion (and vice-versa). This tool exports that logic so you don’t have to rewrite it yourself. You might need one of those functions for example when dealing with challenge and licenses, which are often under a binary format.","anchorH1":"stringutils","anchorH2":"overview"},{"h1":"StringUtils","h2":"How to import it","body":"The simplest way to import the StringUtils is by importing it as a named export from “rx-player/tools”, like so: import { StringUtils } from \"rx-player/tools\";  console.log(StringUtils.strToUtf8(\"hello😀\"));  You can also import only the function(s) you want to use by importing it directly from “rx-player/tools/string-utils”: import { strToUtf8 } from \"rx-player/tools/string-utils\"; console.log(strToUtf8(\"hello😀\")); ","anchorH1":"stringutils","anchorH2":"how_to_import_it"},{"h1":"StringUtils","h2":"StringUtils functions","body":"StringUtils is an object containing the following functions:   strToUtf8: Convert a JS string passed as argument to an Uint8Array of its corresponding representation in UTF-8. Example: import { StringUtils } from \"rx-player/tools\"; StringUtils.strToUtf8(\"hello😀\"); // => Uint8Array(9) [ 104, 101, 108, 108, 111, 240, 159, 152, 128 ] //                    \"h\"  \"e\"  \"l\"  \"l\"  \"o\"  \"grinning face\" emoji    utf8ToStr: Convert a Uint8Array containing a string encoded with UTF-8 into a JS string. Example: import { StringUtils } from \"rx-player/tools\"; const uint8Arr = new Uint8Array([   104,   101,   108,   108,   111,   240,   159,   152,   128, ]); StringUtils.utf8ToStr(uint8Arr); // => \"hello😀\"  Note: if what you have is an ArrayBuffer, you have to convert it to an Uint8Array first: import { StringUtils } from \"rx-player/tools\"; const toUint8Array = new Uint8Array(myArrayBuffer); console.log(StringUtils.utf8ToStr(toUint8Array));    strToUtf16LE: Convert a JS string passed as argument to an Uint8Array containing its corresponding representation in UTF-16-LE (little endian UTF-16). Example: import { StringUtils } from \"rx-player/tools\"; StringUtils.strToUtf16LE(\"hi😀\"); // => Uint8Array(9) [ 104, 0, 105, 0, 61, 216, 0, 222 ] //                    \"h\"     \"i\"     \"grinning face\" emoji    utf16LEToStr: Convert a Uint8Array containing a string encoded with UTF-16-LE (little endian UTF-16) into a JS string. Example: import { StringUtils } from \"rx-player/tools\"; const uint8Arr = new Uint8Array([104, 0, 105, 0, 61, 216, 0, 222]); StringUtils.utf16LEToStr(uint8Arr); // => \"hi😀\"  Note: if what you have is an ArrayBuffer, you have to convert it to an Uint8Array first: import { StringUtils } from \"rx-player/tools\"; const toUint8Array = new Uint8Array(myArrayBuffer); console.log(StringUtils.utf16LEToStr(toUint8Array));    strToUtf16BE: Convert a JS string passed as argument to an Uint8Array containing its corresponding representation in UTF-16-BE (big endian UTF-16). Example: import { StringUtils } from \"rx-player/tools\"; StringUtils.strToUtf16BE(\"hi😀\"); // => Uint8Array(9) [ 0, 104, 0, 105, 216, 61, 222, 0 ] //                    \"h\"     \"i\"     \"grinning face\" emoji    utf16BEToStr: Convert a Uint8Array containing a string encoded with UTF-16-BE (big endian UTF-16) into a JS string. Example: import { StringUtils } from \"rx-player/tools\"; const uint8Arr = new Uint8Array([0, 104, 0, 105, 216, 61, 222, 0]); StringUtils.utf16BEToStr(uint8Arr); // => \"hi😀\"  Note: if what you have is an ArrayBuffer, you have to convert it to an Uint8Array first: import { StringUtils } from \"rx-player/tools\"; const toUint8Array = new Uint8Array(myArrayBuffer); console.log(StringUtils.utf16BEToStr(toUint8Array));   ","anchorH1":"stringutils","anchorH2":"stringutils_functions"}]},{"file":"./api/Tools/parseBifThumbnails.html","index":[{"h1":"parseBifThumbnails","body":"","anchorH1":"parsebifthumbnails"},{"h1":"parseBifThumbnails","h2":"Overview","body":"parseBifThumbnails is a function allowing to easily parse BIF files, which is a file format crafted to contain video thumbnails. Those are usually used to give a visual indication of where in a given media you will seek to when hovering a progress bar.","anchorH1":"parsebifthumbnails","anchorH2":"overview"},{"h1":"parseBifThumbnails","h2":"About BIF files","body":"The BIF format is straightforward. It contains several metadata and then all the images for the whole content, in their original format (e.g. “jpeg”), concatenated.","anchorH1":"parsebifthumbnails","anchorH2":"about_bif_files"},{"h1":"parseBifThumbnails","h2":"How to import it","body":"parseBifThumbnails is for now considered an “experimental” tool. This means that its API could change at any new version of the RxPlayer (don’t worry, we would still document all changes made to it in the corresponding release note). As an experimental tool, it is imported as such: import { parseBifThumbnails } from \"rx-player/experimental/tools\";  You can then begin to use it right away.","anchorH1":"parsebifthumbnails","anchorH2":"how_to_import_it"},{"h1":"parseBifThumbnails","h2":"How to use it","body":"As a simple parser, parseBifThumbnails takes the downloaded BIF file in an ArrayBuffer form and returns its content under an object format, like this: import { parseBifThumbnails } from \"rx-player/experimental/tools\";  // optionally, fetch the BIF resource through the usual APIs fetch(\"http://www.example.com/thumbnails.bif\").then(function(response) {   return response.arrayBuffer(); // obtain an ArrayBuffer response }).then(function(buffer) {   const parsedBif = parseBifThumbnails(buffer);   console.log(\"parsed BIF:\", parsedBif); };  Here is an example of the returned data: {   version: \"0.0.0.0\", // BIF version. For the moment, only \"0.0.0.0\" is                       // specified.   images: [    // Array of thumbnails for this content     {       startTime: 0, // Start position at which the thumbnail should be applied                     // to, in milliseconds.                     // For example, a time of `5000`, indicates that this                     // thumbnail should be shown from the 5 second mark in the                     // content (until the next image is displayed instead)       image: ArrayBuffer() // The thumbnail itself, in an ArrayBuffer form.     },     {       startTime: 10000,       endTime: 20000,       thumbnail: ArrayBuffer()     },     {       startTime: 20000,       endTime: 30000,       thumbnail: ArrayBuffer()     },     // ...   ], } ","anchorH1":"parsebifthumbnails","anchorH2":"how_to_use_it"}]},{"file":"./api/Tools/MediaCapabilitiesProber.html","index":[{"h1":"MediaCapabilitiesProber","body":"","anchorH1":"mediacapabilitiesprober"},{"h1":"MediaCapabilitiesProber","h2":"Overview","body":"The MediaCapabilitiesProber is a tool probing what your browser can do, especially:   Which DRM system is supported   Check for HDCP support   which codecs are available   Check the color space support    This tool is still in an experimental phase, meaning that its API can change at any new release. This is not because it is not stable (it is actually) or should not be used in production. This is just because we want to receive your feedbacks before locking definitely the API.  We can for example add supplementary information of even explode the MediaCapabilitiesProber into several tools to lower the size of the import. We’re waiting for your feedbacks!","anchorH1":"mediacapabilitiesprober","anchorH2":"overview"},{"h1":"MediaCapabilitiesProber","h2":"How to use it","body":"As an experimental tool, the MediaCapabilitiesProber won’t be included in a default RxPlayer build. Instead, it should be imported by adding the RxPlayer through a dependency trough the npm registry (e.g. by doing something like npm install rx-player) and then specifically importing this tool from \"rx-player/experimental/tools\": import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  mediaCapabilitiesProber.getStatusForHDCP(\"1.1\").then((hdcp11Status) => {   if (hdcp11Status === \"Supported\") {     console.log(\"HDCP 1.1 is supported\");   } }); ","anchorH1":"mediacapabilitiesprober","anchorH2":"how_to_use_it"},{"h1":"MediaCapabilitiesProber","h2":"Properties","body":"","anchorH1":"mediacapabilitiesprober","anchorH2":"properties"},{"h1":"MediaCapabilitiesProber","h2":"Properties","h3":"LogLevel","body":"type: string default: \"WARNING\" The current level of verbosity for this prober logs. Those logs all use the console. From the less verbose to the most:   \"NONE\": no log   \"ERROR\": unexpected errors (via console.error)   \"WARNING\": The previous level + minor problems encountered (via console.warn)   \"INFO\": The previous levels + noteworthy events (via console.info)   \"DEBUG\": The previous levels + normal events of the prober (via console.log)   If the value set to this property is different than those, it will be automatically set to \"NONE\". It is set to \"WARNING\" by default as it allows you to know if you forgot to set required information on each APIs, if some APIs are missing in your browser, etc. You might want to set it to \"NONE\" when in production. Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\"; mediaCapabilitiesProber.LogLevel = \"NONE\"; ","anchorH1":"mediacapabilitiesprober","anchorH2":"properties","anchorH3":"loglevel"},{"h1":"MediaCapabilitiesProber","h2":"Functions","body":"","anchorH1":"mediacapabilitiesprober","anchorH2":"functions"},{"h1":"MediaCapabilitiesProber","h2":"Functions","h3":"getCompatibleDRMConfigurations","body":"arguments:   keySystems (Array.<Object>): An array of key system configurations. Those objects have the following properties:   type (string): Key system string identifying it in the browser. Always a reverse domain name (e.g. “org.w3.clearkey”).   configuration (Object): Wanted MediaKeySystemConfiguration for this key system, as defined in the EME w3c specification.     return value: Array.<Object> Probe the support of various key sytems and for each compatible ones, returns the corresponding configuration that will be used. Return value The returned value is an array of object with the same number of elements than the one given in argument. It indicates the support for each Key System given in argument in the same order. Due to that, the objects in this array look like the ones given in argument (but with an added property):   type (string): Corresponding key system string given in input.   configuration (Object): Corresponding wanted MediaKeySystemConfiguration given in input.   compatibleConfiguration (undefined|Object): if the type and configuration are both compatible with the browser, this is the corresponding actual MediaKeySystemConfiguration that will be effectively used. It will often correspond to a subset of the inputted configuration object (for example, you might have there fewer videoCapabilities that in the configuration object). If the type and/or the configuration are not compatible, this property will not be defined.   Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  const mksConfiguration = {   initDataTypes: [\"cenc\"],   videoCapabilities: [     {       contentType: 'video/mp4;codecs=\"avc1.4d401e\"', // standard mp4 codec       robustness: \"HW_SECURE_CRYPTO\",     },     {       contentType: 'video/mp4;codecs=\"avc1.4d401e\"',       robustness: \"SW_SECURE_DECODE\",     },   ], };  const keySystems = [   // Let's consider this one as a compatible key system configuration   { type: \"com.widevine.alpha\", configuration: mksConfiguration },    // Let's consider this one as not compatible   { type: \"com.microsoft.playready\", configuration: mksConfiguration }, ];  mediaCapabilitiesProber   .getCompatibleDRMConfigurations(keySystems)   .then((drmConfigs) => {     drmConfigs.forEach((config) => {       const { type, configuration, compatibleConfiguration } = config;        if (compatibleConfiguration !== undefined) {         console.log(\"# Compatible configuration #############################\");         console.log(\"Key System:\", type);         console.log(\"Wanted configuration:\", configuration);         console.log(\"Compatible configuration:\", compatibleConfiguration);         console.log(\"########################################################\");         console.log(\"\");       } else {         console.log(\"# Incompatible configuration ###########################\");         console.log(\"Key System:\", type);         console.log(\"Wanted configuration:\", configuration);         console.log(\"########################################################\");         console.log(\"\");       }     });   });  // Example output (please note that in this example, one of the widevine // robustness is not supported): // // # Compatible configuration ############################# // Key System: com.widevine.alpha // Wanted configuration: // { //   \"initDataTypes\":[\"cenc\"], //   \"videoCapabilities\": [ //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\": \"HW_SECURE_CRYPTO\" //     }, //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\": \"SW_SECURE_DECODE\" //     } //   ] // } // Compatible configuration: // { //   \"audioCapabilities\": [], //   \"distinctiveIdentifier\": \"not-allowed\", //   \"initDataTypes\": [\"cenc\"], //   \"label\": \"\", //   \"persistentState\": \"not-allowed\", //   \"sessionTypes\": [\"temporary\"], //   \"videoCapabilities\": [ //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\":\"SW_SECURE_DECODE\" //     } //   ] // } // ######################################################## // // # Incompatible configuration ########################### // Key System: com.microsoft.playready // Wanted configuration: // { //   \"initDataTypes\":[\"cenc\"], //   \"videoCapabilities\": [ //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\": \"HW_SECURE_CRYPTO\" //     }, //     { //       \"contentType\": \"video/mp4;codecs=\\\"avc1.4d401e\\\"\", //       \"robustness\": \"SW_SECURE_DECODE\" //     } //   ] // } // ######################################################## ","anchorH1":"mediacapabilitiesprober","anchorH2":"functions","anchorH3":"getcompatibledrmconfigurations"},{"h1":"MediaCapabilitiesProber","h2":"Functions","h3":"getStatusForHDCP","body":"arguments:  type (string): The HDCP type (e.g. “1.0”, “1.1” or “2.0”)  return value: string Test for an HDCP configuration. The returned string of this function is either:   \"Supported\": This HDCP configuration is supported.   \"NotSupported\": The HDCP configuration is not supported.   \"Unknown\": The API is not available or it is but could not check if the HDCP type is supported.    As of the 2018-july-03, this feature is very poorly supported (with only some support on the EDGE browser).  We should have a real support of it in the coming months on Chrome and Firefox.  Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  mediaCapabilitiesProber.getStatusForHDCP(\"1.1\").then((hdcpStatus) => {   switch (hdcpStatus) {     case \"Supported\":       console.log(\"This HDCP version is supported\");       break;      case \"NotSupported\":       console.log(\"This HDCP version is not supported\");       break;      case \"Unknown\":       console.log(\"We could'nt tell if this HDCP version is supported.\");       break;   } }); ","anchorH1":"mediacapabilitiesprober","anchorH2":"functions","anchorH3":"getstatusforhdcp"},{"h1":"MediaCapabilitiesProber","h2":"Functions","h3":"getDecodingCapabilities","body":"arguments:  config (Object): Object with type, video and audio configuration.  return value: string Probe for audio/video decoding capabilities. Argument The object in argument is inspired from the concerned API configurations. All its properties are optional, here are what you can set.   type (string): The media is either buffered in MediaSource, or directly as a file. As such, you can specify which one you want to probe through one of the following strings:  “media-source” “file”.    video (Object): The video capabilities you want to probe.  contentType (string): Media codec in mimeType format. width (number): Video width. height (number): Video Height. bitrate (number): Bitrate of the video (in bits per second). framerate (string): Number of frames used in one second. bitsPerComponent (number): Number of bits used to encode one component par pixel.    audio (Object): The video capabilities you want to probe.  contentType (string): Media codec in mimeType format. channels (string): Audio channels used by the track. bitrate (number): Bitrate from stream (bits/second). samplerate (number): Number of samples of audio carried per second.    Return value The returned string of this function is either:   \"Supported\": This configuration is supported.   \"MaybeSupported\": Some set configuration could not be probed because not enough information was provided, but what has been probed is supported.   \"NotSupported\": The configuration is not supported.   Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  mediaCapabilitiesProber   .getDecodingCapabilities({     type: \"media-source\",     video: {       contentType: 'video/webm; codecs=\"vp09.00.10.08\"',       width: 1920,       height: 1080,       bitrate: 3450000,       framerate: \"25\",       bitsPerComponent: 8,     },     audio: {       contentType: 'audio/webm; codecs=\"opus\"',       channels: 6,       bitrate: 1200,       samplerate: 44100,     },   })   .then((status) => {     switch (status) {       case \"Supported\":         console.log(\"The configuration is supported\");         break;        case \"MaybeSupported\":         console.log(\"The configuration may be supported\");         break;        case \"NotSupported\":         console.log(\"The configuration is not supported\");         break;     }   }); ","anchorH1":"mediacapabilitiesprober","anchorH2":"functions","anchorH3":"getdecodingcapabilities"},{"h1":"MediaCapabilitiesProber","h2":"Functions","h3":"getDisplayCapabilities","body":"arguments:  config (Object): Object with display configuration.  return value: string Probe what can be displayed on the screen. Argument The object in argument is inspired from the concerned API configurations. All its properties are optional, here are what you can set.  colorSpace (string): Wanted color space (“srgb”, “p3”, etc). width (number): Wanted display horizontal resolution. height (number): Wanted display vertical resolution. bitsPerComponent (number): Wanted display bpc capability.  Return Value The returned string of this function is either:   \"Supported\": This configuration is supported.   \"MaybeSupported\": Some set configuration could not be probed because not enough information was provided, but what has been probed is supported.   \"NotSupported\": The configuration is not supported.   Example import { mediaCapabilitiesProber } from \"rx-player/experimental/tools\";  mediaCapabilitiesProber   .getDisplayCapabilities({     colorSpace: \"p3\",     width: 3840,     height: 2160,     bitsPerComponent: 10,   })   .then((status) => {     switch (status) {       case \"Supported\":         console.log(\"The configuration is supported\");         break;        case \"MaybeSupported\":         console.log(\"The configuration may be supported\");         break;        case \"NotSupported\":         console.log(\"The configuration is not supported\");         break;     }   }); ","anchorH1":"mediacapabilitiesprober","anchorH2":"functions","anchorH3":"getdisplaycapabilities"},{"h1":"MediaCapabilitiesProber","h2":"Exploited browser APIs","body":"The tool probes media capabilities from browsers (Chrome, Firefox, etc.) exploiting current available media API:   mediaCapabilities - Chrome >= 64 (https://github.com/WICG/media-capabilities)  Check for decoding capabilites from video and audio attributes.    isTypeSupportedWithFeatures - Microsoft EDGE  Check for DRM support + decoding and displaying capabilites from video, audio, display and media protection configuration.    isTypeSupported - Chrome >= 31 / Firefox >= 41 / EDGE / IE >= 11 / Safari  = 8 (https://developer.mozilla.org/en-US/docs/Web/API/MediaSource/isTypeSupported)   Check for video and audio decoding support from content type.    matchMedia (with color gamut support) - Chrome >= 58.  Check for color space support.    requestMediaKeySystemAccess - Chrome >= 42 / Firefox / EDGE / Safari (https://developer.mozilla.org/fr/docs/Web/API/Navigator/requestMediaKeySystemAccess)  Check for DRM support.    getStatusForPolicy - ? (https://github.com/WICG/hdcp-detection/blob/master/explainer.md)  Query a hypothetical status associated with an HDCP policy.   ","anchorH1":"mediacapabilitiesprober","anchorH2":"exploited_browser_apis"}]},{"file":"./api/Tools/createMetaplaylist.html","index":[{"h1":"createMetaplaylist","body":"","anchorH1":"createmetaplaylist"},{"h1":"createMetaplaylist","h2":"Overview","body":"createMetaplaylist is a function that allows to build a [metaplaylist] (./metaplaylist.md) object from given contents information. You may need to use this function because not all information about contents are known by the user when wanting to create a metaplaylist. For example, the end of a content will be found thanks to the content duration, that can be parsed from the content manifest.","anchorH1":"createmetaplaylist","anchorH2":"overview"},{"h1":"createMetaplaylist","h2":"How to import it","body":"createMetaplaylist is for now considered an “experimental” tool. This means that its API could change at any new version of the RxPlayer (don’t worry, we would still document all changes made to it in the corresponding release note). As an experimental tool, it is imported as such: import { createMetaplaylist } from \"rx-player/experimental/tools\";  You can then begin to use it right away.","anchorH1":"createmetaplaylist","anchorH2":"how_to_import_it"},{"h1":"createMetaplaylist","h2":"How to use it","body":"createMetaplaylist takes two arguments :   contentInfos (Array<Object>) : The list of content information, in the playback order they should have in the metaplaylist. The list is an array of objects with this attributes :  url (string): The URL of the source content transport (string): The transport type of the content (dash, smooth or even metaplaylist)    timeOffset (number|undefined) : the optionnal time offset that applies to the metaplaylist start time (default is 0).   Example: createMetaplaylist(   [     // dash content, 10mn long     {       url: \"https://somedashcontent.mpd\",       transport: \"dash\",     },     // smooth content, 35s long     {       url: \"https://somesmoothcontent.ism\",       transport: \"smooth\",     },     // metaplaylist content, 100mn long     {       url: \"https://somemetaplaylistcontent\",       transport: \"metaplaylist\",     },   ],   1000 );  The returned metaplaylist will look like :     {         type: \"MPL\",         version: \"0.1\",         dynamic: false,         contents: [             {                 url: \"https://somedashcontent.mpd\",                 transport: \"dash\",                 startTime: 1000,                 endTime: 1600,             },             {                 url: \"https://somesmoothcontent.ism\",                 transport: \"smooth\",                 startTime: 1600,                 endTime: 1635,             },             {                 url: \"https://somemetaplaylistcontent\",                 transport: \"metaplaylist\",                 startTime: 1635,                 endTime: 7635,             },         ],     } ","anchorH1":"createmetaplaylist","anchorH2":"how_to_use_it"}]},{"file":"./api/Miscellaneous/plugins.html","index":[{"h1":"Plugins","body":"","anchorH1":"plugins"},{"h1":"Plugins","h2":"Overview","body":"To allow the player to be extended, a system of “plugins” has been added. Those plugins are often under the form of functions passed as an argument to the loadVideo API call.","anchorH1":"plugins","anchorH2":"overview"},{"h1":"Plugins","h2":"segmentLoader","body":"The segmentLoader is a function that can be included as an option of the loadVideo API call. A segmentLoader allows to define a custom audio/video segment loader (it might on the future work for other types of segments, so always check the type if you only want those two). The segment loader is the part performing the segment request. One usecase where you might want to set your own segment loader is to integrate Peer-to-Peer segment downloading through the player. Before the complete documentation, let’s write an example which will just use an XMLHttpRequest (it has no use, as our implementation does the same thing and more): /**  * @param {Object} segmentInfo - Information about the segment to download  * @param {Object} callbacks - Object containing several callbacks to indicate  * that the segment has been loaded, the loading operation has failed or to  * fallback to our default implementation. More information on this object below  * this code example.  * @returns {Function|undefined} - If a function is defined in the return value,  * it will be called if and when the request is canceled.  */ const customSegmentLoader = (segmentInfo, callbacks) => {    // we will only use this custom loader for videos segments.   // we will also ignore edge cases where the URL is undefined.   if (segmentInfo.trackType !== \"video\" || segmentInfo.url === undefined) {     callbacks.fallback();     return;   }    const xhr = new XMLHttpRequest();   const sendingTime = performance.now();    xhr.onload = function onXHRLoaded(r) {     if (200 <= xhr.status && xhr.status < 300) {       const duration = performance.now() - sendingTime;       const size = r.total;       const data = xhr.response;       callbacks.resolve({ duration, size, data });     } else {       const err = new Error(\"didn't work\");       callbacks.reject(err);     }   };    xhr.onprogress = function onXHRProgress(event) {     const currentTime = performance.now();     callbacks.progress({ duration: currentTime - sendingTime,                          size: event.loaded,                          totalSize: event.total });   };    xhr.onerror = function onXHRError() {     const err = new Error(\"didn't work\");     callbacks.reject(err);   };    xhr.open(\"GET\", segmentInfo.url);   xhr.responseType = \"arraybuffer\";    const ranges = segmentInfo.byteRanges;   if (ranges) {     // Theoretically, we could have multiple non-contiguous byte ranges, which     // would imply several requests.     // In reality, this is extremely rare so we just create a global byte-range     // encompassing all in this example.     const range = [ranges[0][0], ranges[ranges.length - 1][1]];     if (range[1] && range[1] !== Infinity) {       xhr.setRequestHeader(\"Range\", `bytes=${range[0]}-${range[1]}`);     } else {       xhr.setRequestHeader(\"Range\", `bytes=${range[0]}-`);     }   }    xhr.send();    return () => {     xhr.abort();   }; };  As you can see, this function takes two arguments:   segmentInfo (object): An Object giving information about the wanted segments.  This object contains the following properties:   url (string|undefined): The URL the segment request should normally be performed at. This property can be undefined in a condition where the segment URL either doesn’t exist or has not been communicated by the Manifest.   timeout (number|undefined: Timeout in milliseconds after which a request should preferably be aborted, according to current configuration. This property is mainly indicative, you may or may not want to exploit this information depending on your use cases.   isInit (boolean|undefined): If true this segment is an initialization segment which contains no decodable data. Those types of segment are mainly there for initialization purposes, such as giving initial infos to the decoder on subsequent media segments that will be pushed. Note that if isInit is false, it only means that the segment contains decodable media, it can also contain important initialization information. If undefined, we could not determine whether this segment was an initialization segment. This case is not currently possible but may be in future versions.   byteRanges (Array.<[number, number]>|undefined): If defined, only the corresponding byte-ranges, which are subsets in bytes of the full data concerned, should be loaded. If multiple non-contiguous byte-ranges are given, the result should be the concatenation of those byte-ranges, in the same order. For example [[0, 100], [150, 180]] means that the bytes of both 0 to 100 (included) and from 150 to 180 (included) should be requested. The communicated result should then be a concatenation of both in the same order.   trackType (string): The concerned type of track. Can be \"video\", \"audio\", \"text\" (for subtitles)     callbacks: An object containing multiple callbacks to allow this segmentLoader to communicate various events to the RxPlayer. This Object contains the following functions:   resolve: To call after the segment is loaded, to communicate it to the RxPlayer. When called, it should be given an object with the following properties:   data (ArrayBuffer|Uint8Array) - the segment data.   duration (Number|undefined) - the duration the request took, in milliseconds. This value may be used to estimate the ideal user bandwidth.   size (Number|undefined) size, in bytes, of the total downloaded response. This value may be used to estimate the ideal user bandwidth.     progress - Callback to call when progress information is available on the current request. This callback allows to improve our adaptive streaming logic by better predicting the bandwidth before the request is finished and whether a request is stalling. When called, it should be given an object with the following properties:   duration (Number) - The duration since the beginning of the request, in milliseconds.   size (Number) - the current size loaded, in bytes.   totalSize (Number|undefined) - the whole size of the wanted data, in bytes. Can be let to undefined when not known.     reject: Callback to call when an error is encountered which made loading the segment impossible. It is recommended (but not enforced) to give it an Object or error instance with the following properties:   canRetry (boolean|undefined): If set to true, the RxPlayer may retry the request (depending on the configuration set by the application). If set to false, the RxPlayer will never try to retry this request and will probably just stop the current content. If not set or set to undefined, the RxPlayer might retry or fail depending on other factors.     fallback: Callback to call if you want to call our default implementation instead for loading this segment. No argument is needed.     The segmentLoader can also return a function, which will be called if/when the request is aborted. You can define one to clean-up or dispose all resources.","anchorH1":"plugins","anchorH2":"segmentloader"},{"h1":"Plugins","h2":"manifestLoader","body":"The manifestLoader is a function that can be included as an option of the loadVideo API call. A manifestLoader allows to define a custom Manifest loader. Before the complete documentation, let’s write an example which will just use an XMLHttpRequest (it has no use, as our implementation does the same thing and more): /**  * @param {Object} manifestInfo - Information about the Manifest to download  * @param {Object} callbacks - Object containing several callbacks to indicate  * that the manifest has been loaded, the loading operation has failed or to  * fallback to our default implementation. More information on this object below  * this code example.  * @returns {Function|undefined} - If a function is defined in the return value,  * it will be called if and when the request is canceled.  */ const customManifestLoader = (manifestInfo, callbacks) => {   const { url } = manifestInfo;   const xhr = new XMLHttpRequest();   const baseTime = performance.now();    xhr.onload = (r) => {     if (200 <= xhr.status && xhr.status < 300) {       const duration = performance.now() - baseTime;        const now = Date.now();       const receivingTime = now;        // Note: We could have calculated `sendingTime` before the request, but       // that date would be wrong if the user updated the clock while the       // request was pending.       // `performance.now` doesn't depend on the user's clock. It is thus a       // better candidate here.       // This is why we re-calculate the sendingTime a posteriori, we are now       // sure to be aligned with the current clock.       const sendingTime = now - duration;        // the request could have been redirected,       // we have to feed back the real URL       const _url = xhr.responseURL || url;        const size = r.total;       const data = xhr.response;       callbacks.resolve({         url: _url,         sendingTime,         receivingTime,         duration,         size,         data,       });     } else {       const err = new Error(\"didn't work\");       err.xhr = xhr;       callbacks.reject(err);     }   };    xhr.onerror = () => {     const err = new Error(\"didn't work\");     err.xhr = xhr;     callbacks.reject(err);   };    xhr.open(\"GET\", url);   xhr.responseType = \"document\";    xhr.send();    return () => {     xhr.abort();   }; };  As you can see, this function takes three arguments:   manifestInfo (object): An Object giving information about the wanted Manifest. This object contains the following properties:   url (string|undefined): The URL the Manifest request should normally be performed at. This argument can be undefined in very rare and specific conditions where the Manifest URL doesn’t exist or has not been communicated by the application.   timeout (number|undefined): Timeout in milliseconds after which a request should preferably be aborted, according to current configuration. This property is mainly indicative, you may or may not want to exploit this information depending on your use cases.     callbacks: An object containing multiple callbacks to allow this manifestLoader to communicate the loaded Manifest or an encountered error to the RxPlayer. This Object contains the following functions:   resolve: To call after the Manifest is loaded, to communicate it to the RxPlayer. When called, it should be given an object with the following properties:   data - the Manifest data. Many formats are accepted depending on what makes sense in the current transport: string, Document, ArrayBuffer, Uint8Array, object.   duration (Number|undefined) - the duration of the request, in milliseconds.   size (Number|undefined) size, in bytes, of the total downloaded response.   url (string|undefined) - url of the Manifest (after any potential redirection if one).   sendingTime (number|undefined) - Time at which the manifest request was done as a unix timestamp in milliseconds.   receivingTime (number|undefined) - Time at which the manifest request was finished as a unix timestamp in milliseconds.     reject: Callback to call when an error is encountered which made loading the Manifest impossible. It is recommended (but not enforced) to give it an Object or error instance with the following properties:   canRetry (boolean|undefined): If set to true, the RxPlayer may retry the request (depending on the configuration set by the application). If set to false, the RxPlayer will never try to retry this request and will probably just stop the current content. If not set or set to undefined, the RxPlayer might retry or fail depending on other factors.     fallback: Callback to call if you want to call our default implementation instead for this Manifest. No argument is needed.     The manifestLoader can also return a function, which will be called if/when the request is aborted. You can define one to clean-up or dispose all resources.","anchorH1":"plugins","anchorH2":"manifestloader"},{"h1":"Plugins","h2":"representationFilter","body":"The representationFilter is a function that can be included as an option of the loadVideo API call. A representationFilter allows you to filter out Representations (i.e. media qualities) based on its attributes. The representationFilter will be called each time we load a Manifest with two arguments:   representation {Object}: An object describing the Representation. This object contains the following properties:   id (string): The id used to identify this Representation.   bitrate (Number|undefined): The bitrate of this Representation, in bits per seconds. undefined if unknown.   width (Number|undefined): If the Representation is from a video track and if its width is known, this is the width of video, in pixels.   height (Number|undefined): If the Representation is from a video track and if its height is known, this is the height of video, in pixels.   codec (string|undefined): The codec the Representation is in.   frameRate (Number|undefined): If the Representation is from a video track and if its frame rate is known, this is the frame rate of video, in image per seconds.   hdrInfo (Object|undefined): If the Representation is from a video track and if it has HDR information associated to it, this is set to an object describing the hdr characteristics of the track. (see HDR support documentation)   contentProtections (Object|undefined): Encryption information linked to this content. If set to an Object, the Representation is known to be encrypted. If unset or set to undefined the Representation is either unencrypted or we don’t know if it is. When set to an object, it may contain the following properties:  keyIds (Array.<Uint8Array>|undefined): Known key ids linked to that Representation.      context {Object}: Basic context about this Representation. Contains the following keys:   trackType {string}: The concerned type of track. Can be \"video\", \"audio\", \"text\" (for subtitles)   language {string|undefined}: The language the Representation is in, as announced by the Manifest.   normalizedLanguage {string|undefined}: An attempt to translate the language into an ISO 639-3 code. If the translation attempt fails (no corresponding ISO 639-3 language code is found), it will equal the value of language   isClosedCaption {Boolean|undefined}: If set to true and if this is a text track, the Representation links to subtitles with added hints for the hard of hearing.   isAudioDescription {Boolean|undefined}: If set to true and if this is an audio track, the Representation links to an audio track with added commentary for the visually impaired.   isDub {Boolean|undefined}): If set to true and if this is an audio track, then this audio track is a “dub”, meaning it was recorded in another language than the original. If set to false, we know that this audio track is in an original language. This property is undefined if we do not known whether it is in an original language or if does not apply for the track type.   isSignInterpreted {Boolean|undefined}): If set to true and if this is a video track, then it contains visual sign interpretation.     This function should then returns true if the Representation should be kept or false if it should be removed. For example, here is a representationFilter that removes video Representations with a video resolution higher than HD (1920x1080): /**  * @param {Object} representationInfo  * @param {Object} infos - supplementary information about the given  * Representation.  * @returns {boolean}  */ function representationFilter(representationInfo, infos) {   if (infos.trackType === \"video\") {     // If video representation, allows only those for which the height and width     // is known to be below our 1920x1080 limit     const { width, height } = representationInfo;     return width != null && height != null && width <= 1920 && height <= 1080;   }    // Otherwise, allow all non-video representations   return true; } ","anchorH1":"plugins","anchorH2":"representationfilter"}]},{"file":"./api/Miscellaneous/Low_Latency.html","index":[{"h1":"Playing Low-Latency contents","body":"","anchorH1":"playing_low-latency_contents"},{"h1":"Playing Low-Latency contents","h2":"Overview","body":"The RxPlayer can play DASH contents specifically crafted to be played with a low latency (read close to the live edge) through a technology called something along the lines of “Chunked-encoded CMAF and Chunked transfer encoding”. Such contents are backward-compatible DASH contents (meaning they can be played in a regular non-low-latency way) which serves CMAF segment with an HTTP 1.1 transfer mechanism called “Chunked transfer encoding”. To vulgarize, such segments are divided into multiple chunks which can be requested while the whole segment is still being encoded - through Chunked transfer encoding HTTP requests. If you want more information on this technology, the best for us is probably to redirect you to the multiple resources you can probably find with your favorite search engine!","anchorH1":"playing_low-latency_contents","anchorH2":"overview"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","body":"","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","h3":"lowLatencyMode option","body":"To play a low-latency DASH content with - well - a low latency, you will need to set the lowLatencyMode loadVideo option. rxPlayer.loadVideo({   url: \"https://www.example.com/low-latency-content.mpd\",   transport: \"dash\",   lowLatencyMode: true, });  When set, this option will perform multiple optimizations specific to low-latency contents. For live contents:   it will by default play much closer to the live edge   it will begin to play faster and seek in non-buffered parts faster   it will do safer choices when choosing the right video / audio quality (to avoid the higher chances of rebuffering)   the delay we use when retrying a failed segment or manifest request will be lower   and multiple other minor optimizations   Note that you can also set the lowLatencyMode mode for VoD (non-live) contents. In that case, the main advantage would be to be able to play and seek faster as long as the content is compatible (again, with CMAF and Chunked Transfer Encoding).","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content","anchorH3":"lowlatencymode_option"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","h3":"Playing even closer to the live edge!","body":"By default, we set a distance of 3.5 seconds relative to the live edge when we start a low latency content. We found that value to be just at the right boundary between rebuffering risks, and delay to the live edge. However, you can still provide a lower distance through the startAt loadVideo option (documented here): rxPlayer.loadVideo({   url: \"https://www.example.com/content.mpd\",   transport: \"dash\",   lowLatencyMode: true,   startAt: { fromLastPosition: 2 }, // Play 2 seconds from the live edge instead   // (beware of much more frequent rebuffering   // risks) }); ","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content","anchorH3":"playing_even_closer_to_the_live_edge!"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","h3":"Note about time synchronization","body":"In most cases, DASH low-latency contents rely on time synchronization between the server and the client without providing a synchronization mechanism. This means that, on poorly configurated client (with bad clock settings), you could lose latency or worse: obtain playback issues. To work around that problem, the RxPlayer allows you to provide a synchronization mechanism to loadVideo. This is done through the serverSyncInfos option of loadVideo. TL;DR You can look at the API documentation for a quick explanation of what to put in it. Here how it works: Imagine you have an URL allowing you to know the UTC time on the server’s side. Let’s call it serverTimeURL. Now you can have the server’s time at a particular point in time (!). The problem is that time continously changes: a time synchronization mechanism will have to be aware of how much time passed since the last request to obtain that time. We could asks for the client’s timestamp - obtained thanks to the Date.now() API - at the time of the request. This would allow us to know how much time have passed since that event by calling Date.now() again in the future and calculating the difference. The problem however is that Date.now() will instantly change if the user updates its system clock. If that happens, we will lose the ability to know how much time has elapsed since the request. To workaround this issue, we can use instead performance.now(), which does not rely on the system’s clock. However, we are still left with two other issues:   performance.now() comparisons are useful only if both values were obtained in the same JS worker. So we have to make sure each performance.now() call is done in the same worker.   performance.now() doesn’t integrate the notion of leap seconds whereas unix time (the server’s time) does. This could mean small time de-synchronization when leap seconds are added or substracted.   We however consider those last two problems minor when compared to Date.now()'s problem (which is the fact that it “breaks” if the system clock is updated). If you would prefer to provide Date.now() anyway, you can open an issue and we will think about a possible implementation. So we now have two values:  serverTimestamp (number): Unix timestamp of the server at a given point in time. clientTime (number): Value of the performance.now() API at the time the serverTimestamp value was true. Please note that if your page contains multiple worker, the performance.now() call should be done on the same worker than the one in which loadVideo is called.  Those two values can be combined in the serverSyncInfos option like this: const timeResponse = await fetch(serverTimeURL); const serverTimestamp = await timeResponse.text(); const clientTime = performance.now(); const serverSyncInfos = { serverTimestamp, clientTime }; rxPlayer.loadVideo({   // ...   serverSyncInfos, }); ","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content","anchorH3":"note_about_time_synchronization"},{"h1":"Playing Low-Latency contents","h2":"How to play a low latency content","h3":"Note about rebuffering and other delay-creating situations","body":"When playing in low latency mode, it is still possible to rebuffer or pause the content, which could lead the user to being far from the live edge. As several applications could want several workaround to that possible issue (like updating the speed, seeking or just signaling the delay to the user), we choose to let that happen by default with the RxPlayer. As an example, ou demo page choose the following strategy for now:   When falling between 6 to 15 seconds behind the live edge, the playback rate is updated proportionally to our delay until we reach 3 seconds behind the live edge.   When falling to 15 seconds behind the live edge or more, we will simply seek to 3 seconds behind the live edge.   When seeking manually or pausing, this logic is disabled (with the possibility to re-enable it).   The live edge is obtainable through the rxPlayer.getMaximumPosition() API, the current position thanks to the rxPlayer.getPosition() API. The distance to the live edge is thus easily computable: rxPlayer.getMaximumPosition() - rxPlayer.getPosition(); ","anchorH1":"playing_low-latency_contents","anchorH2":"how_to_play_a_low_latency_content","anchorH3":"note_about_rebuffering_and_other_delay-creating_situations"}]},{"file":"./api/Miscellaneous/DASH_WASM_Parser.html","index":[{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","body":"The RxPlayer provides two different “parsers” for DASH’s Manifest format, a.k.a. the “MPD”:   A JavaScript parser. Provided in the default “bundled” builds and through the DASH feature in the minimal build.   A generally-faster WebAssembly parser. Only provided through the DASH_WASM experimental feature in the minimal build.   This page is the API documentation page for the second parser.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"Do I need this?","body":"When playing DASH contents, parsing its MPD file often become the most expensive operation in terms of performance. This is especially true when the MPD is sufficiently large (for example, we often encounter MPD of several megabytes in size at Canal+) and when it needs to be refreshed (e.g. some live contents). Even for smaller MPDs, we observed that on some low-end devices (ChromeCast, set-top box, some smart TVs) the parsing operation can noticeably lengthen the content’s loading time and in some rare occasions trigger brief rebuffering periods. If you encouter large MPDs and/or you noticed poor performance when playing DASH contents, you may have a better experience with this parser. Note however that your browser has to be compatible with WebAssembly. In case WebAssembly is not supported on the current platform and both the WebAssembly and default JavaScript DASH parsers are imported through their respective features, the RxPlayer will automatically fallback on the latter.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"do_i_need_this?"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"Do I need this?","h3":"Why “experimental”?","body":"As every other “experimental” features in the RxPlayer, the WebAssembly MPD parser should be stable in functional terms. The “experimental” notion has more to do with the fact that its API can evolve without impacting too much RxPlayer’s semantic versioning. For example, a new minor RxPlayer version could bring with it a complete API change regarding this feature. Still, potential changes would be fully documented and at least a link will be added both to that release’s release note and changelog file. The choice of labeling this feature as experimental has been made so we can have more freedom if we find ways to provide sensible improvements to it in the future, in case they necessitate some incompatible API change.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"do_i_need_this?","anchorH3":"why_%22experimental%22?"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","body":"To use the WebAssembly-based parser you will need to do two things:   the WebAssembly file will have to be stored somewhere, accessible through an URL that can be then communicated to the RxPlayer.   the DASH_WASM experimental feature has to be initialized with it and added to the RxPlayer   Don’t worry, it is relatively straightforward. The current chapter will explain everything you need to do.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Quick code example","body":"Let’s begin by an heavily commented example of a code adding the DASH-WASM feature to the RxPlayer. It might be a lot to grasp now, we will focus on what has been done here step by step in the next chapters. // Import the minimal RxPlayer import RxPlayer from \"rx-player/minimal\";  // Import the function allowing to create the DASH-WASM parser import { DASH_WASM } from \"rx-player/experimental/features\";  // Trigger request for the WebAssembly file. // This function can be called at any point in time. // // Before it is called, the regular JS parser will be used instead // (if it was added as a feature). // // As soon as both this function is called and the DASH_WASM feature is added // (through RxPlayer's `addFeatures` static method) - in any order you wish - // the RxPlayer will begin // to use the DASH_WASM parser for almost all // future encountered MPDs (excluding some extremely rare conditions, such as // non-UTF-8 MPDs). DASH_WASM.initialize({ wasmUrl: \"https://path/to/webassembly.wasm\" });  // Add the DASH_WASM feature to the RxPlayer. // // This can be done before or after calling the `initialize` method on the // `DASH_WASM` object, both actions will be needed to be able to use the // WebAssembly parser. RxPlayer.addFeatures([DASH_WASM]); ","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"quick_code_example"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 1: Obtaining the WebAssembly file","body":"The RxPlayer will need to fetch the WebAssembly file to be able to run the DASH-WASM parser. You can find it at any of the following places:   With every release note published on GitHub (you should only use the files linked to the RxPlayer’s version you’re using), as mpd-parser.wasm.   It is also available as dist/mpd-parser.wasm from the root directory of the project. This file is also published on npm, which mean they might already be loaded in your project, for example in the node_modules directory (most probably in node_modules/rx-player/dist/mpd-parser.wasm depending on your project). `   Once you’ve retrieved the right WebAssembly file linked to your RxPlayer version, you will need to store it and give its URL to the RxPlayer so it will be able to load it.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_1:_obtaining_the_webassembly_file"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 2: using the minimal build of the RxPlayer","body":"The DASH_WASM feature is only available when using the “minimal” version of the RxPlayer. That is, when the player is imported through the \"rx-player/minimal\" path: import RxPlayer from \"rx-player/minimal\";  If you weren’t using the minimal RxPlayer before, note that it necessitates that you add the features you want to it. More information about any of that can be found in the minimal player documentation. This documentation will especially dive into the DASH_WASM feature, which is the WebAssembly parser for MPDs.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_2:_using_the_minimal_build_of_the_rxplayer"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 3: importing the DASH_WASM feature","body":"As indicated before, the DASH-WASM feature is an “experimental” feature. This is because although the feature is considered stable, its API may still change at any new RxPlayer version (if this happens, changes on its API will be explained on our CHANGELOG and this documentation will be updated). As any experimental features, it needs to be imported through the rx-player/experimental/features path: import { DASH_WASM } from \"rx-player/experimental/features\"; ","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_3:_importing_the_%60dash_wasm%60_feature"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 4: Initializing the feature","body":"– This step can be done before or after adding the DASH_WASM feature to the RxPlayer (described as the next step) – This step allows to provide the WebAssembly file to the DASH_WASM feature. This is done through a method call on the imported DASH_WASM function called initialize: DASH_WASM.initialize({ wasmUrl: \"https://path/to/webassembly.wasm\" });  As you can see, this function takes an object in argument which has for now a single required property, wasmUrl, which should be the URL to the WebAssembly file. An important thing to consider is that initialize will immediately request the WebAssembly file. Once this function is called and once the feature is added to the RxPlayer (next described step), the RxPlayer will try to use the WebAssembly parser when possible (even if the WebAssembly request hasn’t yet finished). Note that initialization can fail, for example when WebAssembly is not available or when the request fails. initialize returns a Promise so you can be notified of a possible error if you wish: DASH_WASM.initialize({ wasmUrl: \"https://path/to/webassembly.wasm\" })   .then(() => { console.log(\"everything went well!\"); }),   .catch((err) => { console.warn(\"Could not initialize WebAssembly\", err); });  In the case where initialization fails, the RxPlayer will try to use the regular DASH js parser instead, if that feature has been added. If it has not, an error will be thrown when playing DASH contents.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_4:_initializing_the_feature"},{"h1":"Fast DASH MPD parsing with the DASH-WASM parser","h2":"How to use it?","h3":"Step 4bis: Adding the feature to the RxPlayer","body":"– This step can be done before or after “initializing” the DASH_WASM feature (the aforementioned “step 4”). – To “link” the RxPlayer to the parser, you will need to call the addFeatures static function on the minimal RxPlayer build, like every other features. import RxPlayer from \"rx-player/minimal\";  RxPlayer.addFeatures([DASH_WASM]);  Once both this step an the initialize method (on the DASH_WASM object) is called, the RxPlayer will try to use the WebAssembly DASH_WASM parser by default when encountering DASH contents.","anchorH1":"fast_dash_mpd_parsing_with_the_dash-wasm_parser","anchorH2":"how_to_use_it?","anchorH3":"step_4bis:_adding_the_feature_to_the_rxplayer"}]},{"file":"./api/Miscellaneous/hdr.html","index":[{"h1":"HDR support","body":"","anchorH1":"hdr_support"},{"h1":"HDR support","h2":"Overview","body":"HDR (High Dynamic Range) is a video technology that improves the way light is represented by permitting to render brighter highlights, darker shadows and more details between both ends. Sometimes, it allows to reproduce richer colors than with the standard dynamic range.","anchorH1":"hdr_support","anchorH2":"overview"},{"h1":"HDR support","h2":"API","body":"Behind this principle, several formats exists (HDR10, HLG, Dolby Vision) and implements specific media and stream encoding and packaging technologies. When using streaming technologies, both streaming manifest and codecs strings can provide information about the technical HDR characteristics of the content. These information are parsed and exposed through the hdrInfo attribute that can be found in the periods/adaptation/representation path of the RxPlayer manifest object. Also, the getAvailableVideoTracks and getVideoTrack functions and the videoTrackChange event carries the hdrInfo.","anchorH1":"hdr_support","anchorH2":"api"},{"h1":"HDR support","h2":"API","h3":"hdrInfo","body":" colorDepth: number|undefined : It is the bit depth used for encoding the color for a pixel. The more bits are used for encoding, the more color shades could be rendered. It allows to increase rendering dynamic range without color banding. eotf: string|undefined : It is the HDR eotf. It is the transfer function having the video signal as input and converting it into the linear light output of the display. For example, pq (published as standard SMPTE2084) is an eotf developped by Dolby for HDR contents and capable of rendering brightness until 10000 nits (the derived SI unit of luminance). colorSpace: string|undefined : It is the video color space used for encoding. An HDR content may not have a wide color gamut. HD TV standards define the use of the rec709 color space for content. Most of HDR standards define the use of rec2020, which is a color space that contains rec709 color space and more. In other words, rec2020 can reproduce colors that cannot be shown with the rec709. ","anchorH1":"hdr_support","anchorH2":"api","anchorH3":"hdrinfo"},{"h1":"HDR support","h2":"Exploiting the API","body":"HDR do not specify new display’s capabilities. However, it allows to make better use of the display brightness, contrast and color capabilities. HDR will not be rendered the same way on each used display. It is possible through several APIs to query the browser about its screen characteristics, to speculate about the quality of the HDR rendering. Here are the available APIs now :","anchorH1":"hdr_support","anchorH2":"exploiting_the_api"},{"h1":"HDR support","h2":"Exploiting the API","h3":"Color depth","body":"In HDR, more colors and brightness levels have to be encoded. More than 8 bits par component are used in most of standards. It is possible to check how many bits are used for reproducing colors on the output display, to ensure the color shades could be rendered. /**  * It is the bit depth used for encoding one color. Example :  * screen.colorDepth = 48 :  * - 12 bits for the red component  * - 12 bits for the blue component  * - 12 bits for the green component  * - 12 bits for the alpha component (optional)  */ const colorDepth = screen.colorDepth;  /**  * The media query tells if the current output device is compatible  * with the given media characteristics.  * Here, it tells if the given color depth for one component is supported.  */ const is10bitsSupported = window.matchMedia(\"(min-color: 10)\").matches; ","anchorH1":"hdr_support","anchorH2":"exploiting_the_api","anchorH3":"color_depth"},{"h1":"HDR support","h2":"Exploiting the API","h3":"Color gamut","body":"It is possible to check if the output device is capable of displaying standard color gamut that are used in HDR formats. /**  * The media query tells if the current output device is compatible  * with the given media characteristics.  * Here, it tells if the output device is capable of displaying approximatively  * the given color space.  */ const isRec2020Supported = window.matchMedia(\"(color-gamut: rec2020)\").matches; ","anchorH1":"hdr_support","anchorH2":"exploiting_the_api","anchorH3":"color_gamut"}]},{"file":"./api/Miscellaneous/Local_Contents.html","index":[{"h1":"Local contents (offline playback)","body":"","anchorH1":"local_contents_(offline_playback)"},{"h1":"Local contents (offline playback)","h2":"Preamble","body":"The RxPlayer is also able to load downloaded DASH, Smooth, MetaPlaylist or even HLS (CMAF-based) contents, whether it is for offline playback or just for an online seamless playback without buffering. This documentation page will be about how to load already downloaded contents. We suppose the content is already downloaded and that you just want to play it through the RxPlayer. However, a tool to download DASH/Smooth/MetaPlaylist contents compatible to this API is under way.","anchorH1":"local_contents_(offline_playback)","anchorH2":"preamble"},{"h1":"Local contents (offline playback)","h2":"Overview","body":"To play contents stored locally, the RxPlayer uses its own Manifest format - the “local manifest” which is close in semantics to DASH’s own Manifest file, the MPD. This new Manifest format will be the only element you will need to generate on your side to play stored contents. As such, this what most of this documentation page is about. Note that the wanted content does not need to be completely downloaded before creating this local manifest. Playback can even begin while the content is still downloading. You will just need to:  indicate that this is a “local” content by setting the transport option in loadVideo to \"local\" As the generated Manifest object most likely won’t be available through an URL but directly as a JavaScript object, you will need to communicate it through the manifestLoader option of loadVideo.  Here is an example: rxPlayer.loadVideo({   transport: \"local\",    // Note: `_url` here will be `undefined`   manifestLoader(_url, callbacks) {     // where `localManifest` is the local Manifest in object form     callbacks.resolve({ data: localManifest });   },   // ... });  More infos on the manifestLoader can be found here.","anchorH1":"local_contents_(offline_playback)","anchorH2":"overview"},{"h1":"Local contents (offline playback)","h2":"How to import this feature","body":"The \"LOCAL_MANIFEST\" feature is not included in the default RxPlayer build. To import it, you first need to rely on the “minimal” version of the RxPlayer (through the \"rx-player/minimal\" import), you will need to import the LOCAL_MANIFEST experimental feature: import RxPlayer from \"rx-player/minimal\"; import { LOCAL_MANIFEST } from \"rx-player/experimental/features\";  RxPlayer.addFeatures([LOCAL_MANIFEST]);  More information about this can be found in the minimal player documentation.","anchorH1":"local_contents_(offline_playback)","anchorH2":"how_to_import_this_feature"},{"h1":"Local contents (offline playback)","h2":"The Manifest format","body":"As explained in the overview, offline playback by the RxPlayer mainly rely on a specific sort of manifest, called the “local manifest”. It is not the task of the RxPlayer to download and store the content here (a tool to do just that is on its way), this page only explains how to play a stored content once it has been stored. The local manifest looks like a DASH MPD in its structure and as such is very hierarchical. It has the following structure: manifest Object   ...manifest properties   period Object     ...period properties     adaptation Object       ...adaptation properties       representation Object         ...representation properties  We will go progressively from the elements higher in the hierarchy (the manifest object) to the lower ones (the representation Object).","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_manifest_format"},{"h1":"Local contents (offline playback)","h2":"The manifest Object","body":"The manifest object describes information about the whole local content:  its duration whether it is still downloading or if its completely available the different “parts” (or “periods”) the content is divided in  First, let’s go into an example, before describing what each property is for: {   type: \"local\", // always set to \"local\"   version: \"0.2\", // version number, in a MAJOR.MINOR form   minimumPosition: 0, // Minimum possible reachable position in the content,                       // in seconds   maximumPosition: 120, // Maximum possible reachable position in the content,                         // in seconds   isFinished: true, // if `false`, the content is still downloading   periods: [ // different \"periods\" in the content - see below     // ...   ], }  As you can see, it is a simple JavaScript object with few properties we’re going to dive into just now.","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_manifest_object"},{"h1":"Local contents (offline playback)","h2":"The manifest Object","h3":"properties","body":"Here is the description about all the properties encountered in a local manifest object:   type (string): Must be set to \"local\". This property indicates to the RxPlayer that the current content is a local manifest.   version (string): Version number, in a MAJOR.MINOR form. The present documentation is for the \"0.2\" version. A parser for a version with the a given MAJOR version should be able to parse and play contents for any of the corresponding MINOR versions. The exception is the 0 MAJOR version (i.e. experimental versions). A parser for a version with that major (let’s say 0.1) might be unable to parse local Manifests of another version (e.g. 0.2).   minimumPosition (number|undefined): Optional minimum position reachable in this content once it has been fully loaded, in seconds. If not set or set to undefined, the RxPlayer will assume that the content starts at a 0 position.   maximumPosition (number): Maximum position reachable in this content once it has been fully loaded, in seconds.   isFinished (boolean): true indicates that the content has been completely downloaded and can now be played as a whole. false indicates that the whole content is not available yet and that the RxPlayer may have to refresh the local manifest while playing (to get the new data).   periods (Array.<Object>): The different “periods” available in the content. We will explain what a “period” is in the following chapter.   expired (Promise.<undefined>|undefined): Optional Promise which should resolve when a newer local manifest is available. This is for example useful when playing a content which is still downloading. Here expired could resolve once a new segment is available, the RxPlayer would then request the new local manifest (through the same API than for the initial request, e.g. through the manifestLoader property indicated in loadVideo) and would obtain a new local manifest with this new segment included and a new expired property set. This can go on until the content is completely downloaded at which time expired can be set to undefined or just omitted from the last local manifest.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_manifest_object","anchorH3":"properties"},{"h1":"Local contents (offline playback)","h2":"The period object","body":"As seen in the previous chapter, the local manifest contains a periods property. The concept of period comes from DASH and allow to separate a content into multiple sub-parts, each with their own configurations. For example, you could have in the same content a TV Show in german followed by an american film, each with its own language choices and qualities. If you don’t need that kind of granularity, you can just create a single period for your local manifest. Here’s an example of a period object: {   start: 10, // starting position in the whole content, in seconds   end: 20, // ending position, in seconds   adaptations: [ // available tracks for this period     // ***   ] }  In the context of a local manifest with multiple periods, here is how it can look like: {   type: \"local\",   version: \"0.2\",   minimumPosition: 0,   maximumPosition: 60,   isFinished: true,   periods: [ // Here we have 3 consecutive periods:     {       start: 0,       end: 10,       adaptations: [ /* ... */ ]     },     {       start: 10,       end: 30,       adaptations: [ /* ... */ ]     },     {       start: 30,       end: 60,       adaptations: [ /* ... */ ]     },   ], } ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_period_object"},{"h1":"Local contents (offline playback)","h2":"The period object","h3":"properties","body":"The following properties are found in a period object:   start (number): The position in seconds at which the period starts.   end (number): The position in seconds at which the period ends.   adaptations (Array.<Object>): The different tracks available. See below for more information.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_period_object","anchorH3":"properties_(1)"},{"h1":"Local contents (offline playback)","h2":"the adaptation object","body":"An adaptation is roughly a “track” of the content. It can for the moment be one of those three types:  “audio” “video” “text” (subtitles)  The form of the adaptation object depends on the type of track. Let’s just start with a simple video track example: {   type: \"video\",   language: \"eng\", // optional language code   representations: [ // describes the different available qualities     // ...   ] }  Let’s continue with an audio track example: {   type: \"audio\",   language: \"fra\", // language code for this audio track   audioDescription: false, // if `true`, that audio track is a track adapted for                            // the visually impaired   representations: [ /* ... */ ] }  We’ll finish with a text track example: {   type: \"text\",   language: \"fra\", // language code for this audio track   closedCaption: false, // if `true`, that text track contains supplementary                         // cues about the audio content (generally used for the                         // hard of hearing)   representations: [ /* ... */ ] }  Here how it looks when adaptations are integrated in a given period: {   start: 0,   end: 10,   adaptations: [     {       type: \"video\",       representations: [ /* ... */ ],     },     {       type: \"audio\",       language: \"eng\",       audioDescription: false,       representations: [ /* ... */ ]     },     {       type: \"audio\",       language: \"fra\",       audioDescription: false,       representations: [ /* ... */ ]     },     {       type: \"audio\",       language: \"fra\",       audioDescription: true,       representations: [ /* ... */ ]     },     {       type: \"text\",       language: \"fra\",       closedCaption: false,       representations: [ /* ... */ ]     },     {       type: \"text\",       language: \"fra\",       closedCaption: true,       representations: [ /* ... */ ]     }   ] },  Let’s now describes precizely every properties encountered here.","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_adaptation_object"},{"h1":"Local contents (offline playback)","h2":"the adaptation object","h3":"properties","body":"The following properties are found in an adaptation object:   type (string): The “type” of the current adaptation. Can be one of three strings:  audio video text The two first ones are straightforward to understand, the third one designates subtitles.    language (string|undefined): When relevant, this string allows to define the language code for the language the track is in. This is mostly useful for audio and text adaptations but can also be defined for video tracks.   audioDescription (boolean|undefined): If true, the track contains audio indications helping to understand what’s on the screen. Mostly useful for the visually impaired, this property is generally only relevant for audio tracks.   closedCaption (boolean|undefined): If true, that text track contains supplementary text cues about the audio content. Mostly useful for the hard of hearing, this property is generally only relevant for text tracks helping to understand what’s on the screen. Mostly useful for the visually impaired, this property is generally only relevant for audio tracks.   representations (Array.<Object>): The different available qualities for this track. Will be described below.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_adaptation_object","anchorH3":"properties_(2)"},{"h1":"Local contents (offline playback)","h2":"The representation object","body":"The representation object will describe the different qualities for a given track (or adaptation). It will also contains logic to fetch segments corresponding to that quality. The representation object is very similar to the Representation element in a DASH MPD. As usual, let’s look into an example. {   bitrate: 5000000, // bitrate of the quality, in bits per seconds   mimeType: \"video/mp4\",   codecs: \"avc1.64001f\",   width: 1280, // default width of the quality, in pixels.                // Mostly relevant for video tracks   height: 720, // default height of the quality, in pixels.                // Mostly relevant for video tracks   index: { // declaration of all the linked segments as well as methods to            // retrieve them     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  For audio tracks, it can looks like: {   bitrate: 200000,   mimeType: \"audio/mp4\",   codecs: \"mp4a.40.5\",   index: {     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  At last, an example for text tracks (here ttml in an mp4 container): {   bitrate: 3000, // bitrate of the quality, in bits per seconds   mimeType: \"application/mp4\",   codecs: \"stpp\",   index: {     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ]   } }  We’ll now explain what each property is for, before going deeper into the index attribute, which allows the RxPlayer to fetch the media segments.","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_representation_object"},{"h1":"Local contents (offline playback)","h2":"The representation object","h3":"properties","body":"  bitrate (number): The bitrate the quality is in, in bits per seconds. For example, a bitrate of 5000000 (5.10^6 == 5 MegaBit) would indicate that each second of the content does on average a size of 5 MegaBit.   mimeType (string): As its name suggests, this is the appropriate mime-type for the media. Generally, it is either:  \"video/mp4\" or \"video/webm\" for a video content (depending on the container) \"audio/mp4\" or \"audio/webm\" for an audio content (depending on the container) \"application/mp4\" or \"text/plain\" for a text content (depending on the container / the absence of container)    codecs (string): The codec necessary to be able to play the content. The syntax here is taken from the RFC6381.   width (number|undefined): When relevant (mostly video contents), the width of the media, in pixels   height (number|undefined): When relevant (mostly video contents), the height of the media, in pixels   index (object): Object allowing the RxPlayer to know the list of segments as well as to fetch them. Described in the next chapter.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_representation_object","anchorH3":"properties_(3)"},{"h1":"Local contents (offline playback)","h2":"the index object","body":"As just seen, the index object is a property of a given representation. it contains itself three properties:   segments (Array.<Object>): the list of every available media segments for that representation. Does not include the initialization segment. Do not include in this Array the segments that are not downloaded yet.   loadInitSegment (function): Returns the initialization segment or null if this notion is not relevant, like for subtitles.   loadSegment (function): Returns a specific media segment.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_index_object"},{"h1":"Local contents (offline playback)","h2":"the index object","h3":"the segments array","body":"Let’s start by the first one, segments. segments is an array of objects, each object describing a single segment of media data. Each object has the following properties:  time (number): starting position of the segment, in seconds duration (number): duration of the segment, in seconds timestampOffset (number|undefined): optional time offset to add to the segment’s internal time in seconds to convert its media time to its presentation time, in seconds. If you don’t know what it is, you will most likely not need it.  Let’s see a simple example with four segments of 2 seconds: [   {     time: 0,     duration: 2,   },   {     time: 2,     duration: 2,   },   {     time: 4,     duration: 2,   },   {     time: 6,     duration: 2,   }, ]; ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_index_object","anchorH3":"the_segments_array"},{"h1":"Local contents (offline playback)","h2":"the index object","h3":"the loadInitSegment callback","body":"The loadInitSegment callback allows the RxPlayer to request the initialization segment of this representation. Most audio and video representation have an initialization segment which allows to obtain information about the representation’s data without containing data in itself. For text representations, where it is most likely not needed, this callback can emit null instead of the segment. This callback is given a single argument, which is an object containing callbacks the function should call either when it has fetched the content or when it failed on error. There is two callbacks in that object:   resolve: allows loadInitSegment to communicate the initialization segment in an ArrayBuffer form. Can call resolve with null if no initialization segment is available for that representation.   reject: allows loadInitSegment to communicate an error which made the fetching of the initialization segment impossible.   The loadInitSegment callback can also returns a function which will be called if the caller want to abort the fetch operation. Here is an example of how a loadInitSegment function can look like: async function loadInitSegment(callbacks) {   try {     const initSegment = await getStoredInitSegmentForTheCurrentRepresentation();     callbacks.resolve(initSegment);   } catch (e) {     callbacks.reject(e);   }    // Note: in this example, there is no mean to abort the operation, as a result   // we do not return a function here    // // Here is how it would look like if we could:   // return function abort() {   //   abortStoredInitSegmentRequest();   // } } ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_index_object","anchorH3":"the_loadinitsegment_callback"},{"h1":"Local contents (offline playback)","h2":"the index object","h3":"the loadSegment callback","body":"The loadSegment callback is the callback called by the RxPlayer when it wants any segment in the content. Note that the segment data returned by loadSegment should contain all the data and metadata necessary to play them on the browser. Downloaded DASH segments - for example - are generally sufficient but segments linked to Smooth contents should be updated before being returned by loadSegment. This callback is very similar to loadInitSegment with two differences:   it receives two arguments:  The first being the segment object (from the segments array) of the segment we want to recuperate. You can generally discriminate which segment we want from the time property of the given segment, which should be unique for that representation. The second being the callbacks object, which has the exact same form than the one in loadInitSegment (two properties resolve and reject).    it cannot return null. It has to return an ArrayBuffer corresponding to the wanted segment.   Here is an example of how a loadSegment function can look like: async function loadSegment(segment, callbacks) {   try {     const segmentData = await getStoredSegment(segment);     callbacks.resolve(segmentData);   } catch (e) {     callbacks.reject(e);   }    // Note: in this example, there is no mean to abort the operation, as a result   // we do not return a function here    // // Here is how it would look like if we could:   // return function abort() {   //   abortStoredSegmentRequest();   // } } ","anchorH1":"local_contents_(offline_playback)","anchorH2":"the_index_object","anchorH3":"the_loadsegment_callback"},{"h1":"Local contents (offline playback)","h2":"About DRMs","body":"Content with DRMs should be supported as long as the encryption information is specified in the corresponding containers (e.g. in PSSH boxes for mp4 and other ISOBMFF containers). We also look into adding supplementary encryption information into the local manifest format, but this is not available for now.","anchorH1":"local_contents_(offline_playback)","anchorH2":"about_drms"},{"h1":"Local contents (offline playback)","h2":"Difference with the 0.1 format","body":"The previous 0.1 version of the local Manifest is now obsolete and is not compatible with the new versions of the RxPlayer. Its documentation can be found here. If you were relying on this version before and would like to switch the the 0.2 version, to be able to play it on newer versions of the RxPlayer, here is the exhaustive list of what changed:   a minimumPosition has been added to the “period object”   a maximumPosition has been added to the “period object”   the duration property of the “period object” has been removed   the start property from a “period object” is now expressed in seconds instead of in milliseconds.   the end property from a “period object” is now expressed in seconds instead of in milliseconds.   the time property from a segment in the “segments array” is now expressed in seconds instead of in milliseconds.   the duration property from a segment in the “segments array” is now expressed in seconds instead of in milliseconds.   the timestampOffset property from a segment in the “segments array” is now expressed in seconds. In the 0.1 version the unit of time was unclear.  ","anchorH1":"local_contents_(offline_playback)","anchorH2":"difference_with_the_%600.1%60_format"}]},{"file":"./api/Miscellaneous/Local_Manifest_v0.1.html","index":[{"h1":"Local Manifest format version 0.1","body":" The `0.1` version of the local Manifest format is an old version which is not properly understood by the RxPlayer anymore.  The last version of this specification can be found here. ","anchorH1":"local_manifest_format_version_0.1"},{"h1":"Local Manifest format version 0.1","h2":"Preamble","body":"The RxPlayer is also able to load downloaded DASH, Smooth, MetaPlaylist or even HLS (CMAF-based) contents, whether it is for offline playback or just for an online seamless playback without buffering. This documentation page will be about how to load already downloaded contents. We suppose the content is already downloaded and that you just want to play it through the RxPlayer. However, a tool to download DASH/Smooth/MetaPlaylist contents compatible to this API is under way.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"preamble"},{"h1":"Local Manifest format version 0.1","h2":"Overview","body":"To play contents stored locally, the RxPlayer uses its own Manifest format - the “local manifest” which is close in semantics to DASH’s own Manifest file, the MPD. This new Manifest format will be the only element you will need to generate on your side to play stored contents. As such, this what most of this documentation page is about. Note that the wanted content does not need to be completely downloaded before creating this local manifest. Playback can even begin while the content is still downloading. You will just need to:  indicate that this is a “local” content by setting the transport option in loadVideo to \"local\" As the generated Manifest object most likely won’t be available through an URL but directly as a JavaScript object, you will need to communicate it through the manifestLoader option in the loadVideo call.  Here is an example: rxPlayer.loadVideo({   transport: \"local\",    // Note: `_url` here will be `undefined`   manifestLoader(_url, callbacks) {     // where `localManifest` is the local Manifest in object form     callbacks.resolve({ data: localManifest });   },   // ... });  More infos on the manifestLoader can be found here.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"overview"},{"h1":"Local Manifest format version 0.1","h2":"How to import this feature","body":"The \"LOCAL_MANIFEST\" feature is not included in the default RxPlayer build. To import it, you first need to rely on the “minimal” version of the RxPlayer (through the \"rx-player/minimal\" import), you will need to import the LOCAL_MANIFEST experimental feature: import RxPlayer from \"rx-player/minimal\"; import { LOCAL_MANIFEST } from \"rx-player/experimental/features\";  RxPlayer.addFeatures([LOCAL_MANIFEST]);  More information about this can be found in the minimal player documentation.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"how_to_import_this_feature"},{"h1":"Local Manifest format version 0.1","h2":"The Manifest format","body":"As explained in the overview, offline playback by the RxPlayer mainly rely on a specific sort of manifest, called the “local manifest”. It is not the task of the RxPlayer to download and store the content here (a tool to do just that is on its way), this page only explains how to play a stored content once it has been stored. The local manifest looks like a DASH MPD in its structure and as such is very hierarchical. It has the following structure: manifest Object   ...manifest properties   period Object     ...period properties     adaptation Object       ...adaptation properties       representation Object         ...representation properties  We will go progressively from the elements higher in the hierarchy (the manifest object) to the lower ones (the representation Object).","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_manifest_format"},{"h1":"Local Manifest format version 0.1","h2":"The manifest Object","body":"The manifest object describes information about the whole local content:  its duration whether it is still downloading or if its completely available the different “parts” (or “periods”) the content is divided in  First, let’s go into an example, before describing what each property is for: {   type: \"local\", // always set to \"local\"   version: \"0.1\", // version number, in a MAJOR.MINOR form   duration: 60000, // duration of the whole content, in ms   isFinished: true, // if `false`, the content is still downloading   periods: [ // different \"periods\" in the content - see below     // ...   ], }  As you can see, it is a simple JavaScript object with few properties we’re going to dive into just now.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_manifest_object"},{"h1":"Local Manifest format version 0.1","h2":"The manifest Object","h3":"properties","body":"Here is the description about all the properties encountered in a local manifest object:   type (string): Must be set to \"local\". This property indicates to the RxPlayer that the current content is a local manifest.   version (string): Version number, in a MAJOR.MINOR form. The present documentation is for the \"0.1\" version. A parser for a version with the a given MAJOR version should be able to parse and play contents for any of the corresponding MINOR versions. The exception is the 0 MAJOR version (i.e. experimental versions). A parser for a version with that major (let’s say 0.1) might be unable to parse local Manifests of another version (e.g. 0.2).   duration (number): duration of the whole content, in milliseconds. This means the difference between the absolute maximum position and the absolute minimum position.   isFinished (boolean): true indicates that the content has been completely downloaded and can now be played as a whole. false indicates that the whole content is not available yet and that the RxPlayer may have to refresh the local manifest while playing (to get the new data).   periods (Array.<Object>): The different “periods” available in the content. We will explain what a “period” is in the following chapter.   expired (Promise.<undefined>|undefined): Optional Promise which should resolve when a newer local manifest is available. This is for example useful when playing a content which is still downloading. Here expired could resolve once a new segment is available, the RxPlayer would then request the new local manifest (through the same API than for the initial request, e.g. through the manifestLoader property indicated in loadVideo) and would obtain a new local manifest with this new segment included and a new expired property set. This can go on until the content is completely downloaded at which time expired can be set to undefined or just omitted from the last local manifest.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_manifest_object","anchorH3":"properties"},{"h1":"Local Manifest format version 0.1","h2":"The period object","body":"As seen in the previous chapter, the local manifest contains a periods property. The concept of period comes from DASH and allow to separate a content into multiple sub-parts, each with their own configurations. For example, you could have in the same content a TV Show in german followed by an american film, each with its own language choices and qualities. If you don’t need that kind of granularity, you can just create a single period for your local manifest. Here’s an example of a period object: {   start: 10000, // starting position in the whole content, in ms   end: 20000, // ending position, in ms   adaptations: [ // available tracks for this period     // ***   ] }  In the context of a local manifest with multiple periods, here is how it can look like: {   type: \"local\",   version: \"0.1\",   duration: 60000,   isFinished: true,   periods: [ // Here we have 3 consecutive periods:     {       start: 0,       end: 10000,       adaptations: [ /* ... */ ]     },     {       start: 10000,       end: 30000,       adaptations: [ /* ... */ ]     },     {       start: 30000,       end: 60000,       adaptations: [ /* ... */ ]     },   ], } ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_period_object"},{"h1":"Local Manifest format version 0.1","h2":"The period object","h3":"properties","body":"The following properties are found in a period object:   start (number): The position in milliseconds at which the period starts.   end (number): The position in milliseconds at which the period ends.   adaptations (Array.<Object>): The different tracks available. See below for more information.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_period_object","anchorH3":"properties_(1)"},{"h1":"Local Manifest format version 0.1","h2":"the adaptation object","body":"An adaptation is roughly a “track” of the content. It can for the moment be one of those three types:  “audio” “video” “text” (subtitles)  The form of the adaptation object depends on the type of track. Let’s just start with a simple video track example: {   type: \"video\",   language: \"eng\", // optional language code   representations: [ // describes the different available qualities     // ...   ] }  Let’s continue with an audio track example: {   type: \"audio\",   language: \"fra\", // language code for this audio track   audioDescription: false, // if `true`, that audio track is a track adapted for                            // the visually impaired   representations: [ /* ... */ ] }  We’ll finish with a text track example: {   type: \"text\",   language: \"fra\", // language code for this audio track   closedCaption: false, // if `true`, that text track contains supplementary                         // cues about the audio content (generally used for the                         // hard of hearing)   representations: [ /* ... */ ] }  Here how it looks when adaptations are integrated in a given period: {   start: 0,   end: 10000,   adaptations: [     {       type: \"video\",       representations: [ /* ... */ ],     },     {       type: \"audio\",       language: \"eng\",       audioDescription: false,       representations: [ /* ... */ ]     },     {       type: \"audio\",       language: \"fra\",       audioDescription: false,       representations: [ /* ... */ ]     },     {       type: \"audio\",       language: \"fra\",       audioDescription: true,       representations: [ /* ... */ ]     },     {       type: \"text\",       language: \"fra\",       closedCaption: false,       representations: [ /* ... */ ]     },     {       type: \"text\",       language: \"fra\",       closedCaption: true,       representations: [ /* ... */ ]     }   ] },  Let’s now describes precizely every properties encountered here.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_adaptation_object"},{"h1":"Local Manifest format version 0.1","h2":"the adaptation object","h3":"properties","body":"The following properties are found in an adaptation object:   type (string): The “type” of the current adaptation. Can be one of three strings:  audio video text The two first ones are straightforward to understand, the third one designates subtitles.    language (string|undefined): When relevant, this string allows to define the language code for the language the track is in. This is mostly useful for audio and text adaptations but can also be defined for video tracks.   audioDescription (boolean|undefined): If true, the track contains audio indications helping to understand what’s on the screen. Mostly useful for the visually impaired, this property is generally only relevant for audio tracks.   closedCaption (boolean|undefined): If true, that text track contains supplementary text cues about the audio content. Mostly useful for the hard of hearing, this property is generally only relevant for text tracks helping to understand what’s on the screen. Mostly useful for the visually impaired, this property is generally only relevant for audio tracks.   representations (Array.<Object>): The different available qualities for this track. Will be described below.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_adaptation_object","anchorH3":"properties_(2)"},{"h1":"Local Manifest format version 0.1","h2":"The representation object","body":"The representation object will describe the different qualities for a given track (or adaptation). It will also contains logic to fetch segments corresponding to that quality. The representation object is very similar to the Representation element in a DASH MPD. As usual, let’s look into an example. {   bitrate: 5000000, // bitrate of the quality, in bits per seconds   mimeType: \"video/mp4\",   codecs: \"avc1.64001f\",   width: 1280, // default width of the quality, in pixels.                // Mostly relevant for video tracks   height: 720, // default height of the quality, in pixels.                // Mostly relevant for video tracks   index: { // declaration of all the linked segments as well as methods to            // retrieve them     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ],     incomingRanges: [ /* ... */ ]   } }  For audio tracks, it can looks like: {   bitrate: 200000,   mimeType: \"audio/mp4\",   codecs: \"mp4a.40.5\",   index: {     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ],     incomingRanges: [ /* ... */ ]   } }  At last, an example for text tracks (here ttml in an mp4 container): {   bitrate: 3000, // bitrate of the quality, in bits per seconds   mimeType: \"application/mp4\",   codecs: \"stpp\",   index: {     loadInitSegment(callbacks) { /* ... */  },     loadSegment(segment, callbacks) { /* ... */,     segments: [ /* ... */ ],     incomingRanges: [ /* ... */ ]   } }  We’ll now explain what each property is for, before going deeper into the index attribute, which allows the RxPlayer to fetch the media segments.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_representation_object"},{"h1":"Local Manifest format version 0.1","h2":"The representation object","h3":"properties","body":"  bitrate (number): The bitrate the quality is in, in bits per seconds. For example, a bitrate of 5000000 (5.10^6 == 5 MegaBit) would indicate that each second of the content does on average a size of 5 MegaBit.   mimeType (string): As its name suggests, this is the appropriate mime-type for the media. Generally, it is either:  \"video/mp4\" or \"video/webm\" for a video content (depending on the container) \"audio/mp4\" or \"audio/webm\" for an audio content (depending on the container) \"application/mp4\" or \"text/plain\" for a text content (depending on the container / the absence of container)    codecs (string): The codec necessary to be able to play the content. The syntax here is taken from the RFC6381.   width (number|undefined): When relevant (mostly video contents), the width of the media, in pixels   height (number|undefined): When relevant (mostly video contents), the height of the media, in pixels   index (object): Object allowing the RxPlayer to know the list of segments as well as to fetch them. Described in the next chapter.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_representation_object","anchorH3":"properties_(3)"},{"h1":"Local Manifest format version 0.1","h2":"the index object","body":"As just seen, the index object is a property of a given representation. it contains itself the following properties:   segments (Array.<Object>): the list of every available media segments for that representation. Does not include the initialization segment. Do not include in this Array the segments that are not downloaded yet.   loadInitSegment (function): Returns the initialization segment or null if this notion is not relevant, like for subtitles.   loadSegment (function): Returns a specific media segment.   incomingRanges (Array.<Object>|undefined): The “time ranges” of future segments that are not yet available. Each object in that array takes two number properties start and end which are respectively the start time and end time in seconds of contiguous ranges where future segments will be expected. For example, if in the future a segment will be available from the second 10 to the second 12, another from 12 to 14, and a third from 18 to 20, you can set incomingRanges to: incomingRanges: [   { start: 10, end: 14 }, // the first two segments   { start: 18, end: 20 } // the third one, with its own entry because not                          // contiguous with the previous two ]  Note that you are not forced to collapse this way contiguous ranges, you may also just set it to: incomingRanges: [   { start: 10, end: 12 }, // the first segment   { start: 12, end: 14 }, // the second one   { start: 18, end: 20 } // the third one ]  Both are equivalent. If set, it is important to communicate about EVERY time ranges where segments are to be expected in the future - without including time ranges where the segments are already available. If you cannot tell at least some of the time ranges of data that will be loaded, you can let that property to undefined. An empty array will mean that no data is left to be loaded.  ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_index_object"},{"h1":"Local Manifest format version 0.1","h2":"the index object","h3":"the segments array","body":"Let’s start by the first one, segments. segments is an array of objects, each object describing a single segment of media data. Each object has the following properties:  time (number): starting position of the segment, in milliseconds duration (number): duration of the segment, in milliseconds timestampOffset (number|undefined): optional time offset to add to the segment’s internal time to convert its media time to its presentation time, in milliseconds. If you don’t know what it is, you will most likely not need it.  Let’s see a simple example with four segments of 2 seconds: [   {     time: 0,     duration: 2000,   },   {     time: 2000,     duration: 2000,   },   {     time: 4000,     duration: 2000,   },   {     time: 6000,     duration: 2000,   }, ]; ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_index_object","anchorH3":"the_segments_array"},{"h1":"Local Manifest format version 0.1","h2":"the index object","h3":"the loadInitSegment callback","body":"The loadInitSegment callback allows the RxPlayer to request the initialization segment of this representation. Most audio and video representation have an initialization segment which allows to obtain information about the representation’s data without containing data in itself. For text representations, where it is most likely not needed, this callback can emit null instead of the segment. This callback is given a single argument, which is an object containing callbacks the function should call either when it has fetched the content or when it failed on error. There is two callbacks in that object:   resolve: allows loadInitSegment to communicate the initialization segment in an ArrayBuffer form. Can call resolve with null if no initialization segment is available for that representation.   reject: allows loadInitSegment to communicate an error which made the fetching of the initialization segment impossible.   The loadInitSegment callback can also returns a function which will be called if the caller want to abort the fetch operation. Here is an example of how a loadInitSegment function can look like: async function loadInitSegment(callbacks) {   try {     const initSegment = await getStoredInitSegmentForTheCurrentRepresentation();     callbacks.resolve(initSegment);   } catch (e) {     callbacks.reject(e);   }    // Note: in this example, there is no mean to abort the operation, as a result   // we do not return a function here    // // Here is how it would look like if we could:   // return function abort() {   //   abortStoredInitSegmentRequest();   // } } ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_index_object","anchorH3":"the_loadinitsegment_callback"},{"h1":"Local Manifest format version 0.1","h2":"the index object","h3":"the loadSegment callback","body":"The loadSegment callback is the callback called by the RxPlayer when it wants any segment in the content. Note that the segment data returned by loadSegment should contain all the data and metadata necessary to play them on the browser. Downloaded DASH segments - for example - are generally sufficient but segments linked to Smooth contents should be updated before being returned by loadSegment. This callback is very similar to loadInitSegment with two differences:   it receives two arguments:  The first being the segment object (from the segments array) of the segment we want to recuperate. You can generally discriminate which segment we want from the time property of the given segment, which should be unique for that representation. The second being the callbacks object, which has the exact same form than the one in loadInitSegment (two properties resolve and reject).    it cannot return null. It has to return an ArrayBuffer corresponding to the wanted segment.   Here is an example of how a loadSegment function can look like: async function loadSegment(segment, callbacks) {   try {     const segmentData = await getStoredSegment(segment);     callbacks.resolve(segmentData);   } catch (e) {     callbacks.reject(e);   }    // Note: in this example, there is no mean to abort the operation, as a result   // we do not return a function here    // // Here is how it would look like if we could:   // return function abort() {   //   abortStoredSegmentRequest();   // } } ","anchorH1":"local_manifest_format_version_0.1","anchorH2":"the_index_object","anchorH3":"the_loadsegment_callback"},{"h1":"Local Manifest format version 0.1","h2":"About DRMs","body":"Content with DRMs should be supported as long as the encryption information is specified in the corresponding containers (e.g. in PSSH boxes for mp4 and other ISOBMFF containers). We also look into adding supplementary encryption information into the local manifest format, but this is not available for now.","anchorH1":"local_manifest_format_version_0.1","anchorH2":"about_drms"}]},{"file":"./api/Miscellaneous/Text_Tracks.html","index":[{"h1":"Text Tracks","body":"","anchorH1":"text_tracks"},{"h1":"Text Tracks","h2":"Overview","body":"The rx-player allows to display text tracks - such as subtitles or closed captions - directly over your content: Adding text tracks to contents can be done by two means:  by using a Manifest declaring those text tracks by manually adding text track(s) when you call the loadVideo API  You can then choose the right track through the different text track-related API, all documented in the general API documentation.","anchorH1":"text_tracks","anchorH2":"overview"},{"h1":"Text Tracks","h2":"Supported text track formats","body":"The rx-player supports the following formats:  TTML (TTML1, EBU-TT and IMSC1) WebVTT SAMI SRT TTML embedded in an MP4 file WebVTT embedded in an MP4 file ","anchorH1":"text_tracks","anchorH2":"supported_text_track_formats"},{"h1":"Text Tracks","h2":"Text tracks indicated in a manifest","body":"Each streaming technology supported by the Manifest defines a way to add text track directly in their Manifests files. This chapter explains what is supported by the RxPlayer.","anchorH1":"text_tracks","anchorH2":"text_tracks_indicated_in_a_manifest"},{"h1":"Text Tracks","h2":"Text tracks indicated in a manifest","h3":"In DASH","body":"In DASH, text tracks are defined by AdaptationSet elements, which have a contentType attribute equal to text. Those AdaptationSet can also define a lang, codecs and mimeType, which are then exploited by the RxPlayer. The lang attribute is used to know the language the track is in. The RxPlayer understands the following standards:  ISO 639-1 (2 letters) ISO 639-2 (3 letters) ISO 639-3 (3 letters)  More complex combined formats are also understood, as long as it begins by one of the understood standards, followed by a dash (“-”). For example “en-US” is translated into just “en”, and then inferred to be english. The mimeType attribute is used to know in which format the track is in. The RxPlayer understands the following ones:  application/ttml+xml: TTML in plain text text/vtt: WebVTT in plain text application/x-sami: SAMI in plain text application/mp4: Text track embedded in an MP4 container. text/plain: Generic plain text mimeType  For the last two, the codecs attribute of the AdaptationSet will be exploited to know the exact format. The rx-player uses the codecs attribute for text tracks in only two cases:  the mimeType is equal to application/mp4 the mimeType is equal to text/plain  For the first case, both WebVTT and TTML can be embedded in an MP4 file. To know which one we’re dealing with, the codecs attribute should be equal to:  stpp for TTML wvtt for WebVTT  For the second case (\"text/plain\"), this is specifically to support plain SubRip (SRT) subtitles. To use them you need to set codecs simply to srt. To know if we’re dealing with a closed caption text track, the RxPlayer uses the DVB-DASH specification. That is, an AdaptationSet is inferred to be a closed caption for the hard of hearing, if it contains an Accessibility descriptor with the following attributes:  SchemeIdUri set to urn:tva:metadata:cs:AudioPurposeCS:2007 value set to 2 ","anchorH1":"text_tracks","anchorH2":"text_tracks_indicated_in_a_manifest","anchorH3":"in_dash"},{"h1":"Text Tracks","h2":"Text tracks indicated in a manifest","h3":"In Microsoft Smooth Streaming","body":"In Smooth Manifests, a StreamIndex is inferred to be for a text track if its Type attribute is equal to text. The FourCC attribute is used to infer the format of the text track. Only TTML is understood, and is translated to be a TTML track embedded in an MP4 container. Adding support for other formats is very simple, open an issue if you want us to add a standardized FourCC code for another supported format. The Language is used to know the language the track is in. The rules are the same than for DASH: The rx-player understand the following standards:  ISO 639-1 (2 letters) ISO 639-2 (3 letters) ISO 639-3 (3 letters) More complex combined formats are also understood, as long as it begins by one of the understood standards, followed by a dash (“-”).  For example “en-US” is translated into just “en”, and then inferred to be english. The Subtype attribute is used to know if the language is a closed caption or not. At the moment, the RxPlayer infers the track to be a closed caption only if its value is DESC.","anchorH1":"text_tracks","anchorH2":"text_tracks_indicated_in_a_manifest","anchorH3":"in_microsoft_smooth_streaming"},{"h1":"Text Tracks","h2":"Text tracks added manually","body":"It is also possible to add a supplementary text track dynamically, by using the TextTrackRenderer tool. You can read its documentation here.","anchorH1":"text_tracks","anchorH2":"text_tracks_added_manually"},{"h1":"Text Tracks","h2":"Text track display modes","body":"There is two ways the text track can be displayed:   \"native\": The text track is displayed in <track> elements, which are directly in the linked videoElement.   \"html\": The text track is displayed in a separate <div> element.   The second ones allows for a better track stylisation. The distinction between those two is pretty simple and is explained here, in the loadVideo options documentation.","anchorH1":"text_tracks","anchorH2":"text_track_display_modes"}]},{"file":"./api/Miscellaneous/MetaPlaylist.html","index":[{"h1":"MetaPlaylist v0.1","body":"","anchorH1":"metaplaylist_v0.1"},{"h1":"MetaPlaylist v0.1","h2":"Overview","body":"The MetaPlaylist is a file allowing to define a content composed of multiple DASH or Smooth contents played one after another. It allows advanced use cases for an extremely low cost for the server infrastructure, the main one being creating a linear (live) contents from multiple non-linear (VOD) ones, without touching the original contents. You can also construct a new non-linear contents as a concatenation of multiple non-linear contents put one after the other. This method allows for example for a completely smooth streaming between multiple programs (e.g. when binge-watching a serie).","anchorH1":"metaplaylist_v0.1","anchorH2":"overview"},{"h1":"MetaPlaylist v0.1","h2":"Differences with plain DASH contents","body":"The same result could be approximated with some advanced DASH features, but the MetaPlaylist has several advantages. Some of them are:   it supports DASH and HSS contents (technically HLS would also be possible) without modifying the original MPD/Manifest nor segments.   the Manifest/MPD/Playlist corresponding to the original contents can be lazy-loaded (loaded only when the content will play). This is also possible in DASH with a feature called XLinks but it’s not always doable on the client-side, depending on the other elements present in that MPD. A MetaPlaylist file is much more strict in this regard. This is still a work-in-progress.   it’s a format especially intended to be a concatenation of multiple contents to be played on the web. As such, advanced features such as declaring segments before they should be played or avoiding many customers doing the same manifest request at the exact same time are much easier to implement.   this file rarely needs to be updated, improving the caching of this ressource.   its format is very simple and in JSON, which is easy to integrate with JavaScript codebases. The file can even be very easily generated directly on the client’s page. This paves the way for contents personalized to a single customer.   Digital right management is also much more flexible than with a DASH MPD. For example, different license servers for different contents could be integrated. This is still a work-in-progress.   the specification is simple, try to allow no interpretation and is strict on what is permitted.   All its features have been tested on web applications, meaning that you have the guarantee everything will work on most MSE-compatible browsers, even IE11.  ","anchorH1":"metaplaylist_v0.1","anchorH2":"differences_with_plain_dash_contents"},{"h1":"MetaPlaylist v0.1","h2":"Structure of a MetaPlaylist","body":"A MetaPlaylist file is a simple JSON file. To jump into it right away, let me introduce some examples. For a VOD content: {   \"type\": \"MPL\",   \"version\": \"0.1\",   \"contents\": [     {       \"url\": \"http://url.to.some/DASH/first_content.mpd\",       \"startTime\": 0,       \"endTime\": 100.38,       \"transport\": \"dash\"     },     {       \"url\": \"http://url.to.some/DASH/second_content.Manifest\",       \"startTime\": 100.38,       \"endTime\": 372,       \"transport\": \"smooth\"     },     {       \"url\": \"http://url.to.some/Smooth/third_content.mpd\",       \"startTime\": 372,       \"endTime\": 450.787,       \"transport\": \"dash\"     }   ] }  For a live content: {   \"type\": \"MPL\",   \"version\": \"0.1\",   \"dynamic\": true,   \"pollInterval\": 5,   \"contents\": [     {       \"url\": \"http://url.to.some/DASH/content.mpd\",       \"startTime\": 1545845950.176,       \"endTime\": 1545845985.571,       \"transport\": \"dash\"     },     {       \"url\": \"http://url.to.some/other/DASH/content.mpd\",       \"startTime\": 1545845985.571,       \"endTime\": 1545845998.71,       \"transport\": \"dash\"     },     {       \"url\": \"http://url.to.some/Smooth/content.Manifest\",       \"startTime\": 1545845998.71,       \"endTime\": 1545845117,       \"transport\": \"smooth\"     }   ] }  You may already have a basic understanding of it how works. Let’s define nonetheless every property in that JSON file.","anchorH1":"metaplaylist_v0.1","anchorH2":"structure_of_a_metaplaylist"},{"h1":"MetaPlaylist v0.1","h2":"Structure of a MetaPlaylist","h3":"the header","body":"What I call the “header” here is roughly all root properties but “contents”. Here is an exhaustive list of what you should put there:   type (string): should always be equal to \"MPL\", for “MetaPlayList”. The purpose of this value is to facilitate the checks a player might want to perform to verify that it is handling a MetaPlaylist file. The end goal would be for example to improve error reporting for very frequent mistakes like not providing the URL of the right content.   version (string): version of the MetaPlaylist file. Separated in two parts by a point (‘.’). The first part indicates the major version. If its number is higher than what the client presently manage, the client should not try to read that file. The last part indicates the minor version: A new feature or fix have been added but its support is not needed by a client (a client written for the 1.0 version can be used even for the 1.99 version). Please note that there is an exception for 0.x versions, where each minor versions could have a breaking change (as it is in that case considered an experimental format). At the moment, there is only one version the version \"0.1\". Thus, this is what you have to set in your JSON if you integrate this specification.   dynamic (boolean|undefined): If true, the MetaPlaylist file is not finished, and might need to be updated. If false, the MetaPlaylist could still need to be updated but its current content indicates a finished content: A player should end when the end of the last content has been reached. This property is not mandatory and as such can be omitted. By default, it is considered as not dynamic (so false).   pollInterval (number|undefined): If not set or set to a negative number, the MetaPlaylist file does not need to be reloaded. If set to a positive number, this is the maximum interval in seconds at which the MetaPlaylist file should be fetched from the server (which means that the MetaPlaylist could be refreshed more often depending on the current conditions). This should only be defined for dynamic contents. This property is not mandatory and as such can be omitted. By default, it is equivalent to -1 (which means no reload).  ","anchorH1":"metaplaylist_v0.1","anchorH2":"structure_of_a_metaplaylist","anchorH3":"the_header"},{"h1":"MetaPlaylist v0.1","h2":"Structure of a MetaPlaylist","h3":"The contents","body":"The contents are all defined as a property called contents at the top level of our MetaPlaylist file. It is an array of one or multiple objects (an empty contents array is not a valid MetaPlaylist file). Each of its objects are linked to a single content, here are the exhaustive list of its properties:   url (string): the URL to the original DASH’s MPD or Smooth’s Manifest. For now, only a subset of such contents is supported, mainly:  DASH contents that have their MPD@type set to \"static\" Smooth content that have their isLive attribute not set to true (Simply put, only on-demand contents are supported for the moment).    startTime (number): time, in seconds, at which the beginning of this content should be played. This will correspond to the start time of the first Period in DASH or the first Chunk defined for Smooth content.   endTime (number): time, in seconds, at which the content should end. It the original content is longer, it will be finished at that time instead. The original content should not be shorter.   transport (string): indicates the original streaming protocol. Can be either of those values for now:  \"dash\": the URL points to a DASH’s MPD \"smooth\": the URL points to a Microsoft Smooth Streaming’s Manifest. \"metaplaylist\": Yes, it is possible to put MetaPlaylist files inside other MetaPlaylist files!    All those contents should be contiguous (meaning that the endTime of one should be the same value than the startTime of the following one).","anchorH1":"metaplaylist_v0.1","anchorH2":"structure_of_a_metaplaylist","anchorH3":"the_contents"},{"h1":"MetaPlaylist v0.1","h2":"How to actually play a MetaPlaylist content","body":"","anchorH1":"metaplaylist_v0.1","anchorH2":"how_to_actually_play_a_metaplaylist_content"},{"h1":"MetaPlaylist v0.1","h2":"How to actually play a MetaPlaylist content","h3":"Importing the METAPLAYLIST feature","body":"The \"METAPLAYLIST\" feature is not included in the default RxPlayer build. To import it, you first need to rely on the “minimal” version of the RxPlayer (through the \"rx-player/minimal\" import), you will need to import the METAPLAYLIST experimental feature and every transport protocol you might want to use. For example if you need to use MetaPlaylist with both Smooth and DASH contents, you have to import at least all three as such: import RxPlayer from \"rx-player/minimal\"; import { METAPLAYLIST } from \"rx-player/experimental/features\"; import { DASH, SMOOTH } from \"rx-player/features\";  RxPlayer.addFeatures([METAPLAYLIST, DASH, SMOOTH]);  More information about the minimal version of the RxPlayer can be found in the minimal player documentation.","anchorH1":"metaplaylist_v0.1","anchorH2":"how_to_actually_play_a_metaplaylist_content","anchorH3":"importing_the_metaplaylist_feature"},{"h1":"MetaPlaylist v0.1","h2":"How to actually play a MetaPlaylist content","h3":"Loading a MetaPlaylist content","body":"A MetaPlaylist content can simply be played by setting a \"metaplaylist\" transport in loadVideo: player.loadVideo({   url: \"http://www.example.com/metaplaylist.json\",   transport: \"metaplaylist\", });  If you declare locally your MetaPlaylist file and do not want to set a URL for it, you can serve directly the file through the use of a Manifest Loader: player.loadVideo({   transport: \"metaplaylist\",    // Note: `_url` here will be `undefined`   manifestLoader(_url, callbacks) {     // where `myMetaPlaylistObject` is the MetaPlaylist in either Object or     // String form     callbacks.resolve({ data: myMetaPlaylistObject });   }, });  More infos on the manifestLoader can be found here.","anchorH1":"metaplaylist_v0.1","anchorH2":"how_to_actually_play_a_metaplaylist_content","anchorH3":"loading_a_metaplaylist_content"},{"h1":"MetaPlaylist v0.1","h2":"How to actually play a MetaPlaylist content","h3":"Defining an initial position for a dynamic MetaPlaylist","body":"As already explained, a MetaPlaylist can either be dynamic or static. For calculating the initial position of those contents, the RxPlayer will obey the same rules than for other contents. As such, dynamic MetaPlaylist contents will by default start just before the end of the last defined content which might not be what you want. In those cases, you can make usage of the serverSyncInfos transport options when calling loadVideo to indicate the current time and construct the MetaPlaylist by using unix time for each content’s startTime and endTime. The serverSyncInfos option is explained in the loadVideo options documentation. For example, if you trust the user’s system clock to indicate the current live time (in most cases this is risky however), you can use the Date.now() api: const serverSyncInfos = {   serverTimestamp: Date.now(),   clientTime: performance.now(), };  player.loadVideo({   transport: \"metaplaylist\",   url: \"https://www.example.com/metaplaylist\",   serverSyncInfos, }); ","anchorH1":"metaplaylist_v0.1","anchorH2":"how_to_actually_play_a_metaplaylist_content","anchorH3":"defining_an_initial_position_for_a_dynamic_metaplaylist"}]},{"file":"./api/Miscellaneous/Initial_Position.html","index":[{"h1":"Initial Position","body":"","anchorH1":"initial_position"},{"h1":"Initial Position","h2":"Overview","body":"When you give it a content to load, the RxPlayer has to set at one point the starting playback position. This documentation page explain how that position is calculated. Basically, we can be in one of those four different situations:   a valid startAt option has been set to loadVideo, in which case we use it to define the initial position.   no startAt option has been set and we’re playing a VoD content.   no startAt option has been set and we’re playing a live content.   no startAt option has been set and we’re playing a directfile content.  ","anchorH1":"initial_position","anchorH2":"overview"},{"h1":"Initial Position","h2":"About the minimum and maximum position","body":"Regardless of your current situation, the minimum and maximum position of the content might be calculated and used when defining that starting position. Those positions are inferred directly from the Manifest (when not playing a directfile content). Most Manifests declare every segments currently available. In that case, we can simply use the start of the first announced segment as a minimum position and the end of the last one as a maximum. In some other Manifest files, segment availability is not clearly announced. In those cases, the minimum and maximum positions use other properties declared in the Manifest, often by making usage of a synchronized clock between the client and the server. For “directfile” contents, we directly interrogate the browser to obtain the duration of the content. The minimum position here is always inferred to be 0 (for the moment at least).","anchorH1":"initial_position","anchorH2":"about_the_minimum_and_maximum_position"},{"h1":"Initial Position","h2":"When a startAt option has been set","body":"You can define yourself the start position at which we should play. This is configurable thanks to the startAt option, documented here in the API documentation. Please note however that there is a catch: every of the possible values you will set will be “bounded” to the maximum and minimum position actually detected for the content. This means that if your startAt indicate that we should start at a position of 10 seconds but the content starts at 15 seconds, we will actually start at 15 seconds instead. You can check at which position we actually loaded when the player’s state (accessible either through the getPlayerState method or through the playerStateChanged event) changed to \"LOADED\".","anchorH1":"initial_position","anchorH2":"when_a_startat_option_has_been_set"},{"h1":"Initial Position","h2":"When no startAt option has been set and we’re playing a VoD content","body":"For VoD contents, we will just start to play at the minimum detected position in the Manifest.","anchorH1":"initial_position","anchorH2":"when_no_startat_option_has_been_set_and_we're_playing_a_vod_content"},{"h1":"Initial Position","h2":"When no startAt option has been set and we’re playing a live content","body":"For live contents, we have here three cases:   In the case where we have a clock synchronization mechanism with the server[1] and if the current date can be seeked to (i.e. segments are available for that position), we will try to play close to[2] that date.   if either we do not have a clock synchronization mechanism[1] or if we have one but no segment is defined for the current date, we will play close to[2] the maximum calculated position instead.   Third case, if we do not have any clock synchronization mechanism[1] and if the Manifest does not announce clearly a maximum position, we will use the system clock and play close to[2] that time instead.   [1] We can obtain a synchronized clock allowing us to to know which content should be broadcasted at which time by either of those means:  the Manifest document defines one (e.g. UTCTiming elements for DASH contents). One was provided to loadVideo thanks to the serverSyncInfos transport option see loadVideo documentation.  [2] I wrote “close to” in every cases as we might substract some seconds from that value. How much we might do, depends on:  if the manifest suggest us a delay relative to the live, in which case we apply it if not, we set it to the default: 10 seconds ","anchorH1":"initial_position","anchorH2":"when_no_startat_option_has_been_set_and_we're_playing_a_live_content"},{"h1":"Initial Position","h2":"When no startAt option has been set and we’re playing a directfile content","body":"For directfile contents, we for now just start at 0 if no startAt is defined.","anchorH1":"initial_position","anchorH2":"when_no_startat_option_has_been_set_and_we're_playing_a_directfile_content"}]},{"file":"./api/Miscellaneous/presentationTimeOffset.html","index":[{"h1":"Presentation Time Offset","body":"The presentationTimeOffset is an attribute which can be encountered in an MPD (the “manifest” of the DASH streaming technology).","anchorH1":"presentation_time_offset"},{"h1":"Presentation Time Offset","h2":"Overview","body":"Simply put, this attribute allows to correct an offset present in the media segments once those are decoded. One of the possible usecase would be creating an on demand MPD from a subsection of an already-existing content, without modifying directly the concerned segments nor their (possibly time-based) URLs. Another main usecase is when handling multi-Periods MPDs. Segments in newer Periods already need to consider an offset, corresponding to the start of the given Period. In those cases, the presentationTimeOffset might allows to “cancel” out this offset. This can be useful if the corresponding segments already define the right time.","anchorH1":"presentation_time_offset","anchorH2":"overview"},{"h1":"Presentation Time Offset","h2":"Simple example","body":"For example, let’s imagine some on-demand content with a duration of 2 hours. To stay simple, this content begins at 00:00:00.000 and ends at 01:08:00.000 (1 hour and 8 minutes). CONTENT:  00:00:00.000                                                        01:08:00.000     |====================================================================|   Now let’s say that we want to create a new on-demand content, which is only a sub-part from this content. For example, we will take the subpart going from 00:05:24.000 to 00:12:54.000 (for a duration of 00:07:30.000).  00:00:00.000                                                        02:00:00.000     |====|------|========================================================|             ^       Subpart going from 00:05:24 to 00:12:54.000   Because we might not want to use money uselessly, we want to create this new content simply by creating a new MPD, and without touching the already created segments, nor their URLs. In that condition, we will still need the client to know that this content actually have an offset of 00:05:24.000. If it does not know that, we will just think that the content begins at a default 00:00:00.000 time. Letting the client think that the content begins at the default 00:00:00.000 time could lead to several issues:   it might not be able to request the right first segments (as the URLs could be time-based)   even if it does, it might not be able to actually play the content, as we’re pushing segments corresponding to a 00:05:24.000 while the browser is still waiting for the 00:00:00.000 ones (in that case, we would just have an infinite buffering state).   even if it does, the client timeline will announce a wrong time, offseted 5 minutes and 24 seconds too late.   This is where the presentationTimeOffset comes into play. In our simple example, this value will just announce an offset of 00:05:24.000 (under the form of an integer with a timescale to convert it into seconds), and the client will know what to do. What the client has to do here is:  begin to play at 0 secods ask the right segments, by adding this offset to the one it thinks it needs remove the offset from the segment before decoding it ","anchorH1":"presentation_time_offset","anchorH2":"simple_example"},{"h1":"Presentation Time Offset","h2":"Time conversions","body":"The presentationTimeOffset is linked to multiple other time attributes of an MPD, especially the start of the Period concerned, and of course the time of the segment. We will enounce below a simple equation which put their relation into perspective. To understand this equation, we will need to define some variables:    Variable Definition     PTO The “presentationTimeOffset” attribute of the MPD   mediaTime The start time announced in the segment   TS Timescale used by PTO and segmentTime, to transform them into seconds   periodStart Start time of the given period, in seconds   presentationTime The time at which the segment will be shown, in seconds        mediaTime        PTO   -------------  -  -----  +  periodStart  =  presentationTime        TS            TS ","anchorH1":"presentation_time_offset","anchorH2":"time_conversions"},{"h1":"Presentation Time Offset","h2":"Time conversions","h3":"Easier conversion: the timestampOffset","body":"As seen in the previous chapter, to convert the media time (time announced in the segments) into the presentation time (time that will be shown to the user), you will need to use both also include three other variables:   the start of the period   the presentationTimeOffset   the timescale used by the presentationTimeOffset and the media time   As a convenient plus, those three variables rarely change for a given period. To simplify the conversion, we can thus define a new variable using those three. This is what the timestampOffset is all about. Let’s go back to the equations in the previous chapters, to isolate those three into the really simple equation: mediaTime/TS + timestampOffset = presentationTime (you can refer to the previous chapter to understand what those variables means)    mediaTime       PTO  -----------  -  -----  +  periodStart  =  presentationTime      TS           TS    mediaTime           PTO  -----------  + ( -  -----  +  periodStart ) =  presentationTime      TS               TS                            PTO                                       PTO   timestampOffset  =  -  -----  +  periodStart  =  periodStart  -  -----                           TS                                        TS   With timestampOffset defined, it becomes easy to go back and forth between the mediaTime and the presentationTime:                        mediaTime presentationTime  =   -----------  +  timestampOffset                           TS  mediaTime  =  (  presentationTime  -  timestampOffset  )  *  TS   As an added bonus, SourceBuffers defined in the HTML5 MediaSource Extentions also have a timestampOffset property , which means exactly the same thing as defined here!","anchorH1":"presentation_time_offset","anchorH2":"time_conversions","anchorH3":"easier_conversion:_the_timestampoffset"},{"h1":"Presentation Time Offset","h2":"In the RxPlayer","body":"Now that we have all of those concepts out of the way, how are we going to use it, in the RxPlayer? The RxPlayer has A LOT of time-related values defined for a given segment:   the time defined in the segment itself (mediaTime)   the time displayed when playing it in the HTMLMediaElement (presentationTime)   the time possibly set in the request (requestSegmentTime)   the time as announced in the corresponding attribute of the manifest (manifestTime)   the time used in the corresponding Segment Object in the RxPlayer (playerTime)   the time used in the buffered APIs of a HTMLMediaElement or SourceBuffer (bufferedTime)   …   As it turns out it’s a lot simpler once you make two isolated groups:   the manifest group, which uses the non-offseted mediaTime. In this group you have:  the mediaTime (duh) the manifestTime the requestSegmentTime    the real time group, which uses the offseted presentationTime. In this group you have:  the presentationTime the playerTime the bufferedTime    The manifest group is then only used in the transports code of the RxPlayer. Meanwhile, the real time group is used everywhere else. It’s actually the transports code that does most of the conversion for the rest of the code (removing the offset when requesting new segments, re-adding it once the segment is downloaded. To be able to offset those segments in the SourceBuffer, those are still informed of course of the timestampOffset by the transports code. Then, this timestampOffset will be exploited only by the final decoding code.","anchorH1":"presentation_time_offset","anchorH2":"in_the_rxplayer"}]},{"file":"./api/Miscellaneous/DASH_Adaptation_Difference.html","index":[{"h1":"Differences between DASH’ AdaptationSets and the rx-player “Adaptation”","body":"The RxPlayer defines an Adaptation object (also sometimes called Track) which follow as close as possible the concept of the AdaptationSet in the DASH protocol. However, to answer practically to some of the features allowed by DASH while still respecting the DASH-IF “IOP”, we had to take some (minor) freedom with our interpretation of it.","anchorH1":"differences_between_dash'_adaptationsets_and_the_rx-player_%22adaptation%22"},{"h1":"Differences between DASH’ AdaptationSets and the rx-player “Adaptation”","h2":"Merging of multiple AdaptationSets into a single Adaptation","body":"The main difference is that all similar AdaptationSet which are marked as “seamlessly switchable” between one another are merged into a single Adaptation in the player.","anchorH1":"differences_between_dash'_adaptationsets_and_the_rx-player_%22adaptation%22","anchorH2":"merging_of_multiple_adaptationsets_into_a_single_adaptation"},{"h1":"Differences between DASH’ AdaptationSets and the rx-player “Adaptation”","h2":"Merging of multiple AdaptationSets into a single Adaptation","h3":"Why do we do that","body":"This “switchable” concept is for example used in cases were multiple encryption keys are present for different Representation (e.g. due to limitations coming from right holders). The problem is that the DASH-IF tells us that all Representation in a given AdaptationSet have to use the same license. This means that in the aforementioned case, the concerned Representation have to be divided into multiple AdaptationSet. In a player, different AdaptationSet means different “tracks” and thus a player won’t try to automatically switch between them. This means that our adaptive algorithm won’t be able to set the right quality and that the library user would have to manually manage that instead. Fortunately, the DASH-IF IOP planned a work-around for that kind of situation: To allow a player to seamlessly switch between multiple AdaptationSets, the DASH-IF allows a specific node, called SupplementalProperty to be added as children of the concerned AdaptationSets (with a specific value). However, this brings another set of issues in the rx-player, where this separation would lead to an excessively complicated API.","anchorH1":"differences_between_dash'_adaptationsets_and_the_rx-player_%22adaptation%22","anchorH2":"merging_of_multiple_adaptationsets_into_a_single_adaptation","anchorH3":"why_do_we_do_that"},{"h1":"Differences between DASH’ AdaptationSets and the rx-player “Adaptation”","h2":"Merging of multiple AdaptationSets into a single Adaptation","h3":"What do we do","body":"We thus decided to “merge” the AdaptationSets into a single Adaptation if all those conditions are filled:   they both support seamless-switching between one-another (i.e. they both contain a SupplementalProperty node with the right values)   they represent the same type of content (“audio”, “video” or “text”)   they are of the same language, if one (letter-for-letter in the manifest)   they have the same accessibility information (e.g. both are closed captions or audio description for the visually impaired).   If any of these conditions is not filled, the concerned AdaptationSets stay separated and the player will not try to switch between them.","anchorH1":"differences_between_dash'_adaptationsets_and_the_rx-player_%22adaptation%22","anchorH2":"merging_of_multiple_adaptationsets_into_a_single_adaptation","anchorH3":"what_do_we_do"}]},{"file":"./reference/API_Reference.html","index":[{"h1":"API reference","body":"","anchorH1":"api_reference"},{"h1":"API reference","h2":"Overview","body":"This is the API reference which presents every RxPlayer API in a single page. The point of this page is to provide an easier-to-navigate page than the API documentation for when you’re already familiar with it. API are splitted here in multiple categories depending on if they are properties, methods, events and so on.","anchorH1":"api_reference","anchorH2":"overview"},{"h1":"API reference","h2":"Constructor","body":" new RxPlayer(): Create a new RxPlayer. ","anchorH1":"api_reference","anchorH2":"constructor"},{"h1":"API reference","h2":"Constructor options","body":"  videoElement: specifies the media element on which the content will play.   baseBandwidth: Base value for the bandwidth calculated by the RxPlayer.   wantedBufferAhead: Set the default buffering goal.   maxBufferAhead: Set the default maximum kept buffer ahead of the current position, in seconds.   maxBufferBehind: Set the default maximum kept buffer before the current position, in seconds.   maxVideoBufferSize: Set the default maximum size the video buffer can take in the memory, in kilobytes (kb).   videoResolutionLimit: Limit the maximum video resolution according to the element’s or screen’s resolution.   throttleVideoBitrateWhenHidden: Limit the maximum video bitrate when the current video is hidden to the user.  ","anchorH1":"api_reference","anchorH2":"constructor_options"},{"h1":"API reference","h2":"loadVideo options","body":"  transport: The adaptive streaming technology (e.g. “dash”, “smooth” etc.) used.   url: URL to the content (e.g. DASH’s MPD, Smooth’s Manifest etc.)   keySystems: DRM configuration for the content.   keySystems[].type: Name of the DRM technology wanted.   keySystems[].getLicense: Logic to fetch the license.   keySystems[].getLicenseConfig: Supplementary configuration linked to the getLicense function.   keySystems[].serverCertificate: Eventual certificate encrypting exchanges between the CDM and license server.   keySystems[].persistentLicenseConfig: Allows to ask for the DRM session to persist the license.   keySystems[].onKeyExpiration: Behavior when a key has an \"internal-error\" status.   keySystems[].onKeyOutputRestricted: Behavior when a key has an \"output-restricted\" status.   keySystems[].onKeyInternalError: Behavior when a key has an \"internal-error\" status.   keySystems[].maxSessionCacheSize: Maximum number of DRM sessions cached by the RxPlayer.   keySystems[].closeSessionsOnStop: Closes DRM sessions when the content stops.   keySystems[].singleLicensePer: Allows to use a single getLicense call for keys linked to multiple qualities.   keySystems[].disableMediaKeysAttachmentLock: Disable a lock that may cause the RxPlayer to deadlock on encrypted contents on some peculiar devices.   keySystems[].distinctiveIdentifier: Allows the configuration of the Distinctive Indentifier(s) property.   keySystems[].persistentState: Allows the configuration of the persistentState property.   keySystems[].audioCapabilitiesConfig: Allows the configuration of the audioCapabilities property.   keySystems[].videoCapabilitiesConfig: Allows the configuration of the videoCapabilities property.     autoPlay: Allows to automatically play after a content is loaded.   startAt: Define the position at which the RxPlayer should start.   requestConfig: Configuration linked to the Manifest and segment requests.   requestConfig.segment.maxRetry: Maximum number of retries when a segment request fails.   requestConfig.segment.timeout: Timeout after which segment requests are aborted.   requestConfig.manifest.maxRetry: Maximum number of retries when a Manifest request fails.   requestConfig.manifest.timeout: Timeout after which manifest requests are aborted.     textTrackMode: The way in which the text tracks should be displayed.   textTrackElement: HTMLElement in which text tracks should be displayed.   minimumManifestUpdateInterval: Allows to limit the frequency of Manifest updates.   initialManifest: Allows to provide an initial Manifest to speed-up the content loading   manifestUpdateUrl: Provide another URL, potentially to a shorter Manifest, used only for Manifest updates   representationFilter: Filter out qualities from the Manifest based on its characteristics.   segmentLoader: Provide a custom logic to fetch segments.   manifestLoader: Provide a custom logic to fetch the Manifest.   onCodecSwitch: Behavior when the codec changes between incompatible ones.   defaultAudioTrackSwitchingMode: Default behavior when switching the audio track.   lowLatencyMode: Allows to play low-latency contents efficiently.   enableFastSwitching: Enable or disable an optimization replacing segments of poor quality with segments of a better quality.   checkMediaSegmentIntegrity: Enable supplementary checks to retry a request if a segment appears corrupted.   serverSyncInfos: Provide time synchronization mechanism between the client and server.   referenceDateTime: Default offset to add to the segment’s time to obtain a live time. This is in most cases not needed.  ","anchorH1":"api_reference","anchorH2":"%60loadvideo%60_options"},{"h1":"API reference","h2":"Methods","body":"  loadVideo: Load a content.   getPlayerState: Get the current player’s state.   addEventListener: Add a listener to one of the RxPlayer’s event.   removeEventListener: Remove a listener to one of the RxPlayer’s event.   play: Resume paused content.   pause: Pause the current content.   stop: Stop playing the current content.   getPosition: Get the current playback condition.   getWallClockTime: Get the current playback condition offseted to be relative to the the current date.   seekTo: Seek in the current content.   getMinimumPosition: Get the minimum seekable position.   getMaximumPosition: Get the maximum seekable position.   getMediaDuration: Get the duration linked to the media element.   getError: Returns the current “fatal” error.   getVideoElement: Returns the media element linked to the RxPlayer.   dispose: Dispose of most resources taken by the RxPlayer.   reload: Reload the last loade content as fast as possible.   getAvailablePeriods: Returns the list of available Periods for the current content.   getCurrentPeriod: Returns information on the Period being currently played.   getAudioTrack: Get information on the current audio track.   getTextTrack: Get information on the current text track.   getVideoTrack: Get information on the current video track.   getAvailableAudioTracks: Get information on all the available audio tracks.   getAvailableTextTracks: Get information on all the available text tracks.   getAvailableVideoTracks: Get information on all the available video tracks.   setAudioTrack: Set the current audio track.   setTextTrack: Set the current text track.   setVideoTrack: Set the current video track.   disableTextTrack: Disable the current text track.   disableVideoTrack: Disable the current video track.   getVideoRepresentation: Returns the currently-loading video Representation.   getAudioRepresentation: Returns the currently-loading audio Representation.   lockVideoRepresentations: Select video Representations (a.k.a. qualities) that should the only one being played.   lockAudioRepresentations: Select audio Representations (a.k.a. qualities) that should the only one being played.   unlockVideoRepresentations: Disable a lock previously set with lockVideoRepresentations.   unlockAudioRepresentations: Disable a lock previously set with lockAudioRepresentations.   getLockedVideoRepresentations: Get the list of currently “locked” video Representations (a.k.a. qualities).   getLockedAudioRepresentations: Get the list of currently “locked” audio Representations (a.k.a. qualities).   unlockVideoRepresentations: Deactivate potential pending video Representations (a.k.a. qualities) lock, thus re-allowing any Representation to being played.   unlockAudioRepresentations: Deactivate potential pending audio Representations (a.k.a. qualities) lock, thus re-allowing any Representation to being played.   isTrickModeEnabled: Returns true if trick mode tracks are currently enabled by default.   setPlaybackRate: Update the speed at which the content is played.   getPlaybackRate: Read the speed at which the content is played.   areTrickModeTracksEnabled: Indicates if the tricmode tracks are active by default.   setVolume: Update the audio volume.   getVolume: Get the current audio volume.   mute: Mute the audio volume.   isMute: Return true if the audio volume is set to 0.   isMute: Return true if the audio volume is set to 0.   unMute: Restore the volume as it was before it was muted.   setWantedBufferAhead: Update the buffering goal, in seconds.   getWantedBufferAhead: Get the current buffering goal, in seconds   setMaxBufferBehind: Remove automatically old media data.   getMaxBufferBehind: Get the current maximum kept buffer behind the current position, in seconds.   setMaxBufferAhead: Remove automatically media data too far ahead.   getMaxBufferAhead: Get the current maximum kept buffer ahead of the current position, in seconds.   setMaxVideoBufferSize: Set the maximum memory the video buffer can take up in the memory, in kilobytes.   getMaxVideoBufferSize: Get the maximum memory the video buffer can take up in the memory, in kilobytes.   getCurrentBufferGap: Returns in seconds the difference between the current position and the end of the current media time range.   getContentUrls: Get URLs of the currently-played content.   updateContentUrls: Update URL(s) of the content currently being played.   isLive: Returns true if the content is a “live” content.   getKeySystemConfiguration: Returns information on the key system currently attached to the HTMLMediaElement linked to the RxPlayer.  ","anchorH1":"api_reference","anchorH2":"methods"},{"h1":"API reference","h2":"Static Properties","body":"  version: The current version of the RxPlayer.   LogLevel: Update the verbosity of the RxPlayer logger.   ErrorTypes: All Error types that can be encountered.   ErrorCodes: All Error codes that can be encountered.  ","anchorH1":"api_reference","anchorH2":"static_properties"},{"h1":"API reference","h2":"Events","body":"  playerStateChange: The current state of the player has changed.   error: A fatal error happened.   warning: A non-fatal error happened.   positionUpdate: Regular event about the current position evolving.   seeking: A seek operation began.   seeked: A seek operation ended.   availableAudioTracksChange: The list of available audio tracks changed.   availableVideoTracksChange: The list of available video tracks changed.   availableTextTracksChange: The list of available text tracks changed.   audioTrackChange: The current audio track changed.   videoTrackChange: The current video track changed.   textTrackChange: The current text track changed.   periodChange: A new Period begins.   newAvailablePeriods: New Periods associated to the current content are known. It is also now possible to change their respective tracks and qualities.   brokenRepresentationsLock: Representations previously being locked was automatically unlocked by the RxPlayer.   autoTrackSwitch: A track previously set was automatically changed by the RxPlayer.   inbandEvents: Events in the media have been encountered.   streamEvent: A “stream event” just started.   streamEventSkip: A “stream event” was just skipped.  ","anchorH1":"api_reference","anchorH2":"events"},{"h1":"API reference","h2":"Error types","body":"  NETWORK_ERROR: A network-related error.   MEDIA_ERROR: A media-related error.   ENCRYPTED_MEDIA_ERROR: An error related to media decryption.   OTHER_ERROR: Another non-categorized error.  ","anchorH1":"api_reference","anchorH2":"error_types"},{"h1":"API reference","h2":"Tools","body":"  TextTrackRenderer: Render external text tracks on top of the video.   VideoThumbnailLoader: Display seeking preview thumbnails from trick mode video tracks.   StringUtils: Various string conversion utils.   parseBifThumbnails: Parse thumbnails in the “BIF” format.   MediaCapabilitiesProber: Tool to probe several media-related browser APIs.   createMetaplaylist: Generate a MetaPlaylist content.  ","anchorH1":"api_reference","anchorH2":"tools"}]}]