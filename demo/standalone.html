<!DOCTYPE html>
<html lang="en">

<head>

  <head>
    <meta charset="UTF-8">
    <title>RxPlayer - CANAL+ (stand-alone demo)</title>
  </head>

  <body>
    <canvas id="glcanvas" width="1280px" height="720px"></canvas>
    <script type="text/javascript" src="./lib.js" charset="utf-8"></script>
    <script type="text/javascript" src="http://127.0.0.1:8080/gl-matrix.js" charset="utf-8"></script>
    <script charset="utf-8">
      // will set to true when video can be copied to texture
      var copyVideo = false;

      main();

      //
      // Start here
      //
      function main() {
        const canvas = document.getElementById('glcanvas');
        const gl = canvas.getContext('webgl');

        // If we don't have a GL context, give up now

        if (!gl) {
          alert('Unable to initialize WebGL. Your browser or machine may not support it.');
          return;
        }

        // Vertex shader program

        const vsSource = `
          attribute vec4 aVertexPosition;
          attribute vec3 aVertexNormal;
          attribute vec2 aTextureCoord;
          
          uniform mat4 uNormalMatrix;
          uniform mat4 uModelViewMatrix;
          uniform mat4 uProjectionMatrix;
          
          varying highp vec2 vTextureCoord;
          varying highp vec3 vLighting;
          
          void main(void) {
            gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
            vTextureCoord = aTextureCoord;
            vLighting = vec3(1, 1, 1);
          }
        `;

        // Fragment shader program

        const fsSource = `
          varying highp vec2 vTextureCoord;
          uniform sampler2D blurSampler;  // Texture that will be blurred by this shader

          const highp float sigma = 5.0;
          const highp float vertBlurSize = 4.0 / 720.0;
          const highp float horBlurSize = 4.0 / 1280.0;
          const highp float pi = 3.14159265;

          const highp float numBlurPixelsPerSide = 4.0;
          const highp vec2  vertBlurMultiplyVec = vec2(0.0, 1.0);
          const highp vec2  horBlurMultiplyVec = vec2(1.0, 0.0);


          void main() {
          
            // Incremental Gaussian Coefficent Calculation (See GPU Gems 3 pp. 877 - 889)
            highp vec3 incrementalGaussian;
            incrementalGaussian.x = 1.0 / (sqrt(2.0 * pi) * sigma);
            incrementalGaussian.y = exp(-0.5 / (sigma * sigma));
            incrementalGaussian.z = incrementalGaussian.y * incrementalGaussian.y;
          
            highp vec4 avgValue = vec4(0.0, 0.0, 0.0, 0.0);
            highp float coefficientSum = 0.0;
          
            // Take the central sample first...
            avgValue += texture2D(blurSampler, vTextureCoord.xy) * incrementalGaussian.x;
            coefficientSum += incrementalGaussian.x;
            incrementalGaussian.xy *= incrementalGaussian.yz;
          
            // Go through the remaining 8 vertical samples (4 on each side of the center)
            for (highp float i = 1.0; i <= numBlurPixelsPerSide; i++) { 
              avgValue += texture2D(blurSampler, vTextureCoord.xy - i * vertBlurSize * 
                                    vertBlurMultiplyVec) * incrementalGaussian.x;         
              avgValue += texture2D(blurSampler, vTextureCoord.xy + i * vertBlurSize * 
                                    vertBlurMultiplyVec) * incrementalGaussian.x;   
              avgValue += texture2D(blurSampler, vTextureCoord.xy - i * horBlurSize * 
                                    horBlurMultiplyVec) * incrementalGaussian.x;         
              avgValue += texture2D(blurSampler, vTextureCoord.xy + i * horBlurSize * 
                                    horBlurMultiplyVec) * incrementalGaussian.x;             
              coefficientSum += 4.0 * incrementalGaussian.x;
              incrementalGaussian.xy *= incrementalGaussian.yz;
            }
          
            gl_FragColor = avgValue / coefficientSum;
          }
        `;

        // Initialize a shader program; this is where all the lighting
        // for the vertices and so forth is established.
        const shaderProgram = initShaderProgram(gl, vsSource, fsSource);

        // Collect all the info needed to use the shader program.
        // Look up which attributes our shader program is using
        // for aVertexPosition, aVertexNormal, aTextureCoord,
        // and look up uniform locations.
        const programInfo = {
          program: shaderProgram,
          attribLocations: {
            vertexPosition: gl.getAttribLocation(shaderProgram, 'aVertexPosition'),
            vertexNormal: gl.getAttribLocation(shaderProgram, 'aVertexNormal'),
            textureCoord: gl.getAttribLocation(shaderProgram, 'aTextureCoord'),
          },
          uniformLocations: {
            projectionMatrix: gl.getUniformLocation(shaderProgram, 'uProjectionMatrix'),
            modelViewMatrix: gl.getUniformLocation(shaderProgram, 'uModelViewMatrix'),
            normalMatrix: gl.getUniformLocation(shaderProgram, 'uNormalMatrix'),
            uSampler: gl.getUniformLocation(shaderProgram, 'uSampler'),
          },
        };

        // Here's where we call the routine that builds all the
        // objects we'll be drawing.
        const buffers = initBuffers(gl);
        const texture = initTexture(gl);
        const video = setupPlayer();

        var then = 0;

        // Draw the scene repeatedly
        function render(now) {
          now *= 0.001;  // convert to seconds
          const deltaTime = now - then;
          then = now;

          if (copyVideo) {
            updateTexture(gl, texture, video);
          }

          drawScene(gl, programInfo, buffers, texture, deltaTime);
          requestAnimationFrame(render);
        }
        requestAnimationFrame(render);
      }

      function setupPlayer() {
        const video = document.createElement("video");

        var playing = false;
        var timeupdate = false;

        // Waiting for these 2 events ensures
        // there is data in the video
        const player = new window.RxPlayer({ videoElement: video });
        window.player = player;

        player.addEventListener('playerStateChange', function (state) {
          if (state === "PLAYING") {
            playing = true;
            checkReady();
          }
        }, true);

        video.addEventListener('timeupdate', function () {
          timeupdate = true;
          checkReady();
        }, true);

        player.loadVideo({
          url: "http://dash.edgesuite.net/envivio/EnvivioDash3/manifest.mpd",
          transport: "dash",
          autoPlay: true
        });

        function checkReady() {
          if (playing && timeupdate) {
            copyVideo = true;
          }
        }

        return video;
      }

      //
      // initBuffers
      //
      // Initialize the buffers we'll need. For this demo, we just
      // have one object -- a simple three-dimensional cube.
      //
      function initBuffers(gl) {

        // Create a buffer for the cube's vertex positions.
        const positionBuffer = gl.createBuffer();

        // Select the positionBuffer as the one to apply buffer
        // operations to from here out.
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);

        // Now create an array of positions for the cube.
        const positions = [
          // Front face
          -1.0, 1.0, 0,
          1.0, 1.0, 0,
          1.0, -1.0, 0,
          -1.0, -1.0, 0,
        ];

        // Now pass the list of positions into WebGL to build the
        // shape. We do this by creating a Float32Array from the
        // JavaScript array, then use it to fill the current buffer.

        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);

        // Set up the normals for the vertices, so that we can compute lighting.
        const normalBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, normalBuffer);

        const vertexNormals = [
          // Front
          0.0, 0.0, 0,
          0.0, 0.0, 0,
          0.0, 0.0, 0,
          0.0, 0.0, 0,
        ];

        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertexNormals),
          gl.STATIC_DRAW);

        // Now set up the texture coordinates for the faces.
        const textureCoordBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, textureCoordBuffer);

        const textureCoordinates = [
          // Front
          0.0, 0.0,
          1.0, 0.0,
          1.0, 1.0,
          0.0, 1.0,
        ];

        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(textureCoordinates),
          gl.STATIC_DRAW);

        // Build the element array buffer; this specifies the indices
        // into the vertex arrays for each face's vertices.
        const indexBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);

        // This array defines each face as two triangles, using the
        // indices into the vertex array to specify each triangle's
        // position.
        const indices = [
          0, 1, 2, 0, 2, 3,    // front
        ];

        // Now send the element array to GL
        gl.bufferData(gl.ELEMENT_ARRAY_BUFFER,
          new Uint16Array(indices), gl.STATIC_DRAW);

        return {
          position: positionBuffer,
          normal: normalBuffer,
          textureCoord: textureCoordBuffer,
          indices: indexBuffer,
        };
      }

      //
      // Initialize a texture.
      //
      function initTexture(gl) {
        const texture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, texture);

        // Because video havs to be download over the internet
        // they might take a moment until it's ready so
        // put a single pixel in the texture so we can
        // use it immediately.
        const level = 0;
        const internalFormat = gl.RGBA;
        const width = 1;
        const height = 1;
        const border = 0;
        const srcFormat = gl.RGBA;
        const srcType = gl.UNSIGNED_BYTE;
        const pixel = new Uint8Array([255, 255, 255, 255]);  // opaque blue
        gl.texImage2D(gl.TEXTURE_2D, level, internalFormat,
          width, height, border, srcFormat, srcType,
          pixel);

        // Turn off mips and set  wrapping to clamp to edge so it
        // will work regardless of the dimensions of the video.
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);

        return texture;
      }

      // copy the video texture
      function updateTexture(gl, texture, video) {
        const level = 0;
        const internalFormat = gl.RGBA;
        const srcFormat = gl.RGBA;
        const srcType = gl.UNSIGNED_BYTE;
        gl.bindTexture(gl.TEXTURE_2D, texture);
        gl.texImage2D(gl.TEXTURE_2D, level, internalFormat,
          srcFormat, srcType, video);
      }

      function isPowerOf2(value) {
        return (value & (value - 1)) == 0;
      }

      // Draw the scene.
      function drawScene(gl, programInfo, buffers, texture, deltaTime) {
        gl.clearColor(0.0, 0.0, 0.0, 1.0);  // Clear to black, fully opaque
        gl.clearDepth(1.0);                 // Clear everything
        gl.enable(gl.DEPTH_TEST);           // Enable depth testing
        gl.depthFunc(gl.LEQUAL);            // Near things obscure far things

        // Clear the canvas before we start drawing on it.
        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

        // Create a perspective matrix, a special matrix that is
        // used to simulate the distortion of perspective in a camera.
        // Our field of view is 45 degrees, with a width/height
        // ratio that matches the display size of the canvas
        // and we only want to see objects between 0.1 units
        // and 100 units away from the camera.

        const fieldOfView = 45 * Math.PI / 180;   // in radians
        const aspect = 1;
        const zNear = 0.5;
        const zFar = 20.0;
        const projectionMatrix = mat4.create();

        // note: glmatrix.js always has the first argument
        // as the destination to receive the result.
        mat4.perspective(projectionMatrix,
          fieldOfView,
          aspect,
          zNear,
          zFar);

        // Set the drawing position to the "identity" point, which is
        // the center of the scene.
        const modelViewMatrix = mat4.create();

        // Now move the drawing position a bit to where we want to
        // start drawing the square.

        mat4.translate(modelViewMatrix,     // destination matrix
          modelViewMatrix,     // matrix to translate
          [-0.0, 0.0, -2.40]);  // amount to translate
          
        const normalMatrix = mat4.create();
        mat4.invert(normalMatrix, modelViewMatrix);
        mat4.transpose(normalMatrix, normalMatrix);

        // Tell WebGL how to pull out the positions from the position
        // buffer into the vertexPosition attribute
        {
          const numComponents = 3;
          const type = gl.FLOAT;
          const normalize = false;
          const stride = 0;
          const offset = 0;
          gl.bindBuffer(gl.ARRAY_BUFFER, buffers.position);
          gl.vertexAttribPointer(
            programInfo.attribLocations.vertexPosition,
            numComponents,
            type,
            normalize,
            stride,
            offset);
          gl.enableVertexAttribArray(
            programInfo.attribLocations.vertexPosition);
        }

        // Tell WebGL how to pull out the texture coordinates from
        // the texture coordinate buffer into the textureCoord attribute.
        {
          const numComponents = 2;
          const type = gl.FLOAT;
          const normalize = false;
          const stride = 0;
          const offset = 0;
          gl.bindBuffer(gl.ARRAY_BUFFER, buffers.textureCoord);
          gl.vertexAttribPointer(
            programInfo.attribLocations.textureCoord,
            numComponents,
            type,
            normalize,
            stride,
            offset);
          gl.enableVertexAttribArray(
            programInfo.attribLocations.textureCoord);
        }

        // Tell WebGL how to pull out the normals from
        // the normal buffer into the vertexNormal attribute.
        {
          const numComponents = 3;
          const type = gl.FLOAT;
          const normalize = false;
          const stride = 0;
          const offset = 0;
          gl.bindBuffer(gl.ARRAY_BUFFER, buffers.normal);
          gl.vertexAttribPointer(
            programInfo.attribLocations.vertexNormal,
            numComponents,
            type,
            normalize,
            stride,
            offset);
          gl.enableVertexAttribArray(
            programInfo.attribLocations.vertexNormal);
        }

        // Tell WebGL which indices to use to index the vertices
        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffers.indices);

        // Tell WebGL to use our program when drawing
        gl.useProgram(programInfo.program);

        // Set the shader uniforms
        gl.uniformMatrix4fv(
          programInfo.uniformLocations.projectionMatrix,
          false,
          projectionMatrix);
        gl.uniformMatrix4fv(
          programInfo.uniformLocations.modelViewMatrix,
          false,
          modelViewMatrix);
        gl.uniformMatrix4fv(
          programInfo.uniformLocations.normalMatrix,
          false,
          normalMatrix);

        // Specify the texture to map onto the faces.

        // Tell WebGL we want to affect texture unit 0
        gl.activeTexture(gl.TEXTURE0);

        // Bind the texture to texture unit 0
        gl.bindTexture(gl.TEXTURE_2D, texture);

        // Tell the shader we bound the texture to texture unit 0
        gl.uniform1i(programInfo.uniformLocations.uSampler, 0);

        {
          const vertexCount = 6;
          const type = gl.UNSIGNED_SHORT;
          const offset = 0;
          gl.drawElements(gl.TRIANGLES, vertexCount, type, offset);
        }
      }

      // Initialize a shader program, so WebGL knows how to draw our data
      function initShaderProgram(gl, vsSource, fsSource) {
        const vertexShader = loadShader(gl, gl.VERTEX_SHADER, vsSource);
        const fragmentShader = loadShader(gl, gl.FRAGMENT_SHADER, fsSource);

        // Create the shader program
        const shaderProgram = gl.createProgram();
        gl.attachShader(shaderProgram, vertexShader);
        gl.attachShader(shaderProgram, fragmentShader);
        gl.linkProgram(shaderProgram);

        // If creating the shader program failed, alert
        if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
          alert('Unable to initialize the shader program: ' + gl.getProgramInfoLog(shaderProgram));
          return null;
        }

        return shaderProgram;
      }

      // creates a shader of the given type, uploads the source and
      // compiles it.
      function loadShader(gl, type, source) {
        const shader = gl.createShader(type);

        // Send the source to the shader object
        gl.shaderSource(shader, source);

        // Compile the shader program
        gl.compileShader(shader);

        // See if it compiled successfully
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
          alert('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
          gl.deleteShader(shader);
          return null;
        }

        return shader;
      }
    </script>
  </body>

</html>